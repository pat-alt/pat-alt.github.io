{
  "hash": "302c68e67258f8a66dace2d63006b2f0",
  "result": {
    "markdown": "---\ntitle: Prediction Intervals for any Regression Model\nsubtitle: Conformal Prediction in Julia --- Part 3\ndate: '2022-12-12'\ncategories:\n  - probabilistic programming\n  - uncertainty\n  - conformal prediction\n  - regression\n  - Julia\ndescription: 'This third post introduces conformal regression by going through a standard machine learning workflow using [`MLJ.jl`](https://alan-turing-institute.github.io/MLJ.jl/dev/) and [`ConformalPrediction.jl`](https://github.com/pat-alt/ConformalPrediction.jl).'\nimage: www/intro.gif\ndraft: false\n---\n\n\n\n<div class=\"intro-gif\">\n  <figure>\n    <img src=\"www/intro.gif\">\n    <figcaption>Conformal Prediction intervals for different<br>coverage rates. As coverage grows, so does<br>the width of the prediction interval.</figcaption>\n  </figure>\n</div>\n\nThis is the third (and for now final) part of a series of posts that introduce Conformal Prediction in Julia using [`ConformalPrediction.jl`](https://github.com/pat-alt/ConformalPrediction.jl). The first [post](../conformal-prediction/index.qmd) introduced Conformal Prediction for supervised classification tasks: we learned that conformal classifiers produce set-valued predictions that are guaranteed to include the true label of a new sample with a certain probability. In the second [post](../conformal-image-classifier/) we applied these ideas to a more hands-on example: we saw how easy it is to use [`ConformalPrediction.jl`](https://github.com/pat-alt/ConformalPrediction.jl) to conformalize a Deep Learning image classifier. \n\nIn this post, we will look at regression models instead, that is supervised learning tasks involving a continuous outcome variable. Regression tasks are as ubiquitous as classification tasks. For example, we might be interested in using a machine learning model to predict house prices or the inflation rate of the Euro or the parameter size of the next large language model. In fact, many readers may be more familiar with regression models than classification, in which case it may also be easier for you to understand Conformal Prediction (CP) in this context. \n\n## üìñ Background\n\nBefore we start, let's briefly recap what CP is all about. Don't worry, we're not about to deep-dive into methodology. But just to give you a high-level description upfront:\n\n> Conformal prediction (a.k.a. conformal inference) is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions.\n>\n> --- @angelopoulos2021gentle ([arXiv](https://arxiv.org/pdf/2107.07511.pdf))\n\nIntuitively, CP works under the premise of turning heuristic notions of uncertainty into rigorous uncertainty estimates through repeated sampling or the use of dedicated calibration data. \n\nIn what follows we will explore what CP can do by going through a standard machine learning workflow using [`MLJ.jl`](https://alan-turing-institute.github.io/MLJ.jl/dev/) and [`ConformalPrediction.jl`](https://github.com/pat-alt/ConformalPrediction.jl). There will be less focus on how exactly CP works, but references will point you to additional resources. \n\n:::{.callout-tip}\n## Interactive Version\n\nThis post is also available as a fully interactive [`Pluto.jl`](https://github.com/fonsp/Pluto.jl) üéà notebook hosted on [binder](https://mybinder.org/): [![Binder](https://mybinder.org/badge_logo.svg)](https://binder.plutojl.org/v0.19.12/open?url=https%253A%252F%252Fraw.githubusercontent.com%252Fpat-alt%252FConformalPrediction.jl%252Fmain%252Fdocs%252Fpluto%252Fintro.jl){target=\"_blank\"}\n\nIn my own experience, this may take some time to load, certainly long enough to get yourself a hot beverage ‚òï or first read on here. But I promise you that the wait is worth it!\n:::\n\n## üìà Data\n\nMost machine learning workflows start with data. For illustrative purposes we will work with synthetic data. The helper function below can be used to generate some regression data. \n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\nfunction get_data(;N=1000, xmax=3.0, noise=0.5, fun::Function=fun(X) = X * sin(X))\n    # Inputs:\n    d = Distributions.Uniform(-xmax, xmax)\n    X = rand(d, N)\n    X = MLJBase.table(reshape(X, :, 1))\n\n    # Outputs:\n    Œµ = randn(N) .* noise\n    y = @.(fun(X.x1)) + Œµ\n    y = vec(y)\n    return X, y\nend\n```\n:::\n\n\n@fig-data illustrates our observations (dots) along with the ground-truth mapping from inputs to outputs (line). We have defined that mapping $f: \\mathcal{X} \\mapsto \\mathcal{Y}$ as follows:\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nf(X) = X * cos(X)\n```\n:::\n\n\n::: {.cell execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=45}\n![Some synthetic regression data. Observations are shown as dots. The ground-truth mapping from inputs to outputs is shown as a dashed line.](index_files/figure-html/fig-data-output-1.svg){#fig-data}\n:::\n:::\n\n\n## üèãÔ∏è Model Training using [`MLJ`](https://alan-turing-institute.github.io/MLJ.jl/dev/)\n\n[`ConformalPrediction.jl`]((https://github.com/pat-alt/ConformalPrediction.jl)) is interfaced to [`MLJ.jl`](https://alan-turing-institute.github.io/MLJ.jl/dev/) [@blaom2020mlj]: a comprehensive Machine Learning Framework for Julia. `MLJ.jl` provides a large and growing suite of popular machine learning models that can be used for supervised and unsupervised tasks. Conformal Prediction is a model-agnostic approach to uncertainty quantification, so it can be applied to any common supervised machine learning model. \n\nThe interface to `MLJ.jl` therefore seems natural: any (supervised) `MLJ.jl` model can now be conformalized using `ConformalPrediction.jl`. By leveraging existing `MLJ.jl` functionality for common tasks like training, prediction and model evaluation, this package is light-weight and scalable. Now let's see how all of that works ...\n\nTo start with, let's split our data into a training and test set:\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\ntrain, test = partition(eachindex(y), 0.4, 0.4, shuffle=true)\n```\n:::\n\n\nNow let's define a model for our regression task:\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\nModel = @load KNNRegressor pkg = NearestNeighborModels\nmodel = Model()\n```\n:::\n\n\n:::{.callout-tip}\n## Have it your way!\n\nThink this dataset is too simple? Wondering why on earth I'm not using XGBoost for this task? In the interactive [version](https://binder.plutojl.org/v0.19.12/open?url=https%253A%252F%252Fraw.githubusercontent.com%252Fpat-alt%252FConformalPrediction.jl%252Fmain%252Fdocs%252Fpluto%252Fintro.jl){target=\"_blank\"} of this post you have full control over the data and the model. Try it out!\n:::\n\nUsing standard `MLJ.jl` workflows let us now first train the unconformalized model. We first wrap our model in data:\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\nmach_raw = machine(model, X, y)\n```\n:::\n\n\nThen we fit the machine to the training data:\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\nMLJBase.fit!(mach_raw, rows=train, verbosity=0)\n```\n:::\n\n\n@fig-point below shows the resulting point predictions for the test data set:\n\n::: {.cell execution_count=9}\n\n::: {.cell-output .cell-output-display execution_count=50}\n![Point predictions for our machine learning model.](index_files/figure-html/fig-point-output-1.svg){#fig-point}\n:::\n:::\n\n\nHow is our model doing? It's never quite right, of course, since predictions are estimates and therefore uncertain. Let's see how we can use Conformal Prediction to express that uncertainty.\n\n## üî• Conformalizing the Model\n\nWe can turn our `model` into a conformalized model in just one line of code:\n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\nconf_model = conformal_model(model)\n```\n:::\n\n\nBy default `conformal_model` creates an Inductive Conformal Regressor (more on this below) when called on a `<:Deterministic` model. This behaviour can be changed by using the optional `method` key argument.\n\nTo train our conformal model we can once again rely on standard `MLJ.jl` workflows. We first wrap our model in data:\n\n::: {.cell execution_count=11}\n``` {.julia .cell-code}\nmach = machine(conf_model, X, y)\n```\n:::\n\n\nThen we fit the machine to the data:\n\n::: {.cell execution_count=12}\n``` {.julia .cell-code}\nMLJBase.fit!(mach, rows=train, verbosity=0)\n```\n:::\n\n\nNow let us look at the predictions for our test data again. The chart below shows the results for our conformalized model. Predictions from conformal regressors are range-valued: for each new sample the model returns an interval $(y_{\\text{lb}},y_{\\text{ub}})\\in\\mathcal{Y}$ that covers the test sample with a user-specified probability $(1-\\alpha)$, where $\\alpha$ is the expected error rate. This is known as the **marginal coverage guarantee** and it is proven to hold under the assumption that training and test data are exchangeable. \n\n::: {.cell execution_count=13}\n\n::: {.cell-output .cell-output-display execution_count=54}\n![Prediction intervals for our conformalized machine learning model.](index_files/figure-html/fig-interval-output-1.svg){#fig-interval}\n:::\n:::\n\n\n\n\n\n\nIntuitively, a higher coverage rate leads to larger prediction intervals: since a larger interval covers a larger subspace of $\\mathcal{Y}$, it is more likely to cover the true value.\n\nI don't expect you to believe me that the marginal coverage property really holds. In fact, I couldn't believe it myself when I first learned about it. If you like mathematical proofs, you can find one in this [tutorial](https://arxiv.org/pdf/2107.07511.pdf), for example. If you like convincing yourself through empirical observations, read on below ...\n\n## üßê Evaluation\n\nTo verify the marginal coverage property empirically we can look at the empirical coverage rate of our conformal predictor (see Section 3 of the [tutorial](https://arxiv.org/pdf/2107.07511.pdf) for details). To this end our package provides a custom performance measure `emp_coverage` that is compatible with `MLJ.jl` model evaluation workflows. In particular, we will call `evaluate!` on our conformal model using `emp_coverage` as our performance metric. The resulting empirical coverage rate should then be close to the desired level of coverage.\n\n::: {.cell execution_count=16}\n``` {.julia .cell-code}\nmodel_evaluation =\n    evaluate!(_mach, operation=MLJBase.predict, measure=emp_coverage, verbosity=0)\nprintln(\"Empirical coverage: $(round(model_evaluation.measurement[1], digits=3))\")\nprintln(\"Coverage per fold: $(round.(model_evaluation.per_fold[1], digits=3))\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEmpirical coverage: 0.902\nCoverage per fold: [0.94, 0.904, 0.874, 0.874, 0.898, 0.922]\n```\n:::\n:::\n\n\n::: {.cell execution_count=17}\n\n::: {.cell-output .cell-output-display execution_count=58}\n> ‚úÖ ‚úÖ ‚úÖ  Great! We got an empirical coverage rate that is slightly higher than desired üòÅ ... but why isn't it exactly the same?\n\n\nIn most cases it will be slightly higher than desired, since $(1-\\alpha)$ is a lower bound. But note that it can also be slightly lower than desired. That is because the coverage property is \"marginal\" in the sense that the probability is averaged over the randomness in the data. For most purposes a large enough calibration set size ($n>1000$) mitigates that randomness enough. Depending on your choices above, the calibration set may be quite small (set to 500), which can lead to **coverage slack** (see Section 3 in the [tutorial](https://arxiv.org/pdf/2107.07511.pdf)).\n\n:::\n:::\n\n\n### *So what's happening under the hood?*\n\t\t\nInductive Conformal Prediction (also referred to as Split Conformal Prediction) broadly speaking works as follows:\n\n1. Partition the training into a proper training set and a separate calibration set\n2. Train the machine learning model on the proper training set.\n3. Using some heuristic notion of uncertainty (e.g., absolute error in the regression case), compute nonconformity scores using the calibration data and the fitted model.\n4. For the given coverage ratio compute the corresponding quantile of the empirical distribution of nonconformity scores.\n5. For the given quantile and test sample $X_{\\text{test}}$, form the corresponding conformal prediction set like so: $C(X_{\\text{test}})=\\{y:s(X_{\\text{test}},y) \\le \\hat{q}\\}$\n\n## üîÉ Recap\n\nThis has been a super quick tour of [`ConformalPrediction.jl`](https://github.com/pat-alt/ConformalPrediction.jl). We have seen how the package naturally integrates with [`MLJ.jl`](https://alan-turing-institute.github.io/MLJ.jl/dev/), allowing users to generate rigorous predictive uncertainty estimates for any supervised machine learning model. \n\n### *Are we done?*\n\nQuite cool, right? Using a single API call we are able to generate rigorous prediction intervals for all kinds of different regression models. Have we just solved predictive uncertainty quantification once and for all? Do we even need to bother with anything else? Conformal Prediction is a very useful tool, but like so many other things, it is not the final answer to all our problems. In fact, let's see if we can take CP to its limits.\n\nThe helper function to generate data from above takes an optional argument `xmax`. By increasing that value, we effectively expand the domain of our input. Let's do that and see how our conformal model does on this new out-of-domain data.\n\n::: {.cell execution_count=18}\n\n::: {.cell-output .cell-output-display execution_count=59}\n![Prediction intervals for our conformalized machine learning model applied to out-of-domain data.](index_files/figure-html/fig-ood-output-1.svg){#fig-ood}\n:::\n:::\n\n\n> Whooooops ü§ï ... looks like we're in trouble: in @fig-ood the prediction intervals do not cover out-of-domain test samples well. What happened here?\n\t\nBy expanding the domain of out inputs, we have violated the exchangeability assumption. When that assumption is violated, the marginal coverage property does not hold. But do not despair! There are ways to deal with this.\n\n## üìö Read on\n\nIf you are curious to find out more, be sure to read on in the [docs](https://www.paltmeyer.com/ConformalPrediction.jl/stable/). There are also a number of useful resources to learn more about Conformal Prediction, a few of which I have listed below:\n\n- *A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification* by Angelopoulos and Bates ([2022](https://arxiv.org/pdf/2107.07511.pdf)).\n- *Awesome Conformal Prediction* repository by Manokhin ([2022](https://github.com/valeman/awesome-conformal-prediction))\n- **MAPIE**: a comprehensive Python [library](https://mapie.readthedocs.io/en/latest/index.html) for conformal prediction.\n- My previous two blog posts.\n\nEnjoy!\n\n## References\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}