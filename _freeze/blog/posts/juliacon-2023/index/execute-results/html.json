{
  "hash": "ca231784a004dd5c714c0e8f46b55501",
  "result": {
    "markdown": "---\ntitle: JuliaCon 2023\nsubtitle: Notes\ndate: today\ncategories:\n  - JuliaCon\n  - Julia\ndescription: Notes taken during JuliaCon 2023.\nimage: www/intro.gif\ndraft: true\n---\n\n## [Keynote: Tim Davis](https://pretalx.com/juliacon2023/talk/U9ABUR/)\n\n- GraphBLAS: graph algorithms in the language of linear algebra. \n- Semiring: way of redefining matrix multiplication\n  - conventionally (PLUS, TIMES), sparse case same thing but across intersection of non-zero elements\n- (MIN, PLUS) semiring: minimum of sum across intersection on non-zero elements\n- LAGraph: experimental support for DNN inference\n- 20 times faster than scipy, 20.000 times faster than NetworkX\n- Permion.ai: neurosymbolic AI (trustworthy AI)\n\n## [Keynote: Chris Rackauskas](https://pretalx.com/juliacon2023/talk/YKK7AD/)\n\n- SciML through Symbolic Numerics\n- complex interactions with symbolics and compilers\n- SciML: model-based data-efficient ML -> combining models and data\n- Unversal (Approximator) Differential Equations\n\n## [`Sole.jl`](https://pretalx.com/juliacon2023/talk/LYSQWS/)\n\n- Symbolic learning: inherently interpretable models\n- Example: Decision Tree -> can extract rules from estimated model\n- Today these models find most use in the context of tabular data\n\n### A better idea\n\n- `SoleLogics.jl`: logical formulas\n- `SoleData.jl`: non-tabular datasets\n- `SoleModels.jl`: symbolic models\n\n### Modelling non-tabular data\n\n- *Modal Logic*: strikes the right balance between complexity and interpretability\n\n## [`Progradio.jl`](https://pretalx.com/juliacon2023/talk/QZ3PSY/)\n\n- Projected Gradient Descent is used a lot in Dynamic Optimization (objective over time): `JuDO.jl`\n\n## [`SymbolicRegression.jl`](https://pretalx.com/juliacon2023/talk/FGZBBB/)\n\n### Motivation\n\n- Machine Learning should yield a model that we can understand\n- Science already has a modelling language: mathematical equations\n- Using mathematical expressions as priors for ML models\n\n### Method Sketch\n\n- Represent expressions as trees where edges are binary operators and nodes are variables or constants\n- Optimisation boils down to finding the best mutation of the tree using genetic algorithms\n- Can be parallelised easily: every population of trees can independently evolve in a separate thread\n\n### Library\n\n- `SymbolicRegression.jl` is the core library\n- As high-performance as possible. As configurable as possible. As easy-to-use as possible.\n\n## [`PackageExtensions.jl`](https://pretalx.com/juliacon2023/talk/YQQ9ZV/)\n\n- Balancing the trade-off between usefulness and cost of adding dependencies\n  \nWhy depend on a package?\n\n1. Strong dependency: direct use of functionality\n2. Weak dependency: Extend methods to dependency types\n\n## [Tabular Data Symposium](https://pretalx.com/juliacon2023/talk/HLYTJZ/)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}