{
  "hash": "c00cf6bb4da0d550cfd5e6466e7dcf4e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: ðŸ’° Trillion Dollar Words in Julia\nsubtitle: JuliaCon 2024\nauthor: Patrick Altmeyer\nformat:\n  julia-revealjs: \n    scrollable: true\ndate: last-modified\nbibliography: biblio.bib\nexecute:\n  freeze: auto\n  eval: true\n  echo: true\n  output: false\n---\n\n\n\n## [TrillionDollarWords.jl](https://github.com/pat-alt/TrillionDollarWords.jl)\n\n[![Stable](https://img.shields.io/badge/docs-stable-blue.svg)](https://pat-alt.github.io/TrillionDollarWords.jl/stable/)\n[![Dev](https://img.shields.io/badge/docs-dev-blue.svg)](https://pat-alt.github.io/TrillionDollarWords.jl/dev/)\n[![Build Status](https://github.com/pat-alt/TrillionDollarWords.jl/actions/workflows/CI.yml/badge.svg?branch=main)](https://github.com/pat-alt/TrillionDollarWords.jl/actions/workflows/CI.yml?query=branch%3Amain)\n[![Coverage](https://codecov.io/gh/pat-alt/TrillionDollarWords.jl/branch/main/graph/badge.svg)](https://codecov.io/gh/pat-alt/TrillionDollarWords.jl)\n[![Code Style: Blue](https://img.shields.io/badge/code%20style-blue-4495d1.svg)](https://github.com/invenia/BlueStyle)\n\nA light-weight package providing Julia users easy access to the Trillion Dollar Words dataset and model [@shah2023trillion].\n\n::: {.callout-note}\n\n## Disclaimer  \n\nPlease note that I am not the author of the Trillion Dollar Words paper nor am I affiliated with the authors. The package was developed as a by-product of our research and is not officially endorsed by the authors of the paper. \n\n:::\n\n## Context {.smaller}\n\nDeveloped in the context of our position paper on LLM interpretability presented at [ECONDAT 2024](https://www.kcl.ac.uk/events/econdat-conference-2024) and [ICML 2024](https://icml.cc/Conferences/2024) ([preprint](https://arxiv.org/abs/2402.03962), [blog post](https://www.patalt.org/blog/posts/eccco/), [code](https://github.com/pat-alt/spurious_sentience)):\n\n> *Stop Making Unscientific AGI Performance Claims* [@altmeyer2024position]\n\n:::{.incremental}\n\n- **Experiments**: We probe models of varying complexity including random projections, matrix decompositions, deep autoencoders and transformers.\n  - All of them successfully distill knowledge and yet none of them develop true understanding.\n- **Social sciences review**: Humans are prone to seek patterns and anthropomorphize.\n- **Conclusion and outlook**: More caution at the individual level, and different incentives at the institutional level.\n\n:::\n\n## Basic Functionality\n\nThe package provides the following functionality:\n\n- Load pre-processed data.\n- Load the model proposed in the paper. \n- Basic model inference: compute forward passes and layer-wise activations.\n- Download pre-computed activations for probing the model.\n\n## Loading the Data {.smaller}\n\n::::{.columns}::::\n:::{.column width='50%'}\n\n#### Sentences\n\n40,000 time-stamped sentences from \n\n- meeting minutes\n- press conferences\n- speeches \n\nby members of the Federal Open Market Committee (FOMC):\n\n::: {#c529813e .cell execution_count=2}\n``` {.julia .cell-code}\nusing TrillionDollarWords\nload_all_sentences() |>\n  x -> names(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n8-element Vector{String}:\n \"sentence_id\"\n \"doc_id\"\n \"date\"\n \"event_type\"\n \"label\"\n \"sentence\"\n \"score\"\n \"speaker\"\n```\n:::\n:::\n\n\n:::\n:::{.column width='50%'}\n\n#### All Data\n\nMerged data includes economic indicators\n\n- Consumer Price Index (CPI)\n- Producer Price Index (PPI)\n- US Treasury (UST) yields\n\n::: {#77f7b566 .cell execution_count=3}\n``` {.julia .cell-code}\nload_all_data() |>\n  x -> names(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n11-element Vector{String}:\n \"sentence_id\"\n \"doc_id\"\n \"date\"\n \"event_type\"\n \"label\"\n \"sentence\"\n \"score\"\n \"speaker\"\n \"value\"\n \"indicator\"\n \"maturity\"\n```\n:::\n:::\n\n\n:::\n::::\n\n## Loading the Model\n\n- Can be loaded with or without the classifier head.\n- Uses [Transformers.jl](https://github.com/chengchingwen/Transformers.jl) to retrieve the model from [HuggingFace](https://huggingface.co/gtfintechlab/FOMC-RoBERTa?text=A+very+hawkish+stance+excerted+by+the+doves).\n-  Any keyword arguments accepted by `Transformers.HuggingFace.HGFConfig` can also be passed.\n\n::: {#ba24f7d1 .cell execution_count=4}\n``` {.julia .cell-code}\nload_model(; load_head=false, output_hidden_states=true)\n```\n:::\n\n\n## Basic Model Inference\n\n::::{.columns}::::\n:::{.column width='50%'}\n\n#### From Scratch\n\nLayer-wise activations can be computed as follows:\n\n::: {#31761ebb .cell execution_count=5}\n``` {.julia .cell-code}\ndf = load_all_sentences()\nmod = load_model(\n  load_head=false, \n  output_hidden_states=true\n)\nn = 5\nqueries = df[1:n, :]\nlayerwise_activations(\n  mod, queries\n) \n```\n:::\n\n\n:::\n\n:::{.column width='50%'}\n\n#### From Artifacts\n\nWe have archived activations for each layer and sentence as [artifacts](https://github.com/pat-alt/TrillionDollarWords.jl/releases/tag/activations_2024-01-17):\n\n``` julia\nusing LazyArtifacts\n\nartifact\"activations_layer_24\"\n```\n\n> OK, but why would I need all this? ðŸ¤”\n\n:::\n::::\n\n\n# \"There! It's sentient!\" {.nostretch} \n\n![](www/leo.png){fig-align=\"center\"}\n\n\n\n## Motivation {auto-animate=true}\n\n- $A_1$: $enc($â€žIt is essential to bring inflation back to target to avoid drifting into deflation territory.â€œ$)$\n- $A_2$: $enc($â€žIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.â€œ$)$\n\n## Motivation {auto-animate=true .smaller}\n\n::::{.columns}::::\n:::{.column width='50%'}\n- $A_1$: $enc($â€žIt is essential to bring inflation back to target to avoid drifting into deflation territory.â€œ$)$\n- $A_2$: $enc($â€žIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.â€œ$)$\n\n> \"They're exactly the same.\"\n> \n> --- Linear probe $\\widehat{cpi}=f(A)$\n:::\n:::{.column width='50%'}\n![](www/spider.jpeg)\n:::\n::::\n\n## Embedding FOMC comms {.nostretch}\n\n- We linearly probe all layers to predict unseen economic indicators (CPI, PPI, UST yields).\n- Predictive power increases with layer depth and probes outperform simple AR($p$) models.\n\n![Out-of-sample root mean squared error (RMSE) for the linear probe plotted against FOMC-RoBERTaâ€™s n-th\nlayer for different indicators. ](www/mse_pca_128.png){#fig-mse width=\"80%\"}  \n\n## Sparks of Economic Understanding? {.smaller .nostretch}\n\nIf probe results were indicative of some intrinsic â€˜understandingâ€™ of the economy, then the probe should not be sensitive to random sentences unrelated to economics. \n\n![Probe predictions for sentences about inflation of prices (IP), deflation of prices (DP), inflation of birds (IB)\nand deflation of birds (DB). The vertical axis shows predicted inflation levels subtracted by the average predicted value\nof the probe for random noise.](www/attack_all_measures.png){#fig-attack width=\"80%\"}\n\n## Intended Purpose and Goals\n\nGood starting point for the following ideas:\n\n- Fine-tune additional models on the classification task or other tasks of interest.\n- Further model probing, e.g. using other market indicators not discussed in the original paper.\n- Improve and extend the label annotations. \n\nAny contributions are very much welcome.\n\n# Questions? {.nostretch} \n\nWith thanks to my co-authors Andrew M. Demetriou, Antony Bartlett, and Cynthia C. S. Liem and to the audience for their attention.\n\n![](/www/images/qr.png){width=\"25%\" fig-align=\"center\"}\n\n## References {.scrollable .smaller}\n\n::: {#refs}\n:::\n\n## Image sources\n\n- Leonardo DiCaprio: Meme template by user on <a href=\"https://www.reddit.com/r/MemeTemplatesOfficial/comments/g46e21/i_made_a_png_version_of_leonardo_dicaprio/#lightbox\">Reddit</a>\n\n## Quote sources\n\n- \"There! It's sentient\"---that engineer at Google (probably!)\n\n",
    "supporting": [
      "presentation_files"
    ],
    "filters": [],
    "includes": {}
  }
}