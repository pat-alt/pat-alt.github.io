---
title: Diverse Explanations for Black-Box Models
subtitle: Counterfactual Explanations in Julia --- Part II
date: '2022-12-29'
categories:
  - explainable ai
  - machine learning
  - counterfactual explanations
  - Julia
description: >-
  This second post on Counterfactual Explanations in Julia explores the concept of diverse explanations introduced by @mothilal2020explaining.
image: www/intro.gif
jupyter: julia-1.8
draft: true
---

```{julia}
#| echo: false

using Pkg; Pkg.activate("blog/posts/diverse-explanations")
www_path = "blog/posts/diverse-explanations/www"
```

<!-- <div class="intro-gif">
  <figure>
    <img src="www/intro.gif">
    <figcaption>Conformal Prediction intervals for different<br>coverage rates. As coverage grows, so does<br>the width of the prediction interval.</figcaption>
  </figure>
</div>

This is the third (and for now final) part of a series of posts that introduce Conformal Prediction in Julia using [`ConformalPrediction.jl`](https://github.com/pat-alt/ConformalPrediction.jl). The first [post](../conformal-prediction/index.qmd) introduced Conformal Prediction for supervised classification tasks: we learned that conformal classifiers produce set-valued predictions that are guaranteed to include the true label of a new sample with a certain probability. In the second [post](../conformal-image-classifier/) we applied these ideas to a more hands-on example: we saw how easy it is to use [`ConformalPrediction.jl`](https://github.com/pat-alt/ConformalPrediction.jl) to conformalize a Deep Learning image classifier. 

In this post, we will look at regression models instead, that is supervised learning tasks involving a continuous outcome variable. Regression tasks are as ubiquitous as classification tasks. For example, we might be interested in using a machine learning model to predict house prices or the inflation rate of the Euro or the parameter size of the next large language model. In fact, many readers may be more familiar with regression models than classification, in which case it may also be easier for you to understand Conformal Prediction (CP) in this context.  -->

:::{.callout-tip}

## ğŸƒâ€â™€ï¸ TL;DR

1. Conformal Prediction is an interesting frequentist approach to uncertainty quantification that can even be combined with Bayes (@sec-background).
2. It is scalable and model-agnostic and therefore well applicable to machine learning (@sec-background).
3. [`ConformalPrediction.jl`](https://github.com/pat-alt/ConformalPrediction.jl) implements CP in pure Julia and can be used with any supervised model available from [`MLJ.jl`](https://alan-turing-institute.github.io/MLJ.jl/v0.18/) (@sec-julia).
4. Implementing CP directly on top of an existing, powerful machine learning toolkit demonstrates the potential usefulness of this framework to the ML community (@sec-julia). 
5. Standard conformal classifiers produce set-valued predictions: for ambiguous samples these sets are typically large (for high coverage) or empty (for low coverage) (@sec-scp).
:::

## ğŸ“– Background {#sec-background}

## ğŸ“¦ Conformal Prediction in Julia {#sec-julia}

## ğŸ Conclusion

## ğŸ“š Further Resources
