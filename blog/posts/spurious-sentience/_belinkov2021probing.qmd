- "and the correlational nature of the methodology"

Basic idea:

> "On the surface, the probing classifiers idea seems straightforward. We take a model that was trained on some task, such as a language model. We generate representations using the model, and train another classifier that takes the representations and predicts some property. If the classifier performs well, we say that the model has learned information relevant for the property."

- "A main motivation in this body of work is the opacity of the representations.4 Compared to performance on downstream tasks, probing classifiers aim to provide more nuanced evaluations w.r.t simple properties"
- "Does model f use the information discovered by probe g? In other words, the probing framework may indicate correlations between representations fl(x) and linguistic property z, but it does not tell us whether this property is involved in predictions of f"
- "Giulianelli et al. (2018) use gradients from g to modify the representations in f and evaluate how this change affects both the probing performance and the original model performance. In their case, f is a language model and g predicts subjectâ€“verbnumber agreement. T"