---
title: Spurious Sentience
subtitle: Overblowing Associational Relationships in Latent Spaces
date: '2023-10-06'
categories:
  - spurious sentience
  - artificial intelligence
  - llm
description: >-
  This is an opinionated post that questions the idea that structure in latent embeddings of artificial neural networks is even remotely surprising. 
image: www/intro.gif
jupyter: julia-1.9
draft: false
---

```{julia}
#| echo: false

BLOG_DIR = "blog/posts/spurious-sentience"
using Pkg; Pkg.activate(BLOG_DIR)

using CSV
using DataFrames
using Dates
using Plots
using TidierData
```

We humans are prone to seek patterns everywhere. Meaningful patterns have often proven to help us make sense of our past, navigate our presence and predict the future. Our society is so invested in finding patterns that today it seems we are more willing than ever to outsource this task to an Artificial Intelligence (AI): an omniscient oracle that leads us down the right path. Unfortunately, history has shown time and again that patterns are double-edged swords: if we attribute the wrong meaning to them, they may lead us nowhere at all, or worse, they may lead us down the dark roads. 

In statistics, misleading patterns are referred to as **spurious relationships**: purely associational relationships between two or more variables that are not causally related to each other at all. The world is full of these and as good as we as species may be at recognizing patterns, we typically have a much harder time discerning spurious relationships from causal ones. Despite new and increased momentum in scientific fields concerned with causal inference and discovery, I am also willing to go out on a limb and claim that we are not about to finally reach the top of Judea Pearl's Causal Ladder through the means of Causal AI.

I agree with the premise that in a world full of spurious relationships, causal reasoning is our only remedy. But I am very sceptical of claims that AI will magically provide that remedy. This leads me to the title and topic of this post: **spurious sentience** - patterns exhibited by artificial intelligence that may hint at sentience but are really just reflections of the data used to train them. The article is written in response to a recent paper and claims by one of the authors, Max Tegmark, that revealed structure in the latent embeddings of Llama 2 should finally have us believe that LLMs are more than just parrots. Since this is an opinionated post, I feel that I should start with a few disclaimers:

1. I take no issue with the methodological ideas that form the foundation of the article in question: on the contrary, I think that mechanistic interpretability is an interesting and important toolkit that can help us better understand the intrinsics and behaviour of opaque artificial intelligences.
2. The visualizations are intriguing, the code is open-sourced and the findings are interesting. 
3. I am surprised that people are surprised by the findings: if we agree that LLMs exhibit strong capabilities that can only be connected to the patterns observed in the data they were trained with, then where exactly do you expect this information to be stored if not in the parameters of the model?^[I would be very surprised---concerned even---if our search for patterns in latent spaces of capable LLMs revealed nothing at all.]
4. I therefore do take issue with the way that these findings are being overblown by people with clout. Perhaps the parrot metaphor should not be taken too literally either, but if anything the paper's findings seem to support the notion that LLMs are remarkably capable of memorizing explicit and implicit knowledge contained in text. 

## Patterns in Latent Spaces and How to Find Them

To demonstrate the claim that observing patterns in latent spaces should not generally surprise us, we will now go through a couple of simple examples. 

### Yield Curves and Principal Component Analysis

In response to the claims made by Tegmark, numerous commentators on social media have pointed out that even the simplest of models can exhibit structure in their latent spaces. One of the most popular and illustrative examples I remember from my time at the Bank of England is yield curve decomposition through PCA. The yield curve is a popular tool for investors and economists to gauge the health of the economy. It plots the yields of bonds against their maturities. The slope of the yield curve is often used as a predictor of future economic activity: a steep yield curve is associated with a growing economy, while a flat or inverted yield curve is associated with a contracting economy. To deal with the curse of high dimensionality it can be useful to decompose the yield curve into a set of principal components. 

```{julia}
function to_year(str::String)
    Î· = contains(str, "MO") ? 1/12 : 1
    val = parse(Float64, replace(str, " MO" => "", " YR" => "")) 
    return val * Î·
end
```

```{julia}
df = CSV.read(joinpath(BLOG_DIR, "data/ust_yields.csv"), DataFrame) |>
    x -> @pivot_longer(x, -Date) |>
    x -> @mutate(x, variable=to_year(variable)) |>
    x -> @mutate(x, year=Dates.year(Date)) |>
    x -> @mutate(x, quarter=Dates.quarter(Date)) |>
    x -> @mutate(x, Date=Dates.format(Date, "yyyy-mm-dd")) |>
    x -> @arrange(x, Date) |>
    x -> @fill_missing(x, "down")
ylims = extrema(skipmissing(df.value))
anim = @animate for grouped_df in zip(@group_by(df, year, quarter))
    grouped_df = grouped_df[1]
    plt = plot()
    for plt_df in zip(@group_by(grouped_df, Date))
        plt_df = plt_df[1]
        plot!(
            plt, plt_df.variable, plt_df.value;
            label="", color=:blue, alpha=0.1,
            xlabel="Maturity (years)", ylabel="Yield (%)",
            title="$(plt_df.year[1]) Q$(plt_df.quarter[1])",
            ylims=ylims
        )
    end
end
gif(anim, joinpath(BLOG_DIR, "www/ust_yields.gif"), fps=2)
```

## ðŸŽ“ References