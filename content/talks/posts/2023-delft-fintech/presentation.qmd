---
title: Echos from the Black Box
subtitle: Counterfactual Explanations and Predictive Uncertainty for Trustworthy Machine Learning
author: 
  - name: "**Patrick Altmeyer**"
    url: https://www.paltmeyer.com/
  - name: Arie van Deursen
  - name: Cynthia C. S. Liem
institute: Delft University of Technology
date: today
format: 
  tudelft-revealjs:
    theme: custom.scss
    self-contained: true
    smaller: false
    scrollable: true
    preview-links: auto
    slide-number: true
    transition: slide
    background-transition: fade
    fig-align: center
    html-math-method: mathjax
    include-in-header:
      - text: |
          <script>
          MathJax = {
            options: {
              menuOptions: {
                settings: {
                  assistiveMml: false
                }
              }
            }
          };
          </script>
revealjs-plugins:
  - pointer
crossref: 
  prp-title: RQ
  prp-prefix: RQ
---

## Quick Introduction {.smaller}

::::{.columns}

:::{.column width="60%"}

- Currently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.
- Previously, educational background in Economics and Finance and two years in Monetary Policy at the Bank of England.
- Interested in applying Trustworthy AI to real-world problems, particularly in the financial sector.

:::

:::{.column width="40%"}

<img src="/www/images/qr.png" height="auto" width="250" style="display: block; margin-left: auto; margin-right: auto;">

<div style="text-align: center;">
  <p style="display: inline; vertical-align: middle"> 
    <a href="https://www.linkedin.com/in/patrick-altmeyer-a2a25494/" style="display: inline-block; color: rgb(207, 142, 255) !important;">
      <font style="">
        <img width="60" height="60" src="https://s1g.s3.amazonaws.com/d0fc399dee4218d1e0e0399b8947acab.png" alt="LinkedIn (Personal)" style="border: none; max-width: 100%; height: 60px !important;">
      </font>
    </a>
    <a href="https://twitter.com/paltmey" style="display: inline-block; color: rgb(207, 142, 255) !important;">
      <font style="">
        <img width="60" height="60" src="https://s1g.s3.amazonaws.com/3949237f892004c237021ac9e3182b1d.png" alt="Twitter" style="border: none; max-width: 100%; height: 60px !important;">
      </font>
    </a>
    <a href="https://github.com/pat-alt" style="display: inline-block; color: rgb(207, 142, 255) !important;">
      <font style="">
        <img width="60" height="60" src="https://s1g.s3.amazonaws.com/47f4eb2d0082a8a3611d614b75a09db8.png" alt="Github" style="border: none; max-width: 100%; height: 60px !important;">
      </font>
    </a>
    <a href="https://medium.com/@patrick.altmeyer" style="display: inline-block; color: rgb(207, 142, 255) !important;">
      <font style="">
        <img width="60" height="60" src="https://s1g.s3.amazonaws.com/175f49662614345cb7dbb95fce3f88af.png" alt="Medium" style="border: none; max-width: 100%; height: 60px !important;">
      </font>
    </a>
  </p>
</div>
:::

::::

# Background

## Counterfactual Explanations

**Counterfactual Explanation** (CE) explain how inputs into a model need to change for it to produce different outputs.

. . .

Provided the changes are realistic and actionable, they can be used for **Algorithmic Recourse** (AR) to help individuals who face adverse outcomes.

## Example: Consumer Credit

In @fig-credit, arrows indicate changes from factuals (loan denied) to counterfactuals (loan supplied). 

![Counterfactuals for Give Me Some Credit dataset [@kaggle2011give].](www/gmsc.svg){#fig-credit}

## Predictive Uncertainty

**Predictive Uncertainty** (PU) is a measure of how uncertain a model is about its predictions.

. . .

We have been exploring both Bayesian (**Laplace Redux**) and Frequentist approaches (**Conformal Prediction**) in our work.

## Example: Laplace Redux

::::{.columns}::::
:::{.column width='60%'}
[`LaplaceRedux.jl`](https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl) is our Julia package for Bayesian Neural Networks (BNNs) with Laplace Approximation.
:::
:::{.column width='40%'}
[![](www/laplace_logo.png)](https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl)
:::
::::

![Laplace Redux for a simple Multi-Layer Perceptron.](www/laplace_example.svg){#fig-laplace-example}

## Example: Conformal Prediction

::::{.columns}::::
:::{.column width='60%'}
[`ConformalPrediction.jl`](https://github.com/JuliaTrustworthyAI/ConformalPrediction.jl) is our Julia package for Conformal Prediction.
:::
:::{.column width='40%'}
[![](www/cp_logo.png)](https://github.com/JuliaTrustworthyAI/ConformalPrediction.jl)
:::
::::

![Conformal Prediction sets for an Image Classifier.](www/cp_example.svg){#fig-cp-example width="80%"}

# Research Questions

## Recourse Dynamics {.smaller}

We present evidence suggesting that state-of-the-art applications of Algorithmic Recourse to groups of individuals induce large domain and model shifts and propose ways to mitigate this (IEEE SaTML [paper](https://openreview.net/forum?id=-LFT2YicI9v)).

Joint work with Giovan Angela, Karol Dobiczek, Aleksander Buszydlik, Arie van Deursen and Cynthia C. S. Liem (all TU Delft).

![](www/dynamics_poc.png){align="center" width="100%"}

## A Balancing Act

:::{.incremental}
- Minimizing **private** costs generates **external** costs for other stakeholders.
- To avoid this, counterfactuals need to be **plausible**, i.e. comply with the data-generating process.
- In practice, costs to various stakeholders need to be carefully **balanced**.
:::

. . . 

> Is plausibility really all we need?

## Pick your Poison?

All of these counterfactuals are valid explanations for the model's prediction. Which one would you pick?

![Turning a 9 into a 7: Counterfactual Examplanations for an Image Classifier.](www/poison.png){#fig-cf-example}

## What do Models Learn?

These images are sampled from the posterior distribution learned by the model. Looks different, no?

![Conditional Generated Images from the Image Classifier](www/learn.png){#fig-learn}

## ECCCos from the Black Box {.smaller}

::::{.columns}::::
:::{.column width='60%'}
We propose a framework for generating **E**nergy-**C**onstrained **C**onformal **Co**unterfactuals (*ECCCos*) which explain black-box models *faithfully*.

Joint work with Mojtaba Framanbar (ING), Arie van Deursen (TU Delft) and Cynthia C. S. Liem (TU Delft).
:::
:::{.column width='40%'}
![](www/mnist_eccco.png)
:::
::::

![Gradient fields and counterfactual paths for different generators.](www/poc_gradient_fields.png){#fig-poc-gradient-fields}

# Trustworthy AI in Julia

## ðŸ¶ Taija {.smaller}

> Research informs development, development informs research. 

[![Trustworthy Artificial Intelligence in Julia.](www/logo.png)](https://github.com/JuliaTrustworthyAI)

[Taija](https://github.com/JuliaTrustworthyAI) is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.

Our work has been presented at JuliaCon 2022 and will be presented again at JuliaCon 2023 and hopefully beyond. 

## References


