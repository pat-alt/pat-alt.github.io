---
title: Echos from the Black Box
subtitle: Counterfactual Explanations and Predictive Uncertainty for Trustworthy Machine Learning
author: 
  - name: "**Patrick Altmeyer**"
    url: https://www.paltmeyer.com/
  - name: Arie van Deursen
  - name: Cynthia C. S. Liem
institute: Delft University of Technology
date: today
format: 
  tudelft-revealjs:
    theme: custom.scss
    self-contained: true
    smaller: false
    scrollable: true
    preview-links: auto
    slide-number: true
    transition: slide
    background-transition: fade
    fig-align: center
    html-math-method: mathjax
    include-in-header:
      - text: |
          <script>
          MathJax = {
            options: {
              menuOptions: {
                settings: {
                  assistiveMml: false
                }
              }
            }
          };
          </script>
revealjs-plugins:
  - pointer
crossref: 
  prp-title: RQ
  prp-prefix: RQ
---

## Quick Introduction {.smaller}

::::{.columns}

:::{.column width="60%"}

- Currently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.
- Working on Counterfactual Explanations and Probabilistic Machine Learning with applications in Finance.
- Previously, educational background in Economics and Finance and two years at the Bank of England.
- Enthusiastic about free open-source software, in particular Julia and Quarto. 

:::

:::{.column width="40%"}

<img src="/www/images/qr.png" height="auto" width="250" style="display: block; margin-left: auto; margin-right: auto;">

<div style="text-align: center;">
  <p style="display: inline; vertical-align: middle"> 
    <a href="https://www.linkedin.com/in/patrick-altmeyer-a2a25494/" style="display: inline-block; color: rgb(207, 142, 255) !important;">
      <font style="">
        <img width="60" height="60" src="https://s1g.s3.amazonaws.com/d0fc399dee4218d1e0e0399b8947acab.png" alt="LinkedIn (Personal)" style="border: none; max-width: 100%; height: 60px !important;">
      </font>
    </a>
    <a href="https://twitter.com/paltmey" style="display: inline-block; color: rgb(207, 142, 255) !important;">
      <font style="">
        <img width="60" height="60" src="https://s1g.s3.amazonaws.com/3949237f892004c237021ac9e3182b1d.png" alt="Twitter" style="border: none; max-width: 100%; height: 60px !important;">
      </font>
    </a>
    <a href="https://github.com/pat-alt" style="display: inline-block; color: rgb(207, 142, 255) !important;">
      <font style="">
        <img width="60" height="60" src="https://s1g.s3.amazonaws.com/47f4eb2d0082a8a3611d614b75a09db8.png" alt="Github" style="border: none; max-width: 100%; height: 60px !important;">
      </font>
    </a>
    <a href="https://medium.com/@patrick.altmeyer" style="display: inline-block; color: rgb(207, 142, 255) !important;">
      <font style="">
        <img width="60" height="60" src="https://s1g.s3.amazonaws.com/175f49662614345cb7dbb95fce3f88af.png" alt="Medium" style="border: none; max-width: 100%; height: 60px !important;">
      </font>
    </a>
  </p>
</div>
:::

::::

# Background

## Counterfactual Explanations

**Counterfactual Explanation** (CE) explain how inputs into a model need to change for it to produce different outputs.

. . .

Provided the changes are realistic and actionable, they can be used for **Algorithmic Recourse** (AR) to help individuals who face adverse outcomes.

## Example: Consumer Credit

In @fig-credit, arrows indicate changes from factuals (loan denied) to counterfactuals (loan supplied). 

![Counterfactuals for Give Me Some Credit dataset [@kaggle2011give].](www/gmsc.svg){#fig-credit}

## Predictive Uncertainty

**Predictive Uncertainty** (PU) is a measure of how uncertain a model is about its predictions.

. . .

We have been exploring both Bayesian (**Laplace Redux**) and Frequentist approaches (**Conformal Prediction**) in our work.

## Example: Laplace Redux

::::{.columns}::::
:::{.column width='60%'}
[`LaplaceRedux.jl`](https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl) is our Julia package for Bayesian Neural Networks (BNNs) with Laplace Approximation.
:::
:::{.column width='40%'}
[![](www/laplace_logo.png)](https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl)
:::
::::

![Laplace Redux for a simple Multi-Layer Perceptron.](www/laplace_example.svg){#fig-laplace-example}

## Example: Conformal Prediction

::::{.columns}::::
:::{.column width='60%'}
[`ConformalPrediction.jl`](https://github.com/JuliaTrustworthyAI/ConformalPrediction.jl) is our Julia package for Conformal Prediction.
:::
:::{.column width='40%'}
[![](www/cp_logo.png)](https://github.com/JuliaTrustworthyAI/ConformalPrediction.jl)
:::
::::

![Conformal Prediction sets for an Image Classifier.](www/cp_example.svg){#fig-cp-example width="80%"}

# ECCCos from the Black Box

## Pick your Poison?

All of these counterfactuals are valid explanations for the model's prediction. Which one would you pick?

![Turning a 9 into a 7: Counterfactual Examplanations for an Image Classifier.](www/poison.png){#fig-cf-example}

## What do Models Learn?

These images are sampled from the posterior distribution learned by the model. Looks different, no?

![Conditional Generated Images from the Image Classifier](www/learn.png){#fig-learn}

## ECCCos

# Trustworthy AI in Julia

## ðŸ¶ Taija {.smaller}

> Research informs development, development informs research. 

[![Trustworthy Artificial Intelligence in Julia.](www/logo.png)](https://github.com/JuliaTrustworthyAI)

[Taija](https://github.com/JuliaTrustworthyAI) is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.

Our work has been presented at JuliaCon 2022 and will be presented again at JuliaCon 2023 and hopefully beyond. 

## References


