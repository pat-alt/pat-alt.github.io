---
title: Trustworthy AI in Julia meets Supercomputing
subtitle: JuliaCon 2024
author: Patrick Altmeyer
format:
  julia-revealjs: 
    scrollable: true
    title-slide-attributes:
      data-background-image: ../www/qr.png
    self-contained: true
date: 2024-07-12
date-format: full
bibliography: biblio.bib
engine: julia
execute:
  freeze: auto
  eval: true
  echo: true
  output: false
---

```{julia}
#| echo: false

projectdir = splitpath(pwd()) |>
    ss -> joinpath(ss[1:findall([s == "pat-alt.github.io" for s in ss])[1]]...) 
cd(projectdir)

include("$projectdir/content/talks/posts/2024-juliacon/taija-supercomp/setup.jl")
```

## [T]{style="color:#389836;"}rustworthy [AI]{style="color:#9558B2;"} in [J]{style="color:#CB3C33;"}uli[A]{style="color:#CB3C33;"}

```{mermaid}
%%| echo: false
%%| label: fig-overview
%%| fig-cap: "Overview of the Taija ecosystem. Early-stage packages ommitted."

%%{
  init: {
    'theme': 'base',
    'themeVariables': {
      'primaryColor': '#BB2528',
      'primaryTextColor': '#fff',
      'primaryBorderColor': '#7C0000',
      'lineColor': '#F8B229',
      'secondaryColor': '#006100',
      'tertiaryColor': '#e9edfb',
      'fontFamily': "avenir"
    }
  }
}%%

flowchart TB

    classDef taija fill:#389836,stroke:#333,color:#fff;
    classDef core fill:#CB3C33,stroke:#333,color:#fff;
    classDef base fill:#9558B2,stroke:#333,color:#fff;

    %% Base
    base["TaijaBase.jl"]

    %% Meta
    interop["TaijaInteroperability.jl"]
    data["TaijaData.jl"]
    parallel["TaijaParallel.jl"]
    plotting["TaijaPlotting.jl"]

    %% Core
    ce["CounterfactualExplanations.jl"]
    cp["ConformalPrediction.jl"]
    lr["LaplaceRedux.jl"]
    jem["JointEnergyModels.jl"]

    %% External
    mlj["MLJ.jl"]
    flux["Flux.jl"]

    class base base;
    class interop,data,parallel,plotting taija;
    class ce,cp,lr,jem core;

    %% Graph
    base --> ce & cp & lr & jem

    subgraph "Core Packages"
        ce & cp & lr & jem 
    end

    subgraph "Meta Packages"
        data & plotting & parallel & interop
    end 

    subgraph "External Packages"
        mlj & flux
    end
```

# [TaijaParallel.jl](https://github.com/JuliaTrustworthyAI/TaijaParallel.jl)

[![Stable](https://img.shields.io/badge/docs-stable-blue.svg)](https://JuliaTrustworthyAI.github.io/TaijaParallel.jl/stable/)
[![Dev](https://img.shields.io/badge/docs-dev-blue.svg)](https://JuliaTrustworthyAI.github.io/TaijaParallel.jl/dev/)
[![Build Status](https://github.com/JuliaTrustworthyAI/TaijaParallel.jl/actions/workflows/CI.yml/badge.svg?branch=main)](https://github.com/JuliaTrustworthyAI/TaijaParallel.jl/actions/workflows/CI.yml?query=branch%3Amain)
[![Coverage](https://codecov.io/gh/JuliaTrustworthyAI/TaijaParallel.jl/branch/main/graph/badge.svg)](https://codecov.io/gh/JuliaTrustworthyAI/TaijaParallel.jl)
[![Code Style: Blue](https://img.shields.io/badge/code%20style-blue-4495d1.svg)](https://github.com/invenia/BlueStyle)
[![Aqua QA](https://raw.githubusercontent.com/JuliaTesting/Aqua.jl/master/badge.svg)](https://github.com/JuliaTesting/Aqua.jl)

This package adds custom support for parallelization for certain [Taija](https://github.com/JuliaTrustworthyAI) packages.

. . . 

- Intuitive user interface.
- Support for multi-threading and multi-processing.
- Easy to extend to new parallelization backends and functions.

## Why Supercomputing?

Efforts towards trustworthy AI tend to increase the computational burden involved in training or inference:

. . .

- Explainable AI: we are often required to generate many *local* explanations for many individuals.
- Conformal Prediction: many techniques involve cross-validation or bootstrapping.
- (Quasi) Bayesian DL like deep ensembles.

. . .

> Good news: all of these tasks can be parallelized!

<!-- A firm that is using a machine learning model to screen out job applicants, for example, might be required to explain to each unsuccessful applicant why they were not admitted to the interview stage. In a different context, researchers may need to generate many explanations for evaluation and benchmarking purposes. -->

# Motivating Example

> Generate ALL the Counterfactual Explanations!

- The package was developed to power [research](https://arxiv.org/abs/2312.10648) presented at AAAI 2024 [@altmeyer2024faithful]. 
- The project involved large benchmarks of counterfactual explanations that had to be run on a supercomputer. 

## Benchmarking Explanations {.nostretch}

::::{.columns}::::
:::{.column width='75%'}
**Goal**: Generate faithful counterfactual explanations that reflect model quality.

- Final benchmark: total of **~10 million** counterfactuals across 8 datasets and different DL models.
- Parallelized across **50 to 300 CPUs** on [DelftBlue](https://www.tudelft.nl/dhpc/system) using combination of multi-threading and -processing.
:::
:::{.column width='25%'}
![Counterfactual explanations for different models. Source: @altmeyer2024faithful](www/mnist_eccco.png)
:::
::::

## Source Code

- [ECCCo.jl](https://github.com/pat-alt/ECCCo.jl/tree/main) is a small package build for @altmeyer2024faithful that leverages and extends [CounterfactualExplanations.jl](https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl), [ConformalPrediction.jl](https://github.com/JuliaTrustworthyAI/ConformalPrediction.jl), and [JointEnergyModels.jl](https://github.com/JuliaTrustworthyAI/JointEnergyModels.jl).
- Parallelization is achieved through [TaijaParallel.jl](https://github.com/JuliaTrustworthyAI/TaijaParallel.jl/tree/main). 
- Functionality now being absorbed by CounterfactualExplanations.jl.

. . .

::::{.columns}::::
:::{.column width='90%'}
> Code is open-sourced and available on [GitHub](https://github.com/pat-alt/ECCCo.jl/tree/main).
:::
:::{.column width='10%'}
![](www/qr-eccco.png)
:::
::::

# The Package



## User Interface

::::{.columns}::::
:::{.column width='50%'}

> We aim to minimize the burden on users.

- Users will mostly interact with custom macro `@with_parallelizer`. 
- In @fig-usage, `mpi` is an instance of type `MPIParallelizer`. 

:::
:::{.column width='50%'}
![Generating counterfactuals in parallel using MPI. See [docs](https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/stable/tutorials/parallelization/) for details.](www/usage.png){#fig-usage}
:::
::::

## High-level Architecture

- [TaijaBase.jl](https://github.com/JuliaTrustworthyAI/TaijaBase.jl) ships basic parallelization [functions and symbols](https://github.com/JuliaTrustworthyAI/TaijaBase.jl/blob/main/src/parallelization/base.jl) to make them available to all Taija packages.
  - `CounterfactualExplanations.benchmark`, for example, accepts a `parallelizer` argument of type `Union{Nothing,AbstractParallelizer}`.
- [TaijaParallel.jl](https://github.com/JuliaTrustworthyAI/TaijaParallel.jl) adds out-of-the-box support for parallelization through multi-threading.
- Multi-processing through [MPI.jl](https://github.com/JuliaParallel/MPI.jl) handled through an extension. 

## Backend

- The `@with_parallelizer` macro defined [here](https://github.com/JuliaTrustworthyAI/TaijaParallel.jl/blob/8534c12b67a9f1ecda0186d992843d249e6a0a28/src/TaijaParallel.jl#L27C7-L27C24) parses inputs and calls the `parallelize` function.
- `parallelize` is dispatched on the type of `parallelizer` and the function to be parallelized.
- Easy to add support for new parallelization backends and functions by overloading `parallelize`.
- Possible to combine different forms of parallelization, e.g., multi-threading and multi-processing (see [here](https://github.com/JuliaTrustworthyAI/TaijaParallel.jl/blob/8534c12b67a9f1ecda0186d992843d249e6a0a28/ext/MPIExt/generate_counterfactual.jl#L15) for an example).

## Caveats and Future Work

- The functions to be parallelized must be broadcastable: `generate_counterfactual`, for example, can be broadcasted over a batch of inputs.
- Currently, the package only supports CounterfactualExplanations.jl.
- Work on ConformalPrediction.jl is in progress, and hinges on the ability to parallelize cross-validation. Requires [changes](https://github.com/JuliaTrustworthyAI/ConformalPrediction.jl/pull/119) to ConformalPrediction.jl.

## ALL the Counterfactuals!

```{julia}
#| echo: false
#| eval: false

using BenchmarkTools
using CounterfactualExplanations
using CounterfactualExplanations.Models
using CounterfactualExplanations.Convergence
using CounterfactualExplanations.Evaluation
using Flux
using TaijaParallel
using TaijaData
pllr = ThreadsParallelizer()
data = CounterfactualData(load_mnist()...)
X, y = CounterfactualExplanations.DataPreprocessing.unpack_data(data)
M = load_mnist_mlp()
opt = Flux.Adam(0.1)
gen = GenericGenerator(opt=opt)
conv = DecisionThresholdConvergence(decision_threshold=0.75, max_iter=10)
factual_label = 8
n = 10000
idx = rand(findall(predict_label(M, data).==factual_label), n)
xs = select_factual(data, idx)
target = 3
```

```{julia}
#| echo: false
#| eval: false
ces = @time @with_parallelizer pllr begin 
  generate_counterfactual(
    xs, target, data, M, gen; 
    convergence=conv
  )
end
@info "$(sum(Evaluation.validity.(ces)))/$n valid counterfactuals on $(Threads.nthreads()) threads."
```

::::{.columns}::::
:::{.column width='75%'}
Trustworthy AI may be slow but ...

> Julia go vroom vroom!
:::
:::{.column width='25%'}
![](www/meme.jpg){width="300" top=50 right=50}
:::
::::



![Generating 10,000 counterfactuals for MNIST in parallel in under 2s on a MacBook.](www/all.png)

# Questions? {.nostretch} 

![](/www/images/qr.png){width="25%" fig-align="center"}

## References