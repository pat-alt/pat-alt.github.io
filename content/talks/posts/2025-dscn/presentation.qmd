---
title: Explaining Models or Modelling Explanations
subtitle: Challenging Existing Paradigms in Trustworthy AI
author: 
  - name: "**Patrick Altmeyer**"
    url: https://www.patalt.org/
  - name: Arie van Deursen
  - name: Cynthia C. S. Liem
institute: Delft University of Technology
date: today
format: 
  tudelft-revealjs:
    theme: custom.scss
    self-contained: true
    smaller: false
    scrollable: true
    preview-links: auto
    slide-number: true
    transition: slide
    background-transition: fade
    fig-align: center
    html-math-method: mathjax
    include-in-header:
      - text: |
          <script>
          MathJax = {
            options: {
              menuOptions: {
                settings: {
                  assistiveMml: false
                }
              }
            }
          };
          </script>
revealjs-plugins:
  - pointer
crossref: 
  prp-title: RQ
  prp-prefix: RQ
classoption: "notheorems"
draft: false
---

## Background {.smaller}

::::{.columns}::::
:::{.column width='65%'}

- **Question**: How can we explain predictions of opaque machine learning models and make them "explain themselves better"?
- **Methods**: Counterfactual Explanations, Algorithmic Recourse, Probabilistic Machine Learning, Energy-Based Models, Conformal Prediction, ...
- **Applications**: Mostly finance and economics but also images and natural language.
- **Tools**: I am a Julia developer and the founder of [Taija](https://github.com/JuliaTrustworthyAI), an organization for trustworthy AI in Julia.

:::
:::{.column width='35%'}
![](/www/images/qr.png){width="100%" fig-align="center"}
:::
::::

## Questions {.smaller}

::: {.incremental}

- What are counterfactual explanations (CE) and algorithmic recourse (AR) and why are they useful? 
- What dynamics are generated when off-the-shelf solutions to CE and AR are implemented in practice? 
- Can we generate plausible counterfactuals relying only on the opaque model itself?
- How can we leverage counterfactuals during training to build more trustworthy models?
:::

## Counterfactual Explanations

$$
\begin{aligned}
\min_{\mathbf{Z}^\prime \in \mathcal{Z}^L} \{  {\text{yloss}(M_{\theta}(f(\mathbf{Z}^\prime)),\mathbf{y}^+)} + \lambda {\text{cost}(f(\mathbf{Z}^\prime)) }  \} 
\end{aligned} 
$$ 

::::{.columns}::::
:::{.column width='50%'}
**Counterfactual Explanations** (CE) explain how inputs into a model need to change for it to produce different outputs. 

ðŸ“œ @altmeyer2023explaining \@ JuliaCon 2022.
:::
:::{.column width='50%'}
![Gradient-based counterfactual search.](www/simple_ce.png){#fig-ce-intro width="60%"}
:::
::::

## Algorithmic Recourse

::: {.columns}
::: {.column width="40%"}

Provided CE is valid, plausible and actionable, it can be used to provide recourse to individuals negatively affected by models.

:::
::: {.column width="60%"}

![Counterfactuals for random samples from the Give Me Some Credit dataset [@kaggle2011give]. Features 'age' and 'income' are shown.](www/credit.png){#fig-credit width=80%}

:::
:::



## Dynamics of Counterfactuals

::::{.columns}::::
:::{.column width='50%'}
ðŸ“œ @altmeyer2023endogenous \@ SaTML 2023.
:::
:::{.column width='50%'}
![](www/poc.png){width="100%"}
:::
::::

![Illustration of external cost of individual recourse.](www/bank_cartoon.png){#fig-bank-cartoon width="65%"}

## Pick your Poison

All of these counterfactuals are valid explanations for the model's prediction. 

> Which one would you pick?

![Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using *Wachter* [@wachter2017counterfactual], *Schut* [@schut2021generating] and *REVISE* [@joshi2019realistic].](www/mnist_motivation.png){#fig-cf-example width="80%"}

## ECCCos from the Black-Box {.nostretch .smaller} 

::::{.columns}::::
:::{.column width='30%'}

ðŸ“œ @altmeyer2023faithful \@ AAAI 2024

::: {.callout-tip appearance="minimal"}

## Key Idea

Use the hybrid objective of joint energy models (JEM) and a model-agnostic penalty for predictive uncertainty: Energy-Constrained ($\mathcal{E}_{\theta}$) Conformal ($\Omega$) Counterfactuals (*ECCCo*). 

:::
:::
:::{.column width='70%'}

*ECCCo* objective^[We leverage ideas from @grathwohl2020your and @stutz2022learning. See the paper and appendix for a derivation of the objective from first principles.]:

$$
\begin{aligned}
& \min_{\mathbf{Z}^\prime \in \mathcal{Z}^L} \{  {L_{\text{clf}}(f(\mathbf{Z}^\prime);M_{\theta},\mathbf{y}^+)}+ \lambda_1 {\text{cost}(f(\mathbf{Z}^\prime)) } \\
&+ \lambda_2 \mathcal{E}_{\theta}(f(\mathbf{Z}^\prime)|\mathbf{y}^+) + \lambda_3 \Omega(C_{\theta}(f(\mathbf{Z}^\prime);\alpha)) \} 
\end{aligned} 
$$

![Gradient fields and counterfactual paths for different generators.](www/poc_gradient_fields.png){#fig-poc-gradient-fields width="75%" fig-align="center"}

:::
::::

## Faithful Counterfactuals

::::{.columns}::::
:::{.column width='30%'}
![Turning a 9 into a 7. *ECCCo* applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).](www/mnist_eccco.png){#fig-mnist-eccco width="75%"}
:::
:::{.column width='70%'}
*ECCCo* generates counterfactuals that

- faithfully represent model quality (@fig-mnist-eccco).
- achieve state-of-the-art plausibility (@fig-mnist-benchmark).

![Results for different generators (from 3 to 5).](www/mnist_benchmark.png){#fig-mnist-benchmark width="100%"}
:::
::::

## Spurious Sparks of AGI

::::{.columns}::::
:::{.column width='50%'}
ðŸ“œ In @altmeyer2024position \@ ECONDAT 2024, we challenge the idea that the finding of meaningful patterns in latent spaces of large models is indicative of AGI.
:::
:::{.column width='50%'}
![Inflation of prices or birds? It doesn't matter!](www/attack_inflation.png){#fig-attack-inflation width="100%"}
:::
::::

## Taija {.smaller}

::::{.columns}::::
:::{.column width='50%'}
- Model Explainability ([CounterfactualExplanations.jl](https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl))
- Predictive Uncertainty Quantification ([ConformalPrediction.jl](https://github.com/JuliaTrustworthyAI/ConformalPrediction.jl))
- Effortless Bayesian Deep Learning ([LaplaceRedux.jl](https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl))
- ... and more!
:::
:::{.column width='50%'}
- Work presented \@ JuliaCon 2022, 2023, 2024.
- Running project \@ Google Summer of Code 2024.
- Total of three software projects \@ TU Delft.
:::
::::

[![Trustworthy AI in Julia: github.com/JuliaTrustworthyAI](www/logo.png){width="50%" fig-align="center"}](https://github.com/JuliaTrustworthyAI)

## References {.scrollable .smaller}


