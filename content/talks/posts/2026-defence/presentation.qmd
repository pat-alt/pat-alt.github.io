---
title: Holding AI Accountable
subtitle: "Short answers to 'What are you actually doing in your *Ph.D*?'"
author: 
  - name: "**Patrick Altmeyer**"
    url: https://www.patalt.org/
  - name: Arie van Deursen
  - name: Cynthia C. S. Liem
institute: Delft University of Technology
date: 2026-02-25
format: 
  tudelft-revealjs:
    theme: dark
    slide-number: true
    transition: slide
    background-transition: fade
    html-math-method: mathjax
    auto-animate-easing: ease-in-out
    auto-animate-unmatched: false
    auto-animate-duration: 0.8
  beamer: 
    slide-level: 2
    theme: Berlin
    fontsize: 10pt
---

## The Ground Truth {auto-animate=true}

![Predictors of default risk.](www/presentation/s1.png){#fig-pred}

## The Ground Truth {auto-animate=true} 

![Ground truth outcomes across two predictors.](www/presentation/s2.png){#fig-gt}

## Black-Box AI {auto-animate=true}

![Classifier predicts correctly 8 out of 10 times.](www/presentation/s3.png){#fig-clf}

## Black-Box AI {auto-animate=true}

![Simple counterfactual explanation for the black-box AI.](www/presentation/s4.png){#fig-ce}

## Black-Box AI {auto-animate=true}

![One happy recourse recipient, many losers.](www/presentation/s5.png){#fig-ar}

## Black-Box AI {auto-animate=true}

![Plausible counterfactual explanations for the black-box AI.](www/presentation/s6.png){#fig-plausible-ce}

## Black-Box AI {auto-animate=true}

![One somewhat happy recourse recipient, no losers.](www/presentation/s7.png){#fig-plausible-ar}

## Big, Beautiful Black-Box AI {auto-animate=true}

![Classifier predicts correctly 9 out of 10 times. But ...](www/presentation/s8.png){#fig-big-clf}

## Big, Beautiful Black-Box AI {auto-animate=true}

![Plausible counterfactual explanations remains valid. Happy days?](www/presentation/s9.png){#fig-big-plausible-ce}

## Big, Beautiful Black-Box AI {auto-animate=true}

![White-washed black-box: plausible CE hides bias.](www/presentation/s10.png){#fig-worst-case}

## Holding Models Accountable {auto-animate=true}

![A model trained to use plausible explanations for predictions](www/presentation/s11.png){#fig-best-case}

## 'ok but agi bruh'

![](www/presentation/s12.jpg)
