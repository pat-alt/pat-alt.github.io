---
title: Explaining Models or Modelling Explanations
subtitle: Counterfactual Explanations and Algorithmic Recourse for Trustworthy AI
author: 
  - name: "**Patrick Altmeyer**"
    url: https://www.patalt.org/
  - name: Arie van Deursen
  - name: Cynthia C. S. Liem
institute: Delft University of Technology
date: today
format: 
  beamer: 
    slide-level: 2
    theme: Berlin
    fontsize: 10pt
  tudelft-revealjs:
    theme: custom.scss
    auto-stretch: false
    self-contained: true
    smaller: false
    scrollable: true
    preview-links: auto
    slide-number: true
    transition: slide
    background-transition: fade
    fig-align: center
    html-math-method: mathjax
    include-in-header:
      - text: |
          <script>
          MathJax = {
            options: {
              menuOptions: {
                settings: {
                  assistiveMml: false
                }
              }
            }
          };
          </script>
revealjs-plugins:
  - pointer
crossref: 
  prp-title: RQ
  prp-prefix: RQ
classoption: "notheorems"
draft: false
---

## Background 

::::{.columns}::::
:::{.column width='65%'}

::: {.fragment .fade-in}
{{< fa user>}} Economist, now PhD CS
:::


::: {.fragment .fade-in}
{{< fa question >}} How can we make opaque AI more trustworthy?
:::

::: {.fragment .fade-in}
{{< fa toolbox >}} Explainable AI, Adversarial ML, Probabilistic ML
:::

::: {.fragment .fade-in}
{{< fa code >}} Core developer and maintainer of [Taija](https://github.com/JuliaTrustworthyAI) (Trustworthy AI in Julia)
:::


:::
:::{.column width='35%'}
![Scan for slides. Links to [www.patalt.org](www.patalt.org).](/www/images/qr.png){width="100%" fig-align="center"}
:::
::::

## Agenda 

::: {.incremental}

- **Intro**: counterfactual explanations (CE) and algorithmic recourse (AR) 
- **Unexpected Challenges**: endogenous dynamics of AR
- **Paradigm Shift**: explanations should be faithful first, plausible second
- **New Opportunities**: teaching models plausible explanations through CE
:::

# Intro

## A Toy Problem {.nostretch}

![Cats and dogs in two dimensions.](www/cat_pre.png){width="50%"}

## Traversing the Parameter Space {auto-animate=true}

[*Model Training*]{style="color: orange;"}

::: {.columns}
::: {.column width=50%}
**Objective**:

$$
\begin{aligned}
\min_{\textcolor{orange}{\theta}} \{  {\text{yloss}(M_{\theta}(\mathbf{x}),\mathbf{y})} \}
\end{aligned} 
$$ 
:::
::: {.column width=50%}

:::
:::


## Traversing the Parameter Space {auto-animate=true}

[*Model Training*]{style="color: orange;"}

::: {.columns}
::: {.column width=50%}
**Objective**:

$$
\begin{aligned}
\min_{\textcolor{orange}{\theta}} \{  {\text{yloss}(M_{\theta}(\mathbf{x}),\mathbf{y})} \}
\end{aligned} 
$$ 

**Solution**:

$$
\begin{aligned}
\theta_{t+1} &= \theta_t - \nabla_{\textcolor{orange}{\theta}} \{  {\text{yloss}(M_{\theta}(\mathbf{x}),\mathbf{y})} \} \\
\textcolor{orange}{\theta^*}&=\theta_T
\end{aligned} 
$$
:::
::: {.column width=50%}
![Fitted model. Contour shows predicted probability $y=ðŸ¶$.](www/cat_fitted.png){width="65%"}
:::
:::

## Traversing the Feature Space {auto-animate=true}

[*Counterfactual Search*]{style="color: purple;"}

::: {.columns}
::: {.column width=50%}

**Objective**:

$$
\begin{aligned}
\min_{\textcolor{purple}{\mathbf{x}}} \{  {\text{yloss}(M_{\textcolor{orange}{\theta^*}}(\mathbf{x}),\mathbf{y^{\textcolor{purple}{+}} }) + \lambda \text{reg} } \}
\end{aligned} 
$$ 
:::
::: {.column width=50%}

:::
:::


## Traversing the Feature Space {auto-animate=true}

[*Counterfactual Search*]{style="color: purple;"}


::: {.columns}
::: {.column width=50%}

**Objective**:

$$
\begin{aligned}
\min_{\textcolor{purple}{\mathbf{x}}} \{  {\text{yloss}(M_{\textcolor{orange}{\theta^*}}(\mathbf{x}),\mathbf{y^{\textcolor{purple}{+}} }) + \lambda \text{reg} } \}
\end{aligned} 
$$


**Solution**:

$$
\begin{aligned}
\mathbf{x}_{t+1} &= \mathbf{x}_t - \nabla_{\textcolor{purple}{\theta}} \{  {\text{yloss}(M_{\textcolor{orange}{\theta^*}}(\mathbf{x}),\mathbf{y^{\textcolor{purple}{+}} })} \} \\
\textcolor{purple}{\mathbf{x}^*}&=\mathbf{x}_T
\end{aligned} 
$$
:::
::: {.column width=50%}

::: {.content-visible when-format="html"}
![Counterfactual explanation for what it takes to be a dog.](www/cat.gif){width="85%"}
:::

::: {.content-visible when-format="pdf"}
![Counterfactual explanation for what it takes to be a dog.](www/cat.png){width="85%"}
:::
:::
:::

## Algorithmic Recourse

::: {.columns}
::: {.column width="50%"}

Provided CE is valid, plausible and actionable, it can be used to provide recourse to individuals negatively affected by models.

> "If your income had been `x`, then ..."

:::
::: {.column width="50%"}

![Counterfactuals for random samples from the Give Me Some Credit dataset [@kaggle2011give]. Features 'age' and 'income' are shown.](www/credit.png){#fig-credit width=80%}

:::
:::

# Unexpected Challenges

## Hidden Cost of Implausibility


::::{.columns}::::
:::{.column width='50%'}
AR can introduce costly dynamics^[{{< fa scroll >}} @altmeyer2023endogenous \@ SaTML 2023.]

![Endogenous Macrodynamics in Algorithmic Recourse.](www/poc.png){width="100%"}
:::
:::{.column width='50%'}
![Illustration of external cost of individual recourse.](www/bank_cartoon.png){#fig-bank-cartoon width="100%"}
:::
::::

{{< fa key >}} **Insight**: Implausible Explanations Are Costly

## Mitigation Strategies

::: {.columns}
::: {.column width=50%}
- Incorporate hidden cost in reframed objective.
- Even simple mitigation strategies can help.
- Reducing hidden cost is (roughly) equivalent to ensuring plausibility.
:::
::: {.column width=50%}

**Reframed Objective**

$$
\begin{aligned}
\mathbf{s}^\prime &= \arg \min_{\mathbf{s}^\prime \in \mathcal{S}} \{ {\text{yloss}(M(f(\mathbf{s}^\prime)),y^*)} \\ &+ \lambda_1 {\text{cost}(f(\mathbf{s}^\prime))} + \lambda_2 {\text{extcost}(f(\mathbf{s}^\prime))} \}  
\end{aligned} 
$$

![Mitigation strategies to tackle hidden costs of AR.](www/mitigation.png)
:::
:::


# Paradigm Shift 

## Plausibility at all cost?

All of these counterfactuals are valid explanations for the model's prediction. 

> Pick your poison ...

![Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using *Wachter* [@wachter2017counterfactual], *Schut* [@schut2021generating] and *REVISE* [@joshi2019realistic].](www/mnist_motivation.png){#fig-cf-example width="75%"}

## Faithful First, Plausible Second

Counterfactuals as plausible as the model permits^[{{< fa scroll >}} @altmeyer2023faithful \@ AAAI 2024. [[blog]](/blog/posts/eccco/index.qmd)].

::: {.columns}
::: {.column width="50%"}
![KDE for training data.](www/density_true.png){#fig-dens-true width=70%}
:::
::: {.column width="50%"}
![KDE for model posterior.](www/density_model.png){#fig-dens-mod width=70%}
:::
:::

## Faithful Counterfactuals

::::{.columns}::::
:::{.column width='30%'}
![Turning a 9 into a 7. *ECCCo* applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).](www/mnist_eccco.png){#fig-mnist-eccco width="75%"}
:::
:::{.column width='70%'}
{{< fa key >}} **Insight**: faithfulness facilitates

- model quality checks (@fig-mnist-eccco).
- state-of-the-art plausibility (@fig-mnist-benchmark).

![Results for different generators (from 3 to 5).](www/mnist_benchmark.png){#fig-mnist-benchmark width="100%"}
:::
::::

# New Opportunities

## Counterfactual Training: Method

![(a) conventional training, all mutable; (b) CT, all mutable; (c) conventional, *age* immutable; (d) CT, *age* immutable.](www/ct_poc.png){#fig-ecml width="70%"}

::: {.columns}
::: {.column width="75%"}
1. Contrast faithful CE with data.
2. Enforce actionability constraints.
3. Bonus: use nascent CE as AE. 
:::
::: {.column width="25%"}
::: {.callout-tip appearance="minimal"}

{{< fa key >}} **Insight**: We can hold models accountable for plausible explanations^[{{< fa scroll >}} @altmeyer2025counterfactual \@SaTML '26].
:::
:::
:::

## Counterfactual Training: Results

- Models trained with CT learn more plausible and (provably) actionable explanations.
- Predictive performance does not suffer, robust performance improves.

::: {.columns}
::: {.column width=50%}
![*Plausibility*: BL (top row) vs CT using the *ECCCo* generator (bottom row) counterfactuals for a randomly selected factual from class "0" (in blue). CT produces more plausible counterfactuals than BL.](www/ct_mnist.png){width=70%} 
:::
::: {.column width=50%}
![*Actionability*: Sample visual explanations (integrated gradients) for the *MNIST* dataset. Mutability constraints are imposed on the five top and bottom rows of pixels. CT (bottom) is less sensitive to protected features.](www/mnist_ig.png){width="70%"}
:::
:::



# If we still have time ...

## Spurious Sparks of AGI

::::{.columns}::::
:::{.column width='50%'}
We challenge the idea that the finding of meaningful patterns in latent spaces of large models is indicative of AGI^[{{< fa scroll >}} In @altmeyer2024position \@ ICML 2024].
:::
:::{.column width='50%'}
![Inflation of prices or birds? It doesn't matter!](www/attack_inflation.png){#fig-attack-inflation width="100%"}
:::
::::

## Taija {.smaller}

::::{.columns}::::
:::{.column width='50%'}
- Model Explainability ([CounterfactualExplanations.jl](https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl))
- Predictive Uncertainty Quantification ([ConformalPrediction.jl](https://github.com/JuliaTrustworthyAI/ConformalPrediction.jl))
- Effortless Bayesian Deep Learning ([LaplaceRedux.jl](https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl))
- ... and more!
:::
:::{.column width='50%'}
- Work presented \@ JuliaCon 2022, 2023, 2024.
- Google Summer of Code and Julia Season of Contributions 2024.
- Total of three software projects \@ TU Delft.
:::
::::

[![Trustworthy AI in Julia: github.com/JuliaTrustworthyAI](www/logo.png){width="50%" fig-align="center"}](https://github.com/JuliaTrustworthyAI)

## References {.scrollable .smaller}


