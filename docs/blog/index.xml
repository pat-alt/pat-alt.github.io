<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Patrick Altmeyer</title>
<link>https://www.paltmeyer.com/blog/blog/index.html</link>
<atom:link href="https://www.paltmeyer.com/blog/blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-99.9.9</generator>
<lastBuildDate>Sun, 15 Jan 2023 23:00:00 GMT</lastBuildDate>
<item>
  <title>Quarto on Steroids: Advanced Customization through Quarto Extensions</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/quarto-extensions/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/quarto-extensions/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
A TU Delft Theme for Quarto.
</figcaption>
</figure>
</div>
<p>I‚Äôve said it before and I‚Äôll say it again: <a href="https://quarto.org/">Quarto</a> is amazing! Since the beginning of my PhD I haven‚Äôt used any other tool for prototyping, writing and publishing any of my work.<sup>1</sup> That work has included: this website, presentations, academic articles, notebooks and more. By highlighting useful features of Quarto in articles like this one, I hope to encourage more people to try it out.</p>
<p>While I‚Äôm convinced that Quarto can be useful in almost any context including industry, I realize that certain obstacles may have so far prevented some of you from using it. One such obstacle concerns custom formats: the standard Quarto formats for HTML, PDF, Revealjs, etc. are slick but minimalistic. For many formats, there are various themes to choose from, but they too lack personal touch (or corporate identity in the industry setting).</p>
<p>At first sight, traditional publishing tools like MS Office seem to have an edge here: customization is made easy through GUIs and standardization through templates is possible to a certain degree. I understand the appeal but still would encourage you to look beyond MS Word, Powerpoint and Beamer presentations. To this end, I‚Äôve put together this short tutorial that explains how I have built and contributed a <a href="https://github.com/pat-alt/quarto-tudelft">TU Delft theme</a> for Revealjs. If nothing else, this theme can be used by my colleagues at Delft University of Technology to create beautiful, Delft-styled presentations with ease.</p>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">üìñ Background</h2>
<p>Advanced and reproducible customization in Quarto is done through <a href="https://quarto.org/docs/extensions/">Quarto Extensions</a>:</p>
<blockquote class="blockquote">
<p>‚ÄúQuarto Extensions are a powerful way to modify or extend the behavior of Quarto, and can be created and distributed by anyone.‚Äù</p>
<p>‚Äî Quarto team</p>
</blockquote>
<p>Users can already utilize several open-sourced extensions that add <a href="https://quarto.org/docs/extensions/listing-filters.html">filters</a>, <a href="https://quarto.org/docs/extensions/listing-journals.html">journal article formats</a> and other <a href="https://quarto.org/docs/extensions/listing-formats.html">custom formats</a>. As we will see, it is very straightforward to contribute extensions, so the list of available extensions is growing quickly.</p>
</section>
<section id="contributing-quarto-extensions" class="level2">
<h2 class="anchored" data-anchor-id="contributing-quarto-extensions">ü´¥ Contributing Quarto Extensions</h2>
<p>Normally, I would start by explaining how to use Quarto Extensions, but in this particular case the user and developer experience is so close that I‚Äôll jump straight into development.</p>
<section id="setup" class="level3">
<h3 class="anchored" data-anchor-id="setup">Setup</h3>
<p>To get started with building the TU Delft Custom Format I followed the official <a href="https://quarto.org/docs/extensions/formats.html#quick-start">Quarto docs</a>. I first used the appropriate Quarto command, which initiates an interactive process in the command line:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb1-1"><span class="ex" style="color: null;">$</span> quarto create extension format:revealjs</span>
<span id="cb1-2"> <span class="ex" style="color: null;">?</span> Extension Name ‚Ä∫ lexdoc</span></code></pre></div>
<p>Once done, the basic folder structure for my extension was set up and ready to be pushed to a remote Github repository for distribution: <a href="https://github.com/pat-alt/quarto-tudelft">https://github.com/pat-alt/quarto-tudelft</a>. Even though I had not yet added any custom formatting rules, anyone would now be able to use this empty extension for their work.</p>
</section>
<section id="adding-rules" class="level3">
<h3 class="anchored" data-anchor-id="adding-rules">Adding Rules</h3>
<p>To actually add some custom formatting rules to the extension I started working on the files contained in <code>_extensions/tudelft/</code>. Using my institution‚Äôs PowerPoint template as a reference, I previewed the <code>template.qmd</code> file and simply made appropriate adjustments to the <a href="https://github.com/pat-alt/quarto-tudelft/blob/main/_extensions/tudelft/custom.scss"><code>_extensions/tudelft/custom.scss</code></a> and <a href="https://github.com/pat-alt/quarto-tudelft/blob/main/_extensions/tudelft/_extension.yml"><code>_extensions/tudelft/_extension.yml</code></a> files until I was satisfied. To help me in that process, I took inspiration from various existing Revealjs extensions all listed in the <a href="https://github.com/mcanouil/awesome-quarto#presentations">awesome-quarto</a> repository.</p>
<p>I am no expert in CSS (far from it!), so this was very much trial-and-error based, but I got there eventually. One feature I am particularly happy about is the custom transition slides: by default all slides at level 1, so slides that initiate a new section,</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode md code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><span class="fu" style="color: #4758AB;"># Transition Slide</span></span></code></pre></div>
<p>will be formatted in a standardized way. The relevant CSS rule can be found <a href="https://github.com/pat-alt/quarto-tudelft/blob/b324cee4a6860a5ed5385dc607330d49de052875/_extensions/tudelft/custom.scss#L96">here</a></p>
</section>
<section id="adding-assets" class="level3">
<h3 class="anchored" data-anchor-id="adding-assets">Adding Assets</h3>
<p>The Reavealjs template also includes a few images, which I have lifted from my institution‚Äôs PowerPoint template. To make sure that these images are also available locally when users install the template, any resources need to be stored inside the theme directory <code>_extensions/tudelft/</code>. I have had some issues pointing to the right location of these images in the <a href="https://github.com/pat-alt/quarto-tudelft/blob/main/_extensions/tudelft/custom.scss">_extensions/tudelft/custom.scss</a> and <a href="https://github.com/pat-alt/quarto-tudelft/blob/main/_extensions/tudelft/_extension.yml">_extensions/tudelft/_extension.yml</a> file. At the time of writing this, the image URLs are pointing to their remote location on Github (see <a href="https://github.com/pat-alt/quarto-tudelft/blob/b324cee4a6860a5ed5385dc607330d49de052875/_extensions/tudelft/custom.scss#L12">here</a>). This works, but probably isn‚Äôt ideal, so any suggestions are welcome.</p>
</section>
</section>
<section id="example-presentation---using-quarto-extensions" class="level2">
<h2 class="anchored" data-anchor-id="example-presentation---using-quarto-extensions">üìã Example Presentation - Using Quarto Extensions</h2>
<p>In February, 2023, I will present a research paper on Algorithmic Recourse at the first IEEE Conference on Secure and Trustworthy Machine Learning: <a href="https://satml.org/">SaTML 2023</a>. This was a good incentive for me to build a TU Delft Theme once for this occasion and then be able to reuse it again in the future.</p>
<blockquote class="blockquote">
<p>With the template built and distributed, how do you actually use it?</p>
</blockquote>
<p>This part is truly a walk in the park. As outlined in the <a href="https://github.com/pat-alt/quarto-tudelft">README</a> users can either work directly with the template,</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb3-1"><span class="ex" style="color: null;">quarto</span> use template pat-alt/quarto-tudelft</span></code></pre></div>
<p>or add the template to an existing Quarto project:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb4-1"><span class="ex" style="color: null;">quarto</span> add pat-alt/quarto-tudelft</span></code></pre></div>
<p>The first option will get you started with a working document straight away. For my paper presentation, I worked with the second option. At the time of writing, I am building and hosting all of my presentations in my website repository (the repo that also builds this very article you‚Äôre reading): <a href="https://github.com/pat-alt/pat-alt.github.io">https://github.com/pat-alt/pat-alt.github.io</a>.</p>
<p>With the extension added to the project, I can now use it anywhere within that project by simply specifying,</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb5-1"><span class="fu" style="color: #4758AB;">format</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> tudelft-revealjs</span></span></code></pre></div>
<p>in the YAML header of my Quarto document where <code>tudelft-revealjs</code> is just the name of the custom format.</p>
<p>It gets better ‚Ä¶ The extension can be extended further by providing yet another <a href="https://github.com/pat-alt/pat-alt.github.io/blob/b6207a616f6ef9c7ec09cf8ad3383db788b9148b/content/talks/posts/2023-ieee-satml/custom.scss#L1">custom style sheet</a>, as I have done for my paper presentation:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb6-1"><span class="fu" style="color: #4758AB;">format</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span></span>
<span id="cb6-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">tudelft-revealjs</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb6-3"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">theme</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> custom.scss</span></span></code></pre></div>
<p>Check out the final presentation <a href="../../../content/talks/posts/2023-ieee-satml/presentation.html" target="_blank">here</a> or see the embedded version below:</p>
<iframe src="https://www.paltmeyer.com/content/talks/posts/2023-ieee-satml/presentation.html#/title-slide" width="100%" height="350">
</iframe>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Not entirely true: I‚Äôve also used <code>Pluto.jl</code> üéà and had to resort to <code>.Rmd</code> in one particular case.‚Ü©Ô∏é</p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2023,
  author = {Altmeyer, Patrick},
  title = {Quarto on {Steroids:} {Advanced} {Customization} Through
    {Quarto} {Extensions}},
  date = {23-01-16},
  url = {https://www.paltmeyer.com/blog//blog/posts/quarto-extensions},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2023" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 23AD. <span>‚ÄúQuarto on Steroids: Advanced
Customization Through Quarto Extensions.‚Äù</span> January 16, 23AD. <a href="https://www.paltmeyer.com/blog//blog/posts/quarto-extensions">https://www.paltmeyer.com/blog//blog/posts/quarto-extensions</a>.
</div></div></section></div> ]]></description>
  <category>Quarto</category>
  <category>reproducibility</category>
  <category>open-source</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/quarto-extensions/index.html</guid>
  <pubDate>Sun, 15 Jan 2023 23:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/quarto-extensions/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Prediction Intervals for any Regression Model</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Conformal Prediction intervals for different<br>coverage rates. As coverage grows, so does<br>the width of the prediction interval.
</figcaption>
</figure>
</div>
<p>This is the third (and for now final) part of a series of posts that introduce Conformal Prediction in Julia using <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>. The first <a href="../../../blog/posts/conformal-prediction/index.html">post</a> introduced Conformal Prediction for supervised classification tasks: we learned that conformal classifiers produce set-valued predictions that are guaranteed to include the true label of a new sample with a certain probability. In the second <a href="../conformal-image-classifier/">post</a> we applied these ideas to a more hands-on example: we saw how easy it is to use <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> to conformalize a Deep Learning image classifier.</p>
<p>In this post, we will look at regression models instead, that is supervised learning tasks involving a continuous outcome variable. Regression tasks are as ubiquitous as classification tasks. For example, we might be interested in using a machine learning model to predict house prices or the inflation rate of the Euro or the parameter size of the next large language model. In fact, many readers may be more familiar with regression models than classification, in which case it may also be easier for you to understand Conformal Prediction (CP) in this context.</p>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">üìñ Background</h2>
<p>Before we start, let‚Äôs briefly recap what CP is all about. Don‚Äôt worry, we‚Äôre not about to deep-dive into methodology. But just to give you a high-level description upfront:</p>
<blockquote class="blockquote">
<p>Conformal prediction (a.k.a. conformal inference) is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions.</p>
<p>‚Äî <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span> (<a href="https://arxiv.org/pdf/2107.07511.pdf">arXiv</a>)</p>
</blockquote>
<p>Intuitively, CP works under the premise of turning heuristic notions of uncertainty into rigorous uncertainty estimates through repeated sampling or the use of dedicated calibration data.</p>
<p>In what follows we will explore what CP can do by going through a standard machine learning workflow using <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ.jl</code></a> and <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>. There will be less focus on how exactly CP works, but references will point you to additional resources.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interactive Version
</div>
</div>
<div class="callout-body-container callout-body">
<p>This post is also available as a fully interactive <a href="https://github.com/fonsp/Pluto.jl"><code>Pluto.jl</code></a> üéà notebook hosted on <a href="https://mybinder.org/">binder</a>: <a href="https://binder.plutojl.org/v0.19.12/open?url=https%253A%252F%252Fraw.githubusercontent.com%252Fpat-alt%252FConformalPrediction.jl%252Fmain%252Fdocs%252Fpluto%252Fintro.jl" target="_blank"><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/https:/mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder"></a></p>
<p>In my own experience, this may take some time to load, certainly long enough to get yourself a hot beverage ‚òï or first read on here. But I promise you that the wait is worth it!</p>
</div>
</div>
</section>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">üìà Data</h2>
<p>Most machine learning workflows start with data. For illustrative purposes we will work with synthetic data. The helper function below can be used to generate some regression data.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">get_data</span>(;N<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1000</span>, xmax<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3.0</span>, noise<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>, fun<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">Function</span>=<span class="fu" style="color: #4758AB;">fun</span>(X) <span class="op" style="color: #5E5E5E;">=</span> X <span class="op" style="color: #5E5E5E;">*</span> <span class="fu" style="color: #4758AB;">sin</span>(X))</span>
<span id="cb1-2">    <span class="co" style="color: #5E5E5E;"># Inputs:</span></span>
<span id="cb1-3">    d <span class="op" style="color: #5E5E5E;">=</span> Distributions.<span class="fu" style="color: #4758AB;">Uniform</span>(<span class="op" style="color: #5E5E5E;">-</span>xmax, xmax)</span>
<span id="cb1-4">    X <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">rand</span>(d, N)</span>
<span id="cb1-5">    X <span class="op" style="color: #5E5E5E;">=</span> MLJBase.<span class="fu" style="color: #4758AB;">table</span>(<span class="fu" style="color: #4758AB;">reshape</span>(X, <span class="op" style="color: #5E5E5E;">:</span>, <span class="fl" style="color: #AD0000;">1</span>))</span>
<span id="cb1-6"></span>
<span id="cb1-7">    <span class="co" style="color: #5E5E5E;"># Outputs:</span></span>
<span id="cb1-8">    Œµ <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">randn</span>(N) <span class="op" style="color: #5E5E5E;">.*</span> noise</span>
<span id="cb1-9">    y <span class="op" style="color: #5E5E5E;">=</span> @.(<span class="fu" style="color: #4758AB;">fun</span>(X.x1)) <span class="op" style="color: #5E5E5E;">+</span> Œµ</span>
<span id="cb1-10">    y <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">vec</span>(y)</span>
<span id="cb1-11">    <span class="cf" style="color: #003B4F;">return</span> X, y</span>
<span id="cb1-12"><span class="kw" style="color: #003B4F;">end</span></span></code></pre></div>
</div>
<p>Figure&nbsp;1 illustrates our observations (dots) along with the ground-truth mapping from inputs to outputs (line). We have defined that mapping <img src="https://latex.codecogs.com/png.latex?f:%20%5Cmathcal%7BX%7D%20%5Cmapsto%20%5Cmathcal%7BY%7D"> as follows:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="fu" style="color: #4758AB;">f</span>(X) <span class="op" style="color: #5E5E5E;">=</span> X <span class="op" style="color: #5E5E5E;">*</span> <span class="fu" style="color: #4758AB;">cos</span>(X)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-display" data-execution_count="5">
<div id="fig-data" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index_files/figure-html/fig-data-output-1.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Some synthetic regression data. Observations are shown as dots. The ground-truth mapping from inputs to outputs is shown as a dashed line.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="model-training-using-mlj" class="level2">
<h2 class="anchored" data-anchor-id="model-training-using-mlj">üèãÔ∏è Model Training using <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ</code></a></h2>
<p><a href="(https://github.com/juliatrustworthyai/ConformalPrediction.jl)"><code>ConformalPrediction.jl</code></a> is interfaced to <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ.jl</code></a> <span class="citation" data-cites="blaom2020mlj">(Blaom et al. 2020)</span>: a comprehensive Machine Learning Framework for Julia. <code>MLJ.jl</code> provides a large and growing suite of popular machine learning models that can be used for supervised and unsupervised tasks. Conformal Prediction is a model-agnostic approach to uncertainty quantification, so it can be applied to any common supervised machine learning model.</p>
<p>The interface to <code>MLJ.jl</code> therefore seems natural: any (supervised) <code>MLJ.jl</code> model can now be conformalized using <code>ConformalPrediction.jl</code>. By leveraging existing <code>MLJ.jl</code> functionality for common tasks like training, prediction and model evaluation, this package is light-weight and scalable. Now let‚Äôs see how all of that works ‚Ä¶</p>
<p>To start with, let‚Äôs split our data into a training and test set:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1">train, test <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">partition</span>(<span class="fu" style="color: #4758AB;">eachindex</span>(y), <span class="fl" style="color: #AD0000;">0.4</span>, <span class="fl" style="color: #AD0000;">0.4</span>, shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="cn" style="color: #8f5902;">true</span>)</span></code></pre></div>
</div>
<p>Now let‚Äôs define a model for our regression task:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1">Model <span class="op" style="color: #5E5E5E;">=</span> <span class="pp" style="color: #AD0000;">@load</span> KNNRegressor pkg <span class="op" style="color: #5E5E5E;">=</span> NearestNeighborModels</span>
<span id="cb4-2">model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Model</span>()</span></code></pre></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Have it your way!
</div>
</div>
<div class="callout-body-container callout-body">
<p>Think this dataset is too simple? Wondering why on earth I‚Äôm not using XGBoost for this task? In the interactive <a href="https://binder.plutojl.org/v0.19.12/open?url=https%253A%252F%252Fraw.githubusercontent.com%252Fpat-alt%252FConformalPrediction.jl%252Fmain%252Fdocs%252Fpluto%252Fintro.jl" target="_blank">version</a> of this post you have full control over the data and the model. Try it out!</p>
</div>
</div>
<p>Using standard <code>MLJ.jl</code> workflows let us now first train the unconformalized model. We first wrap our model in data:</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1">mach_raw <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(model, X, y)</span></code></pre></div>
</div>
<p>Then we fit the machine to the training data:</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1">MLJBase.<span class="fu" style="color: #4758AB;">fit!</span>(mach_raw, rows<span class="op" style="color: #5E5E5E;">=</span>train, verbosity<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0</span>)</span></code></pre></div>
</div>
<p>Figure&nbsp;2 below shows the resulting point predictions for the test data set:</p>
<div class="cell" data-execution_count="9">
<div class="cell-output cell-output-display" data-execution_count="10">
<div id="fig-point" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index_files/figure-html/fig-point-output-1.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Point predictions for our machine learning model.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>How is our model doing? It‚Äôs never quite right, of course, since predictions are estimates and therefore uncertain. Let‚Äôs see how we can use Conformal Prediction to express that uncertainty.</p>
</section>
<section id="conformalizing-the-model" class="level2">
<h2 class="anchored" data-anchor-id="conformalizing-the-model">üî• Conformalizing the Model</h2>
<p>We can turn our <code>model</code> into a conformalized model in just one line of code:</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1">conf_model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">conformal_model</span>(model)</span></code></pre></div>
</div>
<p>By default <code>conformal_model</code> creates an Inductive Conformal Regressor (more on this below) when called on a <code>&lt;:Deterministic</code> model. This behaviour can be changed by using the optional <code>method</code> key argument.</p>
<p>To train our conformal model we can once again rely on standard <code>MLJ.jl</code> workflows. We first wrap our model in data:</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">mach <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(conf_model, X, y)</span></code></pre></div>
</div>
<p>Then we fit the machine to the data:</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb9-1">MLJBase.<span class="fu" style="color: #4758AB;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;">=</span>train, verbosity<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0</span>)</span></code></pre></div>
</div>
<p>Now let us look at the predictions for our test data again. The chart below shows the results for our conformalized model. Predictions from conformal regressors are range-valued: for each new sample the model returns an interval <img src="https://latex.codecogs.com/png.latex?(y_%7B%5Ctext%7Blb%7D%7D,y_%7B%5Ctext%7Bub%7D%7D)%5Cin%5Cmathcal%7BY%7D"> that covers the test sample with a user-specified probability <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)">, where <img src="https://latex.codecogs.com/png.latex?%5Calpha"> is the expected error rate. This is known as the <strong>marginal coverage guarantee</strong> and it is proven to hold under the assumption that training and test data are exchangeable.</p>
<div class="cell" data-execution_count="13">
<div class="cell-output cell-output-display" data-execution_count="14">
<div id="fig-interval" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index_files/figure-html/fig-interval-output-1.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3: Prediction intervals for our conformalized machine learning model.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Intuitively, a higher coverage rate leads to larger prediction intervals: since a larger interval covers a larger subspace of <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BY%7D">, it is more likely to cover the true value.</p>
<p>I don‚Äôt expect you to believe me that the marginal coverage property really holds. In fact, I couldn‚Äôt believe it myself when I first learned about it. If you like mathematical proofs, you can find one in this <a href="https://arxiv.org/pdf/2107.07511.pdf">tutorial</a>, for example. If you like convincing yourself through empirical observations, read on below ‚Ä¶</p>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">üßê Evaluation</h2>
<p>To verify the marginal coverage property empirically we can look at the empirical coverage rate of our conformal predictor (see Section 3 of the <a href="https://arxiv.org/pdf/2107.07511.pdf">tutorial</a> for details). To this end our package provides a custom performance measure <code>emp_coverage</code> that is compatible with <code>MLJ.jl</code> model evaluation workflows. In particular, we will call <code>evaluate!</code> on our conformal model using <code>emp_coverage</code> as our performance metric. The resulting empirical coverage rate should then be close to the desired level of coverage.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb10-1">model_evaluation <span class="op" style="color: #5E5E5E;">=</span></span>
<span id="cb10-2">    <span class="fu" style="color: #4758AB;">evaluate!</span>(_mach, operation<span class="op" style="color: #5E5E5E;">=</span>MLJBase.predict, measure<span class="op" style="color: #5E5E5E;">=</span>emp_coverage, verbosity<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0</span>)</span>
<span id="cb10-3"><span class="fu" style="color: #4758AB;">println</span>(<span class="st" style="color: #20794D;">"Empirical coverage: </span><span class="sc" style="color: #5E5E5E;">$</span>(<span class="fu" style="color: #4758AB;">round</span>(model_evaluation.measurement[<span class="fl" style="color: #AD0000;">1</span>], digits<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3</span>))<span class="st" style="color: #20794D;">"</span>)</span>
<span id="cb10-4"><span class="fu" style="color: #4758AB;">println</span>(<span class="st" style="color: #20794D;">"Coverage per fold: </span><span class="sc" style="color: #5E5E5E;">$</span>(<span class="fu" style="color: #4758AB;">round</span>.(model_evaluation.per_fold[<span class="fl" style="color: #AD0000;">1</span>], digits<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3</span>))<span class="st" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Empirical coverage: 0.902</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Coverage per fold: [0.94, 0.904, 0.874, 0.874, 0.898, 0.922]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="cell-output cell-output-display" data-execution_count="18">
<blockquote class="blockquote">
<p>‚úÖ ‚úÖ ‚úÖ Great! We got an empirical coverage rate that is slightly higher than desired üòÅ ‚Ä¶ but why isn‚Äôt it exactly the same?</p>
</blockquote>
<p>In most cases it will be slightly higher than desired, since <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)"> is a lower bound. But note that it can also be slightly lower than desired. That is because the coverage property is ‚Äúmarginal‚Äù in the sense that the probability is averaged over the randomness in the data. For most purposes a large enough calibration set size (<img src="https://latex.codecogs.com/png.latex?n%3E1000">) mitigates that randomness enough. Depending on your choices above, the calibration set may be quite small (set to 500), which can lead to <strong>coverage slack</strong> (see Section 3 in the <a href="https://arxiv.org/pdf/2107.07511.pdf">tutorial</a>).</p>
</div>
</div>
<section id="so-whats-happening-under-the-hood" class="level3">
<h3 class="anchored" data-anchor-id="so-whats-happening-under-the-hood"><em>So what‚Äôs happening under the hood?</em></h3>
<p>Inductive Conformal Prediction (also referred to as Split Conformal Prediction) broadly speaking works as follows:</p>
<ol type="1">
<li>Partition the training into a proper training set and a separate calibration set</li>
<li>Train the machine learning model on the proper training set.</li>
<li>Using some heuristic notion of uncertainty (e.g., absolute error in the regression case), compute nonconformity scores using the calibration data and the fitted model.</li>
<li>For the given coverage ratio compute the corresponding quantile of the empirical distribution of nonconformity scores.</li>
<li>For the given quantile and test sample <img src="https://latex.codecogs.com/png.latex?X_%7B%5Ctext%7Btest%7D%7D">, form the corresponding conformal prediction set like so: <img src="https://latex.codecogs.com/png.latex?C(X_%7B%5Ctext%7Btest%7D%7D)=%5C%7By:s(X_%7B%5Ctext%7Btest%7D%7D,y)%20%5Cle%20%5Chat%7Bq%7D%5C%7D"></li>
</ol>
</section>
</section>
<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">üîÉ Recap</h2>
<p>This has been a super quick tour of <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>. We have seen how the package naturally integrates with <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ.jl</code></a>, allowing users to generate rigorous predictive uncertainty estimates for any supervised machine learning model.</p>
<section id="are-we-done" class="level3">
<h3 class="anchored" data-anchor-id="are-we-done"><em>Are we done?</em></h3>
<p>Quite cool, right? Using a single API call we are able to generate rigorous prediction intervals for all kinds of different regression models. Have we just solved predictive uncertainty quantification once and for all? Do we even need to bother with anything else? Conformal Prediction is a very useful tool, but like so many other things, it is not the final answer to all our problems. In fact, let‚Äôs see if we can take CP to its limits.</p>
<p>The helper function to generate data from above takes an optional argument <code>xmax</code>. By increasing that value, we effectively expand the domain of our input. Let‚Äôs do that and see how our conformal model does on this new out-of-domain data.</p>
<div class="cell" data-execution_count="18">
<div class="cell-output cell-output-display" data-execution_count="19">
<div id="fig-ood" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index_files/figure-html/fig-ood-output-1.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;4: Prediction intervals for our conformalized machine learning model applied to out-of-domain data.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>Whooooops ü§ï ‚Ä¶ looks like we‚Äôre in trouble: in Figure&nbsp;4 the prediction intervals do not cover out-of-domain test samples well. What happened here?</p>
</blockquote>
<p>By expanding the domain of out inputs, we have violated the exchangeability assumption. When that assumption is violated, the marginal coverage property does not hold. But do not despair! There are ways to deal with this.</p>
</section>
</section>
<section id="read-on" class="level2">
<h2 class="anchored" data-anchor-id="read-on">üìö Read on</h2>
<p>If you are curious to find out more, be sure to read on in the <a href="https://www.paltmeyer.com/ConformalPrediction.jl/stable/">docs</a>. There are also a number of useful resources to learn more about Conformal Prediction, a few of which I have listed below:</p>
<ul>
<li><em>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification</em> by Angelopoulos and Bates (<a href="https://arxiv.org/pdf/2107.07511.pdf">2022</a>).</li>
<li><em>Awesome Conformal Prediction</em> repository by Manokhin (<a href="https://github.com/valeman/awesome-conformal-prediction">2022</a>)</li>
<li><strong>MAPIE</strong>: a comprehensive Python <a href="https://mapie.readthedocs.io/en/latest/index.html">library</a> for conformal prediction.</li>
<li>My previous two blog posts.</li>
</ul>
<p>Enjoy!</p>
</section>
<section id="references" class="level2">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-angelopoulos2021gentle" class="csl-entry">
Angelopoulos, Anastasios N., and Stephen Bates. 2021. <span>‚ÄúA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.‚Äù</span> <a href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>.
</div>
<div id="ref-blaom2020mlj" class="csl-entry">
Blaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. <span>‚Äú<span>MLJ</span>: <span>A Julia</span> Package for Composable Machine Learning.‚Äù</span> <em>Journal of Open Source Software</em> 5 (55): 2704. <a href="https://doi.org/10.21105/joss.02704">https://doi.org/10.21105/joss.02704</a>.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {Prediction {Intervals} for Any {Regression} {Model}},
  date = {22-12-12},
  url = {https://www.paltmeyer.com/blog//blog/posts/conformal-regression},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 22AD. <span>‚ÄúPrediction Intervals for Any Regression
Model.‚Äù</span> December 12, 22AD. <a href="https://www.paltmeyer.com/blog//blog/posts/conformal-regression">https://www.paltmeyer.com/blog//blog/posts/conformal-regression</a>.
</div></div></section></div> ]]></description>
  <category>probabilistic programming</category>
  <category>uncertainty</category>
  <category>conformal prediction</category>
  <category>regression</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index.html</guid>
  <pubDate>Sun, 11 Dec 2022 23:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>How to Conformalize a Deep Image Classifier</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Conformalized prediction sets for a<br>simple Deep Image Classifier.
</figcaption>
</figure>
</div>
<p>Deep Learning is popular and ‚Äî for some tasks like image classification ‚Äî remarkably powerful. But it is also well-known that Deep Neural Networks (DNN) can be unstable <span class="citation" data-cites="goodfellow2014explaining">(Goodfellow, Shlens, and Szegedy 2014)</span> and poorly calibrated. Conformal Prediction can be used to mitigate these pitfalls.</p>
<p>In the <a href="../../../blog/posts/conformal-prediction/index.html">first part</a> of this series of posts on Conformal Prediction, we looked at the basic underlying methodology and how CP can be implemented in Julia using <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>. This second part of the series is a more goal-oriented how-to guide: it demonstrates how you can conformalize a deep learning image classifier built in <code>Flux.jl</code> in just a few lines of code.</p>
<p>Since this is meant to be more of a hands-on article, we will avoid diving too deeply into methodological concepts. If you need more colour on this, be sure to check out the <a href="../../../blog/posts/conformal-prediction/index.html">first article</a> on this topic and also <span class="citation" data-cites="angelopoulos2021gentle">A. N. Angelopoulos and Bates (2021)</span>. For a more formal treatment of Conformal Prediction see also <span class="citation" data-cites="angelopoulos2022uncertainty">A. Angelopoulos et al. (2022)</span>.</p>
<section id="the-task-at-hand" class="level2">
<h2 class="anchored" data-anchor-id="the-task-at-hand">üéØ The Task at Hand</h2>
<p>The task at hand is to predict the labels of handwritten images of digits using the famous MNIST dataset <span class="citation" data-cites="lecun1998mnist">(LeCun 1998)</span>. Importing this popular machine learning dataset in Julia is made remarkably easy through <code>MLDatasets.jl</code>:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">MLDatasets</span></span>
<span id="cb1-2">N <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1000</span></span>
<span id="cb1-3">Xraw, yraw <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">MNIST</span>(split<span class="op" style="color: #5E5E5E;">=:</span>train)[<span class="op" style="color: #5E5E5E;">:</span>]</span>
<span id="cb1-4">Xraw <span class="op" style="color: #5E5E5E;">=</span> Xraw[<span class="op" style="color: #5E5E5E;">:</span>,<span class="op" style="color: #5E5E5E;">:</span>,<span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span>N]</span>
<span id="cb1-5">yraw <span class="op" style="color: #5E5E5E;">=</span> yraw[<span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span>N]</span></code></pre></div>
</div>
<p>Figure&nbsp;1 below shows a few random samples from the training data:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">MLJ</span></span>
<span id="cb2-2"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Images</span></span>
<span id="cb2-3">X <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">map</span>(x <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="fu" style="color: #4758AB;">convert2image</span>(MNIST, x), <span class="fu" style="color: #4758AB;">eachslice</span>(Xraw, dims<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3</span>))</span>
<span id="cb2-4">y <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">coerce</span>(yraw, Multiclass)</span>
<span id="cb2-5"></span>
<span id="cb2-6">n_samples <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">10</span></span>
<span id="cb2-7"><span class="fu" style="color: #4758AB;">mosaic</span>(<span class="fu" style="color: #4758AB;">rand</span>(X, n_samples)<span class="op" style="color: #5E5E5E;">...</span>, ncol<span class="op" style="color: #5E5E5E;">=</span>n_samples)</span></code></pre></div>
<div id="fig-samples" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/data:image/png;base64,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" class="figure-img">
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Random samples from the MNIST dataset.</figcaption><p></p>
</figure>
</div>
</div>
</section>
<section id="building-the-network" class="level2">
<h2 class="anchored" data-anchor-id="building-the-network">üöß Building the Network</h2>
<p>To model the mapping from image inputs to labels will rely on a simple Multi-Layer Perceptron (MLP). A great Julia library for Deep Learning is <code>Flux.jl</code>. But wait ‚Ä¶ doesn‚Äôt <code>ConformalPrediction.jl</code> work with models trained in <code>MLJ.jl</code>? That‚Äôs right, but fortunately there exists a <code>Flux.jl</code> interface to <code>MLJ.jl</code>, namely <code>MLJFlux.jl</code>. The interface is still in its early stages, but already very powerful and easily accessible for anyone (like myself) who is used to building Neural Networks in <code>Flux.jl</code>.</p>
<p>In <code>Flux.jl</code>, you could build an MLP for this task as follows,</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Flux</span></span>
<span id="cb3-2"></span>
<span id="cb3-3">mlp <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Chain</span>(</span>
<span id="cb3-4">    Flux.flatten,</span>
<span id="cb3-5">    <span class="fu" style="color: #4758AB;">Dense</span>(<span class="fu" style="color: #4758AB;">prod</span>((<span class="fl" style="color: #AD0000;">28</span>,<span class="fl" style="color: #AD0000;">28</span>)), <span class="fl" style="color: #AD0000;">32</span>, relu),</span>
<span id="cb3-6">    <span class="fu" style="color: #4758AB;">Dense</span>(<span class="fl" style="color: #AD0000;">32</span>, <span class="fl" style="color: #AD0000;">10</span>)</span>
<span id="cb3-7">)</span></code></pre></div>
</div>
<p>where <code>(28,28)</code> is just the input dimension (28x28 pixel images). Since we have ten digits, our output dimension is ten.<sup>1</sup></p>
<p>We can do the exact same thing in <code>MLJFlux.jl</code> as follows,</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">MLJFlux</span></span>
<span id="cb4-2"></span>
<span id="cb4-3">builder <span class="op" style="color: #5E5E5E;">=</span> MLJFlux.<span class="pp" style="color: #AD0000;">@builder</span> <span class="fu" style="color: #4758AB;">Chain</span>(</span>
<span id="cb4-4">    Flux.flatten,</span>
<span id="cb4-5">    <span class="fu" style="color: #4758AB;">Dense</span>(<span class="fu" style="color: #4758AB;">prod</span>(n_in), <span class="fl" style="color: #AD0000;">32</span>, relu),</span>
<span id="cb4-6">    <span class="fu" style="color: #4758AB;">Dense</span>(<span class="fl" style="color: #AD0000;">32</span>, n_out)</span>
<span id="cb4-7">)</span></code></pre></div>
</div>
<p>where here we rely on the <code>@builder</code> macro to make the transition from <code>Flux.jl</code> to <code>MLJ.jl</code> as seamless as possible. Finally, <code>MLJFlux.jl</code> already comes with a number of helper functions to define plain-vanilla networks. In this case, we will use the <code>ImageClassifier</code> with our custom builder and cross-entropy loss:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1">ImageClassifier <span class="op" style="color: #5E5E5E;">=</span> <span class="pp" style="color: #AD0000;">@load</span> ImageClassifier</span>
<span id="cb5-2">clf <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">ImageClassifier</span>(</span>
<span id="cb5-3">    builder<span class="op" style="color: #5E5E5E;">=</span>builder,</span>
<span id="cb5-4">    epochs<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10</span>,</span>
<span id="cb5-5">    loss<span class="op" style="color: #5E5E5E;">=</span>Flux.crossentropy</span>
<span id="cb5-6">)</span></code></pre></div>
</div>
<p>The generated instance <code>clf</code> is a model (in the <code>MLJ.jl</code> sense) so from this point on we can rely on standard <code>MLJ.jl</code> workflows. For example, we can wrap our model in data to create a machine and then evaluate it on a holdout set as follows:</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1">mach <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(clf, X, y)</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="fu" style="color: #4758AB;">evaluate!</span>(</span>
<span id="cb6-4">    mach,</span>
<span id="cb6-5">    resampling<span class="op" style="color: #5E5E5E;">=</span><span class="fu" style="color: #4758AB;">Holdout</span>(rng<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">123</span>, fraction_train<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.8</span>),</span>
<span id="cb6-6">    operation<span class="op" style="color: #5E5E5E;">=</span>predict_mode,</span>
<span id="cb6-7">    measure<span class="op" style="color: #5E5E5E;">=</span>[accuracy]</span>
<span id="cb6-8">)</span></code></pre></div>
</div>
<p>The accuracy of our very simple model is not amazing, but good enough for the purpose of this tutorial. For each image, our MLP returns a softmax output for each possible digit: 0,1,2,3,‚Ä¶,9. Since each individual softmax output is valued between zero and one, <img src="https://latex.codecogs.com/png.latex?y_k%5Cin(0,1)">, this is commonly interpreted as a probability: <img src="https://latex.codecogs.com/png.latex?y_k%20%5Ccoloneqq%20p(y=k%7CX)">. Edge cases ‚Äì that is values close to either zero or one ‚Äì indicate high predictive certainty. But this is only a heuristic notion of predictive uncertainty <span class="citation" data-cites="angelopoulos2021gentle">(A. N. Angelopoulos and Bates 2021)</span>. Next, we will turn this heuristic notion of uncertainty into a rigorous one using Conformal Prediction.</p>
</section>
<section id="conformalizing-the-network" class="level2">
<h2 class="anchored" data-anchor-id="conformalizing-the-network">üî• Conformalizing the Network</h2>
<p>Since <code>clf</code> is a model, it is also compatible with our package: <code>ConformalPrediction.jl</code>. To conformalize our MLP, we therefore only need to call <code>conformal_model(clf)</code>. Since the generated instance <code>conf_model</code> is also just a model, we can still rely on standard <code>MLJ.jl</code> workflows. Below we first wrap it in data and then fit it. Aaaand ‚Ä¶ we‚Äôre done! Let‚Äôs look at the results in the next section.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">ConformalPrediction</span></span>
<span id="cb7-2">conf_model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">conformal_model</span>(clf; method<span class="op" style="color: #5E5E5E;">=:</span>simple_inductive, coverage<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">.95</span>)</span>
<span id="cb7-3">mach <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(conf_model, X, y)</span>
<span id="cb7-4"><span class="fu" style="color: #4758AB;">fit!</span>(mach)</span></code></pre></div>
</div>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">üìä Results</h2>
<p>Figure&nbsp;2 below presents the results. Figure&nbsp;2 (a) displays highly certain predictions, now defined in the rigorous sense of Conformal Prediction: in each case, the conformal set (just beneath the image) includes only one label.</p>
<p>Figure&nbsp;2 (b) and Figure&nbsp;2 (c) display increasingly uncertain predictions of set size two and three, respectively. They demonstrate that CP is well equipped to deal with samples characterized by high aleatoric uncertainty: digits four (4), seven (7) and nine (9) share certain similarities. So do digits five (5) and six (6) as well as three (3) and eight (8). These may be hard to distinguish from each other even after seeing many examples (and even for a human). It is therefore unsurprising to see that these digits often end up together in conformal sets.</p>
<div id="fig-plots" class="cell quarto-layout-panel" data-execution_count="10">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 100.0%;justify-content: center;">
<div id="fig-plots-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/index_files/figure-html/fig-plots-output-1.svg" class="img-fluid figure-img" data-ref-parent="fig-plots"></p>
<p></p><figcaption class="figure-caption">(a) Randomly selected prediction sets of size <img src="https://latex.codecogs.com/png.latex?%7CC%7C=1">.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 100.0%;justify-content: center;">
<div id="fig-plots-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/index_files/figure-html/fig-plots-output-2.svg" class="img-fluid figure-img" data-ref-parent="fig-plots"></p>
<p></p><figcaption class="figure-caption">(b) Randomly selected prediction sets of size <img src="https://latex.codecogs.com/png.latex?%7CC%7C=2">.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 100.0%;justify-content: center;">
<div id="fig-plots-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/index_files/figure-html/fig-plots-output-3.svg" class="img-fluid figure-img" data-ref-parent="fig-plots"></p>
<p></p><figcaption class="figure-caption">(c) Randomly selected prediction sets of size <img src="https://latex.codecogs.com/png.latex?%7CC%7C=3">.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Conformalized predictions from an image classifier.</figcaption><p></p>
</figure>
</div>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">üßê Evaluation</h2>
<p>To evaluate the performance of conformal models, specific performance measures can be used to assess if the model is correctly specified and well-calibrated <span class="citation" data-cites="angelopoulos2021gentle">(A. N. Angelopoulos and Bates 2021)</span>. We will look at this in some more detail in another post in the future. For now, just be aware that these measures are already available in <code>ConformalPrediction.jl</code> and we will briefly showcase them here.</p>
<p>As for many other things, <code>ConformalPrediction.jl</code> taps into the existing functionality of <code>MLJ.jl</code> for model evaluation. In particular, we will see below how we can use the generic <code>evaluate!</code> method on our machine. To assess the correctness of our conformal predictor, we can compute the empirical coverage rate using the custom performance measure <code>emp_coverage</code>. With respect to model calibration we will look at the model‚Äôs conditional coverage. For adaptive, well-calibrated conformal models, conditional coverage is high. One general go-to measure for assessing conditional coverage is size-stratified coverage. The custom measure for this purpose is just called <code>size_stratified_coverage</code>, aliased by <code>ssc</code>.</p>
<p>The code below implements the model evaluation using cross-validation. The Simple Inductive Classifier that we used above is not adaptive and hence the attained conditional coverage is low compared to the overall empirical coverage, which is close to <img src="https://latex.codecogs.com/png.latex?0.95">, so in line with the desired coverage rate specified above.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">_eval <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">evaluate!</span>(</span>
<span id="cb8-2">    mach,</span>
<span id="cb8-3">    resampling<span class="op" style="color: #5E5E5E;">=</span><span class="fu" style="color: #4758AB;">CV</span>(),</span>
<span id="cb8-4">    operation<span class="op" style="color: #5E5E5E;">=</span>predict,</span>
<span id="cb8-5">    measure<span class="op" style="color: #5E5E5E;">=</span>[emp_coverage, ssc]</span>
<span id="cb8-6">)</span>
<span id="cb8-7"><span class="fu" style="color: #4758AB;">display</span>(_eval)</span>
<span id="cb8-8"><span class="fu" style="color: #4758AB;">println</span>(<span class="st" style="color: #20794D;">"Empirical coverage: </span><span class="sc" style="color: #5E5E5E;">$</span>(<span class="fu" style="color: #4758AB;">round</span>(_eval.measurement[<span class="fl" style="color: #AD0000;">1</span>], digits<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3</span>))<span class="st" style="color: #20794D;">"</span>)</span>
<span id="cb8-9"><span class="fu" style="color: #4758AB;">println</span>(<span class="st" style="color: #20794D;">"SSC: </span><span class="sc" style="color: #5E5E5E;">$</span>(<span class="fu" style="color: #4758AB;">round</span>(_eval.measurement[<span class="fl" style="color: #AD0000;">2</span>], digits<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3</span>))<span class="st" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="ansi-escaped-output">
<pre>PerformanceEvaluation object with these fields:
  measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows
Extract:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ measure                                                   ‚îÇ operation ‚îÇ meas ‚ãØ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ emp_coverage (generic function with 1 method)             ‚îÇ predict   ‚îÇ 0.95 ‚ãØ
‚îÇ size_stratified_coverage (generic function with 1 method) ‚îÇ predict   ‚îÇ 0.77 ‚ãØ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span class="ansi-cyan-fg">                                                               3 columns omitted</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Empirical coverage: 0.951
SSC: 0.771</code></pre>
</div>
</div>
<p>We can attain higher adaptivity (SSC) when using adaptive prediction sets:</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb10-1">conf_model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">conformal_model</span>(clf; method<span class="op" style="color: #5E5E5E;">=:</span>adaptive_inductive, coverage<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">.95</span>)</span>
<span id="cb10-2">mach <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(conf_model, X, y)</span>
<span id="cb10-3"><span class="fu" style="color: #4758AB;">fit!</span>(mach)</span>
<span id="cb10-4">_eval <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">evaluate!</span>(</span>
<span id="cb10-5">    mach,</span>
<span id="cb10-6">    resampling<span class="op" style="color: #5E5E5E;">=</span><span class="fu" style="color: #4758AB;">CV</span>(),</span>
<span id="cb10-7">    operation<span class="op" style="color: #5E5E5E;">=</span>predict,</span>
<span id="cb10-8">    measure<span class="op" style="color: #5E5E5E;">=</span>[emp_coverage, ssc]</span>
<span id="cb10-9">)</span>
<span id="cb10-10">results[<span class="op" style="color: #5E5E5E;">:</span>adaptive_inductive] <span class="op" style="color: #5E5E5E;">=</span> mach</span>
<span id="cb10-11"><span class="fu" style="color: #4758AB;">display</span>(_eval)</span>
<span id="cb10-12"><span class="fu" style="color: #4758AB;">println</span>(<span class="st" style="color: #20794D;">"Empirical coverage: </span><span class="sc" style="color: #5E5E5E;">$</span>(<span class="fu" style="color: #4758AB;">round</span>(_eval.measurement[<span class="fl" style="color: #AD0000;">1</span>], digits<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3</span>))<span class="st" style="color: #20794D;">"</span>)</span>
<span id="cb10-13"><span class="fu" style="color: #4758AB;">println</span>(<span class="st" style="color: #20794D;">"SSC: </span><span class="sc" style="color: #5E5E5E;">$</span>(<span class="fu" style="color: #4758AB;">round</span>(_eval.measurement[<span class="fl" style="color: #AD0000;">2</span>], digits<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3</span>))<span class="st" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="ansi-escaped-output">
<pre>PerformanceEvaluation object with these fields:
  measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows
Extract:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ measure                                                   ‚îÇ operation ‚îÇ meas ‚ãØ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ emp_coverage (generic function with 1 method)             ‚îÇ predict   ‚îÇ 0.99 ‚ãØ
‚îÇ size_stratified_coverage (generic function with 1 method) ‚îÇ predict   ‚îÇ 0.94 ‚ãØ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span class="ansi-cyan-fg">                                                               3 columns omitted</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Empirical coverage: 0.991
SSC: 0.948</code></pre>
</div>
</div>
<p>We can also have a look at the resulting set size for both approaches using a custom <code>Plots.jl</code> recipe (fig-setsize). In line with the above, the spread is wider for the adaptive approach, which reflects that ‚Äúthe procedure is effectively distinguishing between easy and hard inputs‚Äù <span class="citation" data-cites="angelopoulos2021gentle">(A. N. Angelopoulos and Bates 2021)</span>.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb12-1">plt_list <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb12-2"><span class="cf" style="color: #003B4F;">for</span> (_mod, mach) <span class="kw" style="color: #003B4F;">in</span> results</span>
<span id="cb12-3">    <span class="fu" style="color: #4758AB;">push!</span>(plt_list, <span class="fu" style="color: #4758AB;">bar</span>(mach.model, mach.fitresult, X; title<span class="op" style="color: #5E5E5E;">=</span><span class="fu" style="color: #4758AB;">String</span>(_mod)))</span>
<span id="cb12-4"><span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb12-5"><span class="fu" style="color: #4758AB;">plot</span>(plt_list<span class="op" style="color: #5E5E5E;">...</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">800</span>,<span class="fl" style="color: #AD0000;">300</span>))</span>
<span id="cb12-6"><span class="fu" style="color: #4758AB;">plot</span>(plt_list<span class="op" style="color: #5E5E5E;">...</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">800</span>,<span class="fl" style="color: #AD0000;">300</span>),bg_colour<span class="op" style="color: #5E5E5E;">=:</span>transparent)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<div id="fig-setsize" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/index_files/figure-html/fig-setsize-output-1.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3: Distribution of set sizes for both approaches.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">üîÅ Recap</h2>
<p>In this short guide we have seen how easy it is to conformalize a deep learning image classifier in Julia using <code>ConformalPrediction.jl</code>. Almost any deep neural network trained in <code>Flux.jl</code> is compatible with <code>MLJ.jl</code> and can therefore be conformalized in just a few lines of code. This makes it remarkably easy to move uncertainty heuristics to rigorous predictive uncertainty estimates. We have also seen a sneak peek at performance evaluation of conformal predictors. Stay tuned for more!</p>
</section>
<section id="references" class="level2">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">üéì References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-angelopoulos2021gentle" class="csl-entry">
Angelopoulos, Anastasios N., and Stephen Bates. 2021. <span>‚ÄúA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.‚Äù</span> <a href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>.
</div>
<div id="ref-angelopoulos2022uncertainty" class="csl-entry">
Angelopoulos, Anastasios, Stephen Bates, Jitendra Malik, and Michael I. Jordan. 2022. <span>‚ÄúUncertainty <span>Sets</span> for <span>Image Classifiers</span> Using <span>Conformal Prediction</span>.‚Äù</span> <span>arXiv</span>. <a href="http://arxiv.org/abs/2009.14193">http://arxiv.org/abs/2009.14193</a>.
</div>
<div id="ref-goodfellow2014explaining" class="csl-entry">
Goodfellow, Ian J, Jonathon Shlens, and Christian Szegedy. 2014. <span>‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù</span> <a href="https://arxiv.org/abs/1412.6572">https://arxiv.org/abs/1412.6572</a>.
</div>
<div id="ref-lecun1998mnist" class="csl-entry">
LeCun, Yann. 1998. <span>‚ÄúThe <span>MNIST</span> Database of Handwritten Digits.‚Äù</span>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>For a full tutorial on how to build an MNIST image classifier relying solely on <code>Flux.jl</code>, check out this <a href="https://fluxml.ai/Flux.jl/stable/tutorials/2021-01-26-mlp/">tutorial</a>.‚Ü©Ô∏é</p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {How to {Conformalize} a {Deep} {Image} {Classifier}},
  date = {22-12-05},
  url = {https://www.paltmeyer.com/blog//blog/posts/conformal-image-classifier},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 22AD. <span>‚ÄúHow to Conformalize a Deep Image
Classifier.‚Äù</span> December 5, 22AD. <a href="https://www.paltmeyer.com/blog//blog/posts/conformal-image-classifier">https://www.paltmeyer.com/blog//blog/posts/conformal-image-classifier</a>.
</div></div></section></div> ]]></description>
  <category>conformal prediction</category>
  <category>uncertainty</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/index.html</guid>
  <pubDate>Sun, 04 Dec 2022 23:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>A year of using Quarto with Julia</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/www/images/julia_quarto.gif" class="figure-img">
<figcaption class="figure-caption">
A year of using Quarto with Julia.
</figcaption>
</figure>
</div>
<p>Earlier this year in July, I gave a short Experience Talk at <a href="https://pretalx.com/juliacon-2022/speaker/8DGYCX/">JuliaCon</a>. In a related blog <a href="../../../blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html">post</a> I explained how the introduction of Quarto made my transition from R to Julia painless: I would be able to start learning Julia without having to give up on all the benefits associated with R Markdown.</p>
<p>In November, 2022, I am presenting on this topic again at the <a href="https://www.linkedin.com/feed/update/urn:li:activity:6995656928957718528?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A6995656928957718528%29">2nd JuliaLang Eindhoven meetup</a>. In addition to the <a href="../../../content/talks/posts/2022-julia-eindhoven/index.html">slides</a>, I thought I‚Äôd share a small companion blog post that highlights some useful tips and tricks for anyone interested in using Quarto with Julia.</p>
<section id="general-things" class="level2">
<h2 class="anchored" data-anchor-id="general-things">General things</h2>
<p>We will start in this section with a few general recommendations.</p>
<section id="setup" class="level3">
<h3 class="anchored" data-anchor-id="setup">Setup</h3>
<p>I continue to recommend using VSCode for any work with Quarto and Julia. The Quarto <a href="https://quarto.org/docs/computations/julia.html#vs-code">docs</a> explain how to get started by installing the necessary Quarto and IJulia extensions. Since most Julia users will regularly want to update their Julia version, I would additionally recommend to add <code>IJulia.jl</code> to your <code>~/.julia/config/startup.jl</code> file:<sup>1</sup></p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># Setup OhMyREPL, Revise and Term</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> <span class="bu" style="color: null;">Pkg</span></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;">let</span></span>
<span id="cb1-4">    pkgs <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"Revise"</span>, <span class="st" style="color: #20794D;">"OhMyREPL"</span>, <span class="st" style="color: #20794D;">"Term"</span>, <span class="st" style="color: #20794D;">"IJulia"</span>]</span>
<span id="cb1-5">    <span class="cf" style="color: #003B4F;">for</span> pkg <span class="kw" style="color: #003B4F;">in</span> pkgs</span>
<span id="cb1-6">        <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">Base</span>.<span class="fu" style="color: #4758AB;">find_package</span>(pkg) <span class="op" style="color: #5E5E5E;">===</span> <span class="cn" style="color: #8f5902;">nothing</span></span>
<span id="cb1-7">            <span class="bu" style="color: null;">Pkg</span>.<span class="fu" style="color: #4758AB;">add</span>(pkg)</span>
<span id="cb1-8">        <span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb1-9">    <span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb1-10"><span class="kw" style="color: #003B4F;">end</span></span></code></pre></div>
<p>Additionally, you only need to remember that ‚Ä¶</p>
<blockquote class="blockquote">
<p>‚Ä¶ if you install a new Julia binary [‚Ä¶], you must update the IJulia installation [‚Ä¶] by running <code>Pkg.build("IJulia")</code></p>
<p>‚Äî Source: <a href="https://julialang.github.io/IJulia.jl/stable/manual/installation/#Updating-Julia-and-IJulia">IJulia docs</a></p>
</blockquote>
<p>I guess this step can also be automated in <code>~/.julia/config/startup.jl</code>, but haven‚Äôt tried that yet.</p>
</section>
<section id="using-.ipynb-vs-.qmd" class="level3">
<h3 class="anchored" data-anchor-id="using-.ipynb-vs-.qmd">Using <code>.ipynb</code> vs <code>.qmd</code></h3>
<p>I also continue to recommend working with Quarto notebooks as opposed to Jupyter notebooks (files ending in <code>.qmd</code> and <code>.ipynb</code>, respectively). This is partially just based on preference (from R Markdown I‚Äôm used to working with <code>.Rmd</code> files), but there is also a good reason to consider using <code>.qmd</code>, even if you‚Äôre used to working with Jupyter: the code chunks in your Quarto notebook automatically link to the Julia REPL in VSCode. In other words, you can run code chunks in your notebook and then access any variable that you may have created in the REPL. I find this quite useful, cause it allows me to quickly test code. Perhaps there‚Äôs a good way to do this with Jupyter notebooks as well, but when I last used them I would always have to insert new code cells to test stuff.</p>
<p>Either way switching between Jupyter and Quarto notebooks is straight-forward: <code>quarto convert notebook.qmd</code> will convert any Quarto notebook into a Jupyter notebook and vice versa. One potential benefit of Jupyter notebooks is their connection to Google Colab: it is possible to store Jupyter notebooks on Github and make them available on Colab, allowing users to quickly interact with your code without the need to clone anything. If this is important to you, you can still work with <code>.qmd</code> documents and simply specify <code>keep-ipynb: true</code> in the YAML header.</p>
</section>
<section id="dynamic-content" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-content">Dynamic Content</h3>
<blockquote class="blockquote">
<p>The world and the data that describes it is not static üìà. Why should scientific outputs be?</p>
</blockquote>
<p>One of the things I have always really loved about R Markdown was the ability to use inline code: the Knitr engine allows you to call and render any object <code>x</code> that you have created in preceding R chunks like this: <code>r x</code>. This is very powerful, because it enables us to bridge the gap between computations and output. In other words, it allows us to easily produce reproducible and dynamic content.</p>
<p>Until recently I had not been aware that this is also possible for Julia. Consider the following example. The code below depends on remote data that is continuously updated:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">MarketData</span></span>
<span id="cb2-2">snp <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">yahoo</span>(<span class="st" style="color: #20794D;">"^GSPC"</span>)</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Dates</span></span>
<span id="cb2-5">last_trade_day <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">timestamp</span>(snp[<span class="kw" style="color: #003B4F;">end</span>])[<span class="fl" style="color: #AD0000;">1</span>]</span>
<span id="cb2-6">p_close <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">values</span>(snp[<span class="kw" style="color: #003B4F;">end</span>,<span class="op" style="color: #5E5E5E;">:</span>Close])[<span class="fl" style="color: #AD0000;">1</span>]</span>
<span id="cb2-7">last_trade_day_formatted <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">Dates</span>.<span class="fu" style="color: #4758AB;">format</span>(last_trade_day, <span class="st" style="color: #20794D;">"U d, yyyy"</span>)</span></code></pre></div>
</div>
<p>It loads the most recent publicly available data on equity prices from Yahoo finance. In an ideal world, we‚Äôd like any updates to these inputs to be reflected in our output. That way you can just re-render the Quarto notebook to get an updated report. To render Julia code inline, we use <code>Markdown.jl</code> like so:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Markdown</span></span>
<span id="cb3-2">Markdown.<span class="fu" style="color: #4758AB;">parse</span>(<span class="st" style="color: #20794D;">"""</span></span>
<span id="cb3-3"><span class="st" style="color: #20794D;">When the S&amp;P 500 last traded, on </span><span class="sc" style="color: #5E5E5E;">$</span>(last_trade_day_formatted)<span class="st" style="color: #20794D;">, it closed at </span><span class="sc" style="color: #5E5E5E;">$</span>(p_close)<span class="st" style="color: #20794D;">. </span></span>
<span id="cb3-4"><span class="st" style="color: #20794D;">"""</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<p>When the S&amp;P 500 last traded, on February 23, 2023, it closed at 4012.320068.</p>
</div>
</div>
<p>In practice, one would of course set <code>#| echo: false</code> in this case. Whatever content you publish, this approach will keep it up-to-date. This practice of simply re-rendering the source notebook also ensures that any other output remains up-to-date (e.g. Figure&nbsp;1)</p>
<div class="cell" data-execution_count="3">
<div class="cell-output cell-output-display" data-execution_count="4">
<div id="fig-snp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/tips-and-tricks-for-using-quarto-with-julia/index_files/figure-html/fig-snp-output-1.svg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Price history of the S&amp;P 500.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="code-execution" class="level3">
<h3 class="anchored" data-anchor-id="code-execution">Code Execution</h3>
<p>Related to the previous point, I typically define the following execution options in my <code>_quarto.yml</code> or <code>_metadata.yml</code>. The <code>freeze: auto</code> option ensures that documents are only rerendered if the source changes. In cases where code should always be re-executed you whould want to set <code>freeze: false</code>, instead. I set <code>output: false</code> because typically I have a lot of code chunks that don‚Äôt generate any output that is of immediate interest to readers.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode yml code-with-copy"><code class="sourceCode yaml"><span id="cb4-1"><span class="fu" style="color: #4758AB;">execute</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb4-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">freeze</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> auto</span></span>
<span id="cb4-3"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">eval</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">true</span></span>
<span id="cb4-4"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">echo</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">true</span></span>
<span id="cb4-5"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">output</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">false</span></span></code></pre></div>
</section>
<section id="reproducibility" class="level3">
<h3 class="anchored" data-anchor-id="reproducibility">Reproducibility</h3>
<p>To ensure that your content can be repoduced easily, it may additionally be helpful to explicitly specify the Julia version you used (<code>jupyter: julia-1.8</code>) and set up a global or local Julia environments. Inserting the following at the beginning of your Quarto notebook</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Pkg; Pkg</span>.<span class="fu" style="color: #4758AB;">activate</span>(<span class="st" style="color: #20794D;">"&lt;path&gt;"</span>)</span></code></pre></div>
<p>ensures that the desired environemnt that lives in <code>&lt;path&gt;</code> is actually activated and used.</p>
</section>
</section>
<section id="package-documentation" class="level2">
<h2 class="anchored" data-anchor-id="package-documentation">Package Documentation</h2>
<p>I have also continued to use Quarto in combination with <code>Documenter.jl</code> to document my Julia packages. This essentially boils down to writing up documentation using interactive <code>.qmd</code> notebooks and then rendering those to <code>.md</code> files as inputs for <code>Documenter.jl</code>. There are a few good reasons for this approach, especially if you‚Äôre used to working with Quarto anyway:</p>
<ol type="1">
<li>Re-rendering any docs with <code>eval: true</code> provides an additional layer of quality assurance: if any of the code chunks throws an error, you know that your documentation is outdated (perhaps due to an API change). It also offers a straight-forward way to test package functions that produce non-testable (e.g.&nbsp;stochastic) output. In such cases, the use of <code>jldoctest</code> is not always straight-forward (see <a href="https://github.com/JuliaDocs/Documenter.jl/issues/452">here</a>).</li>
<li>You get some stuff for free, e.g.&nbsp;citation management. Unfortunately, as far as I‚Äôm aware there is still no support for cross-referencing.</li>
<li>You can use Quarto execution options like <code>execute-dir: project</code> and <code>resources: www/</code> to globally specify the working directory and a directory for external resources like images.</li>
</ol>
<p>There are also a few peculiarities to be aware of. To avoid any issues with <code>Documenter.jl</code>, I‚Äôve found it useful to ensure that the rendered <code>.md</code> files do not contain any raw HTML and to preserve text wrapping:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode yml code-with-copy"><code class="sourceCode yaml"><span id="cb6-1"><span class="fu" style="color: #4758AB;">format</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span></span>
<span id="cb6-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">commonmark</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb6-3"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">variant</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> -raw_html</span></span>
<span id="cb6-4"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">wrap</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> preserve</span></span></code></pre></div>
<p>When working with <code>.qmd</code> files you also need to use a slightly different syntax for <a href="https://documenter.juliadocs.org/stable/showcase/#Admonitions">admonitions</a>. The following syntax inside the <code>.qmd</code></p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode md code-with-copy"><code class="sourceCode markdown"><span id="cb7-1">| !!! note \"An optional title\"</span>
<span id="cb7-2">|     Here is something that you should pay attention to.   </span></code></pre></div>
<p>will generate the desired output inside the rendered <code>.md</code>:<sup>2</sup></p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode md code-with-copy"><code class="sourceCode markdown"><span id="cb8-1">!!! note "An optional title"</span>
<span id="cb8-2">    Here is something that you should pay attention to.   </span></code></pre></div>
<p>Any of my package repos ‚Äî <a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl"><code>CounterfactualExplanations.jl</code></a>, <a href="https://github.com/juliatrustworthyai/LaplaceRedux.jl"><code>LaplaceRedux.jl</code></a>, <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> ‚Äî should provide additional colour on this topic.</p>
</section>
<section id="quarto-for-academic-journal-articles" class="level2">
<h2 class="anchored" data-anchor-id="quarto-for-academic-journal-articles">Quarto for Academic Journal Articles</h2>
<p>Quarto supports <img src="https://latex.codecogs.com/png.latex?%5CLaTeX"> templates/classes, which has helped me with paper submissions in the past (e.g.&nbsp;my pending JuliaCon Proceedings submissions). I‚Äôve found that <a href="https://pkgs.rstudio.com/rticles/articles/rticles.html"><code>rticles</code></a> still has an edge here, but the <a href="https://quarto.org/docs/extensions/listing-journals.html">list</a> of out-of-the-box templates for journal articles is growing. Should I find some time in the future, I will try to add a template for JuliaCon Proceedings. The beauty of this is that it should enable publishers to not only use traditional forms of publication (PDF), but also include more dynamic formats with ease (think <a href="https://distill.pub/">distill</a>, but more than that.)</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping up</h2>
<p>This short post has provided a bit of an update on using Quarto with Julia. From my own experience so far, things have been getting easier and better (thanks to the amazing work of Quarto dev team). I‚Äôm exicted to see things improve even further and still think that Quarto is a revolutionary new tool for scientific publishing. Let‚Äôs hope publishers eventually recognise this value üëÄ.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Unrelated to Quarto, but this <a href="https://discourse.julialang.org/t/what-is-in-your-startup-jl/18228/21">thread</a> on discourse is full of other useful ideas for your <code>startup.jl</code>.‚Ü©Ô∏é</p></li>
<li id="fn2"><p>See related <a href="https://github.com/quarto-dev/quarto-cli/discussions/2947">discussion</a>.‚Ü©Ô∏é</p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {A Year of Using {Quarto} with {Julia}},
  date = {22-11-21},
  url = {https://www.paltmeyer.com/blog//blog/posts/tips-and-tricks-for-using-quarto-with-julia},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 22AD. <span>‚ÄúA Year of Using Quarto with
Julia.‚Äù</span> November 21, 22AD. <a href="https://www.paltmeyer.com/blog//blog/posts/tips-and-tricks-for-using-quarto-with-julia">https://www.paltmeyer.com/blog//blog/posts/tips-and-tricks-for-using-quarto-with-julia</a>.
</div></div></section></div> ]]></description>
  <category>Quarto</category>
  <category>Julia</category>
  <category>open-source</category>
  <category>reproducibility</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html</guid>
  <pubDate>Sun, 20 Nov 2022 23:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/www/images/julia_quarto.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conformal Prediction in Julia üü£üî¥üü¢</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Prediction sets for two different samples <br> and changing coverage rates. <br> As coverage grows, so does the size of the <br> prediction sets.
</figcaption>
</figure>
</div>
<p>A first crucial step towards building trustworthy AI systems is to be transparent about predictive uncertainty. Model parameters are random variables and their values are estimated from noisy data. That inherent stochasticity feeds through to model predictions and should to be addressed, at the very least in order to avoid overconfidence in models.</p>
<p>Beyond that obvious concern, it turns out that quantifying model uncertainty actually opens up a myriad of possibilities to improve up- and down-stream modeling tasks like active learning and robustness. In Bayesian Active Learning, for example, uncertainty estimates are used to guide the search for new input samples, which can make ground-truthing tasks more efficient <span class="citation" data-cites="houlsby2011bayesian">(Houlsby et al. 2011)</span>. With respect to model performance in downstream tasks, uncertainty quantification can be used to improve model calibration and robustness <span class="citation" data-cites="lakshminarayanan2016simple">(Lakshminarayanan, Pritzel, and Blundell 2016)</span>.</p>
<p>In previous posts we have looked at how uncertainty can be quantified in the Bayesian context (see <a href="https://www.paltmeyer.com/blog/posts/bayesian-logit/">here</a> and <a href="https://www.paltmeyer.com/blog/posts/effortsless-bayesian-dl/">here</a>). Since in Bayesian modeling we are generally concerned with estimating posterior distributions, we get uncertainty estimates almost as a byproduct. This is great for all intends and purposes, but it hinges on assumptions about prior distributions. Personally, I have no quarrel with the idea of making prior distributional assumptions. On the contrary, I think the Bayesian framework formalizes the idea of integrating prior information in models and therefore provides a powerful toolkit for conducting science. Still, in some cases this requirement may be seen as too restrictive or we may simply lack prior information.</p>
<p>Enter: Conformal Prediction (CP) ‚Äî a scalable frequentist approach to uncertainty quantification and coverage control. In this post we will go through the basic concepts underlying CP. A number of hands-on usage examples in Julia should hopefully help to convey some intuition and ideally attract people interested in contributing to a new and exciting open-source development.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üèÉ‚Äç‚ôÄÔ∏è TL;DR
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Conformal Prediction is an interesting frequentist approach to uncertainty quantification that can even be combined with Bayes (Section&nbsp;1).</li>
<li>It is scalable and model-agnostic and therefore well applicable to machine learning (Section&nbsp;1).</li>
<li><a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> implements CP in pure Julia and can be used with any supervised model available from <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> (Section&nbsp;2).</li>
<li>Implementing CP directly on top of an existing, powerful machine learning toolkit demonstrates the potential usefulness of this framework to the ML community (Section&nbsp;2).</li>
<li>Standard conformal classifiers produce set-valued predictions: for ambiguous samples these sets are typically large (for high coverage) or empty (for low coverage) (Section&nbsp;2.1).</li>
</ol>
</div>
</div>
<section id="sec-background" class="level2">
<h2 class="anchored" data-anchor-id="sec-background">üìñ Background</h2>
<p>Conformal Prediction promises to be an easy-to-understand, distribution-free and model-agnostic way to generate statistically rigorous uncertainty estimates. That‚Äôs quite a mouthful, so let‚Äôs break it down: firstly, as I will hopefully manage to illustrate in this post, the underlying concepts truly are fairly straight-forward to understand; secondly, CP indeed relies on only minimal distributional assumptions; thirdly, common procedures to generate conformal predictions really do apply almost universally to all supervised models, therefore making the framework very intriguing to the ML community; and, finally, CP does in fact come with a frequentist coverage guarantee that ensures that conformal prediction sets contain the true value with a user-chosen probability. For a formal proof of this <em>marginal coverage</em> property and a detailed introduction to the topic, I recommend <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In what follows we will loosely treat the tutorial by <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span> and the general framework it sets as a reference. You are not expected to have read the paper, but I also won‚Äôt reiterate any details here.</p>
</div>
</div>
<p>CP can be used to generate prediction intervals for regression models and prediction sets for classification models (more on this later). There is also some recent work on conformal predictive distributions and probabilistic predictions. Interestingly, it can even be used to complement Bayesian methods. <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span>, for example, point out that prior information should be incorporated into prediction sets and demonstrate how Bayesian predictive distributions can be conformalized in order to comply with the frequentist notion of coverage. Relatedly, <span class="citation" data-cites="hoff2021bayesoptimal">Hoff (2021)</span> proposes a Bayes-optimal prediction procedure. And finally, <span class="citation" data-cites="stanton2022bayesian">Stanton, Maddox, and Wilson (2022)</span> very recently proposed a way to introduce conformal prediction in Bayesian Optimization. I find this type of work that combines different schools of thought very promising, but I‚Äôm drifting off a little ‚Ä¶ So, without further ado, let us look at some code.</p>
</section>
<section id="sec-julia" class="level2">
<h2 class="anchored" data-anchor-id="sec-julia">üì¶ Conformal Prediction in Julia</h2>
<p>In this section of this first short post on CP we will look at how conformal prediction can be implemented in Julia. In particular, we will look at an approach that is compatible with any of the many supervised machine learning models available in <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a>: a beautiful, comprehensive machine learning framework funded by the <a href="https://www.turing.ac.uk/">Alan Turing Institute</a> and the <a href="https://www.mbie.govt.nz/science-and-technology/science-and-innovation/funding-information-and-opportunities/investment-funds/strategic-science-investment-fund/ssif-funded-programmes/university-of-auckland/">New Zealand Strategic Science Investment Fund</a> <span class="citation" data-cites="blaom2020mlj">Blaom et al. (2020)</span>. We will go through some basic usage examples employing a new Julia package that I have been working on: <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>ConformalPrediction.jl</code> is a package for uncertainty quantification through conformal prediction for machine learning models trained in <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a>. At the time of writing it is still in its early stages of development, but already implements a range of different approaches to CP. Contributions are very much welcome:</p>
<ul>
<li><a href="https://www.paltmeyer.com/ConformalPrediction.jl/stable/">Documentation</a></li>
<li><a href="https://www.paltmeyer.com/ConformalPrediction.jl/stable/#Contribute">Contributor‚Äôs Guide</a></li>
</ul>
</div>
</div>
<section id="sec-scp" class="level3">
<h3 class="anchored" data-anchor-id="sec-scp">Split Conformal Classification</h3>
<p>We consider a simple binary classification problem. Let <img src="https://latex.codecogs.com/png.latex?(X_i,%20Y_i),%20%5C%20i=1,...,n"> denote our feature-label pairs and let <img src="https://latex.codecogs.com/png.latex?%5Cmu:%20%5Cmathcal%7BX%7D%20%5Cmapsto%20%5Cmathcal%7BY%7D"> denote the mapping from features to labels. For illustration purposes we will use the moons dataset üåô. Using <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> we first generate the data and split into into a training and test set:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">MLJ</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Random</span></span>
<span id="cb1-3"><span class="bu" style="color: null;">Random</span>.<span class="fu" style="color: #4758AB;">seed!</span>(<span class="fl" style="color: #AD0000;">123</span>)</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;"># Data:</span></span>
<span id="cb1-6">X, y <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">make_moons</span>(<span class="fl" style="color: #AD0000;">500</span>; noise<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.15</span>)</span>
<span id="cb1-7">train, test <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">partition</span>(<span class="fu" style="color: #4758AB;">eachindex</span>(y), <span class="fl" style="color: #AD0000;">0.8</span>, shuffle<span class="op" style="color: #5E5E5E;">=</span><span class="cn" style="color: #8f5902;">true</span>)</span></code></pre></div>
</div>
<p>Here we will use a specific case of CP called <em>split conformal prediction</em> which can then be summarized as follows:<sup>1</sup></p>
<ol type="1">
<li>Partition the training into a proper training set and a separate calibration set: <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_n=%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Btrain%7D%7D%20%5Ccup%20%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Bcali%7D%7D">.</li>
<li>Train the machine learning model on the proper training set: <img src="https://latex.codecogs.com/png.latex?%5Chat%5Cmu_%7Bi%20%5Cin%20%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Btrain%7D%7D%7D(X_i,Y_i)">.</li>
<li>Compute nonconformity scores, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BS%7D">, using the calibration data <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Bcali%7D%7D"> and the fitted model <img src="https://latex.codecogs.com/png.latex?%5Chat%5Cmu_%7Bi%20%5Cin%20%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Btrain%7D%7D%7D">.</li>
<li>For a user-specified desired coverage ratio <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)"> compute the corresponding quantile, <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">, of the empirical distribution of nonconformity scores, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BS%7D">.</li>
<li>For the given quantile and test sample <img src="https://latex.codecogs.com/png.latex?X_%7B%5Ctext%7Btest%7D%7D">, form the corresponding conformal prediction set:</li>
</ol>
<p><span id="eq-set"><img src="https://latex.codecogs.com/png.latex?%0AC(X_%7B%5Ctext%7Btest%7D%7D)=%5C%7By:s(X_%7B%5Ctext%7Btest%7D%7D,y)%20%5Cle%20%5Chat%7Bq%7D%5C%7D%0A%5Ctag%7B1%7D"></span></p>
<p>This is the default procedure used for classification and regression in <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>.</p>
<p>You may want to take a look at the source code for the classification case <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl/blob/67712e870dc3a438bf0846d376fa48480612f042/src/ConformalModels/inductive_classification.jl#L1">here</a>. As a <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl/blob/67712e870dc3a438bf0846d376fa48480612f042/src/ConformalModels/inductive_classification.jl#L3">first</a> important step, we begin by defining a concrete type <code>SimpleInductiveClassifier</code> that wraps a supervised model from <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> and reserves additional fields for a few hyperparameters. As a <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl/blob/67712e870dc3a438bf0846d376fa48480612f042/src/ConformalModels/inductive_classification.jl#L26">second</a> step, we define the training procedure, which includes the data-splitting and calibration step. Finally, as a <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl/blob/67712e870dc3a438bf0846d376fa48480612f042/src/ConformalModels/inductive_classification.jl#L56">third</a> step we implement the procedure in Equation&nbsp;1 to compute the conformal prediction set.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Development Status
</div>
</div>
<div class="callout-body-container callout-body">
<p>The permalinks above take you to the version of the package that was up-to-date at the time of writing. Since the package is in its early stages of development, the code base and API can be expected to change.</p>
</div>
</div>
<p>Now let‚Äôs take this to our üåô data. To illustrate the package functionality we will demonstrate the envisioned workflow. We first define our atomic machine learning model following standard <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> conventions. Using <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> we then wrap our atomic model in a conformal model using the standard API call <code>conformal_model(model::Supervised; kwargs...)</code>. To train and predict from our conformal model we can then rely on the conventional <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> procedure again. In particular, we wrap our conformal model in data (turning it into a machine) and then fit it on the training set. Finally, we use our machine to predict the label for a new test sample <code>Xtest</code>:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># Model:</span></span>
<span id="cb2-2">KNNClassifier <span class="op" style="color: #5E5E5E;">=</span> <span class="pp" style="color: #AD0000;">@load</span> KNNClassifier pkg<span class="op" style="color: #5E5E5E;">=</span>NearestNeighborModels</span>
<span id="cb2-3">model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">KNNClassifier</span>(;K<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">50</span>) </span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;"># Training:</span></span>
<span id="cb2-6"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">ConformalPrediction</span></span>
<span id="cb2-7">conf_model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">.9</span>)</span>
<span id="cb2-8">mach <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(conf_model, X, y)</span>
<span id="cb2-9"><span class="fu" style="color: #4758AB;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;">=</span>train)</span>
<span id="cb2-10"></span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;"># Conformal Prediction:</span></span>
<span id="cb2-12">Xtest <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">selectrows</span>(X, <span class="fu" style="color: #4758AB;">first</span>(test))</span>
<span id="cb2-13">ytest <span class="op" style="color: #5E5E5E;">=</span> y[<span class="fu" style="color: #4758AB;">first</span>(test)]</span>
<span id="cb2-14"><span class="fu" style="color: #4758AB;">predict</span>(mach, Xtest)[<span class="fl" style="color: #AD0000;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>import NearestNeighborModels</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> ‚úî</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div class="ansi-escaped-output">
<pre>           <span class="ansi-bright-white-fg ansi-bold">UnivariateFinite{Multiclass{2}}</span>      
     <span class="ansi-bright-black-fg">‚îå                                        ‚îê</span> 
   0 <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.94 <span class="ansi-bright-black-fg"> </span> 
     <span class="ansi-bright-black-fg">‚îî                                        ‚îò</span> </pre>
</div>
</div>
</div>
<p>The final predictions are set-valued. While the softmax output remains unchanged for the <code>SimpleInductiveClassifier</code>, the size of the prediction set depends on the chosen coverage rate, <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)">.</p>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-display" data-execution_count="5">
<p>When specifying a coverage rate very close to one, the prediction set will typically include many (in some cases all) of the possible labels. Below, for example, both classes are included in the prediction set when setting the coverage rate equal to <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)">=1.0. This is intuitive, since high coverage quite literally requires that the true label is covered by the prediction set with high probability.</p>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1">conf_model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;">=</span>coverage)</span>
<span id="cb5-2">mach <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(conf_model, X, y)</span>
<span id="cb5-3"><span class="fu" style="color: #4758AB;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;">=</span>train)</span>
<span id="cb5-4"></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;"># Conformal Prediction:</span></span>
<span id="cb5-6">Xtest <span class="op" style="color: #5E5E5E;">=</span> (x1<span class="op" style="color: #5E5E5E;">=</span>[<span class="fl" style="color: #AD0000;">1</span>],x2<span class="op" style="color: #5E5E5E;">=</span>[<span class="fl" style="color: #AD0000;">0</span>])</span>
<span id="cb5-7"><span class="fu" style="color: #4758AB;">predict</span>(mach, Xtest)[<span class="fl" style="color: #AD0000;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div class="ansi-escaped-output">
<pre>           <span class="ansi-bright-white-fg ansi-bold">UnivariateFinite{Multiclass{2}}</span>      
     <span class="ansi-bright-black-fg">‚îå                                        ‚îê</span> 
   0 <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.5 <span class="ansi-bright-black-fg"> </span> 
   1 <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.5 <span class="ansi-bright-black-fg"> </span> 
     <span class="ansi-bright-black-fg">‚îî                                        ‚îò</span> </pre>
</div>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="cell-output cell-output-display" data-execution_count="7">
<p>Conversely, for low coverage rates, prediction sets can also be empty. For a choice of <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)">=0.1, for example, the prediction set for our test sample is empty. This is a bit difficult to think about intuitively and I have not yet come across a satisfactory, intuitive interpretation.<sup>2</sup> When the prediction set is empty, the <code>predict</code> call currently returns <code>missing</code>:</p>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1">conf_model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;">=</span>coverage)</span>
<span id="cb6-2">mach <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(conf_model, X, y)</span>
<span id="cb6-3"><span class="fu" style="color: #4758AB;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;">=</span>train)</span>
<span id="cb6-4"></span>
<span id="cb6-5"><span class="co" style="color: #5E5E5E;"># Conformal Prediction:</span></span>
<span id="cb6-6"><span class="fu" style="color: #4758AB;">predict</span>(mach, Xtest)[<span class="fl" style="color: #AD0000;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>missing</code></pre>
</div>
</div>
<p>Figure&nbsp;1 should provide some more intuition as to what exactly is happening here. It illustrates the effect of the chosen coverage rate on the predicted softmax output and the set size in the two-dimensional feature space. Contours are overlayed with the moon data points (including test data). The two samples highlighted in red, <img src="https://latex.codecogs.com/png.latex?X_1"> and <img src="https://latex.codecogs.com/png.latex?X_2">, have been manually added for illustration purposes. Let‚Äôs look at these one by one.</p>
<p>Firstly, note that <img src="https://latex.codecogs.com/png.latex?X_1"> (red cross) falls into a region of the domain that is characterized by high predictive uncertainty. It sits right at the bottom-right corner of our class-zero moon üåú (orange), a region that is almost entirely enveloped by our class-one moon üåõ (green). For low coverage rates the prediction set for <img src="https://latex.codecogs.com/png.latex?X_1"> is empty: on the left-hand side this is indicated by the missing contour for the softmax probability; on the right-hand side we can observe that the corresponding set size is indeed zero. For high coverage rates the prediction set includes both <img src="https://latex.codecogs.com/png.latex?y=0"> and <img src="https://latex.codecogs.com/png.latex?y=1">, indicative of the fact that the conformal classifier is uncertain about the true label.</p>
<p>With respect to <img src="https://latex.codecogs.com/png.latex?X_2">, we observe that while also sitting on the fringe of our class-zero moon, this sample populates a region that is not fully enveloped by data points from the opposite class. In this region, the underlying atomic classifier can be expected to be more certain about its predictions, but still not highly confident. How is this reflected by our corresponding conformal prediction sets?</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">Xtest_2 <span class="op" style="color: #5E5E5E;">=</span> (x1<span class="op" style="color: #5E5E5E;">=</span>[<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.5</span>],x2<span class="op" style="color: #5E5E5E;">=</span>[<span class="fl" style="color: #AD0000;">0.25</span>])</span>
<span id="cb8-2">cov_ <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">.9</span></span>
<span id="cb8-3">conf_model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;">=</span>cov_)</span>
<span id="cb8-4">mach <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(conf_model, X, y)</span>
<span id="cb8-5"><span class="fu" style="color: #4758AB;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;">=</span>train)</span>
<span id="cb8-6">pÃÇ_2 <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">pdf</span>(<span class="fu" style="color: #4758AB;">predict</span>(mach, Xtest_2)[<span class="fl" style="color: #AD0000;">1</span>], <span class="fl" style="color: #AD0000;">0</span>)</span></code></pre></div>
</details>
</div>
<div class="cell" data-execution_count="10">
<div class="cell-output cell-output-display" data-execution_count="11">
<p>Well, for low coverage rates (roughly <img src="https://latex.codecogs.com/png.latex?%3C0.9">) the conformal prediction set does not include <img src="https://latex.codecogs.com/png.latex?y=0">: the set size is zero (right panel). Only for higher coverage rates do we have <img src="https://latex.codecogs.com/png.latex?C(X_2)=%5C%7B0%5C%7D">: the coverage rate is high enough to include <img src="https://latex.codecogs.com/png.latex?y=0">, but the corresponding softmax probability is still fairly low. For example, for <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)=0.9"> we have <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bp%7D(y=0%7CX_2)=0.72."></p>
</div>
</div>
<p>These two examples illustrate an interesting point: for regions characterised by high predictive uncertainty, conformal prediction sets are typically empty (for low coverage) or large (for high coverage). While set-valued predictions may be something to get used to, this notion is overall intuitive.</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb9-1"><span class="co" style="color: #5E5E5E;"># Setup</span></span>
<span id="cb9-2">coverages <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">range</span>(<span class="fl" style="color: #AD0000;">0.75</span>,<span class="fl" style="color: #AD0000;">1.0</span>,length<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">5</span>)</span>
<span id="cb9-3">n <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">100</span></span>
<span id="cb9-4">x1_range <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">range</span>(<span class="fu" style="color: #4758AB;">extrema</span>(X.x1)<span class="op" style="color: #5E5E5E;">...</span>,length<span class="op" style="color: #5E5E5E;">=</span>n)</span>
<span id="cb9-5">x2_range <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">range</span>(<span class="fu" style="color: #4758AB;">extrema</span>(X.x2)<span class="op" style="color: #5E5E5E;">...</span>,length<span class="op" style="color: #5E5E5E;">=</span>n)</span>
<span id="cb9-6"></span>
<span id="cb9-7">anim <span class="op" style="color: #5E5E5E;">=</span> <span class="pp" style="color: #AD0000;">@animate</span> <span class="cf" style="color: #003B4F;">for</span> coverage <span class="kw" style="color: #003B4F;">in</span> coverages</span>
<span id="cb9-8">    conf_model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;">=</span>coverage)</span>
<span id="cb9-9">    mach <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">machine</span>(conf_model, X, y)</span>
<span id="cb9-10">    <span class="fu" style="color: #4758AB;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;">=</span>train)</span>
<span id="cb9-11">    p1 <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">contourf_cp</span>(mach, x1_range, x2_range; <span class="kw" style="color: #003B4F;">type</span><span class="op" style="color: #5E5E5E;">=:</span>proba, title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Softmax"</span>, axis<span class="op" style="color: #5E5E5E;">=</span><span class="cn" style="color: #8f5902;">nothing</span>)</span>
<span id="cb9-12">    <span class="fu" style="color: #4758AB;">scatter!</span>(p1, X.x1, X.x2, group<span class="op" style="color: #5E5E5E;">=</span>y, ms<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">2</span>, msw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.75</span>)</span>
<span id="cb9-13">    <span class="fu" style="color: #4758AB;">scatter!</span>(p1, Xtest.x1, Xtest.x2, ms<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">6</span>, c<span class="op" style="color: #5E5E5E;">=:</span>red, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"X‚ÇÅ"</span>, shape<span class="op" style="color: #5E5E5E;">=:</span>cross, msw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">6</span>)</span>
<span id="cb9-14">    <span class="fu" style="color: #4758AB;">scatter!</span>(p1, Xtest_2.x1, Xtest_2.x2, ms<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">6</span>, c<span class="op" style="color: #5E5E5E;">=:</span>red, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"X‚ÇÇ"</span>, shape<span class="op" style="color: #5E5E5E;">=:</span>diamond, msw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">6</span>)</span>
<span id="cb9-15">    p2 <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">contourf_cp</span>(mach, x1_range, x2_range; <span class="kw" style="color: #003B4F;">type</span><span class="op" style="color: #5E5E5E;">=:</span>set_size, title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Set size"</span>, axis<span class="op" style="color: #5E5E5E;">=</span><span class="cn" style="color: #8f5902;">nothing</span>)</span>
<span id="cb9-16">    <span class="fu" style="color: #4758AB;">scatter!</span>(p2, X.x1, X.x2, group<span class="op" style="color: #5E5E5E;">=</span>y, ms<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">2</span>, msw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.75</span>)</span>
<span id="cb9-17">    <span class="fu" style="color: #4758AB;">scatter!</span>(p2, Xtest.x1, Xtest.x2, ms<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">6</span>, c<span class="op" style="color: #5E5E5E;">=:</span>red, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"X‚ÇÅ"</span>, shape<span class="op" style="color: #5E5E5E;">=:</span>cross, msw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">6</span>)</span>
<span id="cb9-18">    <span class="fu" style="color: #4758AB;">scatter!</span>(p2, Xtest_2.x1, Xtest_2.x2, ms<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">6</span>, c<span class="op" style="color: #5E5E5E;">=:</span>red, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"X‚ÇÇ"</span>, shape<span class="op" style="color: #5E5E5E;">=:</span>diamond, msw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">6</span>)</span>
<span id="cb9-19">    <span class="fu" style="color: #4758AB;">plot</span>(p1, p2, plot_title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"(1-Œ±)=</span><span class="sc" style="color: #5E5E5E;">$</span>(<span class="fu" style="color: #4758AB;">round</span>(coverage,digits<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">2</span>))<span class="st" style="color: #20794D;">"</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">800</span>,<span class="fl" style="color: #AD0000;">300</span>))</span>
<span id="cb9-20"><span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb9-21"></span>
<span id="cb9-22"><span class="fu" style="color: #4758AB;">gif</span>(anim, fps<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>)</span></code></pre></div>
</details>
<div id="fig-anim" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/data:image/gif;base64,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" class="figure-img">
<p></p><figcaption class="figure-caption">Figure&nbsp;1: The effect of the coverage rate on the conformal prediction set. Softmax probabilities are shown on the left. The size of the prediction set is shown on the right.</figcaption><p></p>
</figure>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">üèÅ Conclusion</h2>
<p>This has really been a whistle-stop tour of Conformal Prediction: an active area of research that probably deserves much more attention. Hopefully, though, this post has helped to provide some color and, if anything, made you more curious about the topic. Let‚Äôs recap the TL;DR from above:</p>
<ol type="1">
<li>Conformal Prediction is an interesting frequentist approach to uncertainty quantification that can even be combined with Bayes (Section&nbsp;1).</li>
<li>It is scalable and model-agnostic and therefore well applicable to machine learning (Section&nbsp;1).</li>
<li><a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> implements CP in pure Julia and can be used with any supervised model available from <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> (Section&nbsp;2).</li>
<li>Implementing CP directly on top of an existing, powerful machine learning toolkit demonstrates the potential usefulness of this framework to the ML community (Section&nbsp;2).</li>
<li>Standard conformal classifiers produce set-valued predictions: for ambiguous samples these sets are typically large (for high coverage) or empty (for low coverage) (Section&nbsp;2.1).</li>
</ol>
<p>Below I will leave you with some further resources.</p>
</section>
<section id="further-resources" class="level2">
<h2 class="anchored" data-anchor-id="further-resources">üìö Further Resources</h2>
<p>Chances are that you have already come across the Awesome Conformal Prediction <a href="https://github.com/valeman/awesome-conformal-prediction">repo</a>: <span class="citation" data-cites="manokhin2022awesome">Manokhin (n.d.)</span> provides a comprehensive, up-to-date overview of resources related to the conformal prediction. Among the listed articles you will also find <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span>, which inspired much of this post. The repo also points to open-source implementations in other popular programming languages including Python and R.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-angelopoulos2021gentle" class="csl-entry">
Angelopoulos, Anastasios N., and Stephen Bates. 2021. <span>‚ÄúA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.‚Äù</span> <a href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>.
</div>
<div id="ref-blaom2020mlj" class="csl-entry">
Blaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. <span>‚Äú<span>MLJ</span>: <span>A Julia</span> Package for Composable Machine Learning.‚Äù</span> <em>Journal of Open Source Software</em> 5 (55): 2704. <a href="https://doi.org/10.21105/joss.02704">https://doi.org/10.21105/joss.02704</a>.
</div>
<div id="ref-hoff2021bayesoptimal" class="csl-entry">
Hoff, Peter. 2021. <span>‚ÄúBayes-Optimal Prediction with Frequentist Coverage Control.‚Äù</span> <a href="https://arxiv.org/abs/2105.14045">https://arxiv.org/abs/2105.14045</a>.
</div>
<div id="ref-houlsby2011bayesian" class="csl-entry">
Houlsby, Neil, Ferenc Husz√°r, Zoubin Ghahramani, and M√°t√© Lengyel. 2011. <span>‚ÄúBayesian Active Learning for Classification and Preference Learning.‚Äù</span> <a href="https://arxiv.org/abs/1112.5745">https://arxiv.org/abs/1112.5745</a>.
</div>
<div id="ref-lakshminarayanan2016simple" class="csl-entry">
Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2016. <span>‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù</span> <a href="https://arxiv.org/abs/1612.01474">https://arxiv.org/abs/1612.01474</a>.
</div>
<div id="ref-manokhin2022awesome" class="csl-entry">
Manokhin, Valery. n.d. <span>‚ÄúAwesome Conformal Prediction.‚Äù</span>
</div>
<div id="ref-stanton2022bayesian" class="csl-entry">
Stanton, Samuel, Wesley Maddox, and Andrew Gordon Wilson. 2022. <span>‚ÄúBayesian <span>Optimization</span> with <span>Conformal Coverage Guarantees</span>.‚Äù</span> <a href="https://arxiv.org/abs/2210.12496">https://arxiv.org/abs/2210.12496</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In other places split conformal prediction is sometimes referred to as <em>inductive</em> conformal prediction.‚Ü©Ô∏é</p></li>
<li id="fn2"><p>Any thoughts/comments welcome!‚Ü©Ô∏é</p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {Conformal {Prediction} in {Julia} üü£üî¥üü¢},
  date = {22-10-25},
  url = {https://www.paltmeyer.com/blog//blog/posts/conformal-prediction},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 22AD. <span>‚ÄúConformal Prediction in Julia
üü£üî¥üü¢.‚Äù</span> October 25, 22AD. <a href="https://www.paltmeyer.com/blog//blog/posts/conformal-prediction">https://www.paltmeyer.com/blog//blog/posts/conformal-prediction</a>.
</div></div></section></div> ]]></description>
  <category>conformal prediction</category>
  <category>uncertainty</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/index.html</guid>
  <pubDate>Mon, 24 Oct 2022 22:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>A new tool for explainable AI</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Turning a 9 (nine) into a 4 (four).
</figcaption>
</figure>
</div>
<!-- Intro -->
<p>Counterfactual explanations, which I introduced in one of my previous posts<sup>1</sup>, offer a simple and intuitive way to explain black-box models without opening them. Still, as of today there exists only one open-source library that provides a unifying approach to generate and benchmark counterfactual explanations for models built and trained in Python <span class="citation" data-cites="pawelczyk2021carla">(Pawelczyk et al. 2021)</span>. This is great, but of limited use to users of other programming languages ü•≤.</p>
<p>Enter <a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/stable/"><code>CounterfactualExplanations.jl</code></a>: a Julia package that can be used to explain machine learning algorithms developed and trained in Julia, Python and R. Counterfactual explanations fall into the broader category of explainable artificial intelligence (XAI).</p>
<p>Explainable AI typically involves models that are not inherently interpretable but require additional tools to be explainable to humans. Examples of the latter include ensembles, support vector machines and deep neural networks. This is not to be confused with interpretable AI, which involves models that are inherently interpretable and transparent such as general additive models (GAM), decision trees and rule-based models.</p>
<p>Some would argue that we best avoid explaining black-box models altogether <span class="citation" data-cites="rudin2019stop">(Rudin 2019)</span> and instead focus solely on interpretable AI. While I agree that initial efforts should always be geared towards interpretable models, stopping there would entail missed opportunities and anyway is probably not very realistic in times of <a href="https://openai.com/blog/dall-e/">DALL<img src="https://latex.codecogs.com/png.latex?%5Ccdot">E</a> and Co.</p>
<blockquote class="blockquote">
<p>Even though [‚Ä¶] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the ‚Äúblack box.‚Äù</p>
<p>‚Äî <span class="citation" data-cites="wachter2017counterfactual">Wachter, Mittelstadt, and Russell (2017)</span></p>
</blockquote>
<!-- Nut paragraph -->
<p>This post introduces the main functionality of the new Julia package. Following a motivating example using a model trained in Julia, we will see how easy the package can be adapted to work with models trained in Python and R. Since the motivation for this post is also to hopefully attract contributors, the final section outlines some of the exciting developments we have planned.</p>
<section id="counterfactuals-for-image-data" class="level2">
<h2 class="anchored" data-anchor-id="counterfactuals-for-image-data">Counterfactuals for image data üñº</h2>
<p>To introduce counterfactual explanations I used a simple binary classification problem in my previous <a href="https://towardsdatascience.com/individual-recourse-for-black-box-models-5e9ed1e4b4cc">post</a>. It involved a linear classifier and a linearly separable, synthetic data set with just two features. This time we are going to step it up a notch: we will generate counterfactual explanations MNIST data. The MNIST dataset contains 60,000 training samples of handwritten digits in the form of 28x28 pixel grey-scale images <span class="citation" data-cites="lecun1998mnist">(LeCun 1998)</span>. Each image is associated with a label indicating the digit (0-9) that the image represents.</p>
<p>The <a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/stable/"><code>CounterfactualExplanations.jl</code></a> package ships with two black-box models that were trained to predict labels for this data: firstly, a simple multi-layer perceptron (MLP) and, secondly, a corresponding deep ensemble. Originally proposed by <span class="citation" data-cites="lakshminarayanan2016simple">Lakshminarayanan, Pritzel, and Blundell (2016)</span>, deep ensembles are really just ensembles of deep neural networks. They are still among the most popular approaches to Bayesian deep learning.<sup>2</sup></p>
<section id="black-box-models" class="level3">
<h3 class="anchored" data-anchor-id="black-box-models">Black-box models</h3>
<p>The code below loads relevant packages along with the MNIST data and pre-trained models.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># Load package, models and data:</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">CounterfactualExplanations</span>, <span class="bu" style="color: null;">Flux</span></span>
<span id="cb1-3"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">CounterfactualExplanations.Data</span>: mnist_data, mnist_model, mnist_ensemble</span>
<span id="cb1-4">data, X, ys <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">mnist_data</span>()</span>
<span id="cb1-5">model <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">mnist_model</span>()</span>
<span id="cb1-6">ensemble <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">mnist_ensemble</span>()</span>
<span id="cb1-7">counterfactual_data <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">CounterfactualData</span>(X,ys;domain<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">0</span>,<span class="fl" style="color: #AD0000;">1</span>))</span></code></pre></div>
</div>
<p>While the package can currently handle a few simple classification models natively, it is designed to be easily extensible through users and contributors. Extending the package to deal with custom models typically involves only two simple steps:</p>
<ol type="1">
<li><strong>Subtyping</strong>: the custom model needs to be declared as a subtype of the package-internal type <code>AbstractFittedModel</code>.</li>
<li><strong>Multiple dispatch</strong>: the package-internal functions <code>logits</code> and <code>probs</code> need to be extended through custom methods for the new model type.</li>
</ol>
<p>The following code implements these two steps first for the MLP and then for the deep ensemble.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">CounterfactualExplanations.Models</span></span>
<span id="cb2-2"><span class="im" style="color: #00769E;">import</span> <span class="bu" style="color: null;">CounterfactualExplanations.Models</span>: logits, probs</span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;"># MLP:</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;"># Step 1)</span></span>
<span id="cb2-5"><span class="kw" style="color: #003B4F;">struct</span> NeuralNetwork <span class="op" style="color: #5E5E5E;">&lt;:</span><span class="dt" style="color: #AD0000;"> Models.AbstractFittedModel</span></span>
<span id="cb2-6">    model<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">Any</span></span>
<span id="cb2-7"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;"># Step 2)</span></span>
<span id="cb2-9"><span class="fu" style="color: #4758AB;">logits</span>(M<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">NeuralNetwork</span>, X<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">AbstractArray</span>) <span class="op" style="color: #5E5E5E;">=</span> M.<span class="fu" style="color: #4758AB;">model</span>(X)</span>
<span id="cb2-10"><span class="fu" style="color: #4758AB;">probs</span>(M<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">NeuralNetwork</span>, X<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">AbstractArray</span>)<span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">softmax</span>(<span class="fu" style="color: #4758AB;">logits</span>(M, X))</span>
<span id="cb2-11">M <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">NeuralNetwork</span>(model)</span>
<span id="cb2-12"></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;"># Deep ensemble:</span></span>
<span id="cb2-14"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Flux</span>: stack</span>
<span id="cb2-15"><span class="co" style="color: #5E5E5E;"># Step 1)</span></span>
<span id="cb2-16"><span class="kw" style="color: #003B4F;">struct</span> FittedEnsemble <span class="op" style="color: #5E5E5E;">&lt;:</span><span class="dt" style="color: #AD0000;"> Models.AbstractFittedModel</span></span>
<span id="cb2-17">    ensemble<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">AbstractArray</span></span>
<span id="cb2-18"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb2-19"><span class="co" style="color: #5E5E5E;"># Step 2)</span></span>
<span id="cb2-20"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Statistics</span></span>
<span id="cb2-21"><span class="fu" style="color: #4758AB;">logits</span>(M<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">FittedEnsemble</span>, X<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">AbstractArray</span>) <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">mean</span>(<span class="fu" style="color: #4758AB;">stack</span>([<span class="fu" style="color: #4758AB;">m</span>(X) for m <span class="kw" style="color: #003B4F;">in</span> M.ensemble],<span class="fl" style="color: #AD0000;">3</span>),dims<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3</span>)</span>
<span id="cb2-22"><span class="fu" style="color: #4758AB;">probs</span>(M<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">FittedEnsemble</span>, X<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">AbstractArray</span>) <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">mean</span>(<span class="fu" style="color: #4758AB;">stack</span>([<span class="fu" style="color: #4758AB;">softmax</span>(<span class="fu" style="color: #4758AB;">m</span>(X)) for m <span class="kw" style="color: #003B4F;">in</span> M.ensemble],<span class="fl" style="color: #AD0000;">3</span>),dims<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">3</span>)</span>
<span id="cb2-23">M_ensemble <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">FittedEnsemble</span>(ensemble)</span></code></pre></div>
</div>
</section>
<section id="counterfactual-generators" class="level3">
<h3 class="anchored" data-anchor-id="counterfactual-generators">Counterfactual generators</h3>
<p>Next, we need to specify the counterfactual generators we want to use. The package currently ships with two default generators that both need gradient access: firstly, the generic generator introduced by <span class="citation" data-cites="wachter2017counterfactual">Wachter, Mittelstadt, and Russell (2017)</span> and, secondly, a greedy generator introduced by <span class="citation" data-cites="schut2021generating">Schut et al. (2021)</span>.</p>
<p>The greedy generator is designed to be used with models that incorporate uncertainty in their predictions such as the deep ensemble introduced above. It works for probabilistic (Bayesian) models, because they only produce high-confidence predictions in regions of the feature domain that are populated by training samples. As long as the model is expressive enough and well-specified, counterfactuals in these regions will always be realistic and unambiguous since by construction they should look very similar to training samples. Other popular approaches to counterfactual explanations like REVISE <span class="citation" data-cites="joshi2019realistic">(Joshi et al. 2019)</span> and CLUE <span class="citation" data-cites="antoran2020getting">(Antor√°n et al. 2020)</span> also play with this simple idea.</p>
<p>The following code instantiates the two generators for the problem at hand.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1">generic <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">GenericGenerator</span>(;loss<span class="op" style="color: #5E5E5E;">=:</span>logitcrossentropy)</span>
<span id="cb3-2">greedy <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">GreedyGenerator</span>(;loss<span class="op" style="color: #5E5E5E;">=:</span>logitcrossentropy)</span></code></pre></div>
</div>
</section>
<section id="explanations" class="level3">
<h3 class="anchored" data-anchor-id="explanations">Explanations</h3>
<p>Once the model and counterfactual generator are specified, running counterfactual search is very easy using the package. For a given factual (<code>x</code>), target class (<code>target</code>) and data set (<code>counterfactual_data</code>), simply running</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1"><span class="fu" style="color: #4758AB;">generate_counterfactual</span>(x, target, counterfactual_data, M, generic)</span></code></pre></div>
</div>
<p>will generate the results, in this case using the generic generator (<code>generic</code>) for the MLP (<code>M</code>). Since we have specified two different black-box models and two different counterfactual generators, we have four combinations of a model and a generator in total. For each of these combinations I have used the <code>generate_counterfactual</code> function to produce the results in Figure&nbsp;1.</p>
<p>In every case the desired label switch is in fact achieved, but arguably from a human perspective only the counterfactuals for the deep ensemble look like a four. The generic generator produces mild perturbations in regions that seem irrelevant from a human perspective, but nonetheless yields a counterfactual that can pass as a four. The greedy approach clearly targets pixels at the top of the handwritten nine and yields the best result overall. For the non-Bayesian MLP, both the generic and the greedy approach generate counterfactuals that look much like adversarial examples: they perturb pixels in seemingly random regions on the image.</p>
<div id="fig-mnist-9to4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/www/mnist_9_to_4.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Counterfactual explanations for MNIST: turning a nine (9) into a four (4).</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="language-interoperability" class="level2">
<h2 class="anchored" data-anchor-id="language-interoperability">Language interoperability üë•</h2>
<p>The Julia language offers unique support for programming language interoperability. For example, calling R or Python is made remarkably easy through <code>RCall.jl</code> and <code>PyCall.jl</code>, respectively. This functionality can be leveraged to use <code>CounterfactualExplanations.jl</code> to generate explanations for models that were developed in other programming languages. At this time there is no native support for foreign programming languages, but the following example involving a <code>torch</code> neural network trained in <code>R</code> demonstrates how versatile the package is.<sup>3</sup></p>
<section id="explaining-a-torch-model" class="level3">
<h3 class="anchored" data-anchor-id="explaining-a-torch-model">Explaining a <code>torch</code> model</h3>
<p>We will consider a simple MLP trained for a binary classification task. As before we first need to adapt this custom model for use with our package. The code below the two necessary steps - sub-typing and method extension. Logits are returned by the <code>torch</code> model and copied from the R environment into the Julia scope. Probabilities are then computed inside the Julia scope by passing the logits through the sigmoid function.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Flux</span></span>
<span id="cb5-2"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">CounterfactualExplanations</span>, <span class="bu" style="color: null;">CounterfactualExplanations.Models</span></span>
<span id="cb5-3"><span class="im" style="color: #00769E;">import</span> <span class="bu" style="color: null;">CounterfactualExplanations.Models</span>: logits, probs <span class="co" style="color: #5E5E5E;"># import functions in order to extend</span></span>
<span id="cb5-4"></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;"># Step 1)</span></span>
<span id="cb5-6"><span class="kw" style="color: #003B4F;">struct</span> TorchNetwork <span class="op" style="color: #5E5E5E;">&lt;:</span><span class="dt" style="color: #AD0000;"> Models.AbstractFittedModel</span></span>
<span id="cb5-7">    nn<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">Any</span></span>
<span id="cb5-8"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb5-9"></span>
<span id="cb5-10"><span class="co" style="color: #5E5E5E;"># Step 2)</span></span>
<span id="cb5-11"><span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">logits</span>(M<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">TorchNetwork</span>, X<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">AbstractArray</span>)</span>
<span id="cb5-12">  nn <span class="op" style="color: #5E5E5E;">=</span> M.nn</span>
<span id="cb5-13">  y <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">rcopy</span>(R<span class="st" style="color: #20794D;">"as_array(</span><span class="sc" style="color: #5E5E5E;">$</span>nn<span class="st" style="color: #20794D;">(torch_tensor(t(</span><span class="sc" style="color: #5E5E5E;">$</span>X<span class="st" style="color: #20794D;">))))"</span>)</span>
<span id="cb5-14">  y <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">isa</span>(y, <span class="dt" style="color: #AD0000;">AbstractArray</span>) ? y <span class="op" style="color: #5E5E5E;">:</span> [y]</span>
<span id="cb5-15">  <span class="cf" style="color: #003B4F;">return</span> y<span class="op" style="color: #5E5E5E;">'</span></span>
<span id="cb5-16"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb5-17"><span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">probs</span>(M<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">TorchNetwork</span>, X<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">AbstractArray</span>)</span>
<span id="cb5-18">  <span class="cf" style="color: #003B4F;">return</span> <span class="fu" style="color: #4758AB;">œÉ</span>.(<span class="fu" style="color: #4758AB;">logits</span>(M, X))</span>
<span id="cb5-19"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb5-20">M <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">TorchNetwork</span>(R<span class="st" style="color: #20794D;">"model"</span>)</span></code></pre></div>
</div>
<p>Compared to models trained in Julia, we need to do a little more work at this point. Since our counterfactual generators need gradient access, we essentially need to allow our package to communicate with the R <code>torch</code> library. While this may sound daunting, it turns out to be quite manageable: all we have to do is respecify the function that computes the gradient with respect to the counterfactual loss function so that it can deal with the <code>TorchNetwork</code> type we defined above. That is all the adjustment needed to use <code>CounterfactualExplanations.jl</code> for our custom R model. Figure&nbsp;2 shows a counterfactual path for a randomly chosen sample with respect to the MLP trained in R.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Experimental functionality
</div>
</div>
<div class="callout-body-container callout-body">
<p>You may have stumbled across the term <em>respecify</em> above: does it really seem like a good idea to just replace an existing function from our package? Surely not! There are certainly better ways to go about this, which we will consider when adding native support for Python and R models in future package releases. Which brings us to our final section ‚Ä¶</p>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><span class="im" style="color: #00769E;">import</span> <span class="bu" style="color: null;">CounterfactualExplanations.Generators</span>: ‚àÇ‚Ñì</span>
<span id="cb6-2"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">LinearAlgebra</span></span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="co" style="color: #5E5E5E;"># Countefactual loss:</span></span>
<span id="cb6-5"><span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">‚àÇ‚Ñì</span>(</span>
<span id="cb6-6">    generator<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">AbstractGradientBasedGenerator</span>, </span>
<span id="cb6-7">    counterfactual_state<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">CounterfactualState</span>) </span>
<span id="cb6-8">  M <span class="op" style="color: #5E5E5E;">=</span> counterfactual_state.M</span>
<span id="cb6-9">  nn <span class="op" style="color: #5E5E5E;">=</span> M.nn</span>
<span id="cb6-10">  x‚Ä≤ <span class="op" style="color: #5E5E5E;">=</span> counterfactual_state.x‚Ä≤</span>
<span id="cb6-11">  t <span class="op" style="color: #5E5E5E;">=</span> counterfactual_state.target_encoded</span>
<span id="cb6-12">  R<span class="st" style="color: #20794D;">"""</span></span>
<span id="cb6-13"><span class="st" style="color: #20794D;">  x &lt;- torch_tensor(</span><span class="sc" style="color: #5E5E5E;">$</span>x<span class="st" style="color: #20794D;">‚Ä≤, requires_grad=TRUE)</span></span>
<span id="cb6-14"><span class="st" style="color: #20794D;">  output &lt;- </span><span class="sc" style="color: #5E5E5E;">$</span>nn<span class="st" style="color: #20794D;">(x)</span></span>
<span id="cb6-15"><span class="st" style="color: #20794D;">  loss_fun &lt;- nnf_binary_cross_entropy_with_logits</span></span>
<span id="cb6-16"><span class="st" style="color: #20794D;">  obj_loss &lt;- loss_fun(output,</span><span class="sc" style="color: #5E5E5E;">$</span>t<span class="st" style="color: #20794D;">)</span></span>
<span id="cb6-17"><span class="st" style="color: #20794D;">  obj_loss</span><span class="sc" style="color: #5E5E5E;">$</span>backward<span class="st" style="color: #20794D;">()</span></span>
<span id="cb6-18"><span class="st" style="color: #20794D;">  """</span></span>
<span id="cb6-19">  grad <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">rcopy</span>(R<span class="st" style="color: #20794D;">"as_array(x</span><span class="sc" style="color: #5E5E5E;">$</span>grad<span class="st" style="color: #20794D;">)"</span>)</span>
<span id="cb6-20">  <span class="cf" style="color: #003B4F;">return</span> grad</span>
<span id="cb6-21"><span class="kw" style="color: #003B4F;">end</span></span></code></pre></div>
</div>
<div id="fig-torch" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/www/interop_r.gif" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Counterfactual path using the generic counterfactual generator for a model trained in R.</figcaption><p></p>
</figure>
</div>
<!-- kicker -->
</section>
</section>
<section id="we-need-you" class="level2">
<h2 class="anchored" data-anchor-id="we-need-you">We need you! ü´µ</h2>
<p>The ambition for <code>CounterfactualExplanations.jl</code> is to provide a go-to place for counterfactual explanations to the Julia community and beyond. This is a grand ambition, especially for a package that has so far been built by a single developer who has little prior experience with Julia. We would therefore very much like to invite community contributions. If you have an interest in trustworthy AI, the open-source community and Julia, please do get involved! This package is still in its early stages of development, so any kind of contribution is welcome: advice on the core package architecture, pull requests, issues, discussions and even just comments below would be much appreciated.</p>
<p>To give you a flavor of what type of future developments we envision, here is a non-exhaustive list:</p>
<ol type="1">
<li>Native support for additional counterfactual generators and predictive models including those built and trained in Python or R.</li>
<li>Additional datasets for testing, evaluation and benchmarking.</li>
<li>Improved preprocessing including native support for categorical features.</li>
<li>Support for regression models.</li>
</ol>
<p>Finally, if you like this project but don‚Äôt have much time, then simply sharing this article or starring the <a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl">repo</a> on GitHub would also go a long way.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading üìö</h2>
<p>If you‚Äôre interested in learning more about this development, feel free to check out the following resources:</p>
<ul>
<li>Package docs: <a href="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/stable">[stable]</a>, <a href="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/dev">[dev]</a>.</li>
<li><a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/stable/contributing/">Contributor‚Äôs guide</a>.</li>
<li><a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl">GitHub repo</a>.</li>
</ul>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-antoran2020getting" class="csl-entry">
Antor√°n, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and Jos√© Miguel Hern√°ndez-Lobato. 2020. <span>‚ÄúGetting a Clue: <span>A</span> Method for Explaining Uncertainty Estimates.‚Äù</span> <a href="https://arxiv.org/abs/2006.06848">https://arxiv.org/abs/2006.06848</a>.
</div>
<div id="ref-joshi2019realistic" class="csl-entry">
Joshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. <span>‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù</span> <a href="https://arxiv.org/abs/1907.09615">https://arxiv.org/abs/1907.09615</a>.
</div>
<div id="ref-lakshminarayanan2016simple" class="csl-entry">
Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2016. <span>‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù</span> <a href="https://arxiv.org/abs/1612.01474">https://arxiv.org/abs/1612.01474</a>.
</div>
<div id="ref-lecun1998mnist" class="csl-entry">
LeCun, Yann. 1998. <span>‚ÄúThe <span>MNIST</span> Database of Handwritten Digits.‚Äù</span>
</div>
<div id="ref-pawelczyk2021carla" class="csl-entry">
Pawelczyk, Martin, Sascha Bielawski, Johannes van den Heuvel, Tobias Richter, and Gjergji Kasneci. 2021. <span>‚ÄúCarla: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms.‚Äù</span> <a href="https://arxiv.org/abs/2108.00783">https://arxiv.org/abs/2108.00783</a>.
</div>
<div id="ref-rudin2019stop" class="csl-entry">
Rudin, Cynthia. 2019. <span>‚ÄúStop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.‚Äù</span> <em>Nature Machine Intelligence</em> 1 (5): 206‚Äì15.
</div>
<div id="ref-schut2021generating" class="csl-entry">
Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. <span>‚ÄúGenerating <span>Interpretable Counterfactual Explanations By Implicit Minimisation</span> of <span>Epistemic</span> and <span>Aleatoric Uncertainties</span>.‚Äù</span> In <em>International <span>Conference</span> on <span>Artificial Intelligence</span> and <span>Statistics</span></em>, 1756‚Äì64. <span>PMLR</span>.
</div>
<div id="ref-wachter2017counterfactual" class="csl-entry">
Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. <span>‚ÄúCounterfactual Explanations Without Opening the Black Box: <span>Automated</span> Decisions and the <span>GDPR</span>.‚Äù</span> <em>Harv. JL &amp; Tech.</em> 31: 841.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See: [<a href="https://towardsdatascience.com/individual-recourse-for-black-box-models-5e9ed1e4b4cc">TDS</a>], [<a href="https://www.paltmeyer.com/blog/posts/individual-recourse-for-black-box-models/">blog</a>]‚Ü©Ô∏é</p></li>
<li id="fn2"><p>For more information on Bayesian deep learning see my previous post: [<a href="https://towardsdatascience.com/go-deep-but-also-go-bayesian-ab25efa6f7b">TDS</a>], [<a href="https://www.paltmeyer.com/blog/posts/effortsless-bayesian-dl/">blog</a>].‚Ü©Ô∏é</p></li>
<li id="fn3"><p>The corresponding example involving <code>PyTorch</code> is analogous and therefore not included here. You may find it <a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/dev/tutorials/interop/">here</a>.‚Ü©Ô∏é</p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {A New Tool for Explainable {AI}},
  date = {22-04-20},
  url = {https://www.paltmeyer.com/blog//blog/posts/a-new-tool-for-explainable-ai},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 22AD. <span>‚ÄúA New Tool for Explainable AI.‚Äù</span>
April 20, 22AD. <a href="https://www.paltmeyer.com/blog//blog/posts/a-new-tool-for-explainable-ai">https://www.paltmeyer.com/blog//blog/posts/a-new-tool-for-explainable-ai</a>.
</div></div></section></div> ]]></description>
  <category>counterfactuals</category>
  <category>explainable AI</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/index.html</guid>
  <pubDate>Tue, 19 Apr 2022 22:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Julia and Quarto: a match made in heaven? üå§</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/julia-and-quarto-a-match-made-in-heaven/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Julia and Quarto: a perfect match.
</figcaption>
</figure>
</div>
<p>Does your work involve research, coding, writing and publishing? If so, then chances are that you often find yourself bouncing back and forth between different open-source text editors, IDEs, programming languages and platforms depending on your current needs. Using a diverse set of tools is reasonable, because there typically is no single perfect approach that solves all our problems. For example, interactive notebooks like Jupyter are useful for working with code and communicating it to others, but they are probably not anyone‚Äôs first choice for producing a scientific article. Similarly, Beamer presentations can be useful for presenting science in a standardized fashion, but they are the very opposite of interactive and look incredibly boring.</p>
<p>As much as the great variety of free tools deserves being celebrated, all this bouncing back and forth can be really tiring. What if there was a single tool, an engine that can turn your work into all kinds of different outputs? I mean literally any output you can think of: Markdown, HTML, PDF, LateX, ePub, entire websites, presentations (yes, also Beamer if you have to), MS Word, OpenOffice, ‚Ä¶ the list goes on. All of that starting from the same place: a plain Markdown document blended with essentially any programming language of your choice and a YAML header defining your output. This tool now exists and it goes by the name <a href="https://quarto.org/">Quarto</a>.</p>
<p>In this short blog post I hope to convince you that Quarto is the only publishing engine you will ever need. What I am definitely not going to tell you is which IDE, text editor or programming language you should be using to actually produce your work. Quarto does not care about that. Quarto is here to make your life a bit easier (and by ‚Äòa bit‚Äô I mean a whole lot). Quarto is nothing less but a revolution for scientific publishing.</p>
<p>To put this all in some context (well, my context), I will now tell you a bit about what has led me to making such bold claims about yet another open-source tool.</p>
<blockquote class="blockquote">
<p>Hold up?! Wasn‚Äôt this supposed to be about Julia and Quarto?</p>
</blockquote>
<p>Yes! But it‚Äôs worth noting that a lot of the benefits that Quarto brings have been available to R users for many years, thanks to the amazing work of many great open-source contributors like <a href="https://twitter.com/xieyihui">@xieyihui</a>. Julia was the main reason for me to branch out of this comfortable R bubble as I describe below. That said, if you are a Julia user who really couldn‚Äôt care less about my previous experiences with R Markdown, this is a good time to skip straight ahead to Section&nbsp;2. By the way, if you haven‚Äôt clicked on that link, here‚Äôs a small showcase demonstrating how it was generated. It shows easy it is to have everything well organised and connected with Quarto.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Cross-referencing
</div>
</div>
<div class="callout-body-container callout-body">
<p>There is a standard recipe for generating cross-references in Quarto. The example below involves a section cross-reference.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1">If you are a Julia user that really couldn't care less about my previous experiences with R Markdown, this is a good time to skip straight ahead to @sec-match.</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;">## Quarto and Julia - a perfect match {#sec-match}</span></span></code></pre></div>
<p>There is actually a comprehensive 8-step guide explaining how to achieve something similar in MS Word, but personally I wouldn‚Äôt go there. Anyway, take your pick:</p>
<ol type="a">
<li>üî¥ <a href="https://support.microsoft.com/en-us/office/create-a-cross-reference-300b208c-e45a-487a-880b-a02767d9774b">Go there</a>.</li>
<li>üü¢ Move on to Section&nbsp;1 #safespace.</li>
</ol>
</div>
</div>
<section id="sec-bubble" class="level2">
<h2 class="anchored" data-anchor-id="sec-bubble">A comfortable bubble üéà</h2>
<p>For many years I have used R Markdown for essentially anything work-related. As an undergraduate economics student facing the unfortunate reality that people still teach Stata, I was drawn to R. This was partially because R has a great open-source community and also partially because Stata. Once I realised that I would be able to use R Markdown to write up all of my future homework assignments and even my thesis, I never looked back. MS Word was now officially dead to me. Overleaf was nothing more than a last resort if everyone else in my team insisted on using it for a group project. Being able to write my undergraduate dissertation in R Markdown was a first truly triumphant moment. Soon after that I would also try myself at Shiny, produce outputs in HTML and build entire websites through <code>blogdown</code>. And all of that from within R Studio involving R and Markdown and really not much else. During my first professional job at the Bank of England I was reluctant to use anything other than R Markdown to produce all of my output. Luckily for me, the Bank was very much heading in that same direction at the time and my reluctance was not perceived as stubbornness, but actually welcome (at least I hoped so).</p>
<section id="cracks-in-the-bubble" class="level4">
<h4 class="anchored" data-anchor-id="cracks-in-the-bubble">Cracks in the bubble üß®</h4>
<p>Soon though, part of me felt a little boxed in. For any work that required me to look outside of the R bubble, I knew I might also have to give up a very, very comfortable work environment and my productivity would surely take a hit. During my master‚Äôs in Data Science, for example, the mantra was very much ‚ÄúPython + Jupyter or die‚Äù. Through <a href="https://rstudio.github.io/reticulate/"><code>reticulate</code></a> and R Studio‚Äôs growing support for Python I managed to get by without having to leave my bubble too often. But <code>reticulate</code> always felt a little clunky (sorry!) and some professors were reluctant to accept anything other than Jupyter notebooks. Even if others had not perceived it that way in the past, I certainly started to feel that I might just be a little too attached the beautiful bubble that R Studio had created around me.</p>
</section>
<section id="enter-julia" class="level4">
<h4 class="anchored" data-anchor-id="enter-julia">Enter: Julia üí£</h4>
<p>Then there was Julia: elegant, fast, pure, scientific and - oh my REPL! - those beautiful colors and unicode symbols. The stuff of dreams, really! Geeky dreams, but dreams nonetheless. I had once before given Julia a shot when working with high-frequency trade data for a course in market microstructure. This was the first time R really revealed its limitations to me and my bubble nearly burst, but thanks to <code>data.table</code> and <code>Rcpp</code> I managed to escape with only minor bruises. Still, Julia kept popping up, teasing me whenever I would work on some Frakenstein-style C++ code snippets that would hopefully resolve my R bottlenecks. I actually enjoyed mixing <strong>some</strong> C++ into my R code like I did <a href="https://github.com/pat-alt/reinforcement_learning">here</a>, but the process was just a little painful and slow. But wouldn‚Äôt learning <strong>all of</strong> Julia take even more time and patience? And what about my dependence on R Markdown?</p>
</section>
<section id="julia-bursts-my-bubble" class="level4">
<h4 class="anchored" data-anchor-id="julia-bursts-my-bubble">Julia bursts my bubble üí•</h4>
<p>As I started my PhD in September 2021, I eventually gave in. New beginnings - time to suck it up! If it meant that I‚Äôd have to use Jupyter notebooks with Julia, so be it! And so I was off to a somewhat bumpy start that would have me bouncing back and forth between trying to make Julia work in R Studio (meh), setting up Jupyter Lab (meeeh), just using the Julia REPL because ‚Äúthe REPL is all you need‚Äù (nope) and even struggling with Vim and Emacs. Then there was also <code>Pluto.jl</code>, of course, which admittedly looks amazing! But it also looks very much tailored to Julia and (I believe) the number of different output formats you can produce is still very limited. Eventually, I settled for VSCode in combination with Jupyter notebooks. As much as I dreaded the latter, Jupyter is popular, arguably versatile and supports both R and Julia. This setup worked well enough for me, but it still definitely fell short of the breeze that R Studio had always provided. One thing that really bugged me, for example, was the fact that the IJulia kernel was not accessible from the Julia REPL. Each notebook would have its own environment, which could only be accessed through the notebook. In R Studio the interaction between R Markdown and the console is seamless, as both have access to the same environment variables.</p>
</section>
<section id="enter-quarto" class="level4">
<h4 class="anchored" data-anchor-id="enter-quarto">Enter: Quarto ‚ù§Ô∏è‚Äçü©π</h4>
<p>Around the same time that I started using Julia, I read about Quarto for the first time. It looked ‚Ä¶ great! Like a timely little miracle really! But also ‚Ä¶ unfinished? Definitely experimental at the time. I loved the idea though and in a footnote somewhere on their website it said that the project was supported by R Studio which I took as a very good sign. So I decided to at least give it a quick try and built a small (tiny) <a href="https://www.paltmeyer.com/tai/">website</a> summarising some of the literature I had read for my PhD:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Just had my first go <a href="https://twitter.com/hashtag/quarto?src=hash&amp;ref_src=twsrc%5Etfw">#quarto</a> and I absolutely love the concept! Open-source and language agnostic - truly amazing work from <a href="https://twitter.com/rstudio?ref_src=twsrc%5Etfw">&amp;#64rstudio</a> <a href="https://t.co/veCg7ywQ8v">https://t.co/veCg7ywQ8v</a>
</p>
‚Äî Patrick Altmeyer (&amp;#64paltmey) <a href="https://twitter.com/paltmey/status/1454042807019180035?ref_src=twsrc%5Etfw">October 29, 2021</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This was a first very pleasant encounter with Quarto, arguable even smoother than building websites in <code>blogdown</code>. As for working with Julia though, I had made up my mind that VSCode was the way to go and at the time there was no Quarto extension (there is <a href="https://marketplace.visualstudio.com/items?itemName=quarto.quarto">now</a>). There was also little in terms of communication about the project by R Studio, probably because things were really still in the early development stages. I was hopeful that eventually Quarto would enable me to emulate the R Studio experience in VS Code, but for now things were not quite there yet.</p>
</section>
<section id="quarto-keeps-growing" class="level4">
<h4 class="anchored" data-anchor-id="quarto-keeps-growing">Quarto keeps growing ü§û</h4>
<p>Since I was now working with VSCode + Jupyter and since Quarto supports Jupyter as well as all of my old R Markdown work, my next little Quarto project involved turning my old <code>blogdown</code>-powered blog into a Quarto-powered <a href="https://www.paltmeyer.com/blog/">blog</a>. This was not strictly necessary, as I could always export my new Jupyter notebooks to HTML and let <code>blogdown</code> do the rest. But it did streamline things a little bit and the default Quarto blog theme - you are staring at it - is actually üî•. I also did not have to feel guilty towards <a href="https://twitter.com/xieyihui">@xieyihui</a> about leaving <code>blogdown</code>, because unsurprisingly he is on the Quarto team. As I was working on this little project I started noticing that the Quarto website was updated regularly and responses to issues I opened like this <a href="https://github.com/quarto-dev/quarto-cli/issues/293">one</a> were answered very swiftly. Clearly, things were moving and they were moving fast. More recently, the news about Quarto has been spreading and it‚Äôs left some folks as confused and amazed as I was, when I first heard about it:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
<a href="https://twitter.com/hashtag/RStats?src=hash&amp;ref_src=twsrc%5Etfw">#RStats</a> can someone explain to me what's the difference between {Quarto} and {RMarkdown}? I saw a tweet about Quarto and now I'm all confused ‚Ä¶ What gap is it supposed to fill?
</p>
‚Äî Erwin Lares (&amp;#64lasrubieras) <a href="https://twitter.com/lasrubieras/status/1509014670262390784?ref_src=twsrc%5Etfw">March 30, 2022</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This is why finally I‚Äôve decided I should write a brief post about how and why I use Quarto. Since I have been working mostly with Julia for the past couple of months, I‚Äôve chosen to focus on the interaction between Quarto and Julia. Coincidentally, yesterday was also the first time I saw a <a href="https://quarto.org/docs/computations/julia.html">guide</a> dedicated to Julia on the Quarto website, so evidently I am not the only one interested in that marriage. This also means that there really is not too much left for me to talk about now, since Quarto‚Äôs documentation is state-of-the-art. But a few bits and pieces I mention below might hopefully still be useful or at least some food for thought.</p>
</section>
</section>
<section id="sec-match" class="level2">
<h2 class="anchored" data-anchor-id="sec-match">Quarto and Julia: a perfect match üíôüíúüíö</h2>
<p>While what follows may be relevant to other programming languages, my main goal for this last section is to flag Quarto to the Julia community. In any case, #rstats folks have been using R and Python in R Markdown documents for a while now and won‚Äôt need much of an introduction to Quarto. As for Python aficionados, I can only recommend to give Quarto a shot (you will still be able to use Jupyter notebooks).</p>
<section id="working-with-vscode-quarto-and-julia" class="level4">
<h4 class="anchored" data-anchor-id="working-with-vscode-quarto-and-julia">Working with VSCode, Quarto and Julia</h4>
<p>The very article you are reading right now was composed in a Quarto document. These documents feel and look very much like standard Julia Markdown documents, but you can do a lot more with them. You can find the source code for this and other documents presented in this blog <a href="https://github.com/pat-alt/blog">here</a>.</p>
<p>To get you started, here is my current setup combining VSCode, Quarto and Julia:</p>
<ol type="1">
<li>VSCode extensions: in addition to the <a href="https://marketplace.visualstudio.com/items?itemName=julialang.language-julia">Julia extension</a> you will need the <a href="https://marketplace.visualstudio.com/items?itemName=quarto.quarto">Quarto extension</a>. In addition, the <a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-yaml">YAML extension</a> and some extension to preview Markdown docs would be helpful. I am not sure if <a href="https://marketplace.visualstudio.com/items?itemName=colinfang.markdown-julia">Markdown Julia</a> and <a href="https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter">Jupyter</a> are strictly necessary, but it won‚Äôt hurt.</li>
<li>I do most of my work in Quarto documents <code>.qmd</code>.</li>
<li>If you choose to also do that, make sure that the <code>.qmd</code> document has access to a <code>Pkg.jl</code> environment that has <code>IJulia</code> added.</li>
</ol>
<p>Julia code cells can be added anywhere along with your plain text Markdown. They look like this:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><span class="in" style="color: #5E5E5E;">```{julia}</span></span>
<span id="cb2-2">using Pkg</span>
<span id="cb2-3">Pkg.add(<span class="ot" style="color: #003B4F;">"</span><span class="st" style="color: #20794D;">CounterfactualExplanations</span><span class="ot" style="color: #003B4F;">"</span>)</span>
<span id="cb2-4"><span class="in" style="color: #5E5E5E;">```</span></span></code></pre></div>
<p>Contrary to Jupyter notebooks, executing this code cells will start a Julia REPL in VSCode. I find this very helpful, because it lets me fiddle with anything I have created inside the Quarto notebook without having to click into cells all the time. Quarto comes with great support for specifying <a href="https://quarto.org/docs/computations/julia.html">code executing options</a>. For example, for the code below I have specified <code>#| echo: true</code> in order for the code to be rendered. The code itself is the code I actually used to build the animation above (heavily borrowed from this <code>Javis.jl</code> <a href="https://juliaanimators.github.io/Javis.jl/stable/tutorials/tutorial_7/">tutorial</a>).</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="co" style="color: #5E5E5E;">#| echo: true</span></span>
<span id="cb3-2"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Javis</span>, <span class="bu" style="color: null;">Animations</span>, <span class="bu" style="color: null;">Colors</span></span>
<span id="cb3-3"></span>
<span id="cb3-4">size <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">600</span></span>
<span id="cb3-5">radius_factor <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.33</span></span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">ground</span>(args<span class="op" style="color: #5E5E5E;">...</span>)</span>
<span id="cb3-8">    <span class="fu" style="color: #4758AB;">background</span>(<span class="st" style="color: #20794D;">"transparent"</span>)</span>
<span id="cb3-9">    <span class="fu" style="color: #4758AB;">sethue</span>(<span class="st" style="color: #20794D;">"white"</span>)</span>
<span id="cb3-10"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb3-11"></span>
<span id="cb3-12"><span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">rotate_anim</span>(idx<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">Number</span>, total<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">Number</span>) </span>
<span id="cb3-13">    distance_circle <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.875</span></span>
<span id="cb3-14">    steps <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">collect</span>(<span class="fu" style="color: #4758AB;">range</span>(distance_circle,<span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>distance_circle,length<span class="op" style="color: #5E5E5E;">=</span>total))</span>
<span id="cb3-15">    <span class="fu" style="color: #4758AB;">Animation</span>(</span>
<span id="cb3-16">        [<span class="fl" style="color: #AD0000;">0</span>, <span class="fl" style="color: #AD0000;">1</span>], <span class="co" style="color: #5E5E5E;"># must go from 0 to 1</span></span>
<span id="cb3-17">        [<span class="fl" style="color: #AD0000;">0</span>, steps[idx]<span class="op" style="color: #5E5E5E;">*</span><span class="fl" style="color: #AD0000;">2</span>œÄ],</span>
<span id="cb3-18">        [<span class="fu" style="color: #4758AB;">sineio</span>()],</span>
<span id="cb3-19">    )</span>
<span id="cb3-20"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb3-21"></span>
<span id="cb3-22">translate_anim <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Animation</span>(</span>
<span id="cb3-23">    [<span class="fl" style="color: #AD0000;">0</span>, <span class="fl" style="color: #AD0000;">1</span>], <span class="co" style="color: #5E5E5E;"># must go from 0 to 1</span></span>
<span id="cb3-24">    [O, <span class="fu" style="color: #4758AB;">Point</span>(size<span class="op" style="color: #5E5E5E;">*</span>radius_factor, <span class="fl" style="color: #AD0000;">0</span>)],</span>
<span id="cb3-25">    [<span class="fu" style="color: #4758AB;">sineio</span>()],</span>
<span id="cb3-26">)</span>
<span id="cb3-27"></span>
<span id="cb3-28">translate_back_anim <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Animation</span>(</span>
<span id="cb3-29">    [<span class="fl" style="color: #AD0000;">0</span>, <span class="fl" style="color: #AD0000;">1</span>], <span class="co" style="color: #5E5E5E;"># must go from 0 to 1</span></span>
<span id="cb3-30">    [O, <span class="fu" style="color: #4758AB;">Point</span>(<span class="fu" style="color: #4758AB;">-</span>(size<span class="op" style="color: #5E5E5E;">*</span>radius_factor), <span class="fl" style="color: #AD0000;">0</span>)],</span>
<span id="cb3-31">    [<span class="fu" style="color: #4758AB;">sineio</span>()],</span>
<span id="cb3-32">)</span>
<span id="cb3-33"></span>
<span id="cb3-34">julia_colours <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Dict</span>(</span>
<span id="cb3-35">    <span class="op" style="color: #5E5E5E;">:</span>blue <span class="op" style="color: #5E5E5E;">=&gt;</span> <span class="st" style="color: #20794D;">"#4063D8"</span>,</span>
<span id="cb3-36">    <span class="op" style="color: #5E5E5E;">:</span>green <span class="op" style="color: #5E5E5E;">=&gt;</span> <span class="st" style="color: #20794D;">"#389826"</span>,</span>
<span id="cb3-37">    <span class="op" style="color: #5E5E5E;">:</span>purple <span class="op" style="color: #5E5E5E;">=&gt;</span> <span class="st" style="color: #20794D;">"#9558b2"</span>,</span>
<span id="cb3-38">    <span class="op" style="color: #5E5E5E;">:</span>red <span class="op" style="color: #5E5E5E;">=&gt;</span> <span class="st" style="color: #20794D;">"#CB3C33"</span></span>
<span id="cb3-39">)</span>
<span id="cb3-40">colour_order <span class="op" style="color: #5E5E5E;">=</span> [<span class="op" style="color: #5E5E5E;">:</span>red, <span class="op" style="color: #5E5E5E;">:</span>purple, <span class="op" style="color: #5E5E5E;">:</span>green, <span class="op" style="color: #5E5E5E;">:</span>blue]</span>
<span id="cb3-41">n_colours <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">length</span>(julia_colours)</span>
<span id="cb3-42"><span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">color_anim</span>(start_colour<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">String</span>, quarto_col<span class="op" style="color: #5E5E5E;">::</span><span class="dt" style="color: #AD0000;">String</span>=<span class="st" style="color: #20794D;">"#4b95d0"</span>)</span>
<span id="cb3-43">    <span class="fu" style="color: #4758AB;">Animation</span>(</span>
<span id="cb3-44">        [<span class="fl" style="color: #AD0000;">0</span>, <span class="fl" style="color: #AD0000;">1</span>], <span class="co" style="color: #5E5E5E;"># must go from 0 to 1</span></span>
<span id="cb3-45">        [<span class="fu" style="color: #4758AB;">Lab</span>(<span class="fu" style="color: #4758AB;">color</span>(start_colour)), <span class="fu" style="color: #4758AB;">Lab</span>(<span class="fu" style="color: #4758AB;">color</span>(quarto_col))],</span>
<span id="cb3-46">        [<span class="fu" style="color: #4758AB;">sineio</span>()],</span>
<span id="cb3-47">    )</span>
<span id="cb3-48"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb3-49"></span>
<span id="cb3-50">video <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Video</span>(size, size)</span>
<span id="cb3-51"></span>
<span id="cb3-52">frame_starts <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span><span class="fl" style="color: #AD0000;">10</span><span class="op" style="color: #5E5E5E;">:</span><span class="fl" style="color: #AD0000;">40</span></span>
<span id="cb3-53">n_total <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">250</span></span>
<span id="cb3-54">n_frames <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">150</span></span>
<span id="cb3-55"><span class="fu" style="color: #4758AB;">Background</span>(<span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span>n_total, ground)</span>
<span id="cb3-56"></span>
<span id="cb3-57"><span class="co" style="color: #5E5E5E;"># Blob:</span></span>
<span id="cb3-58"><span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">element</span>(; radius <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1</span>)</span>
<span id="cb3-59">    <span class="fu" style="color: #4758AB;">circle</span>(O, radius, <span class="op" style="color: #5E5E5E;">:</span>fill) <span class="co" style="color: #5E5E5E;"># The 4 is to make the circle not so small</span></span>
<span id="cb3-60"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb3-61"></span>
<span id="cb3-62"><span class="co" style="color: #5E5E5E;"># Cross:</span></span>
<span id="cb3-63"><span class="kw" style="color: #003B4F;">function</span> <span class="fu" style="color: #4758AB;">cross</span>(color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"black"</span>;orientation<span class="op" style="color: #5E5E5E;">=:</span>horizontal)</span>
<span id="cb3-64">    <span class="fu" style="color: #4758AB;">sethue</span>(color)</span>
<span id="cb3-65">    <span class="fu" style="color: #4758AB;">setline</span>(<span class="fl" style="color: #AD0000;">10</span>)</span>
<span id="cb3-66">    <span class="cf" style="color: #003B4F;">if</span> orientation<span class="op" style="color: #5E5E5E;">==:</span>horizontal</span>
<span id="cb3-67">        out <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">line</span>(<span class="fu" style="color: #4758AB;">Point</span>(<span class="op" style="color: #5E5E5E;">-</span>size,<span class="fl" style="color: #AD0000;">0</span>),<span class="fu" style="color: #4758AB;">Point</span>(size,<span class="fl" style="color: #AD0000;">0</span>), <span class="op" style="color: #5E5E5E;">:</span>stroke)</span>
<span id="cb3-68">    <span class="cf" style="color: #003B4F;">else</span></span>
<span id="cb3-69">        out <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">line</span>(<span class="fu" style="color: #4758AB;">Point</span>(<span class="fl" style="color: #AD0000;">0</span>,<span class="op" style="color: #5E5E5E;">-</span>size),<span class="fu" style="color: #4758AB;">Point</span>(<span class="fl" style="color: #AD0000;">0</span>,size), <span class="op" style="color: #5E5E5E;">:</span>stroke)</span>
<span id="cb3-70">    <span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb3-71">    <span class="cf" style="color: #003B4F;">return</span> out</span>
<span id="cb3-72"><span class="kw" style="color: #003B4F;">end</span></span>
<span id="cb3-73"></span>
<span id="cb3-74"><span class="cf" style="color: #003B4F;">for</span> (i, frame_start) <span class="kw" style="color: #003B4F;">in</span> <span class="fu" style="color: #4758AB;">enumerate</span>(<span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span><span class="fl" style="color: #AD0000;">10</span><span class="op" style="color: #5E5E5E;">:</span><span class="fl" style="color: #AD0000;">40</span>)</span>
<span id="cb3-75"></span>
<span id="cb3-76">    <span class="co" style="color: #5E5E5E;"># Julia circles:</span></span>
<span id="cb3-77">    blob <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Object</span>(frame_start<span class="op" style="color: #5E5E5E;">:</span>n_total, (args<span class="op" style="color: #5E5E5E;">...</span>;radius<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="fu" style="color: #4758AB;">element</span>(;radius<span class="op" style="color: #5E5E5E;">=</span>radius))</span>
<span id="cb3-78">    <span class="fu" style="color: #4758AB;">act!</span>(blob, <span class="fu" style="color: #4758AB;">Action</span>(<span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span><span class="fu" style="color: #4758AB;">Int</span>(<span class="fu" style="color: #4758AB;">round</span>(n_frames<span class="op" style="color: #5E5E5E;">*</span><span class="fl" style="color: #AD0000;">0.25</span>)), <span class="fu" style="color: #4758AB;">change</span>(<span class="op" style="color: #5E5E5E;">:</span>radius, <span class="fl" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">=&gt;</span> <span class="fl" style="color: #AD0000;">75</span>))) <span class="co" style="color: #5E5E5E;"># scale up</span></span>
<span id="cb3-79">    <span class="fu" style="color: #4758AB;">act!</span>(blob, <span class="fu" style="color: #4758AB;">Action</span>(n_frames<span class="op" style="color: #5E5E5E;">:</span>(n_frames<span class="op" style="color: #5E5E5E;">+</span><span class="fl" style="color: #AD0000;">50</span>), <span class="fu" style="color: #4758AB;">change</span>(<span class="op" style="color: #5E5E5E;">:</span>radius, <span class="fl" style="color: #AD0000;">75</span> <span class="op" style="color: #5E5E5E;">=&gt;</span> <span class="fl" style="color: #AD0000;">250</span>))) <span class="co" style="color: #5E5E5E;"># scale up further</span></span>
<span id="cb3-80">    <span class="fu" style="color: #4758AB;">act!</span>(blob, <span class="fu" style="color: #4758AB;">Action</span>(<span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span><span class="fl" style="color: #AD0000;">30</span>, translate_anim, <span class="fu" style="color: #4758AB;">translate</span>()))</span>
<span id="cb3-81">    <span class="fu" style="color: #4758AB;">act!</span>(blob, <span class="fu" style="color: #4758AB;">Action</span>(<span class="fl" style="color: #AD0000;">31</span><span class="op" style="color: #5E5E5E;">:</span><span class="fl" style="color: #AD0000;">120</span>, <span class="fu" style="color: #4758AB;">rotate_anim</span>(i, n_colours), <span class="fu" style="color: #4758AB;">rotate_around</span>(<span class="fu" style="color: #4758AB;">Point</span>(<span class="fu" style="color: #4758AB;">-</span>(size<span class="op" style="color: #5E5E5E;">*</span>radius_factor), <span class="fl" style="color: #AD0000;">0</span>))))</span>
<span id="cb3-82">    <span class="fu" style="color: #4758AB;">act!</span>(blob, <span class="fu" style="color: #4758AB;">Action</span>(<span class="fl" style="color: #AD0000;">121</span><span class="op" style="color: #5E5E5E;">:</span><span class="fl" style="color: #AD0000;">150</span>, translate_back_anim, <span class="fu" style="color: #4758AB;">translate</span>()))</span>
<span id="cb3-83">    <span class="fu" style="color: #4758AB;">act!</span>(blob, <span class="fu" style="color: #4758AB;">Action</span>(<span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span><span class="fl" style="color: #AD0000;">150</span>, <span class="fu" style="color: #4758AB;">color_anim</span>(julia_colours[colour_order[i]]), <span class="fu" style="color: #4758AB;">sethue</span>()))</span>
<span id="cb3-84"></span>
<span id="cb3-85">    <span class="co" style="color: #5E5E5E;"># Quarto cross:</span></span>
<span id="cb3-86">    cross_h <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Object</span>((n_frames<span class="op" style="color: #5E5E5E;">+</span><span class="fl" style="color: #AD0000;">50</span>)<span class="op" style="color: #5E5E5E;">:</span>n_total, (args<span class="op" style="color: #5E5E5E;">...</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="fu" style="color: #4758AB;">cross</span>(;orientation<span class="op" style="color: #5E5E5E;">=:</span>horizontal))</span>
<span id="cb3-87">    cross_v <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Object</span>((n_frames<span class="op" style="color: #5E5E5E;">+</span><span class="fl" style="color: #AD0000;">50</span>)<span class="op" style="color: #5E5E5E;">:</span>n_total, (args<span class="op" style="color: #5E5E5E;">...</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="fu" style="color: #4758AB;">cross</span>(;orientation<span class="op" style="color: #5E5E5E;">=:</span>vertical))</span>
<span id="cb3-88"><span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb3-89"></span>
<span id="cb3-90"><span class="fu" style="color: #4758AB;">render</span>(</span>
<span id="cb3-91">    video;</span>
<span id="cb3-92">    pathname <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">joinpath</span>(www_path, <span class="st" style="color: #20794D;">"intro.gif"</span>),</span>
<span id="cb3-93">)</span></code></pre></div>
</section>
<section id="working-with-documenter.jl-and-quarto" class="level4">
<h4 class="anchored" data-anchor-id="working-with-documenter.jl-and-quarto">Working with <code>Documenter.jl</code> and Quarto</h4>
<p>An interesting application of Quarto in the Julia ecosystem is package documentation. This is of course best done using <code>Documenter.jl</code> and fortunately the two play nicely with each other, since both share a common ground (Markdown). Their interaction is perhaps best demonstrated through this Julia library I recently developed: <a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl"><code>CounterfactualExplanatinos.jl</code></a>. On there you will find lot of Julia scripts <code>*.jl</code> under <code>src/</code> and <code>test/</code>, as well as many Markdown <code>.md</code> and Quarto documents <code>.qmd</code> under <code>docs</code>. I <em>wrote</em> the package documentation in the Quarto documents, <em>rendered</em> documents individually through <code>quarto render [doc].qmd</code> and then fed the resulting Markdown documents to <code>Documenter.jl</code> as always.</p>
<p>Below is my standard YAML header for those Quarto documents:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb4-1"><span class="fu" style="color: #4758AB;">format</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span></span>
<span id="cb4-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">commonmark</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb4-3"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">variant</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> -raw_html</span></span>
<span id="cb4-4"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">wrap</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> none</span></span>
<span id="cb4-5"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">self-contained</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">true</span></span>
<span id="cb4-6"><span class="fu" style="color: #4758AB;">crossref</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb4-7"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">fig-prefix</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> Figure</span></span>
<span id="cb4-8"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">tbl-prefix</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> Table</span></span>
<span id="cb4-9"><span class="fu" style="color: #4758AB;">bibliography</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> https://raw.githubusercontent.com/pat-alt/bib/main/bib.bib</span></span>
<span id="cb4-10"><span class="fu" style="color: #4758AB;">output</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> asis</span></span>
<span id="cb4-11"><span class="fu" style="color: #4758AB;">execute</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span></span>
<span id="cb4-12"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">echo</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">true</span></span>
<span id="cb4-13"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">eval</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">false</span></span>
<span id="cb4-14"><span class="fu" style="color: #4758AB;">jupyter</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> julia-1.7</span></span></code></pre></div>
<p>You can see that it points to Bibtex file I host on another Github repository. This makes it very easy to generate citations and references for the rendered Markdown documents, that also show up in the docs (e.g.&nbsp;<a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/stable/cats_dogs/">here</a>). Unfortunately, cross-referencing only partially works, because it relies on auto-generated HTML and <code>Documenter.jl</code> expects this to be passed in blocks. Choosing <code>variant: -raw_html</code> is only a workaround as I have discussed <a href="https://github.com/JuliaDocs/Documenter.jl/issues/1778">here</a>. Ideally, <code>Documenter.jl</code> would just accept HTML documents rendered from Quarto, but currently only Markdown documents are accepted by <code>make_docs</code>. Still, if anything this workaround is a nice gimmick that extends the default <code>Documenter.jl</code> functionality, without any hassle involved. Hopefully, this can be improved in the future.</p>
</section>
<section id="using-quarto-for-juliacon-proceedings" class="level4">
<h4 class="anchored" data-anchor-id="using-quarto-for-juliacon-proceedings">Using Quarto for JuliaCon Proceedings</h4>
<p>Another very good use-case for Quarto involves actual scientific publications in journals such as JuliaCon Proceedings. The existing submission process is tailored towards reproducibility and actually involves reviews directly on GitHub, which is fantastic. But currently only submissions in TeX format are accepted, which is not so great. Using Quarto would not only streamline this process further, but also open the JuliaCon Proceedings Journal up to publishing content in different output formats. Quarto docs could be used to still render the traditional PDF. But those same documents could also be used to create interactive versions in HTML. Arguably, the entire journal could probably be built through Quarto.</p>
</section>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping up üéó</h2>
<p>In this post I wanted to demonstrate that Quarto might just be the next revolution in scientific publishing. In particular, I hope I have managed to demonstrate its appeal to the Julia community, which I am proud to be part of now that I have managed to branch out of my old R bubble. Please let me hear your thoughts and comments below!</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {Julia and {Quarto:} A Match Made in Heaven? üå§},
  date = {22-04-07},
  url = {https://www.paltmeyer.com/blog//blog/posts/julia-and-quarto-a-match-made-in-heaven},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 22AD. <span>‚ÄúJulia and Quarto: A Match Made in
Heaven? üå§.‚Äù</span> April 7, 22AD. <a href="https://www.paltmeyer.com/blog//blog/posts/julia-and-quarto-a-match-made-in-heaven">https://www.paltmeyer.com/blog//blog/posts/julia-and-quarto-a-match-made-in-heaven</a>.
</div></div></section></div> ]]></description>
  <category>scientific publishing</category>
  <category>Quarto</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html</guid>
  <pubDate>Wed, 06 Apr 2022 22:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/julia-and-quarto-a-match-made-in-heaven/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Go deep, but also ‚Ä¶ go Bayesian!</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
A Bayesian Neural Network gradually learns.
</figcaption>
</figure>
</div>
<p>Deep learning has dominated AI research in recent years<sup>1</sup> - but how much promise does it really hold? That is very much an ongoing and increasingly polarising debate that you can follow live on <a href="https://twitter.com/ilyasut/status/1491554478243258368">Twitter</a>. On one side you have optimists like Ilya Sutskever, chief scientist of OpenAI, who believes that large deep neural networks may already be slightly conscious - that‚Äôs ‚Äúmay‚Äù and ‚Äúslightly‚Äù and only if you just go deep enough? On the other side you have prominent skeptics like Judea Pearl who has long since argued that deep learning still boils down to curve fitting - purely associational and not even remotely intelligent <span class="citation" data-cites="pearl2018book">(Pearl and Mackenzie 2018)</span>.</p>
<section id="the-case-for-bayesian-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="the-case-for-bayesian-deep-learning">The case for Bayesian Deep Learning</h2>
<p>Whatever side of this entertaining twitter dispute you find yourself on, the reality is that deep-learning systems have already been deployed at large scale both in academia and industry. More pressing debates therefore revolve around the trustworthiness of these existing systems. How robust are they and in what way exactly do they arrive at decisions that affect each and every one of us? Robustifying deep neural networks generally involves some form of adversarial training, which is costly, can hurt generalization <span class="citation" data-cites="raghunathan2019adversarial">(Raghunathan et al. 2019)</span> and does ultimately not guarantee stability <span class="citation" data-cites="bastounis2021mathematics">(Bastounis, Hansen, and Vlaƒçiƒá 2021)</span>. With respect to interpretability, surrogate explainers like LIME and SHAP are among the most popular tools, but they too have been shown to lack robustness <span class="citation" data-cites="slack2020fooling">(Slack et al. 2020)</span>.</p>
<p>Exactly why are deep neural networks unstable and in-transparent? Let <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D=%5C%7Bx,y%5C%7D_%7Bn=1%7D%5EN"> denote our feature-label pairs and let <img src="https://latex.codecogs.com/png.latex?f(x;%5Ctheta)=y"> denote some deep neural network specified by its parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta">. Then the first thing to note is that the number of free parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is typically huge (if you ask Mr Sutskever it really probably cannot be huge enough!). That alone makes it very hard to monitor and interpret the inner workings of deep-learning algorithms. Perhaps more importantly though, the number of parameters <em>relative</em> to the size of <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> is generally huge:</p>
<blockquote class="blockquote">
<p>[‚Ä¶] deep neural networks are typically very underspecified by the available data, and [‚Ä¶] parameters [therefore] correspond to a diverse variety of compelling explanations for the data. <span class="citation" data-cites="wilson2020case">(Wilson 2020)</span></p>
</blockquote>
<p>In other words, training a single deep neural network may (and usually does) lead to one random parameter specification that fits the underlying data very well. But in all likelihood there are many other specifications that also fit the data very well. This is both a strength and vulnerability of deep learning: it is a strength because it typically allows us to find one such ‚Äúcompelling explanation‚Äù for the data with ease through stochastic optimization; it is a vulnerability because one has to wonder:</p>
<blockquote class="blockquote">
<p>How compelling is an explanation really if it competes with many other equally compelling, but potentially very different explanations?</p>
</blockquote>
<p>A scenario like this very much calls for treating predictions from deep learning models probabilistically [<span class="citation" data-cites="wilson2020case">Wilson (2020)</span>]<sup>2</sup><sup>3</sup>.</p>
<p>Formally, we are interested in estimating the posterior predictive distribution as the following Bayesian model average (BMA):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(y%7Cx,%5Cmathcal%7BD%7D)%20=%20%5Cint%20p(y%7Cx,%5Ctheta)p(%5Ctheta%7C%5Cmathcal%7BD%7D)d%5Ctheta%0A"></p>
<p>The integral implies that we essentially need many predictions from many different specifications of <img src="https://latex.codecogs.com/png.latex?%5Ctheta">. Unfortunately, this means more work for us or rather our computers. Fortunately though, researchers have proposed many ingenious ways to approximate the equation above in recent years: <span class="citation" data-cites="gal2016dropout">Gal and Ghahramani (2016)</span> propose using dropout at test time while <span class="citation" data-cites="lakshminarayanan2016simple">Lakshminarayanan, Pritzel, and Blundell (2016)</span> show that averaging over an ensemble of just five models seems to do the trick. Still, despite their simplicity and usefulness these approaches involve additional computational costs compared to training just a single network. As we shall see now though, another promising approach has recently entered the limelight: <strong>Laplace approximation</strong> (LA).</p>
<p>If you have read my <a href="https://towardsdatascience.com/bayesian-logistic-regression-53df017ba90f">previous post</a> on Bayesian Logistic Regression, then the term Laplace should already sound familiar to you. As a matter of fact, we will see that all concepts covered in that previous post can be naturally extended to deep learning. While some of these concepts will be revisited below, I strongly recommend you check out the previous post before reading on here. Without further ado let us now see how LA can be used for truly effortless deep learning.</p>
</section>
<section id="laplace-approximation" class="level2">
<h2 class="anchored" data-anchor-id="laplace-approximation">Laplace Approximation</h2>
<p>While LA was first proposed in the 18th century, it has so far not attracted serious attention from the deep learning community largely because it involves a possibly large Hessian computation. <span class="citation" data-cites="daxberger2021laplace">Daxberger et al. (2021)</span> are on a mission to change the perception that LA has no use in DL: in their <a href="https://arxiv.org/pdf/2106.14806.pdf">NeurIPS 2021 paper</a> they demonstrate empirically that LA can be used to produce Bayesian model averages that are at least at par with existing approaches in terms of uncertainty quantification and out-of-distribution detection and significantly cheaper to compute. They show that recent advancements in autodifferentation can be leveraged to produce fast and accurate approximations of the Hessian and even provide a fully-fledged <a href="https://aleximmer.github.io/Laplace/">Python library</a> that can be used with any pretrained Torch model. For this post, I have built a much less comprehensive, pure-play equivalent of their package in Julia - <a href="https://www.paltmeyer.com/LaplaceRedux.jl/dev/">LaplaceRedux.jl</a> can be used with deep learning models built in <a href="https://fluxml.ai/">Flux.jl</a>, which is Julia‚Äôs main DL library. As in the previous post on Bayesian logistic regression I will rely on Julia code snippits instead of equations to convey the underlying maths. If you‚Äôre curious about the maths, the <a href="https://arxiv.org/pdf/2106.14806.pdf">NeurIPS 2021 paper</a> provides all the detail you need.</p>
<section id="from-bayesian-logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="from-bayesian-logistic-regression">From Bayesian Logistic Regression ‚Ä¶</h3>
<p>Let‚Äôs recap: in the case of logistic regression we had a assumed a zero-mean Gaussian prior <img src="https://latex.codecogs.com/png.latex?p(%5Cmathbf%7Bw%7D)%20%5Csim%20%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7B0%7D,%20%5Csigma_0%5E2%20%5Cmathbf%7BI%7D%20%5Cright)=%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7B0%7D,%20%5Cmathbf%7BH%7D_0%5E%7B-1%7D%20%5Cright)"> for the weights that are used to compute logits <img src="https://latex.codecogs.com/png.latex?%5Cmu_n=%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_n">, which in turn are fed to a sigmoid function to produce probabilities <img src="https://latex.codecogs.com/png.latex?p(y_n=1)=%5Csigma(%5Cmu_n)">. We saw that under this assumption solving the logistic regression problem corresponds to minimizing the following differentiable loss function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cell(%5Cmathbf%7Bw%7D)=%20-%20%5Csum_%7Bn%7D%5EN%20%5By_n%20%5Clog%20%5Cmu_n%20+%20(1-y_n)%5Clog%20(1-%5Cmu_n)%5D%20+%20%5C%5C%20%5Cfrac%7B1%7D%7B2%7D%20(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%5ET%5Cmathbf%7BH%7D_0(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%0A"></p>
<p>As our first step towards Bayesian deep learning, we observe the following: the loss function above corresponds to the objective faced by a single-layer artificial neural network with sigmoid activation and weight decay<sup>4</sup>. In other words, regularized logistic regression is equivalent to a very simple neural network architecture and hence it is not surprising that underlying concepts can in theory be applied in much the same way.</p>
<p>So let‚Äôs quickly recap the next core concept: LA relies on the fact that the second-order Taylor expansion of our loss function <img src="https://latex.codecogs.com/png.latex?%5Cell"> evaluated at the <strong>maximum a posteriori</strong> (MAP) estimate <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5Chat%7Bw%7D%7D=%5Carg%5Cmax_%7B%5Cmathbf%7Bw%7D%7D%20p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> amounts to a multi-variate Gaussian distribution. In particular, that Gaussian is centered around the MAP estimate with covariance equal to the inverse Hessian evaluated at the mode <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5CSigma%7D=(%5Cmathbf%7BH%7D(%5Cmathbf%7B%5Chat%7Bw%7D%7D))%5E%7B-1%7D"> <span class="citation" data-cites="murphy2022probabilistic">(Murphy 2022)</span>.</p>
<p>That is basically all there is to the story: if we have a good estimate of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BH%7D(%5Cmathbf%7B%5Chat%7Bw%7D%7D)"> we have an analytical expression for an (approximate) posterior over parameters. So let‚Äôs go ahead and start by run Bayesian Logistic regression using <a href="https://fluxml.ai/">Flux.jl</a>. We begin by loading some required packages including <a href="https://www.paltmeyer.com/LaplaceRedux.jl/dev/">LaplaceRedux.jl</a>. It ships with a helper function <code>toy_data_linear</code> that creates a toy data set composed of linearly separable samples evenly balanced across the two classes.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># Import libraries.</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Flux</span>, <span class="bu" style="color: null;">Plots</span>, <span class="bu" style="color: null;">Random</span>, <span class="bu" style="color: null;">PlotThemes</span>, <span class="bu" style="color: null;">Statistics</span>, <span class="bu" style="color: null;">LaplaceRedux</span></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;">theme</span>(<span class="op" style="color: #5E5E5E;">:</span>wong)</span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;"># Number of points to generate.</span></span>
<span id="cb1-5">xs, y <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">toy_data_linear</span>(<span class="fl" style="color: #AD0000;">100</span>)</span>
<span id="cb1-6">X <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">hcat</span>(xs<span class="op" style="color: #5E5E5E;">...</span>); <span class="co" style="color: #5E5E5E;"># bring into tabular format</span></span>
<span id="cb1-7">data <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">zip</span>(xs,y);</span></code></pre></div>
</div>
<p>Then we proceed to prepare the single-layer neural network with weight decay. The term <img src="https://latex.codecogs.com/png.latex?%5Clambda"> determines the strength of the <img src="https://latex.codecogs.com/png.latex?%5Cell2"> penalty: we regularize parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> more heavily for higher values. Equivalently, we can say that from the Bayesian perspective it governs the strength of the prior <img src="https://latex.codecogs.com/png.latex?p(%5Ctheta)%20%5Csim%20%5Cmathcal%7BN%7D%20%5Cleft(%20%5Ctheta%20%7C%20%5Cmathbf%7B0%7D,%20%5Csigma_0%5E2%20%5Cmathbf%7BI%7D%20%5Cright)=%20%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7B0%7D,%20%5Clambda_0%5E%7B-2%7D%20%5Cmathbf%7BI%7D%20%5Cright)">: a higher value of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> indicates a higher conviction about our prior belief that <img src="https://latex.codecogs.com/png.latex?%5Ctheta=%5Cmathbf%7B0%7D">, which is of course equivalent to regularizing more heavily. The exact choice of <img src="https://latex.codecogs.com/png.latex?%5Clambda=0.5"> for this toy example is somewhat arbitrary (it made for good visualizations below). Note that I have used <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> to denote our neural parameters to distinguish the case from Bayesian logistic regression, but we are in fact still solving the same problem.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1">nn <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Chain</span>(<span class="fu" style="color: #4758AB;">Dense</span>(<span class="fl" style="color: #AD0000;">2</span>,<span class="fl" style="color: #AD0000;">1</span>))</span>
<span id="cb2-2">Œª <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span></span>
<span id="cb2-3"><span class="fu" style="color: #4758AB;">sqnorm</span>(x) <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">sum</span>(abs2, x)</span>
<span id="cb2-4"><span class="fu" style="color: #4758AB;">weight_regularization</span>(Œª<span class="op" style="color: #5E5E5E;">=</span>Œª) <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">/</span><span class="fl" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">*</span> Œª<span class="op" style="color: #5E5E5E;">^</span><span class="fl" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="fu" style="color: #4758AB;">sum</span>(sqnorm, Flux.<span class="fu" style="color: #4758AB;">params</span>(nn))</span>
<span id="cb2-5"><span class="fu" style="color: #4758AB;">loss</span>(x, y) <span class="op" style="color: #5E5E5E;">=</span> Flux.Losses.<span class="fu" style="color: #4758AB;">logitbinarycrossentropy</span>(<span class="fu" style="color: #4758AB;">nn</span>(x), y) <span class="op" style="color: #5E5E5E;">+</span> <span class="fu" style="color: #4758AB;">weight_regularization</span>();</span></code></pre></div>
</div>
<p>Before we apply Laplace approximation we train our model:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="im" style="color: #00769E;">using</span> <span class="bu" style="color: null;">Flux.Optimise</span>: update!, ADAM</span>
<span id="cb3-2">opt <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">ADAM</span>()</span>
<span id="cb3-3">epochs <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">50</span></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="cf" style="color: #003B4F;">for</span> epoch <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span>epochs</span>
<span id="cb3-6">  <span class="cf" style="color: #003B4F;">for</span> d <span class="kw" style="color: #003B4F;">in</span> data</span>
<span id="cb3-7">    gs <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">gradient</span>(<span class="fu" style="color: #4758AB;">params</span>(nn)) <span class="cf" style="color: #003B4F;">do</span></span>
<span id="cb3-8">      l <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">loss</span>(d<span class="op" style="color: #5E5E5E;">...</span>)</span>
<span id="cb3-9">    <span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb3-10">    <span class="fu" style="color: #4758AB;">update!</span>(opt, <span class="fu" style="color: #4758AB;">params</span>(nn), gs)</span>
<span id="cb3-11">  <span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb3-12"><span class="cf" style="color: #003B4F;">end</span></span></code></pre></div>
</div>
<p>Up until this point we have just followed the standard recipe for training a regularized artificial neural network in <a href="https://fluxml.ai/">Flux.jl</a> for a simple binary classification task. To compute the Laplace approximation using <a href="https://www.paltmeyer.com/LaplaceRedux.jl/dev/">LaplaceRedux.jl</a> we need just two more lines of code:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1">la <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">laplace</span>(nn, Œª<span class="op" style="color: #5E5E5E;">=</span>Œª)</span>
<span id="cb4-2"><span class="fu" style="color: #4758AB;">fit!</span>(la, data);</span></code></pre></div>
</div>
<p>Under the hood the Hessian is approximated through the <strong>empirical Fisher</strong>, which can be computed using only the gradients of our loss function <img src="https://latex.codecogs.com/png.latex?%5Cnabla_%7B%5Ctheta%7D%5Cell(f(%5Cmathbf%7Bx%7D_n;%5Ctheta,y_n))"> where <img src="https://latex.codecogs.com/png.latex?%5C%7B%5Cmathbf%7Bx%7D_n,y_n%5C%7D"> are training data (see <a href="https://arxiv.org/pdf/2106.14806.pdf">NeurIPS 2021 paper</a> for details). Finally, <a href="https://www.paltmeyer.com/LaplaceRedux.jl/dev/">LaplaceRedux.jl</a> ships with a function <code>predict(ùë≥::LaplaceRedux, X::AbstractArray; link_approx=:probit)</code> that computes the posterior predictive using a probit approximation, much like we saw in the previous post. That function is used under the hood of the <code>plot_contour</code> function below to create the right panel of Figure&nbsp;1. It visualizes the posterior predictive distribution in the 2D feature space. For comparison I have added the corresponding plugin estimate as well. Note how for the Laplace approximation the predicted probabilities fan out indicating that confidence decreases in regions scarce of data.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1">p_plugin <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Plugin"</span>,<span class="kw" style="color: #003B4F;">type</span><span class="op" style="color: #5E5E5E;">=:</span>plugin);</span>
<span id="cb5-2">p_laplace <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Laplace"</span>)</span>
<span id="cb5-3"><span class="co" style="color: #5E5E5E;"># Plot the posterior distribution with a contour plot.</span></span>
<span id="cb5-4">plt <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">plot</span>(p_plugin, p_laplace, layout<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">1</span>,<span class="fl" style="color: #AD0000;">2</span>), size<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">1000</span>,<span class="fl" style="color: #AD0000;">400</span>))</span>
<span id="cb5-5"><span class="fu" style="color: #4758AB;">savefig</span>(plt, <span class="st" style="color: #20794D;">"www/posterior_predictive_logit.png"</span>);</span></code></pre></div>
</div>
<div id="fig-logit" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/posterior_predictive_logit.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Posterior predictive distribution of Logistic regression in the 2D feature space using plugin estimator (left) and Laplace approximation (right).</figcaption><p></p>
</figure>
</div>
</section>
<section id="to-bayesian-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="to-bayesian-neural-networks">‚Ä¶ to Bayesian Neural Networks</h3>
<p>Now let‚Äôs step it up a notch: we will repeat the exercise from above, but this time for data that is not linearly separable using a simple MLP instead of the single-layer neural network we used above. The code below is almost the same as above, so I will not go through the various steps again.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># Number of points to generate:</span></span>
<span id="cb6-2">xs, y <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">toy_data_non_linear</span>(<span class="fl" style="color: #AD0000;">200</span>)</span>
<span id="cb6-3">X <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">hcat</span>(xs<span class="op" style="color: #5E5E5E;">...</span>); <span class="co" style="color: #5E5E5E;"># bring into tabular format</span></span>
<span id="cb6-4">data <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">zip</span>(xs,y)</span>
<span id="cb6-5"></span>
<span id="cb6-6"><span class="co" style="color: #5E5E5E;"># Build MLP:</span></span>
<span id="cb6-7">n_hidden <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">32</span></span>
<span id="cb6-8">D <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">size</span>(X)[<span class="fl" style="color: #AD0000;">1</span>]</span>
<span id="cb6-9">nn <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">Chain</span>(</span>
<span id="cb6-10">    <span class="fu" style="color: #4758AB;">Dense</span>(D, n_hidden, œÉ),</span>
<span id="cb6-11">    <span class="fu" style="color: #4758AB;">Dense</span>(n_hidden, <span class="fl" style="color: #AD0000;">1</span>)</span>
<span id="cb6-12">)  </span>
<span id="cb6-13">Œª <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.01</span></span>
<span id="cb6-14"><span class="fu" style="color: #4758AB;">sqnorm</span>(x) <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">sum</span>(abs2, x)</span>
<span id="cb6-15"><span class="fu" style="color: #4758AB;">weight_regularization</span>(Œª<span class="op" style="color: #5E5E5E;">=</span>Œª) <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">/</span><span class="fl" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">*</span> Œª<span class="op" style="color: #5E5E5E;">^</span><span class="fl" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">*</span> <span class="fu" style="color: #4758AB;">sum</span>(sqnorm, Flux.<span class="fu" style="color: #4758AB;">params</span>(nn))</span>
<span id="cb6-16"><span class="fu" style="color: #4758AB;">loss</span>(x, y) <span class="op" style="color: #5E5E5E;">=</span> Flux.Losses.<span class="fu" style="color: #4758AB;">logitbinarycrossentropy</span>(<span class="fu" style="color: #4758AB;">nn</span>(x), y) <span class="op" style="color: #5E5E5E;">+</span> <span class="fu" style="color: #4758AB;">weight_regularization</span>()</span>
<span id="cb6-17"></span>
<span id="cb6-18"><span class="co" style="color: #5E5E5E;"># Training:</span></span>
<span id="cb6-19">epochs <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">200</span></span>
<span id="cb6-20"><span class="cf" style="color: #003B4F;">for</span> epoch <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">:</span>epochs</span>
<span id="cb6-21">  <span class="cf" style="color: #003B4F;">for</span> d <span class="kw" style="color: #003B4F;">in</span> data</span>
<span id="cb6-22">    gs <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">gradient</span>(<span class="fu" style="color: #4758AB;">params</span>(nn)) <span class="cf" style="color: #003B4F;">do</span></span>
<span id="cb6-23">      l <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">loss</span>(d<span class="op" style="color: #5E5E5E;">...</span>)</span>
<span id="cb6-24">    <span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb6-25">    <span class="fu" style="color: #4758AB;">update!</span>(opt, <span class="fu" style="color: #4758AB;">params</span>(nn), gs)</span>
<span id="cb6-26">  <span class="cf" style="color: #003B4F;">end</span></span>
<span id="cb6-27"><span class="cf" style="color: #003B4F;">end</span></span></code></pre></div>
</div>
<p>Fitting the Laplace approximation is also analogous, but note that this we have added an argument: <code>subset_of_weights=:last_layer</code>. This specifies that we only want to use the parameters of the last layer of our MLP. While we could have used all of them (<code>subset_of_weights=:all</code>), <span class="citation" data-cites="daxberger2021laplace">Daxberger et al. (2021)</span> find that the last-layer Laplace approximation produces satisfying results, while be computationally cheaper. Figure&nbsp;2 demonstrates that once again the Laplace approximation yields a posterior predictive distribution that is more conservative than the over-confident plugin estimate.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1">la <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">laplace</span>(nn, Œª<span class="op" style="color: #5E5E5E;">=</span>Œª, subset_of_weights<span class="op" style="color: #5E5E5E;">=:</span>last_layer)</span>
<span id="cb7-2"><span class="fu" style="color: #4758AB;">fit!</span>(la, data);</span>
<span id="cb7-3">p_plugin <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Plugin"</span>,<span class="kw" style="color: #003B4F;">type</span><span class="op" style="color: #5E5E5E;">=:</span>plugin)</span>
<span id="cb7-4">p_laplace <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Laplace"</span>)</span>
<span id="cb7-5"><span class="co" style="color: #5E5E5E;"># Plot the posterior distribution with a contour plot.</span></span>
<span id="cb7-6">plt <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">plot</span>(p_plugin, p_laplace, layout<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">1</span>,<span class="fl" style="color: #AD0000;">2</span>), size<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">1000</span>,<span class="fl" style="color: #AD0000;">400</span>))</span>
<span id="cb7-7"><span class="fu" style="color: #4758AB;">savefig</span>(plt, <span class="st" style="color: #20794D;">"www/posterior_predictive_mlp.png"</span>);</span></code></pre></div>
</div>
<div id="fig-mlp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/posterior_predictive_mlp.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Posterior predictive distribution of MLP in the 2D feature space using plugin estimator (left) and Laplace approximation (right).</figcaption><p></p>
</figure>
</div>
<p>To see why this is a desirable outcome consider the zoomed out version of Figure&nbsp;2 below: the plugin estimator classifies with full confidence in regions completely scarce of any data. Arguably Laplace approximation produces a much more reasonable picture, even though it too could likely be improved by fine-tuning our choice of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> and the neural network architecture.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">zoom<span class="op" style="color: #5E5E5E;">=-</span><span class="fl" style="color: #AD0000;">50</span></span>
<span id="cb8-2">p_plugin <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Plugin"</span>,<span class="kw" style="color: #003B4F;">type</span><span class="op" style="color: #5E5E5E;">=:</span>plugin,zoom<span class="op" style="color: #5E5E5E;">=</span>zoom);</span>
<span id="cb8-3">p_laplace <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Laplace"</span>,zoom<span class="op" style="color: #5E5E5E;">=</span>zoom);</span>
<span id="cb8-4"><span class="co" style="color: #5E5E5E;"># Plot the posterior distribution with a contour plot.</span></span>
<span id="cb8-5">plt <span class="op" style="color: #5E5E5E;">=</span> <span class="fu" style="color: #4758AB;">plot</span>(p_plugin, p_laplace, layout<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">1</span>,<span class="fl" style="color: #AD0000;">2</span>), size<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">1000</span>,<span class="fl" style="color: #AD0000;">400</span>));</span>
<span id="cb8-6"><span class="fu" style="color: #4758AB;">savefig</span>(plt, <span class="st" style="color: #20794D;">"www/posterior_predictive_mlp_zoom.png"</span>);</span></code></pre></div>
</div>
<div id="fig-mlp-zoom" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/posterior_predictive_mlp_zoom.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3: Posterior predictive distribution of MLP in the 2D feature space using plugin estimator (left) and Laplace approximation (right). Zoomed out.</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping up</h2>
<p>Recent state-of-the-art research on neural information processing suggests that Bayesian deep learning can be effortless: Laplace approximation for deep neural networks appears to work very well and it does so at minimal computational cost <span class="citation" data-cites="daxberger2021laplace">(Daxberger et al. 2021)</span>. This is great news, because the case for turning Bayesian is strong: society increasingly relies on complex automated decision-making systems that need to be trustworthy. More and more of these systems involve deep learning which in and of itself is not trustworthy. We have seen that typically there exist various viable parameterizations of deep neural networks each with their own distinct and compelling explanation for the data at hand. When faced with many viable options, don‚Äôt put all of your eggs in one basket. In other words, go Bayesian!</p>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<p>To get started with Bayesian deep learning I have found many useful and free resources online, some of which are listed below:</p>
<ul>
<li><a href="https://turing.ml/dev/tutorials/03-bayesian-neural-network/"><code>Turing.jl</code> tutorial</a> on Bayesian deep learning in Julia.</li>
<li>Various RStudio AI blog posts including <a href="https://blogs.rstudio.com/ai/posts/2018-11-12-uncertainty_estimates_dropout/">this one</a> and <a href="https://blogs.rstudio.com/ai/posts/2019-06-05-uncertainty-estimates-tfprobability/">this one</a>.</li>
<li><a href="https://medium.com/tensorflow/regression-with-probabilistic-layers-in-tensorflow-probability-e46ff5d37baf">TensorFlow blog post</a> on regression with probabilistic layers.</li>
<li>Kevin Murphy‚Äôs <a href="https://probml.github.io/pml-book/book1.html">draft text book</a>, now also available as print.</li>
</ul>
</section>
<section id="references" class="level2">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bastounis2021mathematics" class="csl-entry">
Bastounis, Alexander, Anders C Hansen, and Verner Vlaƒçiƒá. 2021. <span>‚ÄúThe Mathematics of Adversarial Attacks in <span>AI</span>‚Äì<span>Why</span> Deep Learning Is Unstable Despite the Existence of Stable Neural Networks.‚Äù</span> <a href="https://arxiv.org/abs/2109.06098">https://arxiv.org/abs/2109.06098</a>.
</div>
<div id="ref-daxberger2021laplace" class="csl-entry">
Daxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. <span>‚ÄúLaplace <span>Redux-Effortless Bayesian Deep Learning</span>.‚Äù</span> <em>Advances in Neural Information Processing Systems</em> 34.
</div>
<div id="ref-gal2016dropout" class="csl-entry">
Gal, Yarin, and Zoubin Ghahramani. 2016. <span>‚ÄúDropout as a Bayesian Approximation: <span>Representing</span> Model Uncertainty in Deep Learning.‚Äù</span> In <em>International Conference on Machine Learning</em>, 1050‚Äì59. <span>PMLR</span>.
</div>
<div id="ref-lakshminarayanan2016simple" class="csl-entry">
Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2016. <span>‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù</span> <a href="https://arxiv.org/abs/1612.01474">https://arxiv.org/abs/1612.01474</a>.
</div>
<div id="ref-murphy2022probabilistic" class="csl-entry">
Murphy, Kevin P. 2022. <em>Probabilistic <span>Machine Learning</span>: <span>An</span> Introduction</em>. <span>MIT Press</span>.
</div>
<div id="ref-pearl2018book" class="csl-entry">
Pearl, Judea, and Dana Mackenzie. 2018. <em>The Book of Why: The New Science of Cause and Effect</em>. <span>Basic books</span>.
</div>
<div id="ref-raghunathan2019adversarial" class="csl-entry">
Raghunathan, Aditi, Sang Michael Xie, Fanny Yang, John C Duchi, and Percy Liang. 2019. <span>‚ÄúAdversarial Training Can Hurt Generalization.‚Äù</span> <a href="https://arxiv.org/abs/1906.06032">https://arxiv.org/abs/1906.06032</a>.
</div>
<div id="ref-slack2020fooling" class="csl-entry">
Slack, Dylan, Sophie Hilgard, Emily Jia, Sameer Singh, and Himabindu Lakkaraju. 2020. <span>‚ÄúFooling Lime and Shap: <span>Adversarial</span> Attacks on Post Hoc Explanation Methods.‚Äù</span> In <em>Proceedings of the <span>AAAI</span>/<span>ACM Conference</span> on <span>AI</span>, <span>Ethics</span>, and <span>Society</span></em>, 180‚Äì86.
</div>
<div id="ref-wilson2020case" class="csl-entry">
Wilson, Andrew Gordon. 2020. <span>‚ÄúThe Case for <span>Bayesian</span> Deep Learning.‚Äù</span> <a href="https://arxiv.org/abs/2001.10995">https://arxiv.org/abs/2001.10995</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See for example <a href="https://www.technologyreview.com/2019/01/25/1436/we-analyzed-16625-papers-to-figure-out-where-ai-is-headed-next/">this article</a> in the MIT Technology Review‚Ü©Ô∏é</p></li>
<li id="fn2"><p>In fact, not treating probabilistic deep learning models as such is sheer madness because remember that the underlying parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> are random variables. Frequentists and Bayesians alike will tell you that relying on a single point estimate of random variables is just nuts!‚Ü©Ô∏é</p></li>
<li id="fn3"><p>Proponents of Causal AI like Judea Pearl would argue that the Bayesian treatment still does not go far enough: in their view model explanations can only be truly compelling if they are causally found.‚Ü©Ô∏é</p></li>
<li id="fn4"><p>See this <a href="https://stats.stackexchange.com/a/500973/288736">answer</a> on Stack Exchange for a detailed discussion.‚Ü©Ô∏é</p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {Go Deep, but Also ... Go {Bayesian!}},
  date = {22-02-18},
  url = {https://www.paltmeyer.com/blog//blog/posts/effortsless-bayesian-dl},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 22AD. <span>‚ÄúGo Deep, but Also ... Go
Bayesian!‚Äù</span> February 18, 22AD. <a href="https://www.paltmeyer.com/blog//blog/posts/effortsless-bayesian-dl">https://www.paltmeyer.com/blog//blog/posts/effortsless-bayesian-dl</a>.
</div></div></section></div> ]]></description>
  <category>bayes</category>
  <category>deep learning</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/index.html</guid>
  <pubDate>Thu, 17 Feb 2022 23:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Bayesian Logistic Regression</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/index.html</link>
  <description><![CDATA[ 



<section id="uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="uncertainty">Uncertainty</h2>
<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Simulation of changing parameter distribution.
</figcaption>
</figure>
</div>
<p>If you‚Äôve ever searched for evaluation metrics to assess model accuracy, chances are that you found many different options to choose from (too many?). Accuracy is in some sense the holy grail of prediction so it‚Äôs not at all surprising that the machine learning community spends a lot time thinking about it. In a world where more and more high-stake decisions are being automated, model accuracy is in fact a very valid concern.</p>
<p>But does this recipe for model evaluation seem like a sound and complete approach to automated decision-making? Haven‚Äôt we forgot anything? Some would argue that we need to pay more attention to <strong>model uncertainty</strong>. No matter how many times you have cross-validated your model, the loss metric that it is being optimized against as well as its parameters and predictions remain inherently random variables. Focusing merely on prediction accuracy and ignoring uncertainty altogether can install a false level of confidence in automated decision-making systems. Any <strong>trustworthy</strong> approach to learning from data should therefore at the very least be transparent about its own uncertainty.</p>
<p>How can we estimate uncertainty around model parameters and predictions? <strong>Frequentist</strong> methods for uncertainty quantification generally involve either closed-form solutions based on asymptotic theory or bootstrapping (see for example <a href="https://web.stanford.edu/class/archive/stats/stats200/stats200.1172/Lecture26.pdf">here</a> for the case of logistic regression). In Bayesian statistics and machine learning we are instead concerned with modelling the <strong>posterior distribution</strong> over model parameters. This approach to uncertainty quantification is known as <strong>Bayesian Inference</strong> because we treat model parameters in a Bayesian way: we make assumptions about their distribution based on <strong>prior</strong> knowledge or beliefs and update these beliefs in light of new evidence. The frequentist approach avoids the need for being explicit about prior beliefs, which in the past has sometimes been considered as <em>un</em>scientific. However, frequentist methods come with their own assumptions and pitfalls (see for example <span class="citation" data-cites="murphy2012machine">Murphy (2012)</span>) for a discussion). Without diving further into this argument, let us now see how <strong>Bayesian Logistic Regression</strong> can be implemented from the bottom up.</p>
</section>
<section id="the-ground-truth" class="level2">
<h2 class="anchored" data-anchor-id="the-ground-truth">The ground truth</h2>
<p>In this post we will work with a synthetic toy data set <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> composed of <img src="https://latex.codecogs.com/png.latex?N"> binary labels <img src="https://latex.codecogs.com/png.latex?y_n%5Cin%5C%7B0,1%5C%7D"> and corresponding feature vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_n%5Cin%20%5Cmathbb%7BR%7D%5ED">. Working with synthetic data has the benefit that we have control over the <strong>ground truth</strong> that generates our data. In particular, we will assume that the binary labels <img src="https://latex.codecogs.com/png.latex?y_n"> are generated by a logistic regression model</p>
<p><span id="eq-logreg"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(y_n%7C%5Cmathbf%7Bx%7D_n;%5Cmathbf%7Bw%7D)&amp;%5Csim%5Ctext%7BBer%7D(y_n%7C%5Csigma(%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_n))%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B1%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Csigma(a)=1/(1+e%5E%7B-a%7D)"> is the <strong>sigmoid</strong> or <strong>logit</strong> function <span class="citation" data-cites="murphy2022probabilistic">(Murphy 2022)</span>.<sup>1</sup> Features are generated from a mixed Gaussian model.</p>
<p>To add a little bit of life to our example we will assume that the binary labels classify samples into cats and dogs, based on their height and tail length. Figure&nbsp;1 shows the synthetic data in the two-dimensional feature domain. Following an introduction to Bayesian Logistic Regression in the next section we will use the synthetic data <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> to estimate our model.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ground" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/index_files/figure-html/fig-ground-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Ground truth labels.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="the-maths" class="level2">
<h2 class="anchored" data-anchor-id="the-maths">The maths</h2>
<p>Estimation usually boils down to finding the vector of parameters <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bw%7D%7D"> that maximizes the likelihood of observing <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> under the assumed model. That estimate can then be used to compute predictions for some new unlabelled data set <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D=%5C%7Bx_m:m=1,...,M%5C%7D">.</p>
<section id="problem-setup" class="level3">
<h3 class="anchored" data-anchor-id="problem-setup">Problem setup</h3>
<p>The starting point for Bayesian Logistic Regression is <strong>Bayes‚Äô Theorem</strong>:</p>
<p><span id="eq-posterior"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)&amp;%5Cpropto%20p(%5Cmathcal%7BD%7D%7C%5Cmathbf%7Bw%7D)p(%5Cmathbf%7Bw%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B2%7D"></span></p>
<p>Formally, this says that the posterior distribution of parameters <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> is proportional to the product of the likelihood of observing <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> given <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> and the prior density of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D">. Applied to our context this can intuitively be understood as follows: our posterior beliefs around <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> are formed by both our prior beliefs and the evidence we observe. Yet another way to look at this is that maximising Equation&nbsp;2 with respect to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> corresponds to maximum likelihood estimation regularized by prior beliefs (we will come back to this).</p>
<p>Under the assumption that individual label-feature pairs are <strong>independently</strong> and <strong>identically</strong> distributed, their joint likelihood is simply the product over their individual densities. The prior beliefs around <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> are at our discretion. In practice they may be derived from previous experiments. Here we will use a zero-mean spherical Gaussian prior for reasons explained further below. To sum this up we have</p>
<p><span id="eq-prior"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(%5Cmathcal%7BD%7D%7C%5Cmathbf%7Bw%7D)&amp;%20%5Csim%20%5Cprod_%7Bn=1%7D%5EN%20p(y_n%7C%5Cmathbf%7Bx%7D_n;%5Cmathbf%7Bw%7D)%5C%5C%0A&amp;&amp;%20p(%5Cmathbf%7Bw%7D)&amp;%20%5Csim%20%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7Bw%7D_0,%20%5CSigma_0%20%5Cright)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B3%7D"></span></p>
<p>with <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_0=%5Cmathbf%7B0%7D"> and <img src="https://latex.codecogs.com/png.latex?%5CSigma_0=%5Csigma%5E2%5Cmathbf%7BI%7D">. Plugging this into Bayes‚Äô rule we finally have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)&amp;%5Cpropto%5Cprod_%7Bn=1%7D%5EN%20%5Ctext%7BBer%7D(y_n%7C%5Csigma(%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_n))%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7Bw%7D_0,%20%5CSigma_0%20%5Cright)%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>Unlike with linear regression there are no closed-form analytical solutions to estimating or maximising this posterior, but fortunately accurate approximations do exist <span class="citation" data-cites="murphy2022probabilistic">(Murphy 2022)</span>. One of the simplest approaches called <strong>Laplace Approximation</strong> is straight-forward to implement and computationally very efficient. It relies on the observation that under the assumption of a Gaussian prior, the posterior of logistic regression is also approximately Gaussian: in particular, this Gaussian distribution is centered around the <strong>maximum a posteriori</strong> (MAP) estimate <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bw%7D%7D=%5Carg%5Cmax_%7B%5Cmathbf%7Bw%7D%7D%20p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> with a covariance matrix equal to the inverse Hessian evaluated at the mode <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5CSigma%7D=(%5Cmathbf%7BH%7D(%5Chat%7B%5Cmathbf%7Bw%7D%7D))%5E%7B-1%7D">. With that in mind, finding <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bw%7D%7D"> seems like a natural next step.</p>
</section>
<section id="solving-the-problem" class="level3">
<h3 class="anchored" data-anchor-id="solving-the-problem">Solving the problem</h3>
<p>In practice we do not maximize the posterior <img src="https://latex.codecogs.com/png.latex?p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> directly. Instead we minimize the negative log likelihood, which is an equivalent optimization problem and easier to implement. In Equation&nbsp;4 below I have denoted the negative log likelihood as <img src="https://latex.codecogs.com/png.latex?%5Cell(%5Cmathbf%7Bw%7D)"> indicating that this is the <strong>loss function</strong> we aim to minimize. The following two lines in Equation&nbsp;4 show the gradient and Hessian - so the first- and second-order derivatives of <img src="https://latex.codecogs.com/png.latex?%5Cell"> with respect to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> - where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BH%7D_0=%5CSigma_0%5E%7B-1%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmu_n=%5Csigma(%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_n)">. To understand how exactly the gradient and Hessian are derived see for example chapter 10 in <span class="citation" data-cites="murphy2022probabilistic">Murphy (2022)</span>.<sup>2</sup>.</p>
<p><span id="eq-likeli"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cell(%5Cmathbf%7Bw%7D)&amp;=-%20%5Csum_%7Bn=1%7D%5E%7BN%7D%20%5By_n%20%5Clog%20%5Cmu_n%20+%20(1-y_n)%5Clog%20(1-%5Cmu_n)%5D%20+%20%5Cfrac%7B1%7D%7B2%7D%20(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%5ET%5Cmathbf%7BH%7D_0(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%20%5C%5C%0A&amp;&amp;%20%5Cnabla_%7B%5Cmathbf%7Bw%7D%7D%5Cell(%5Cmathbf%7Bw%7D)&amp;=%20%5Csum_%7Bn=1%7D%5E%7BN%7D%20(%5Cmu_n-y_n)%20%5Cmathbf%7Bx%7D_n%20+%20%5Cmathbf%7BH%7D_0(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%20%5C%5C%0A&amp;&amp;%20%5Cnabla%5E2_%7B%5Cmathbf%7Bw%7D%7D%5Cell(%5Cmathbf%7Bw%7D)&amp;=%20%5Csum_%7Bn=1%7D%5E%7BN%7D%20(%5Cmu_n-y_n)%20%5Cleft(%20%5Cmu_n(1-%5Cmu_n)%20%5Cmathbf%7Bx%7D_n%20%5Cmathbf%7Bx%7D_n%5ET%20%5Cright)%20+%20%5Cmathbf%7BH%7D_0%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B4%7D"></span></p>
<div class="sidenote">
<p><strong>SIDENOTE</strong> üí°</p>
<p>Note how earlier I mentioned that maximising the posterior likelihood can be seen as regularized maximum likelihood estimation. We can now make that connection explicit: in Equation&nbsp;4 let us assume that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_0=%5Cmathbf%7B0%7D">. Then since <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BH%7D_0=%5Clambda%5Cmathbf%7BI%7D"> with <img src="https://latex.codecogs.com/png.latex?1/%5Csigma%5E2"> the second term in the first line is simply <img src="https://latex.codecogs.com/png.latex?%5Clambda%20%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bw%7D=%5Clambda%20%5Cfrac%7B1%7D%7B2%7D%20%7C%7C%5Cmathbf%7Bw%7D%7C%7C_2%5E2">. This is equivalent to running logistic regression with an <img src="https://latex.codecogs.com/png.latex?%5Cell_2">-penalty <span class="citation" data-cites="bishop2006pattern">(Bishop 2006)</span>.</p>
</div>
<p><br></p>
<p>Since minimizing the loss function in Equation&nbsp;4 is a convex optimization problem we have many efficient algorithms to choose from in order to solve this problem. With the Hessian at hand it seems natural to use a second-order method, because incorporating information about the curvature of the loss function generally leads to faster convergence. Here we will implement <strong>Newton‚Äôs method</strong> in line with the presentation in chapter 8 of <span class="citation" data-cites="murphy2022probabilistic">Murphy (2022)</span>.</p>
</section>
<section id="posterior-predictive" class="level3">
<h3 class="anchored" data-anchor-id="posterior-predictive">Posterior predictive</h3>
<p>Suppose now that we have trained the Bayesian Logistic Regression model as our binary classifier <img src="https://latex.codecogs.com/png.latex?g_N(%5Cmathbf%7Bx%7D)"> using our training data <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D">. A new unlabelled sample <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%7Bx%7D_%7BN+1%7D,?)"> arrives. As with any binary classifier we can predict the missing label by simply plugging the new sample into our classifier <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_%7BN+1%7D=g_N(%5Cmathbf%7Bx%7D_%7BN+1%7D)=%5Csigma(%5Chat%7B%5Cmathbf%7Bw%7D%7D%5ET%5Cmathbf%7Bx%7D_%7BN+1%7D)">, where <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bw%7D%7D"> is the MAP estimate as before. If at training phase we have found <img src="https://latex.codecogs.com/png.latex?g_N(%5Cmathbf%7Bx%7D)"> to achieve good accuracy, we may expect <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%7Bx%7D_%7BN+1%7D,%5Chat%7By%7D_%7BN+1%7D)"> to be a reasonably good approximation of the true and unobserved pair <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%7Bx%7D_%7BN+1%7D,y_%7BN+1%7D)">. But since we are still dealing with an expected value of a random variable, we would generally like to have an idea of how noisy this prediction is.</p>
<p>Formally, we are interested in the <strong>posterior predictive</strong> distribution:</p>
<p><span id="eq-posterior-pred"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Cmathcal%7BD%7D)&amp;=%20%5Cint%20%5Csigma(%5Cmathbf%7Bw%7D%5ET%20%5Cmathbf%7Bx%7D)p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)d%5Cmathbf%7Bw%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B5%7D"></span></p>
<div class="sidenote">
<p><strong>SIDENOTE</strong> üí°</p>
<p>The approach that ignores uncertainty altogether corresponds to what is referred to as <strong>plugin</strong> approximation of the posterior predictive. Formally, it imposes <img src="https://latex.codecogs.com/png.latex?p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Cmathcal%7BD%7D)%5Capprox%20p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Chat%7B%5Cmathbf%7Bw%7D%7D)">.</p>
</div>
<p><br></p>
<p>With the posterior distribution over model parameters <img src="https://latex.codecogs.com/png.latex?p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> at hand we have the necessary ingredients to estimate the posterior predictive distribution <img src="https://latex.codecogs.com/png.latex?p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Cmathcal%7BD%7D)">.</p>
<p>An obvious, but computationally expensive way to estimate it is through Monte Carlo: draw <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_s"> from <img src="https://latex.codecogs.com/png.latex?p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> for <img src="https://latex.codecogs.com/png.latex?s=1:S"> and compute fitted values <img src="https://latex.codecogs.com/png.latex?%5Csigma(%5Cmathbf%7Bw_s%7D%5ET%5Cmathbf%7Bx%7D)"> each. Then the posterior predictive distribution corresponds to the average over all fitted values, <img src="https://latex.codecogs.com/png.latex?p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Cmathcal%7BD%7D)=1/S%20%5Csum_%7Bs=1%7D%5E%7BS%7D%5Csigma(%5Cmathbf%7Bw_s%7D%5ET%5Cmathbf%7Bx%7D)">. By the law of large numbers the Monte Carlo estimate is an accurate estimate of the true posterior predictive for large enough <img src="https://latex.codecogs.com/png.latex?S">. Of course, ‚Äúlarge enough‚Äù is somewhat loosely defined here and depending on the problem can mean ‚Äúvery large‚Äù. Consequently, the computational costs involved essentially know no upper bound.</p>
<p>Fortunately, it turns out that we can trade off a little bit of accuracy in return for a convenient analytical solution. In particular, we have that <img src="https://latex.codecogs.com/png.latex?%5Csigma(a)%20%5Capprox%20%5CPhi(%5Clambda%20a)"> where <img src="https://latex.codecogs.com/png.latex?%5CPhi(.)"> is the standard Gaussian cdf and <img src="https://latex.codecogs.com/png.latex?%5Clambda=%5Cpi/8"> ensures that the two functions have the same slope at the origin (Figure&nbsp;2). Without dwelling further on the details we can use this finding to approximate the integral in Equation&nbsp;5 as a sigmoid function. This is called <strong>probit approximation</strong> and implemented below.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-probit" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/index_files/figure-html/fig-probit-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Demonstration of the probit approximation.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="the-code" class="level2">
<h2 class="anchored" data-anchor-id="the-code">The code</h2>
<p>We now have all the necessary ingredients to code Bayesian Logistic Regression up from scratch. While in practice we would usually want to rely on existing packages that have been properly tested, I often find it very educative and rewarding to program algorithms from the bottom up. You will see that Julia‚Äôs syntax so closely resembles the mathematical formulas we have seen above, that going from maths to code is incredibly easy. Seeing those formulas and algorithms then actually doing their magic is quite fun! The code chunk below, for example, shows the implementation of the loss function and its derivatives from Equation&nbsp;4 above. Take a moment to go through the code line-by-line and try to understand how it relates back to the equations in Equation&nbsp;4. Isn‚Äôt it amazing how closely the code resembles the actual equations?</p>
<script src="https://gist.github.com/pat-alt/cc53a11470e4fb736f24bb6de2393f54.js"></script>
<p>Aside from the optimization routine this is essentially all there is to coding up Bayesian Logistic Regression from scratch in Julia Language. If you are curious to see the full source code in detail you can check out this <a href="https://colab.research.google.com/github/pat-alt/pat-alt.github.io/blob/main/content/post/2021-11-15-bayesian-logistic-regression/julia_implementation.ipynb">interactive notebook</a>. Now let us finally turn back to our synthetic data and see how Bayesian Logistic Regression can help us understand the uncertainty around our model predictions.</p>
<div class="disclaimer">
<p><strong>DISCLAIMER</strong> ‚ùóÔ∏è</p>
<p>I should mention that this is the first time I program in Julia, so for any Julia pros out there: please bear with me! Happy to hear your suggestions/comments.</p>
</div>
<p><br></p>
</section>
<section id="the-estimates" class="level2">
<h2 class="anchored" data-anchor-id="the-estimates">The estimates</h2>
<p>Figure&nbsp;3 below shows the resulting posterior distribution for <img src="https://latex.codecogs.com/png.latex?w_2"> and <img src="https://latex.codecogs.com/png.latex?w_3"> at varying degrees of prior uncertainty <img src="https://latex.codecogs.com/png.latex?%5Csigma">. The constant <img src="https://latex.codecogs.com/png.latex?w_1"> is held constant at the mode (<img src="https://latex.codecogs.com/png.latex?%5Chat%7Bw%7D_1">). The red dot indicates the MLE. Note how for the choice of <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Crightarrow%200"> the posterior is equal to the prior. This is intuitive since we have imposed that we have no uncertainty around our prior beliefs and hence no amount of new evidence can move us in any direction. Conversely, for <img src="https://latex.codecogs.com/png.latex?%5Csigma%20%5Crightarrow%20%5Cinfty"> the posterior distribution is centered around the unconstrained MLE: prior knowledge is very uncertain and hence the posterior is dominated by the likelihood of the data.</p>
<div id="fig-posterior" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/www/images/posterior.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3: Posterior distribution for <img src="https://latex.codecogs.com/png.latex?w_2"> and <img src="https://latex.codecogs.com/png.latex?w_3"> at varying degrees of prior uncertainty <img src="https://latex.codecogs.com/png.latex?%5Csigma">.</figcaption><p></p>
</figure>
</div>
<p>What about the posterior predictive? The story is similar: since for <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Crightarrow%200"> the posterior is completely dominated by the zero-mean prior we have <img src="https://latex.codecogs.com/png.latex?p(y=1%7C%5Cmathbf%7Bx%7D,%5Chat%7B%5Cmathbf%7Bw%7D%7D)=0.5"> everywhere (top left panel in Figure&nbsp;4. As we gradually increase uncertainty around our prior the predictive posterior depends more and more on the data <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D">: uncertainty around predicted labels is high only in regions that are not populated by samples <img src="https://latex.codecogs.com/png.latex?(y_n,%20%5Cmathbf%7Bx%7D_n)">. Not surprisingly, this effect is strongest for the MLE (<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Crightarrow%20%5Cinfty">) where we see some evidence of overfitting.</p>
<div id="fig-predictive" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/www/images/predictive.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;4: Predictive posterior distribution at varying degrees of prior uncertainty <img src="https://latex.codecogs.com/png.latex?%5Csigma">.</figcaption><p></p>
</figure>
</div>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping up</h2>
<p>In this post we have seen how Bayesian Logistic Regression can be implemented from scratch in Julia language. The estimated posterior distribution over model parameters can be used to quantify uncertainty around coefficients and model predictions. I have argued that it is important to be transparent about model uncertainty to avoid being overly confident in estimates.</p>
<p>There are many more benefits associated with Bayesian (probabilistic) machine learning. Understanding where in the input domain our model exerts high uncertainty can for example be instrumental in labelling data: see for example <span class="citation" data-cites="gal2017deep">Gal, Islam, and Ghahramani (2017)</span> and follow-up works for an interesting application to <strong>active learning</strong> for image data. Similarly, there is a recent work that uses estimates of the posterior predictive in the context of <strong>algorithmic recourse</strong> <span class="citation" data-cites="schut2021generating">(Schut et al. 2021)</span>. For a brief introduction to algorithmic recourse see one of my <a href="../../../blog/posts/individual-recourse-for-black-box-models/index.html">previous posts</a>.</p>
<p>As a great reference for further reading about probabilistic machine learning I can highly recommend <span class="citation" data-cites="murphy2022probabilistic">Murphy (2022)</span>. An electronic version of the book is currently freely available as a draft. Finally, remember that if you want to try yourself at the code, you can check out this <a href="https://colab.research.google.com/github/pat-alt/pat-alt.github.io/blob/43e18fe5e8cc625ffe1e4270da49f253dac8523a/content/post/2021-10-27-bayesian-logistic-regression/julia_implementation.ipynb">interactive notebook</a>.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bishop2006pattern" class="csl-entry">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. <span>springer</span>.
</div>
<div id="ref-gal2017deep" class="csl-entry">
Gal, Yarin, Riashat Islam, and Zoubin Ghahramani. 2017. <span>‚ÄúDeep Bayesian Active Learning with Image Data.‚Äù</span> In <em>International <span>Conference</span> on <span>Machine Learning</span></em>, 1183‚Äì92. <span>PMLR</span>.
</div>
<div id="ref-murphy2012machine" class="csl-entry">
Murphy, Kevin P. 2012. <em>Machine Learning: <span>A</span> Probabilistic Perspective</em>. <span>MIT press</span>.
</div>
<div id="ref-murphy2022probabilistic" class="csl-entry">
‚Äî‚Äî‚Äî. 2022. <em>Probabilistic <span>Machine Learning</span>: <span>An</span> Introduction</em>. <span>MIT Press</span>.
</div>
<div id="ref-schut2021generating" class="csl-entry">
Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. <span>‚ÄúGenerating <span>Interpretable Counterfactual Explanations By Implicit Minimisation</span> of <span>Epistemic</span> and <span>Aleatoric Uncertainties</span>.‚Äù</span> In <em>International <span>Conference</span> on <span>Artificial Intelligence</span> and <span>Statistics</span></em>, 1756‚Äì64. <span>PMLR</span>.
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>We let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D=(10,%200.75,%20-2.5)%5ET"> define the true coefficients.‚Ü©Ô∏é</p></li>
<li id="fn2"><p>Note that the author works with the negative log likelihood scaled by the sample size‚Ü©Ô∏é</p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick},
  title = {Bayesian {Logistic} {Regression}},
  date = {21-11-15},
  url = {https://www.paltmeyer.com/blog//blog/posts/bayesian-logit},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 21AD. <span>‚ÄúBayesian Logistic Regression.‚Äù</span>
November 15, 21AD. <a href="https://www.paltmeyer.com/blog//blog/posts/bayesian-logit">https://www.paltmeyer.com/blog//blog/posts/bayesian-logit</a>.
</div></div></section></div> ]]></description>
  <category>bayes</category>
  <category>logistic regression</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/index.html</guid>
  <pubDate>Sun, 14 Nov 2021 23:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Individual recourse for Black Box Models</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/intro.gif" class="figure-img">
</figure>
</div>
<blockquote class="blockquote">
<p>‚ÄúYou cannot appeal to [algorithms]. They do not listen. Nor do they bend.‚Äù</p>
<p>‚Äî Cathy O‚ÄôNeil</p>
</blockquote>
<p>In her popular book <a href="https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction">Weapons of Math Destruction</a> Cathy O‚ÄôNeil presents the example of public school teacher Sarah Wysocki, who lost her job after a teacher evaluation algorithm had rendered her redundant <span class="citation" data-cites="oneil2016weapons">(O‚ÄôNeil 2016)</span>. Sarah was highly popular among her peers, supervisors and students.</p>
<p>This post looks at a novel algorithmic solution to the problem that individuals like Sarah, who are faced with an undesirable outcome, should be provided with means to revise that outcome. The literature commonly refers to this as <em>individual recourse</em>. One of the first approaches towards individual recourse was proposed by <span class="citation" data-cites="ustun2019actionable">Ustun, Spangher, and Liu (2019)</span>. In a recent follow-up paper, <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span> propose a methodology coined <code>REVISE</code>, which extends the earlier approach in at least three key ways:</p>
<ol type="1">
<li><code>REVISE</code> provides a framework that avoids suggesting an unrealistic set of changes by imposing a threshold likelihood on the revised attributes.</li>
<li>It is applicable to a broader class of models including Black Box classifiers and structural causal models.</li>
<li>It can be used to detect poorly defined proxies and biases.</li>
</ol>
<p>For a detailed discussion of these points you may check out this <a href="paper_presentation.pdf">slide deck</a> or consult the paper directly (freely available on <a href="https://deepai.org/publication/towards-realistic-individual-recourse-and-actionable-explanations-in-black-box-decision-making-systems">DeepAI</a>). Here, we will abstract from some of these complications and instead look at an application of a slightly simplified version of <code>REVISE</code>. This should help us to first build a good intuition. Readers interested in the technicalities and code may find all of this in the annex below.</p>
<section id="from-to" class="level2">
<h2 class="anchored" data-anchor-id="from-to">From üê± to üê∂</h2>
<p>We will explain <code>REVISE</code> through a short tale of cats and dogs. The protagonist of this tale is Kitty üê±, a young cat that identifies as a dog. Unfortunately, Kitty is not very tall and her tail, though short for a cat, is longer than that of the average dog (Figure&nbsp;1).</p>
<div id="fig-density" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/density.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Empirical distributions of simulated data set describing cats and dogs. Vertical stalks represent Kitty‚Äôs attribute values.</figcaption><p></p>
</figure>
</div>
<p>Much to her dismay, Kitty has been recognized as a cat by a linear classifier <img src="https://latex.codecogs.com/png.latex?g_n(X)"> that we trained through stochastic gradient descent using the data on animals‚Äô height and tail length. Once again interested readers may find technical details and code in the annex below. Figure&nbsp;2 shows the resulting linear separation in the attribute space with the decision boundary in solid black and Kitty‚Äôs location indicated by a red circle. Can we provide individual recourse to Kitty?</p>
<div id="fig-class" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/class.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Linear separation of cats and dogs in the 2-dimensional attribute space with the decision boundary of the fitted classifier in solid black. Kitty‚Äôs location is indicated by a red circle.</figcaption><p></p>
</figure>
</div>
<p>Let‚Äôs see if and how we can apply <code>REVISE</code> to Kitty‚Äôs problem. The following summary should give you some flavour of how the algorithm works:</p>
<ol type="1">
<li>Initialize <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i'%5E%7B(0)%7D">, that is the attributes that will be revised recursively. Kitty‚Äôs original attributes seem like a reasonable place to start.</li>
<li>Through gradient descent recursively revise <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i'%5E%7B(t)%7D"> until <img src="https://latex.codecogs.com/png.latex?g_n(%5Cmathbf%7Bx%7D_i'%5E%7B(T)%7D)=">üê∂. At this point <img src="https://latex.codecogs.com/png.latex?T"> the descent terminates since for these revised attributes the classifier labels Kitty as a dog.</li>
<li>Return <img src="https://latex.codecogs.com/png.latex?%5Cdelta_i=%5Cmathbf%7Bx%7D_i'%5E%7B(T)%7D-%5Cmathbf%7Bx%7D_i">, that is the individual recourse for Kitty.</li>
</ol>
<p>Figure&nbsp;3 illustrates what happens when this approach is applied to Kitty‚Äôs problem. The different panels show the results for different values of a regularization parameter <img src="https://latex.codecogs.com/png.latex?%5Clambda"> that governs the trade-off between achieving the desired label switch and keeping the distance between the original (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i">) and revised (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i'">) attributes small. In all but one case, <code>REVISE</code> converges: a decrease in tail length along with an increase in height eventually allows Kitty to cross the decision boundary. In other words, we have successfully turned Kitty into a dog - at least in the eyes of the linear classifier!</p>
<p>We also observe that as we increase <img src="https://latex.codecogs.com/png.latex?%5Clambda"> for a fixed learning rate, <code>REVISE</code> takes longer to converge. This should come as no surprise, since higher values of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> lead to greater regularization with respect to the penalty we place on the distance that Kitty has to travel. When we penalize too much (<img src="https://latex.codecogs.com/png.latex?%5Clambda=10">), Kitty never reaches the decision boundary, because she is reluctant to change her characteristics beyond a certain point. While not visible to the naked eye, in this particular example <img src="https://latex.codecogs.com/png.latex?%5Clambda=0.001"> corresponds to the best choice among the candidate values.</p>
<div id="fig-revise" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/revise.gif" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3: The simplified <code>REVISE</code> algorithm in action: how Kitty crosses the decision boundary by changing her attributes. Regularization with respect to the distance penalty increases from top left to bottom right.</figcaption><p></p>
</figure>
</div>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>While hopefully Kitty‚Äôs journey has provided you with some useful intuition, the story is of course very silly. Even if your cat ever seems to signal that she wants to be a dog, helping her cross that decision boundary will be tricky. Some attributes are simply immutable or very difficult to change, which <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span> do not fail to account for in their framework. Their proposed methodology offers a simple and ingenious approach towards providing individual recourse. Instead of concerning ourselves with Black Box interpretability, why not simply provide remedy in case things go wrong?</p>
<p>To some extent that idea has its merit. As this post has hopefully shown, <code>REVISE</code> is straight-forward to understand and readily applicable. It could be a very useful tool to provide individual recourse in many real-world applications. As the implementation of our simplified version of <code>REVISE</code> demonstrates, researchers should also find it relatively easy to develop the methodology further and tailor it to specific use cases. The simpler version here, for example, may be useful in settings where the dimensionality is relatively small and one can reasonably model the distribution of attributes without the need for generative models.</p>
<p>Still, you may be wondering: if the original classifier is based on poorly defined rules and proxies, then what good does <code>REVISE</code> really do? Going back to the example of high-school teacher Sarah Wysocki, one of the key attributes determining teachers‚Äô evaluations was their students‚Äô performance. Realizing this, some teachers took the shortest route to success by artificially inflating their students‚Äô test scores. That same course of action may well have been suggested by <code>REVISE</code>. As <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span> demonstrate, this very property of <code>REVISE</code> may actually proof useful in detecting weaknesses of decision making systems before setting them loose (key contribution 3).</p>
<p>Nonetheless, the example above also demonstrates that approaches like <code>REVISE</code>, useful as they may be, tend to provide solutions for very particular problems. In reality data-driven decision making systems are often subject to many different problems and hence research on trustworthy AI will need to tackle the issue from various angles. A few places to start include the question of dealing with data that is inherently biased, improving ad-hoc and post-hoc model interpretability and continuing efforts around causality-inspired AI.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-joshi2019realistic" class="csl-entry">
Joshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. <span>‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù</span> <a href="https://arxiv.org/abs/1907.09615">https://arxiv.org/abs/1907.09615</a>.
</div>
<div id="ref-oneil2016weapons" class="csl-entry">
O‚ÄôNeil, Cathy. 2016. <em>Weapons of Math Destruction: <span>How</span> Big Data Increases Inequality and Threatens Democracy</em>. <span>Crown</span>.
</div>
<div id="ref-ustun2019actionable" class="csl-entry">
Ustun, Berk, Alexander Spangher, and Yang Liu. 2019. <span>‚ÄúActionable Recourse in Linear Classification.‚Äù</span> In <em>Proceedings of the <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 10‚Äì19.
</div>
</div>
</section>
<section id="annex" class="level2">
<h2 class="anchored" data-anchor-id="annex">Annex</h2>
<p>In my blog posts I aim to implement interesting ideas from scratch even if that sometimes means that things need to undergo some sort of simplification. The benefit of this approach is that the experience is educationally rewarding - both for myself and hopefully also for readers. The first two sections of this annex show how <code>REVISE</code> and linear classification can be implemented in R. The final section just shows how the synthetic data was generated. To also inspect the code that generates the visualizations and everything else, you can find the source code of this file on <a href="https://github.com/pat-alt/patalt/blob/master/content/post/2021-04-26-individual-recourse-for-black-box-models/index.Rmd">GitHub</a>.</p>
<section id="linear-classifier" class="level3">
<h3 class="anchored" data-anchor-id="linear-classifier">Linear classifier</h3>
<p>Linear classification is implemented through stochastic gradient descent (SGD) with Hinge loss</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cell(-%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_i%20y_i)&amp;=(1-%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_i%20y_i)_+%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> is a coefficient vector, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i"> is the attribute vector of individual <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?y_i"> is the individual‚Äôs outcome. Since we apply SGD in order to minimize the loss function <img src="https://latex.codecogs.com/png.latex?%5Cell"> by varying <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D">, we need an expression for its gradient with respect to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D">, which is given by:</p>
<p><span id="eq-hinge"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cnabla_%7B%5Cmathbf%7BW%7D%7D%20%5Cleft(%20%5Cell(-%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_i%20y_i)%20%5Cright)%20&amp;=%20%5Cbegin%7Bcases%7D%20-%5Cmathbf%7Bx%7D_i%20y_i%20&amp;%20%5Ctext%7Bif%7D%20%5C%20%5C%20%5C%20%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_i%20y_i%20%5Cle%201%5C%5C%200%20&amp;%20%5Ctext%7Botherwise%7D%20%5Cend%7Bcases%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B1%7D"></span></p>
<p>The code below uses this analytical solution to perform SGD over <img src="https://latex.codecogs.com/png.latex?T"> iterations or as long as updates yield feasible parameter values. As the final vector of coefficients the function returns <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5Cbar%7Bw%7D%7D=%20%5Cfrac%7B1%7D%7BT%7D%20%5Csum_%7Bt=1%7D%5E%7BT%7D%20%5Cmathbf%7Bw%7D_t">. Denoting the optimal coefficient vector as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%5E*">, it can be shown that under certain conditions <img src="https://latex.codecogs.com/png.latex?%5Cell(%5Cmathbf%7B%5Cbar%7Bw%7D%7D)%5Crightarrow%5Cell(%5Cmathbf%7Bw%7D%5E*)"> as <img src="https://latex.codecogs.com/png.latex?T%5Crightarrow%5Cinfty">.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="co" style="color: #5E5E5E;">#' Stochastic gradient descent</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;">#'</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;">#' @param X Feature matrix.</span></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;">#' @param y Vector containing training labels.</span></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;">#' @param eta Learning rate.</span></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;">#' @param n_iter Maximum number of iterations.</span></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;">#' @param w_init Initial parameter values.</span></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;">#' @param save_steps Boolean checking if coefficients should be saved at each step.</span></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;">#'</span></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;">#' @return</span></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;">#' @export</span></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;">#'</span></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;">#' @author Patrick Altmeyer</span></span>
<span id="cb1-14">linear_classifier <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(X,y,<span class="at" style="color: #657422;">eta=</span><span class="fl" style="color: #AD0000;">0.001</span>,<span class="at" style="color: #657422;">n_iter=</span><span class="dv" style="color: #AD0000;">1000</span>,<span class="at" style="color: #657422;">w_init=</span><span class="cn" style="color: #8f5902;">NULL</span>,<span class="at" style="color: #657422;">save_steps=</span><span class="cn" style="color: #8f5902;">FALSE</span>) {</span>
<span id="cb1-15">  <span class="co" style="color: #5E5E5E;"># Initialization: ----</span></span>
<span id="cb1-16">  n <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">nrow</span>(X) <span class="co" style="color: #5E5E5E;"># number of observations</span></span>
<span id="cb1-17">  d <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">ncol</span>(X) <span class="co" style="color: #5E5E5E;"># number of dimensions</span></span>
<span id="cb1-18">  <span class="cf" style="color: #003B4F;">if</span> (<span class="fu" style="color: #4758AB;">is.null</span>(w_init)) {</span>
<span id="cb1-19">    w <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">matrix</span>(<span class="fu" style="color: #4758AB;">rep</span>(<span class="dv" style="color: #AD0000;">0</span>,d)) <span class="co" style="color: #5E5E5E;"># initialize coefficients as zero...</span></span>
<span id="cb1-20">  } <span class="cf" style="color: #003B4F;">else</span> {</span>
<span id="cb1-21">    w <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">matrix</span>(w_init) <span class="co" style="color: #5E5E5E;"># ...unless initial values have been provided.</span></span>
<span id="cb1-22">  }</span>
<span id="cb1-23">  w_avg <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">/</span>n_iter <span class="sc" style="color: #5E5E5E;">*</span> w <span class="co" style="color: #5E5E5E;"># initialize average coefficients</span></span>
<span id="cb1-24">  iter <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">1</span> <span class="co" style="color: #5E5E5E;"># iteration count</span></span>
<span id="cb1-25">  <span class="cf" style="color: #003B4F;">if</span> (save_steps) {</span>
<span id="cb1-26">    steps <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">data.table</span>(<span class="at" style="color: #657422;">iter=</span><span class="dv" style="color: #AD0000;">0</span>, <span class="at" style="color: #657422;">w=</span><span class="fu" style="color: #4758AB;">c</span>(w), <span class="at" style="color: #657422;">d=</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span>d) <span class="co" style="color: #5E5E5E;"># if desired, save coefficient at each step</span></span>
<span id="cb1-27">  } <span class="cf" style="color: #003B4F;">else</span> {</span>
<span id="cb1-28">    steps <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cn" style="color: #8f5902;">NA</span></span>
<span id="cb1-29">  }</span>
<span id="cb1-30">  feasible_w <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cn" style="color: #8f5902;">TRUE</span> <span class="co" style="color: #5E5E5E;"># to check if coefficients are finite, non-nan, ...</span></span>
<span id="cb1-31">  <span class="co" style="color: #5E5E5E;"># Surrogate loss:</span></span>
<span id="cb1-32">  l <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(X,y,w) {</span>
<span id="cb1-33">    x <span class="ot" style="color: #003B4F;">&lt;-</span> (<span class="sc" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="sc" style="color: #5E5E5E;">*</span> <span class="fu" style="color: #4758AB;">crossprod</span>(X,w) <span class="sc" style="color: #5E5E5E;">*</span> y</span>
<span id="cb1-34">    <span class="fu" style="color: #4758AB;">pmax</span>(<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">1</span> <span class="sc" style="color: #5E5E5E;">+</span> x) <span class="co" style="color: #5E5E5E;"># Hinge loss</span></span>
<span id="cb1-35">  }</span>
<span id="cb1-36">  grad <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(X,y,w) {</span>
<span id="cb1-37">    X <span class="sc" style="color: #5E5E5E;">%*%</span> <span class="fu" style="color: #4758AB;">ifelse</span>(<span class="fu" style="color: #4758AB;">crossprod</span>(X,w) <span class="sc" style="color: #5E5E5E;">*</span> y<span class="sc" style="color: #5E5E5E;">&lt;=</span><span class="dv" style="color: #AD0000;">1</span>,<span class="sc" style="color: #5E5E5E;">-</span>y,<span class="dv" style="color: #AD0000;">0</span>) <span class="co" style="color: #5E5E5E;"># Gradient of Hinge loss</span></span>
<span id="cb1-38">  }</span>
<span id="cb1-39">  <span class="co" style="color: #5E5E5E;"># Stochastic gradient descent: ----</span></span>
<span id="cb1-40">  <span class="cf" style="color: #003B4F;">while</span> (feasible_w <span class="sc" style="color: #5E5E5E;">&amp;</span> iter<span class="sc" style="color: #5E5E5E;">&lt;</span>n_iter) {</span>
<span id="cb1-41">    t <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sample</span>(<span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span>n,<span class="dv" style="color: #AD0000;">1</span>) <span class="co" style="color: #5E5E5E;"># random draw</span></span>
<span id="cb1-42">    X_t <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">matrix</span>(X[t,])</span>
<span id="cb1-43">    y_t <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">matrix</span>(y[t])</span>
<span id="cb1-44">    v_t <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">grad</span>(X_t,y_t,w) <span class="co" style="color: #5E5E5E;"># compute estimate of gradient</span></span>
<span id="cb1-45">    <span class="co" style="color: #5E5E5E;"># Update:</span></span>
<span id="cb1-46">    w <span class="ot" style="color: #003B4F;">&lt;-</span> w <span class="sc" style="color: #5E5E5E;">-</span> eta <span class="sc" style="color: #5E5E5E;">*</span> v_t <span class="co" style="color: #5E5E5E;"># update coefficient vector</span></span>
<span id="cb1-47">    feasible_w <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">all</span>(<span class="fu" style="color: #4758AB;">sapply</span>(w, <span class="cf" style="color: #003B4F;">function</span>(i) <span class="sc" style="color: #5E5E5E;">!</span><span class="fu" style="color: #4758AB;">is.na</span>(i) <span class="sc" style="color: #5E5E5E;">&amp;</span> <span class="fu" style="color: #4758AB;">is.finite</span>(i))) <span class="co" style="color: #5E5E5E;"># check if feasible</span></span>
<span id="cb1-48">    <span class="cf" style="color: #003B4F;">if</span> (feasible_w) {</span>
<span id="cb1-49">      w_avg <span class="ot" style="color: #003B4F;">&lt;-</span> w_avg <span class="sc" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">/</span>n_iter <span class="sc" style="color: #5E5E5E;">*</span> w <span class="co" style="color: #5E5E5E;"># update average</span></span>
<span id="cb1-50">    }</span>
<span id="cb1-51">    <span class="cf" style="color: #003B4F;">if</span> (save_steps) {</span>
<span id="cb1-52">      steps <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">rbind</span>(steps, <span class="fu" style="color: #4758AB;">data.table</span>(<span class="at" style="color: #657422;">iter=</span>iter, <span class="at" style="color: #657422;">w=</span><span class="fu" style="color: #4758AB;">c</span>(w), <span class="at" style="color: #657422;">d=</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span>d))</span>
<span id="cb1-53">    }</span>
<span id="cb1-54">    iter <span class="ot" style="color: #003B4F;">&lt;-</span> iter <span class="sc" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span> <span class="co" style="color: #5E5E5E;"># increase counter</span></span>
<span id="cb1-55">  }</span>
<span id="cb1-56">  <span class="co" style="color: #5E5E5E;"># Output: ----</span></span>
<span id="cb1-57">  output <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">list</span>(</span>
<span id="cb1-58">    <span class="at" style="color: #657422;">X =</span> X,</span>
<span id="cb1-59">    <span class="at" style="color: #657422;">y =</span> <span class="fu" style="color: #4758AB;">matrix</span>(y),</span>
<span id="cb1-60">    <span class="at" style="color: #657422;">coefficients =</span> w_avg,</span>
<span id="cb1-61">    <span class="at" style="color: #657422;">eta =</span> eta,</span>
<span id="cb1-62">    <span class="at" style="color: #657422;">n_iter =</span> n_iter,</span>
<span id="cb1-63">    <span class="at" style="color: #657422;">steps =</span> steps</span>
<span id="cb1-64">  )</span>
<span id="cb1-65">  <span class="fu" style="color: #4758AB;">class</span>(output) <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="st" style="color: #20794D;">"classifier"</span> <span class="co" style="color: #5E5E5E;"># assign S3 class</span></span>
<span id="cb1-66">  <span class="fu" style="color: #4758AB;">return</span>(output)</span>
<span id="cb1-67">}</span>
<span id="cb1-68"></span>
<span id="cb1-69"><span class="co" style="color: #5E5E5E;"># Methods: ----</span></span>
<span id="cb1-70">print.classifier <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(classifier) {</span>
<span id="cb1-71">  <span class="fu" style="color: #4758AB;">print</span>(<span class="st" style="color: #20794D;">"Coefficients:"</span>)</span>
<span id="cb1-72">  <span class="fu" style="color: #4758AB;">print</span>(classifier<span class="sc" style="color: #5E5E5E;">$</span>coefficients)</span>
<span id="cb1-73">}</span>
<span id="cb1-74">print <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(classifier) {</span>
<span id="cb1-75">  <span class="fu" style="color: #4758AB;">UseMethod</span>(<span class="st" style="color: #20794D;">"print"</span>)</span>
<span id="cb1-76">}</span>
<span id="cb1-77"></span>
<span id="cb1-78">predict.classifier <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(classifier, <span class="at" style="color: #657422;">newdata=</span><span class="cn" style="color: #8f5902;">NULL</span>, <span class="at" style="color: #657422;">discrete=</span><span class="cn" style="color: #8f5902;">TRUE</span>) {</span>
<span id="cb1-79">  <span class="cf" style="color: #003B4F;">if</span> (<span class="sc" style="color: #5E5E5E;">!</span><span class="fu" style="color: #4758AB;">is.null</span>(newdata)) {</span>
<span id="cb1-80">    fitted <span class="ot" style="color: #003B4F;">&lt;-</span> newdata <span class="sc" style="color: #5E5E5E;">%*%</span> classifier<span class="sc" style="color: #5E5E5E;">$</span>coefficients <span class="co" style="color: #5E5E5E;"># out-of-sampple prediction</span></span>
<span id="cb1-81">  } <span class="cf" style="color: #003B4F;">else</span> {</span>
<span id="cb1-82">    fitted <span class="ot" style="color: #003B4F;">&lt;-</span> classifier<span class="sc" style="color: #5E5E5E;">$</span>X <span class="sc" style="color: #5E5E5E;">%*%</span> classifier<span class="sc" style="color: #5E5E5E;">$</span>coefficients <span class="co" style="color: #5E5E5E;"># in-sample fit</span></span>
<span id="cb1-83">  }</span>
<span id="cb1-84">  <span class="cf" style="color: #003B4F;">if</span> (discrete) {</span>
<span id="cb1-85">    fitted <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sign</span>(fitted) <span class="co" style="color: #5E5E5E;"># map to {-1,1}</span></span>
<span id="cb1-86">  }</span>
<span id="cb1-87">  <span class="fu" style="color: #4758AB;">return</span>(fitted)</span>
<span id="cb1-88">}</span>
<span id="cb1-89">predict <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(classifier, <span class="at" style="color: #657422;">newdata=</span><span class="cn" style="color: #8f5902;">NULL</span>, <span class="at" style="color: #657422;">discrete=</span><span class="cn" style="color: #8f5902;">TRUE</span>) {</span>
<span id="cb1-90">  <span class="fu" style="color: #4758AB;">UseMethod</span>(<span class="st" style="color: #20794D;">"predict"</span>)</span>
<span id="cb1-91">}</span></code></pre></div>
</div>
</section>
<section id="revise-simplified" class="level3">
<h3 class="anchored" data-anchor-id="revise-simplified"><code>REVISE</code> (simplified)</h3>
<p>As flagged above, we are looking at a slightly simplified version of the algorithm presented in <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span>. In particular, the approach here does not incorporate the threshold on the likelihood nor does it account for immutable attributes.</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?y%5Cin%5C%7B-1,1%5C%7D"> be a binary outcome variable, <img src="https://latex.codecogs.com/png.latex?X%5Cin%5Cmathbb%7BR%7D%5Ed"> a feature matrix containing individuals‚Äô attributes and <img src="https://latex.codecogs.com/png.latex?g_n(X)"> a corresponding data-dependent classifier. Suppose <img src="https://latex.codecogs.com/png.latex?y_i=-1"> (the negative outcome) for some individual characterized by attributes <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i">. Then we want to find <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i'"> closest to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i"> such that the classifier assigns the positive outcome <img src="https://latex.codecogs.com/png.latex?g(%5Cmathbf%7Bx%7D_i%5E%7B'%7D)=1">. In order to do so, we use gradient descent with Hinge loss <img src="https://latex.codecogs.com/png.latex?%5Cell"> to minimize the following function</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cmin_%7B%5Cmathbf%7Bx%7D_i%5E%7B'%7D%7D&amp;%20%5C%20%5Cell(g_n(%5Cmathbf%7Bx%7D_i%5E%7B'%7D),1)%20+%20%5Clambda%20d(%5Cmathbf%7Bx%7D_i%5E%7B'%7D,%5Cmathbf%7Bx%7D_i)%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?d=%7C%7C%5Cmathbf%7Bx%7D_i%5E%7B'%7D-%5Cmathbf%7Bx%7D_i%7C%7C"> denotes the Euclidean distance. Note that this time we take the coefficient vector defining <img src="https://latex.codecogs.com/png.latex?g_n"> as given and instead vary the attributes. In particular, we will perform gradient descent steps as follows</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%7B%5Cmathbf%7Bx%7D_i%5E%7B'%7D%7D%5Et&amp;%5Cleftarrow%20%7B%5Cmathbf%7Bx%7D_i%5E%7B'%7D%7D%5E%7Bt-1%7D%20+%20%5Ceta%20%5Cnabla_%7B%7B%5Cmathbf%7Bx%7D_i%5E%7B'%7D%7D%7D%20%5Cleft(%20%5Cell(g_n(%5Cmathbf%7Bx%7D_i%5E%7B'%7D),1)%20+%20%5Clambda%20d(%5Cmathbf%7Bx%7D_i%5E%7B'%7D,%5Cmathbf%7Bx%7D_i)%20%20%5Cright)%20%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Ceta"> is the learning rate. The descent step is almost equivalent to the one described in <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span>, but here we greatly simplify things by optimizing directly in the attribute space instead of a latent space. The gradient of the loss function looks very similar to Equation&nbsp;1. With respect to the Euclidean distance partial derivatives are of the following form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%20%5Cfrac%7B%5Cpartial%20%7C%7C%5Cmathbf%7Bx%7D_i%5E%7B'%7D-%5Cmathbf%7Bx%7D_i%7C%7C%7D%7B%5Cpartial%20%7Bx_i'%7D%5E%7B(d)%7D%7D%20%20&amp;=%20%5Cfrac%7B%7Bx_i'%7D%5E%7B(d)%7D-%7Bx_i%7D%5E%7B(d)%7D%7D%7B%7C%7C%5Cmathbf%7Bx%7D_i%5E%7B'%7D-%5Cmathbf%7Bx%7D_i%7C%7C%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>The code that implements this optimization follows below.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="co" style="color: #5E5E5E;">#' REVISE algoritm - a simplified version</span></span>
<span id="cb2-2"><span class="co" style="color: #5E5E5E;">#'</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;">#' @param classifier The fitted classifier.</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;">#' @param x_star Attributes of individual seeking individual recourse.</span></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;">#' @param eta Learning rate.</span></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;">#' @param lambda Regularization parameter.</span></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;">#' @param n_iter Maximum number of operations.</span></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;">#' @param save_steps Boolean indicating if intermediate steps should be saved.</span></span>
<span id="cb2-9"><span class="co" style="color: #5E5E5E;">#'</span></span>
<span id="cb2-10"><span class="co" style="color: #5E5E5E;">#' @return</span></span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;">#' @export</span></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;">#'</span></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;">#' @author Patrick Altmeyer</span></span>
<span id="cb2-14">revise.classifier <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(classifier,x_star,<span class="at" style="color: #657422;">eta=</span><span class="dv" style="color: #AD0000;">1</span>,<span class="at" style="color: #657422;">lambda=</span><span class="fl" style="color: #AD0000;">0.01</span>,<span class="at" style="color: #657422;">n_iter=</span><span class="dv" style="color: #AD0000;">1000</span>,<span class="at" style="color: #657422;">save_steps=</span><span class="cn" style="color: #8f5902;">FALSE</span>) {</span>
<span id="cb2-15">  <span class="co" style="color: #5E5E5E;"># Initialization: ----</span></span>
<span id="cb2-16">  d <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">length</span>(x_star) <span class="co" style="color: #5E5E5E;"># number of dimensions</span></span>
<span id="cb2-17">  <span class="cf" style="color: #003B4F;">if</span> (<span class="sc" style="color: #5E5E5E;">!</span><span class="fu" style="color: #4758AB;">is.null</span>(<span class="fu" style="color: #4758AB;">names</span>(x_star))) {</span>
<span id="cb2-18">    d_names <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">names</span>(x_star) <span class="co" style="color: #5E5E5E;"># names of attributes, if provided</span></span>
<span id="cb2-19">  } <span class="cf" style="color: #003B4F;">else</span> {</span>
<span id="cb2-20">    d_names <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">sprintf</span>(<span class="st" style="color: #20794D;">"X%i"</span>, <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span>d)</span>
<span id="cb2-21">  }</span>
<span id="cb2-22">  w <span class="ot" style="color: #003B4F;">&lt;-</span> classifier<span class="sc" style="color: #5E5E5E;">$</span>coefficients <span class="co" style="color: #5E5E5E;"># coefficient vector</span></span>
<span id="cb2-23">  x <span class="ot" style="color: #003B4F;">&lt;-</span> x_star <span class="co" style="color: #5E5E5E;"># initialization of revised attributes</span></span>
<span id="cb2-24">  distance <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">0</span> <span class="co" style="color: #5E5E5E;"># initial distance from starting point</span></span>
<span id="cb2-25">  converged <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(classifier, <span class="at" style="color: #657422;">newdata =</span> x)[<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">1</span>]<span class="sc" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">1</span> <span class="co" style="color: #5E5E5E;"># positive outcome?</span></span>
<span id="cb2-26">  iter <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">1</span> <span class="co" style="color: #5E5E5E;"># counter</span></span>
<span id="cb2-27">  <span class="cf" style="color: #003B4F;">if</span> (save_steps) {</span>
<span id="cb2-28">    steps <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">data.table</span>(<span class="at" style="color: #657422;">iter=</span><span class="dv" style="color: #AD0000;">1</span>, <span class="at" style="color: #657422;">x=</span>x, <span class="at" style="color: #657422;">d=</span>d_names) <span class="co" style="color: #5E5E5E;"># save intermediate steps, if desired</span></span>
<span id="cb2-29">  } <span class="cf" style="color: #003B4F;">else</span> {</span>
<span id="cb2-30">    steps <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cn" style="color: #8f5902;">NA</span></span>
<span id="cb2-31">  }</span>
<span id="cb2-32">  <span class="co" style="color: #5E5E5E;"># Gradients:</span></span>
<span id="cb2-33">  grad <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(x,y,w) {</span>
<span id="cb2-34">    w <span class="sc" style="color: #5E5E5E;">%*%</span> <span class="fu" style="color: #4758AB;">ifelse</span>(<span class="fu" style="color: #4758AB;">crossprod</span>(x,w) <span class="sc" style="color: #5E5E5E;">*</span> y<span class="sc" style="color: #5E5E5E;">&lt;=</span><span class="dv" style="color: #AD0000;">1</span>,<span class="sc" style="color: #5E5E5E;">-</span>y,<span class="dv" style="color: #AD0000;">0</span>) <span class="co" style="color: #5E5E5E;"># gradient of Hinge loss with respect to X</span></span>
<span id="cb2-35">  }</span>
<span id="cb2-36">  grad_dist <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(x,x_star) {</span>
<span id="cb2-37">    d <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">length</span>(x_star)</span>
<span id="cb2-38">    distance <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">dist</span>(<span class="fu" style="color: #4758AB;">matrix</span>(<span class="fu" style="color: #4758AB;">cbind</span>(x_star,x),<span class="at" style="color: #657422;">nrow=</span>d,<span class="at" style="color: #657422;">byrow =</span> T))</span>
<span id="cb2-39">    <span class="fu" style="color: #4758AB;">matrix</span>((x<span class="sc" style="color: #5E5E5E;">-</span>x_star) <span class="sc" style="color: #5E5E5E;">/</span> distance) <span class="co" style="color: #5E5E5E;"># gradient of Euclidean distance with respect to X</span></span>
<span id="cb2-40">  }</span>
<span id="cb2-41">  <span class="co" style="color: #5E5E5E;"># Gradient descent: ----</span></span>
<span id="cb2-42">  <span class="cf" style="color: #003B4F;">while</span>(<span class="sc" style="color: #5E5E5E;">!</span>converged <span class="sc" style="color: #5E5E5E;">&amp;</span> iter<span class="sc" style="color: #5E5E5E;">&lt;</span>n_iter) {</span>
<span id="cb2-43">    <span class="cf" style="color: #003B4F;">if</span> (distance<span class="sc" style="color: #5E5E5E;">!=</span><span class="dv" style="color: #AD0000;">0</span>) {</span>
<span id="cb2-44">      x <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">c</span>(x <span class="sc" style="color: #5E5E5E;">-</span> eta <span class="sc" style="color: #5E5E5E;">*</span> (<span class="fu" style="color: #4758AB;">grad</span>(<span class="at" style="color: #657422;">x=</span><span class="fu" style="color: #4758AB;">matrix</span>(x),<span class="at" style="color: #657422;">y=</span><span class="dv" style="color: #AD0000;">1</span>,w) <span class="sc" style="color: #5E5E5E;">+</span> lambda <span class="sc" style="color: #5E5E5E;">*</span> <span class="fu" style="color: #4758AB;">grad_dist</span>(x,x_star))) <span class="co" style="color: #5E5E5E;"># gradient descent step</span></span>
<span id="cb2-45">    } <span class="cf" style="color: #003B4F;">else</span> {</span>
<span id="cb2-46">      x <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">c</span>(x <span class="sc" style="color: #5E5E5E;">-</span> eta <span class="sc" style="color: #5E5E5E;">*</span> <span class="fu" style="color: #4758AB;">grad</span>(<span class="at" style="color: #657422;">x=</span><span class="fu" style="color: #4758AB;">matrix</span>(x),<span class="at" style="color: #657422;">y=</span><span class="dv" style="color: #AD0000;">1</span>,w)) <span class="co" style="color: #5E5E5E;"># gradient with respect to distance not defined at zero</span></span>
<span id="cb2-47">    }</span>
<span id="cb2-48">    converged <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">predict</span>(classifier, <span class="at" style="color: #657422;">newdata =</span> x)[<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">1</span>]<span class="sc" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">1</span> <span class="co" style="color: #5E5E5E;"># positive outcome?</span></span>
<span id="cb2-49">    iter <span class="ot" style="color: #003B4F;">&lt;-</span> iter <span class="sc" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span> <span class="co" style="color: #5E5E5E;"># update counter</span></span>
<span id="cb2-50">    <span class="cf" style="color: #003B4F;">if</span> (save_steps) {</span>
<span id="cb2-51">      steps <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">rbind</span>(steps, <span class="fu" style="color: #4758AB;">data.table</span>(<span class="at" style="color: #657422;">iter=</span>iter, <span class="at" style="color: #657422;">x=</span>x, <span class="at" style="color: #657422;">d=</span>d_names))</span>
<span id="cb2-52">    }</span>
<span id="cb2-53">    distance <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">dist</span>(<span class="fu" style="color: #4758AB;">matrix</span>(<span class="fu" style="color: #4758AB;">cbind</span>(x_star,x),<span class="at" style="color: #657422;">nrow=</span>d,<span class="at" style="color: #657422;">byrow =</span> T)) <span class="co" style="color: #5E5E5E;"># update distance</span></span>
<span id="cb2-54">  }</span>
<span id="cb2-55">  <span class="co" style="color: #5E5E5E;"># Output: ----</span></span>
<span id="cb2-56">  <span class="cf" style="color: #003B4F;">if</span> (converged) {</span>
<span id="cb2-57">    revise <span class="ot" style="color: #003B4F;">&lt;-</span> x <span class="sc" style="color: #5E5E5E;">-</span> x_star</span>
<span id="cb2-58">  } <span class="cf" style="color: #003B4F;">else</span> {</span>
<span id="cb2-59">    revise <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cn" style="color: #8f5902;">NA</span></span>
<span id="cb2-60">  }</span>
<span id="cb2-61">  output <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">list</span>(</span>
<span id="cb2-62">    <span class="at" style="color: #657422;">x_star =</span> x_star,</span>
<span id="cb2-63">    <span class="at" style="color: #657422;">revise =</span> revise,</span>
<span id="cb2-64">    <span class="at" style="color: #657422;">classifier =</span> classifier,</span>
<span id="cb2-65">    <span class="at" style="color: #657422;">steps =</span> steps,</span>
<span id="cb2-66">    <span class="at" style="color: #657422;">lambda =</span> lambda,</span>
<span id="cb2-67">    <span class="at" style="color: #657422;">distance =</span> distance,</span>
<span id="cb2-68">    <span class="at" style="color: #657422;">mean_distance =</span> <span class="fu" style="color: #4758AB;">mean</span>(<span class="fu" style="color: #4758AB;">abs</span>(revise))</span>
<span id="cb2-69">  )</span>
<span id="cb2-70">  <span class="fu" style="color: #4758AB;">return</span>(output)</span>
<span id="cb2-71">}</span>
<span id="cb2-72"></span>
<span id="cb2-73">revise <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(classifier,x_star,<span class="at" style="color: #657422;">eta=</span><span class="dv" style="color: #AD0000;">1</span>,<span class="at" style="color: #657422;">lambda=</span><span class="fl" style="color: #AD0000;">0.01</span>,<span class="at" style="color: #657422;">n_iter=</span><span class="dv" style="color: #AD0000;">1000</span>,<span class="at" style="color: #657422;">save_steps=</span><span class="cn" style="color: #8f5902;">FALSE</span>) {</span>
<span id="cb2-74">  <span class="fu" style="color: #4758AB;">UseMethod</span>(<span class="st" style="color: #20794D;">"revise"</span>)</span>
<span id="cb2-75">}</span></code></pre></div>
</div>
</section>
<section id="simulated-data" class="level3">
<h3 class="anchored" data-anchor-id="simulated-data">Simulated data</h3>
<p>The synthetic data describing cats and dogs was generated as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1">sim_data <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="cf" style="color: #003B4F;">function</span>(<span class="at" style="color: #657422;">n=</span><span class="dv" style="color: #AD0000;">100</span>,averages,<span class="at" style="color: #657422;">noise=</span><span class="fl" style="color: #AD0000;">0.1</span>) {</span>
<span id="cb3-2">  d <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">ncol</span>(averages)</span>
<span id="cb3-3">  y <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">2</span><span class="sc" style="color: #5E5E5E;">*</span>(<span class="fu" style="color: #4758AB;">rbinom</span>(n,<span class="dv" style="color: #AD0000;">1</span>,<span class="fl" style="color: #AD0000;">0.5</span>)<span class="sc" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.5</span>) <span class="co" style="color: #5E5E5E;"># generate binary outcome: 1=dog, -1=cat</span></span>
<span id="cb3-4">  X <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">as.matrix</span>(averages[(y<span class="sc" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="sc" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span><span class="sc" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>,]) <span class="co" style="color: #5E5E5E;"># generate attributes conditional on y</span></span>
<span id="cb3-5">  dogs <span class="ot" style="color: #003B4F;">&lt;-</span> y<span class="sc" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">1</span> <span class="co" style="color: #5E5E5E;"># boolean index for dogs</span></span>
<span id="cb3-6">  cats <span class="ot" style="color: #003B4F;">&lt;-</span> y<span class="sc" style="color: #5E5E5E;">==-</span><span class="dv" style="color: #AD0000;">1</span> <span class="co" style="color: #5E5E5E;"># boolean index for cats</span></span>
<span id="cb3-7">  X[cats,] <span class="ot" style="color: #003B4F;">&lt;-</span> X[cats,] <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb3-8">    <span class="fu" style="color: #4758AB;">matrix</span>(<span class="fu" style="color: #4758AB;">rnorm</span>(<span class="fu" style="color: #4758AB;">sum</span>(cats)<span class="sc" style="color: #5E5E5E;">*</span>d),<span class="at" style="color: #657422;">nrow=</span><span class="fu" style="color: #4758AB;">sum</span>(cats)) <span class="sc" style="color: #5E5E5E;">%*%</span> <span class="fu" style="color: #4758AB;">diag</span>(noise<span class="sc" style="color: #5E5E5E;">*</span>averages[<span class="dv" style="color: #AD0000;">2</span>,]) <span class="co" style="color: #5E5E5E;"># add noise for y=1 (cats)</span></span>
<span id="cb3-9">  X[dogs,] <span class="ot" style="color: #003B4F;">&lt;-</span> X[dogs,] <span class="sc" style="color: #5E5E5E;">+</span> </span>
<span id="cb3-10">    <span class="fu" style="color: #4758AB;">matrix</span>(<span class="fu" style="color: #4758AB;">rnorm</span>(<span class="fu" style="color: #4758AB;">sum</span>(dogs)<span class="sc" style="color: #5E5E5E;">*</span>d),<span class="at" style="color: #657422;">nrow=</span><span class="fu" style="color: #4758AB;">sum</span>(dogs)) <span class="sc" style="color: #5E5E5E;">%*%</span> <span class="fu" style="color: #4758AB;">diag</span>(noise<span class="sc" style="color: #5E5E5E;">*</span>averages[<span class="dv" style="color: #AD0000;">2</span>,]) <span class="co" style="color: #5E5E5E;"># add noise for y=1 (dogs)</span></span>
<span id="cb3-11">  <span class="fu" style="color: #4758AB;">return</span>(<span class="fu" style="color: #4758AB;">list</span>(<span class="at" style="color: #657422;">X=</span>X,<span class="at" style="color: #657422;">y=</span>y))</span>
<span id="cb3-12">}</span></code></pre></div>
</div>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick},
  title = {Individual Recourse for {Black} {Box} {Models}},
  date = {21-04-27},
  url = {https://www.paltmeyer.com/blog//blog/posts/individual-recourse-for-black-box-models},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 21AD. <span>‚ÄúIndividual Recourse for Black Box
Models.‚Äù</span> April 27, 21AD. <a href="https://www.paltmeyer.com/blog//blog/posts/individual-recourse-for-black-box-models">https://www.paltmeyer.com/blog//blog/posts/individual-recourse-for-black-box-models</a>.
</div></div></section></div> ]]></description>
  <category>counterfactuals</category>
  <category>algorithmic recourse</category>
  <category>deep learning</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/index.html</guid>
  <pubDate>Mon, 26 Apr 2021 22:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>A peek inside the ‚ÄòBlack Box‚Äô - interpreting neural networks</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/www/intro.jpeg" class="figure-img">
</figure>
</div>
<p>Propelled by advancements in modern computer technology, deep learning has re-emerged as perhaps the most promising artificial intelligence (AI) technology of the last two decades. By treating problems as a nested, hierarchy of hidden layers deep artificial neural networks achieve the power and flexibility necessary for AI systems to navigate complex real-world environments. Unfortunately, their very nature has earned them a reputation as <em>Black Box</em> algorithms and their lack of interpretability remains a major impediment to their more wide-spread application.</p>
<p>In science, research questions usually demand not just answers but also explanations and variable selection is often as important as prediction <span class="citation" data-cites="ish-horowicz2019interpreting">(Ish-Horowicz et al. 2019)</span>. Economists, for example, recognise the undeniable potential of deep learning, but are rightly hesitant to employ novel tools that are not fully transparent and ultimately cannot be trusted. Similarly, real-world applications of AI have come under increasing scrutiny with regulators imposing that individuals influenced by algorithms should have the right to obtain explanations <span class="citation" data-cites="fan2020interpretability">(Fan, Xiong, and Wang 2020)</span>. In high-risk decision-making fields such as AI systems that drive autonomous vehicles the need for explanations is self-evident <span class="citation" data-cites="ish-horowicz2019interpreting">(Ish-Horowicz et al. 2019)</span>.</p>
<p>In light of these challenges it is not surprising that research on explainable AI has recently gained considerable momentum <span class="citation" data-cites="arrieta2020explainable">(Arrieta et al. 2020)</span>. While in this short essay we will focus on deep learning in particular, it should be noted that this growing body of literature is concerned with a broader realm of machine learning models. The rest of this note is structured as follows: the first section provides a brief overview of recent advancements towards interpreting deep neural networks largely drawing on <span class="citation" data-cites="fan2020interpretability">Fan, Xiong, and Wang (2020)</span>; the second section considers a novel entropy-based approach towards interpretability proposed by <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span>; finally, in the last section we will see how this approach can be applied to deep neural networks as proposed in <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span>.</p>
<section id="interpretable-dl" class="level1">
<h1>Interpretable DL - a whistle-stop tour</h1>
<p>Before delving further into <em>how</em> the intrinsics of deep neural networks can be disentangled we should first clarify <em>what</em> interpretability in the context of algorithms actually means. <span class="citation" data-cites="fan2020interpretability">Fan, Xiong, and Wang (2020)</span> describes model interpretability simply as the extent to which humans can ‚Äúunderstand and reason‚Äù the model. This may concern an understanding of both the <em>ad-hoc</em> workings of the algorithm as well as the <em>post-hoc</em> interpretability of its output. In the context of linear regression, for example, <em>ad-hoc</em> workings of the model are often described through the intuitive idea of linearly projecting the outcome variable <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7By%7D"> onto the column space of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">. <em>Post-hoc</em> interpretations usually center around variable importance ‚Äì the main focus of the following sections. Various recent advancements tackle interpretability of DNNs from different angles depending on whether the focus is on <em>ad-hoc</em> or <em>post-hoc</em> interpretability. <span class="citation" data-cites="fan2020interpretability">Fan, Xiong, and Wang (2020)</span> further asses that model interpretability hinges on three main aspects of <em>simulatability</em>, <em>decomposability</em> and <em>algorithmic transparency</em>, but for the purpose of this short note the <em>ad-hoc</em> vs.&nbsp;<em>post-hoc</em> taxonomy provides a simpler more natural framework. <sup>1</sup></p>
<p>Understanding the <em>ad-hoc</em> intrinsic mechanisms of a DNN is inherently difficult. While generally transparency may be preserved in the presence of nonlinearity (e.g.&nbsp;decision trees), multiple hidden layers of networks (each of them) involving nonlinear operations are usually out of the realm of human comprehension <span class="citation" data-cites="fan2020interpretability">(Fan, Xiong, and Wang 2020)</span>. Training also generally involves optimization of non-convex functions that involve an increasing number of saddle points as the dimensionality increases <span class="citation" data-cites="fan2020interpretability">(Fan, Xiong, and Wang 2020)</span>. Methods to circumvent this problematic usually boil down to decreasing the overall complexity, either by regularizing the model or through proxy methods. Regularization ‚Äì while traditionally done to avoid overfitting ‚Äì has been found to be useful to create more interpretable representations. Monotonicity constraints, for example, impose that as the value of a specified covariate increases model predictions either monotonically decrease or increase. Proxy methods construct simpler representations of a learned DNN, such as a rule-based decision tree. This essentially involves repeatedly querying the trained network while varying the inputs and then deriving decision rules based on the model output.</p>
<p>Post-hoc interpretability usually revolves around the understanding of feature importance. A greedy approach to this issue involves simply removing features one by one and checking how model predictions change. A more sophisticated approach along these lines is <em>Shapley</em> value, which draws on cooperative game theory. The Shapley value assigns varying payouts to players depending on their contribution to overall payout. In the context of neural networks input covariate <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_p"> represents a player while overall payout is represented by the difference between average and individual outcome predictions.<sup>2</sup> Exact computations of Shapley values are prohibitive as the dimensionality increases, though approximate methods have recently been developed <span class="citation" data-cites="fan2020interpretability">(Fan, Xiong, and Wang 2020)</span>.</p>
<p>The remainder of this note focuses on a novel approach to feature extraction that measures entropy shifts in a learned probabilistic neural network in response to model inputs <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX_1%7D,...,%5Cmathbf%7BX%7D_P">. We will first introduce this methodology in the context of Gaussian Process regression in the following section before finally turning to its application to Bayesian neural networks.</p>
</section>
<section id="rate" class="level1">
<h1>An entropy-based approach to variable importance</h1>
<p><span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> motivate their methodology for interpreting neural networks through Gaussian Process regression. Consider the following Bayesian regression model with Gaussian priors:</p>
<p><span id="eq-bayes"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20f(%5Cmathbf%7BX%7D%7C%5Cmathbf%7Bw%7D)&amp;=%5Cphi(%5Cmathbf%7BX%7D)%5ET%5Cmathbf%7Bw%7D%20+%20%5Cvarepsilon,%20&amp;&amp;%5Cvarepsilon%20%5Csim%20%5Cmathcal%7BN%7D(0,%5Cmathbf%7BI%7D)%20%5C%5C%0A&amp;&amp;%20%5Cmathbf%7Bw%7D&amp;%20%5Csim%20%5Cmathcal%7BN%7D(0,%7B1%5Cover%7B%5Clambda%7D%7D%20%5Cmathbf%7BI%7D)%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B1%7D"></span></p>
<p>This naturally gives rise to a particular example of a Gaussian Process (GP). In particular, since <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)=%5CPhi(%5Cmathbf%7BX%7D)%5ET%5Cmathbf%7Bw%7D"> is just a linear combination fo Gaussian random variables it follows a Gaussian Process itself</p>
<p><span id="eq-khbs"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)=%5CPhi(%5Cmathbf%7BX%7D)%5ET%5Cmathbf%7Bw%7D&amp;%20%5Csim%20%5Cmathcal%7BN%7D(%5Cmathbf%7B0%7D,%20%5Cmathbf%7BK%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B2%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BK%7D"> is the Kernel (or Gram) matrix and <img src="https://latex.codecogs.com/png.latex?K_%7Bi,j%7D=k(%5Cmathbf%7BX_i,%5Cmathbf%7BX%7D_j%7D)=%7B1%5Cover%7B%5Clambda%7D%7D%5Cphi(%5Cmathbf%7BX_i%7D)%5ET%5Cphi(%5Cmathbf%7BX_m%7D)"> is the kernel function <span class="citation" data-cites="bishop2006pattern">(Bishop 2006)</span>. In other words, the prior distribution over <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> induces a probability distribution over random functions <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)">. Similarly, the GP can be understood as a prior distribution over a an infinite-dimensional reproducible kernel Hilbert space (RKHS) <span class="citation" data-cites="crawford2019variable">(Crawford et al. 2019)</span>, which in a finite-dimensional setting becomes multivariate Gaussian.</p>
<p>In a standard linear regression model coefficients characterize the projection of the outcome variable <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7By%7D"> onto the column space of the regressors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">. In particular, with ordinary least square we define:</p>
<p><span id="eq-ols"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cbeta&amp;=(%5Cmathbf%7BX%7D%5ET%5Cmathbf%7BX%7D)%5E%7B-1%7D%5Cmathbf%7BX%7D%5ET%5Cmathbf%7By%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B3%7D"></span></p>
<p>The primary focus here is to learn the mapping from input to output. The key differentiating feature between this approach and the non-parametric model in Equation&nbsp;1 is the fact that in case of the latter we are interested in learning not only the mapping from inputs to outputs, but also the representation (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)">) of the inputs (see for example <span class="citation" data-cites="goodfellow2016deep">(Goodfellow, Bengio, and Courville 2016)</span>). To be even more specific, treating the feature representation itself as random as in Equation&nbsp;1 allows us to learn non-linear relationships between the covariates <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">, since they are implicitly captured by the RKHS <span class="citation" data-cites="crawford2019variable">(Crawford et al. 2019)</span>. Neural networks share this architecture and hence it is worth dwelling on it a bit further: the fact that the learned model inherently incorporates variable interactions leads to the observation that an individual feature is rarely important on its own with respect to the mapping from <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D"> to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7By%7D"> <span class="citation" data-cites="ish-horowicz2019interpreting">(Ish-Horowicz et al. 2019)</span>. Hence, in order to gain an understanding of individual variable importance, one should aim to understand what role feature <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j"> plays <em>within</em> the learned model, thereby taking into account its interactions with other covariates. Formally, <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> and define the <em>effect size analogue</em> as the equivalent of the familiar regression coefficient in the non-parametric setting</p>
<p><span id="eq-effect-size"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Ctilde%5Cbeta&amp;=%5Cmathbf%7BX%7D%5E+%5CPhi%5ET%5Cmathbf%7Bw%7D=%5Cmathbf%7BX%7D%5E+%5Cmathbf%7Bu%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B4%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D%5E+=%5Clim_%7B%5Calpha%7D%20(%5Cmathbf%7BX%7D%5ET%5Cmathbf%7BX%7D+%5Calpha%20%5Cmathbf%7BI%7D)%5E%7B-1%7D%5Cmathbf%7BX%7D%5ET"> denotes the Moore-Penrose pseudo-inverse (see for example <span class="citation" data-cites="goodfellow2016deep">Goodfellow, Bengio, and Courville (2016)</span>). Intuitively the effect size analogue can be thought of as the resulting coefficients from regressing the fitted values <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bu%7D%7D"> from the learned probabilistic model on the covariates <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">. It can be interpreted in the same way as linear regression coefficients, in the sense that <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta_j"> describes the marginal change in <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> given a unit increase in <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j"> holding all else constant. Note here the subtle, but crucial difference between Equation&nbsp;3 ‚Äì a projection from the outcome variable onto the column space of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D"> ‚Äì and Equation&nbsp;4 ‚Äì a projection from the learned model to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">. In other words, looking at <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta"> can be thought of peeking directly into the <em>Block Box</em>. Unfortunately, as <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> point out, working with Equation&nbsp;4 is usually not straight-forward. From a practitioner‚Äôs point of view, it may also not be obvious how to interpret a coefficient that describes marginal effects of input variables on a learned model. A more useful indicator in this context would provide a measure of how much individual variables contribute to the overall variation in the learned model. For this purpose <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> propose to work with a distributional centrality measure based on <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta">, which we shall turn to next.</p>
<p>The proposed methodology in <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> and <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> depends on the availability of a posterior distribution over <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta"> in that it measures its entropic shifts in response to the introduction of covariates. The intuition is straight-forward: within the context of the learned probabilistic model is covariate <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j"> informative or not? More formally this boils down to determining if the posterior distribution of <img src="https://latex.codecogs.com/png.latex?p(%5Ctilde%5Cbeta_%7B-j%7D)"> is dependent on the effect of <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta_j">. This can be quantified through the Kullback-Leibler divergence (KLD) between <img src="https://latex.codecogs.com/png.latex?p(%5Ctilde%5Cbeta_%7B-j%7D)"> and the conditional posterior <img src="https://latex.codecogs.com/png.latex?p(%5Ctilde%5Cbeta_%7B-j%7D%7C%5Ctilde%5Cbeta_j)">:</p>
<p><span id="eq-kld"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Ctext%7BKLD%7D_j&amp;=%5Ctext%7BKL%7D%5Cleft(p(%5Ctilde%5Cbeta_%7B-j%7D)%20%7C%7C%20p(%5Ctilde%5Cbeta_%7B-j%7D%7C%5Ctilde%5Cbeta_j)%5Cright)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B5%7D"></span></p>
<p>Covariates that contribute significant information to the model will have <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BKLD%7D%3E0">, while for insignificant covariates <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BKLD%7D%5Capprox0">. The measure of induced entropy change gives rise to a ranking of the covariates in terms of their relative importance in the model. The RATE criterion of variable <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j"> is then simply defined as</p>
<p><span id="eq-rate"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cgamma_j&amp;=%5Cfrac%7B%5Ctext%7BKLD%7D_j%7D%7B%5Csum_%7Bp=1%7D%5E%7BP%7D%5Ctext%7BKLD%7D_p%7D%5Cin%5B0,1%5D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B6%7D"></span></p>
<p>which in light of its bounds can naturally be interpreted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j">`s percentage contribution to the learned model. It is worth noting that <img src="https://latex.codecogs.com/png.latex?p(%5Ctilde%5Cbeta_%7B-j%7D%7C%5Ctilde%5Cbeta_j)"> of course depends on the value of the conditioning variable. A natural choice is <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta_j=0"> which usually corresponds to the null hypothesis.</p>
</section>
<section id="interpreting-bnns" class="level1">
<h1>Application to Bayesian neural networks</h1>
<p>In order to use the RATE criterion in the context of deep learning we need to work in the Bayesian setting. Contrary to standard artificial neural networks which work under the assumption that weights have some true latent value, Bayesian neural networks place a prior distribution over network parameters and hence treat weights as random variables <span class="citation" data-cites="goan2020bayesian">(Goan and Fookes 2020)</span>. Not only does it perhaps seem more natural to treat unobserved weights as random, but the Bayesian setting also naturally gives rise to reason about uncertainty in predictions, which can ultimately help us develop more trustworthy models <span class="citation" data-cites="goan2020bayesian">(Goan and Fookes 2020)</span>. A drawback of BNNs is that exact computation of posteriors is computationally challenging and often intractable (a non-trivial issue that we will turn back to in a moment).</p>
<p>When the prior placed over parameters is Gaussian, the output of the BNN approaches a Gaussian Process as the width of the network grows, in line with the discussion in the previous section. This is exactly the assumption that <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> work with. They propose an architecture for a multi-layer perceptron (MLP) composed of (1) an input layer collecting covariates <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_1,...,%5Cmathbf%7BX%7D_p">, (2) a single deterministic, hidden layer and (3) an outer layer producing predictions from a probabilistic model <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)">. Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D"> be a <img src="https://latex.codecogs.com/png.latex?(N%20%5Ctimes%20P)"> matrix of covariates. Then formally, we have</p>
<p><span id="eq-bnn"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Chat%7B%5Cmathbf%7By%7D%7D&amp;=%5Csigma(%5Cmathbf%7Bu%7D)%20%5C%5C%0A&amp;&amp;%20%5Cmathbf%7Bu%7D(%5Cmathbf%7BZ%7D)&amp;=%5Cmathbf%7BZ%7D(%5Cmathbf%7BX%7D)%5Cmathbf%7Bw%7D%5E%7B(L+1)%7D,%20&amp;&amp;%20%5Cmathbf%7Bw%7D%5E%7B(L+1)%7D%20%5Csim%20%5Cmathcal%7BN%7D(%5Cmathbf%7Bm%7D,%20%5Cmathbf%7BV%7D)%20%5C%5C%0A&amp;&amp;%20%5Cmathbf%7BZ%7D(%5Cmathbf%7BX%7D)&amp;=f(%5Cmathbf%7BX%7D%5Cmathbf%7Bw%7D%5E%7B(L)%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B7%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Csigma(.)"> is a link function and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)"> represents the probabilistic model learned in the outer layer with weights <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%5E%7B(L+1)%7D"> assumed to be Gaussian random variables.<sup>3</sup> Finally, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BZ%7D(%5Cmathbf%7BX%7D)"> denotes the inner (or more generally penultimate) layer, an <img src="https://latex.codecogs.com/png.latex?(N%20%5Ctimes%20P)"> matrix of neural activations through <img src="https://latex.codecogs.com/png.latex?f:(%5Cmathbf%7BX%7D%5Cmathbf%7Bw%7D%5E%7B(L)%7D)%5Cmapsto%20%5Cmathbf%7BZ%7D">. <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> work with a simple single-layer MLP, but it should be evident that this be extended to arbitrary depth and complexity, while still maintaining the high-level structure imposed by Equation&nbsp;7. This flexibility allows RATE to be applied to a wide range of Bayesian network architectures, since all that is really required is the posterior distribution over weights <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%5E%7B(L+1)%7D">, which arises from the probabilistic outer layer. The fact that only the outer layer needs to be probabilistic has the additional benefit of mitigating the computational burden that comes with Bayesian inference, which was mentioned earlier.</p>
<p>Having established this basic, flexible set-up the <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> go on to derive closed-form expressions for RATE in this setting. The details are omitted here since the logic is largely analogous to what we learned above, but can be found in <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span>.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The RATE criterion originally proposed by <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> and shown to be applicable to Bayesian neural networks in <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> offers an intuitive way to measure variable importance in the context of deep learning. By defining variable importance as the contribution inputs make to a probabilistic model, it implicitly incorporates the interactions between covariates and nonlinearities that the model has learned. In other words, it allows researchers to peek directly into the <em>Black Box</em>. This opens up interesting avenues for future research, as the approach can be readily applied in academic disciplines and real-world applications that rely heavily on explainability of outcomes.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-arrieta2020explainable" class="csl-entry">
Arrieta, Alejandro Barredo, Natalia Diaz-Rodriguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garcia, et al. 2020. <span>‚ÄúExplainable <span>Artificial Intelligence</span> (<span>XAI</span>): <span>Concepts</span>, Taxonomies, Opportunities and Challenges Toward Responsible <span>AI</span>.‚Äù</span> <em>Information Fusion</em> 58: 82‚Äì115.
</div>
<div id="ref-bishop2006pattern" class="csl-entry">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. <span>springer</span>.
</div>
<div id="ref-crawford2019variable" class="csl-entry">
Crawford, Lorin, Seth R Flaxman, Daniel E Runcie, and Mike West. 2019. <span>‚ÄúVariable Prioritization in Nonlinear Black Box Methods: <span>A</span> Genetic Association Case Study.‚Äù</span> <em>The Annals of Applied Statistics</em> 13 (2): 958.
</div>
<div id="ref-fan2020interpretability" class="csl-entry">
Fan, Fenglei, Jinjun Xiong, and Ge Wang. 2020. <span>‚ÄúOn Interpretability of Artificial Neural Networks.‚Äù</span> <a href="https://arxiv.org/abs/2001.02522">https://arxiv.org/abs/2001.02522</a>.
</div>
<div id="ref-goan2020bayesian" class="csl-entry">
Goan, Ethan, and Clinton Fookes. 2020. <span>‚ÄúBayesian <span>Neural Networks</span>: <span>An Introduction</span> and <span>Survey</span>.‚Äù</span> In <em>Case <span>Studies</span> in <span>Applied Bayesian Data Science</span></em>, 45‚Äì87. <span>Springer</span>.
</div>
<div id="ref-goodfellow2016deep" class="csl-entry">
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep <span>Learning</span></em>. <span>MIT Press</span>.
</div>
<div id="ref-ish-horowicz2019interpreting" class="csl-entry">
Ish-Horowicz, Jonathan, Dana Udwin, Seth Flaxman, Sarah Filippi, and Lorin Crawford. 2019. <span>‚ÄúInterpreting Deep Neural Networks Through Variable Importance.‚Äù</span> <a href="https://arxiv.org/abs/1901.09839">https://arxiv.org/abs/1901.09839</a>.
</div>
</div>
<div style="page-break-after: always;"></div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Simulatability describes the overall, high-level understandability of the mechanisms underlying the model ‚Äì put simply, the less complex the model, the higher its simulatability. Decomposability concerns the extent to which the model can be taken apart into smaller pieces ‚Äì neural networks by there very nature are compositions of multiple layers. Finally, algorithmic transparency refers to the extent to which the training of the algorithm is well-understood and to some extent observable ‚Äì since DNNs generally deal with optimization of non-convex functions and often lack unique solution they are inherently intransparent.‚Ü©Ô∏é</p></li>
<li id="fn2"><p>For more detail see for example <a href="https://christophm.github.io/interpretable-ml-book/shapley.html">here</a>.‚Ü©Ô∏é</p></li>
<li id="fn3"><p>For simplicity I have omitted the deterministic bias term.‚Ü©Ô∏é</p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick},
  title = {A Peek Inside the ‚Äú{Black} {Box}‚Äù - Interpreting Neural
    Networks},
  date = {21-02-07},
  url = {https://www.paltmeyer.com/blog//blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 21AD. <span>‚ÄúA Peek Inside the <span>‚ÄòBlack
Box‚Äô</span> - Interpreting Neural Networks.‚Äù</span> February 7, 21AD. <a href="https://www.paltmeyer.com/blog//blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks">https://www.paltmeyer.com/blog//blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks</a>.
</div></div></section></div> ]]></description>
  <category>deep learning</category>
  <category>explainable AI</category>
  <category>bayes</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html</guid>
  <pubDate>Sat, 06 Feb 2021 23:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/www/intro.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>How I‚Äôm building this website in R</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/how-i-m-building-this-website-in-r/index.html</link>
  <description><![CDATA[ 



<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Update on Feb 20, 2022</strong></p>
<p>The post below was written when I still used <code>blogdown</code> in combination with Hugo to build this blog. I have recently migrated the blog (along pretty much everything else I do) to <a href="https://quarto.org/">quarto</a>.</p>
<blockquote class="blockquote">
<p>Quarto¬Æ is an open-source scientific and technical publishing system built on Pandoc.</p>
</blockquote>
<p>Based on my first few experiences I would go further and say that quarto is <em>the only</em> open-source scientific and technical publishing system you‚Äôll ever need. The project is supported by RStudio and (unsurprisingly) Yihui Xie is one of the contributors. Go check it out!</p>
</div>
</div>
<section id="getting-started" class="level2">
<h2 class="anchored" data-anchor-id="getting-started">Getting started</h2>
<p>It turns out building a static website in R is remarkably easy, as long as you know your way around R Markdown. Knowledge of HTML and CSS helps, but is not strictly necessary and can be acquired along the way. My package of choice for this website is <code>blogdown</code> by <a href="https://yihui.org/">Yihui Xie</a> who has had a major impact on the R community through his many package contributions (<code>knitr</code>, <code>bookdown</code>, <code>pagedown</code>, ‚Ä¶) and certainly made my life a lot easier on many occasions.</p>
<p>To get started just follow the instructions on <code>blogdown</code>‚Äôs <a href="https://github.com/rstudio/blogdown">GitHub repository</a> or keep reading here for a high-level overview. Setting up a basic website in R requires exactly two steps:</p>
<ol type="1">
<li><p>Set up a local directory for the website. Let‚Äôs suppose you create it here <code>~/Documents/myAwesomeWebsite</code>.</p></li>
<li><p>In R, navigate to the directory and simply run <code>blogdown::newsite()</code>.</p></li>
</ol>
<p>This will set up a basic template which you can develop. Changing the theme and playing with the basic structure of the website is relatively straight-forward. Personally I have so far managed to work things out based on a working knowledge of HTML and CSS that I‚Äôve developed in the past through my work with R Shiny.</p>
</section>
<section id="deploying-your-website" class="level2">
<h2 class="anchored" data-anchor-id="deploying-your-website">Deploying your website</h2>
<p>There are various ways to deploy your website, i.e.&nbsp;make it accessible to the public. This website is deployed through GitHub pages. Detailed instructions on how to do this can be found <a href="https://bookdown.org/yihui/blogdown/github-pages.html">here</a>. Since I already had an existing local clone of my <code>pat-alt.github.io</code> repo, I just dropped it in the source directory of the website:</p>
<pre><code>source/
‚îÇ
‚îú‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ content/
‚îú‚îÄ‚îÄ themes/
‚îî‚îÄ‚îÄ ...

patalt.github.io/
‚îÇ
‚îú‚îÄ‚îÄ .git/
‚îú‚îÄ‚îÄ .nojekyll
‚îú‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ about/
‚îî‚îÄ‚îÄ ...</code></pre>
<p>After adding <code>publishDir: pat-alt.github.io</code> to my <code>config.yaml</code> and then running <code>blogdown::hugo_build()</code> the website was built inside the clone. All that was left to do was to commit changes from the local clone to the <code>pat-alt.github.io</code> remote repo. A few moments later the website was already up and running.</p>
</section>
<section id="why-all-the-trouble" class="level2">
<h2 class="anchored" data-anchor-id="why-all-the-trouble">Why all the trouble?</h2>
<p>There are certainly easier ways to build a website. But if like me you do pretty much all your work in R Markdown and want to share some of it, then you will love <code>blogdown</code>. The beauty of it is that once the basic infrastructure is set up, adding content is as simple as running the following wrapper function</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1">blogdown<span class="sc" style="color: #5E5E5E;">::</span><span class="fu" style="color: #4758AB;">new_post</span>(<span class="st" style="color: #20794D;">"Your new post"</span>, <span class="at" style="color: #657422;">ext =</span> <span class="st" style="color: #20794D;">".Rmd"</span>)</span></code></pre></div>
</div>
<p>where the first argument is just the title of your post and the <code>ext</code> argument can be used to specify that you want to create an R Markdown document that can include code chucks. The wrapper function will automatically set up a directory for your post under <code>/post/</code>. R Studio will redirect you to the relevant <code>.Rmd</code> file that you can then fill with content. By default that folder will look roughly like this:</p>
<pre><code>‚îú‚îÄ‚îÄ index.Rmd
‚îú‚îÄ‚îÄ index.html
‚îî‚îÄ‚îÄ index_files
    ‚îî‚îÄ‚îÄ header-attrs
        ‚îî‚îÄ‚îÄ header-attrs.js</code></pre>
</section>
<section id="a-simple-coding-example" class="level2">
<h2 class="anchored" data-anchor-id="a-simple-coding-example">A simple coding example</h2>
<p>As you can probably tell from the code chunks above this post was created just in the way I described. So I thought I might as well go ahead with a simple coding example to add some flavour. Suppose you have built some function that you think is worth sharing with the world or simply learned something new and interesting. As a case in point, I recently had a look at the <code>Rcpp</code> package and wrote a small program in C++ to be used in R. Since R Markdown supports <code>Rcpp</code> code chunks (along with Python, bash, SQL, ‚Ä¶) it is straight-forward to show-case that code on this website.</p>
<p>The program can be used to simulate data from a categorical distribution. This distribution describes the possible results of a random variable that can take on one of <img src="https://latex.codecogs.com/png.latex?K"> possible categories with different probabilities. In base R we could use <code>rmultinom(n=1000,1,p=c(0.5,0.1,0.4))</code> to simulate draws from one such distribution with three different categories. Alternatively, we could write the program in C++ as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb4-1"><span class="pp" style="color: #AD0000;">#include </span><span class="im" style="color: #00769E;">&lt;Rcpp.h&gt;</span></span>
<span id="cb4-2"><span class="kw" style="color: #003B4F;">using</span> <span class="kw" style="color: #003B4F;">namespace</span> Rcpp<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;">// [[Rcpp::export]]</span></span>
<span id="cb4-5">NumericMatrix simCategorical<span class="op" style="color: #5E5E5E;">(</span><span class="dt" style="color: #AD0000;">int</span> n<span class="op" style="color: #5E5E5E;">,</span> NumericVector p<span class="op" style="color: #5E5E5E;">)</span> <span class="op" style="color: #5E5E5E;">{</span></span>
<span id="cb4-6">  <span class="dt" style="color: #AD0000;">int</span> k <span class="op" style="color: #5E5E5E;">=</span> p<span class="op" style="color: #5E5E5E;">.</span>size<span class="op" style="color: #5E5E5E;">();</span></span>
<span id="cb4-7">  NumericMatrix mat<span class="op" style="color: #5E5E5E;">(</span>k<span class="op" style="color: #5E5E5E;">,</span> n<span class="op" style="color: #5E5E5E;">);</span></span>
<span id="cb4-8">  <span class="co" style="color: #5E5E5E;">// Normalise prob if necessary:</span></span>
<span id="cb4-9">  <span class="cf" style="color: #003B4F;">if</span> <span class="op" style="color: #5E5E5E;">(</span>sum<span class="op" style="color: #5E5E5E;">(</span>p<span class="op" style="color: #5E5E5E;">)!=</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">)</span> <span class="op" style="color: #5E5E5E;">{</span></span>
<span id="cb4-10">    p <span class="op" style="color: #5E5E5E;">=</span> p<span class="op" style="color: #5E5E5E;">/</span>sum<span class="op" style="color: #5E5E5E;">(</span>p<span class="op" style="color: #5E5E5E;">);</span></span>
<span id="cb4-11">  <span class="op" style="color: #5E5E5E;">}</span></span>
<span id="cb4-12">  NumericVector emp_cdf <span class="op" style="color: #5E5E5E;">=</span> cumsum<span class="op" style="color: #5E5E5E;">(</span>p<span class="op" style="color: #5E5E5E;">);</span></span>
<span id="cb4-13">  NumericVector u <span class="op" style="color: #5E5E5E;">=</span> Rcpp<span class="op" style="color: #5E5E5E;">::</span>runif<span class="op" style="color: #5E5E5E;">(</span>n<span class="op" style="color: #5E5E5E;">,</span> <span class="dv" style="color: #AD0000;">0</span><span class="op" style="color: #5E5E5E;">,</span> <span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">);</span></span>
<span id="cb4-14">  <span class="co" style="color: #5E5E5E;">// Matrix for 1-hot-encoding:</span></span>
<span id="cb4-15">  <span class="cf" style="color: #003B4F;">for</span> <span class="op" style="color: #5E5E5E;">(</span><span class="dt" style="color: #AD0000;">int</span> j <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span><span class="op" style="color: #5E5E5E;">;</span> j <span class="op" style="color: #5E5E5E;">&lt;</span> n<span class="op" style="color: #5E5E5E;">;</span> j<span class="op" style="color: #5E5E5E;">++)</span> <span class="op" style="color: #5E5E5E;">{</span></span>
<span id="cb4-16">    <span class="co" style="color: #5E5E5E;">// Perform binary search:</span></span>
<span id="cb4-17">    <span class="dt" style="color: #AD0000;">int</span> l <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb4-18">    <span class="dt" style="color: #AD0000;">int</span> r <span class="op" style="color: #5E5E5E;">=</span> k<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb4-19">    <span class="dt" style="color: #AD0000;">double</span> target <span class="op" style="color: #5E5E5E;">=</span> u<span class="op" style="color: #5E5E5E;">[</span>j<span class="op" style="color: #5E5E5E;">];</span></span>
<span id="cb4-20">    <span class="cf" style="color: #003B4F;">while</span> <span class="op" style="color: #5E5E5E;">(</span>l <span class="op" style="color: #5E5E5E;">&lt;</span> r<span class="op" style="color: #5E5E5E;">)</span> <span class="op" style="color: #5E5E5E;">{</span></span>
<span id="cb4-21">      <span class="dt" style="color: #AD0000;">int</span> m <span class="op" style="color: #5E5E5E;">=</span> floor<span class="op" style="color: #5E5E5E;">((</span>l<span class="op" style="color: #5E5E5E;">+</span>r<span class="op" style="color: #5E5E5E;">)/</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">);</span></span>
<span id="cb4-22">      <span class="cf" style="color: #003B4F;">if</span> <span class="op" style="color: #5E5E5E;">(</span>emp_cdf<span class="op" style="color: #5E5E5E;">[</span>m<span class="op" style="color: #5E5E5E;">]</span> <span class="op" style="color: #5E5E5E;">&gt;</span> target<span class="op" style="color: #5E5E5E;">)</span> <span class="op" style="color: #5E5E5E;">{</span></span>
<span id="cb4-23">        r <span class="op" style="color: #5E5E5E;">=</span> m<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb4-24">      <span class="op" style="color: #5E5E5E;">}</span> <span class="cf" style="color: #003B4F;">else</span> <span class="op" style="color: #5E5E5E;">{</span></span>
<span id="cb4-25">        l <span class="op" style="color: #5E5E5E;">=</span> m<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb4-26">      <span class="op" style="color: #5E5E5E;">}</span></span>
<span id="cb4-27">    <span class="op" style="color: #5E5E5E;">}</span></span>
<span id="cb4-28">    mat<span class="op" style="color: #5E5E5E;">(</span>r<span class="op" style="color: #5E5E5E;">,</span>j<span class="op" style="color: #5E5E5E;">)</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb4-29">  <span class="op" style="color: #5E5E5E;">}</span></span>
<span id="cb4-30">  <span class="cf" style="color: #003B4F;">return</span> mat<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb4-31"><span class="op" style="color: #5E5E5E;">}</span></span></code></pre></div>
</div>
<p>In terms of performance it turns out that the simple C++ program actually does somewhat better than the base R alternative:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="fu" style="color: #4758AB;">library</span>(microbenchmark)</span>
<span id="cb5-2"><span class="fu" style="color: #4758AB;">library</span>(ggplot2)</span>
<span id="cb5-3">n <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">1000</span></span>
<span id="cb5-4">p <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="fl" style="color: #AD0000;">0.5</span>,<span class="fl" style="color: #AD0000;">0.1</span>,<span class="fl" style="color: #AD0000;">0.4</span>)</span>
<span id="cb5-5">mb <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">microbenchmark</span>(</span>
<span id="cb5-6">    <span class="st" style="color: #20794D;">"rmultinom"</span> <span class="ot" style="color: #003B4F;">=</span> {<span class="fu" style="color: #4758AB;">rmultinom</span>(n, <span class="dv" style="color: #AD0000;">1</span>, p)},</span>
<span id="cb5-7">    <span class="st" style="color: #20794D;">"Rcpp"</span> <span class="ot" style="color: #003B4F;">=</span> {<span class="fu" style="color: #4758AB;">simCategorical</span>(n, p)}</span>
<span id="cb5-8">)</span>
<span id="cb5-9"><span class="fu" style="color: #4758AB;">autoplot</span>(mb)</span></code></pre></div>
</div>
</section>
<section id="embedding-existing-work" class="level2">
<h2 class="anchored" data-anchor-id="embedding-existing-work">Embedding existing work</h2>
<p>If you have some existing work that you would like to share you can just use it to overwrite the <code>index.Rmd</code> file. <code>blogdown</code> supports any kind of R Markdown documents so you can use all of your favourite markdown packages (<code>bookdown</code>, <code>pagedown</code>, ‚Ä¶). Just make sure to specify HTML output in the YAML header.</p>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<p>For more information about <code>blogdown</code> see <a href="https://bookdown.org/yihui/blogdown/">here</a>. To inspect the code that builds this website check out my <a href="https://github.com/pat-alt/patalt">GitHub repository</a>.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick},
  title = {How {I‚Äôm} Building This Website in {R}},
  date = {21-02-02},
  url = {https://www.paltmeyer.com/blog//blog/posts/how-i-m-building-this-website-in-r},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 21AD. <span>‚ÄúHow I‚Äôm Building This Website in
R.‚Äù</span> February 2, 21AD. <a href="https://www.paltmeyer.com/blog//blog/posts/how-i-m-building-this-website-in-r">https://www.paltmeyer.com/blog//blog/posts/how-i-m-building-this-website-in-r</a>.
</div></div></section></div> ]]></description>
  <category>blogdown</category>
  <category>rmarkdown</category>
  <category>C++</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/how-i-m-building-this-website-in-r/index.html</guid>
  <pubDate>Mon, 01 Feb 2021 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Welcome</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/welcome/index.html</link>
  <description><![CDATA[ 



<p>Welcome to my blog!</p>
<p>Having worked with R Markdown and some of <a href="https://yihui.org/">Yihui Xie</a>‚Äôs amazing packages for years, I have only now come across his <a href="https://bookdown.org/yihui/blogdown/">blogdown</a> package. For a while I have been thinking about a good way to share some of my work and actually started collecting snippets in a <a href="https://pat-alt.github.io/fromScratch/">Gitbook</a> through <a href="https://bookdown.org/yihui/bookdown/">bookdown</a> quite some time ago. While the book is a work-in-progress that I aim to finish eventually, I will use this website to regularly share content related to my work, research and other things.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Update on Feb 20, 2022</strong></p>
<p>I have recently migrated this blog and pretty much everything else I do to <a href="https://quarto.org/">quarto</a>.</p>
<blockquote class="blockquote">
<p>Quarto¬Æ is an open-source scientific and technical publishing system built on Pandoc.</p>
</blockquote>
<p>Based on my first few experiences I would go further and say that quarto is <em>the only</em> open-source scientific and technical publishing system you‚Äôll ever need. The project is supported by RStudio and (unsurprisingly) Yihui Xie is one of the contributors. Go check it out!</p>
</div>
</div>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick and Altmeyer, Patrick},
  title = {Welcome},
  date = {21-02-01},
  url = {https://www.paltmeyer.com/blog//blog/posts/welcome},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick, and Patrick Altmeyer. 21AD. <span>‚ÄúWelcome.‚Äù</span>
February 1, 21AD. <a href="https://www.paltmeyer.com/blog//blog/posts/welcome">https://www.paltmeyer.com/blog//blog/posts/welcome</a>.
</div></div></section></div> ]]></description>
  <guid>https://www.paltmeyer.com/blog/blog/posts/welcome/index.html</guid>
  <pubDate>Sun, 31 Jan 2021 23:00:00 GMT</pubDate>
</item>
</channel>
</rss>
