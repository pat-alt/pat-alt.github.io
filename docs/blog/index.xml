<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Patrick Altmeyer</title>
<link>https://www.paltmeyer.com/blog/blog/index.html</link>
<atom:link href="https://www.paltmeyer.com/blog/blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-99.9.9</generator>
<lastBuildDate>Wed, 05 Jul 2023 04:00:00 GMT</lastBuildDate>
<item>
  <title>Building a Conformal Chatbot in Julia</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/conformal-llm/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-llm/www/intro.gif" style="width: 400px; height: 300px;" class="figure-img">
<figcaption class="figure-caption">
Short demo of our conformal chatbot.
</figcaption>
</figure>
</div>
<p>Large Language Models are all the buzz right now. They are used for a variety of tasks, including text classification, question answering, and text generation. In this tutorial, we will show how to conformalize a transformer language model for text classification. We will use the <a href="https://arxiv.org/abs/2003.04807">Banking77</a> dataset <span class="citation" data-cites="casanueva2020efficient">(Casanueva et al. 2020)</span>, which consists of 13,083 queries from 77 intents. On the model side, we will use the <a href="https://huggingface.co/mrm8488/distilroberta-finetuned-banking77">DistilRoBERTa</a> model, which is a distilled version of <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a> <span class="citation" data-cites="liu2019roberta">(Liu et al. 2019)</span> finetuned on the Banking77 dataset.</p>
<section id="huggingface-model" class="level2">
<h2 class="anchored" data-anchor-id="huggingface-model">ü§ó HuggingFace Model</h2>
<p>The model can be loaded from HF straight into our running Julia session using the <a href="https://github.com/chengchingwen/Transformers.jl/tree/master"><code>Transformers.jl</code></a> package. Below we load the tokenizer <code>tkr</code> and the model <code>mod</code>. The tokenizer is used to convert the text into a sequence of integers, which is then fed into the model. The model outputs a hidden state, which is then fed into a classifier to get the logits for each class. Finally, the logits are then passed through a softmax function to get the corresponding predicted probabilities. Below we run a few queries through the model to see how it performs.</p>
<div id="678fb923" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load model from HF ü§ó:</span></span>
<span id="cb1-2">tkr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> hgf<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mrm8488/distilroberta-finetuned-banking77:tokenizer"</span></span>
<span id="cb1-3">mod <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> hgf<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mrm8488/distilroberta-finetuned-banking77:ForSequenceClassification"</span></span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Test model:</span></span>
<span id="cb1-6">query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb1-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is the base of the exchange rates?"</span>,</span>
<span id="cb1-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Why is my card not working?"</span>,</span>
<span id="cb1-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"My Apple Pay is not working, what should I do?"</span>,</span>
<span id="cb1-10">]</span>
<span id="cb1-11">a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">encode</span>(tkr, query)</span>
<span id="cb1-12">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mod.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">model</span>(a)</span>
<span id="cb1-13">c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mod.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cls</span>(b.hidden_state)</span>
<span id="cb1-14">d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">softmax</span>(c.logit)</span>
<span id="cb1-15">[labels[i] for i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> Flux.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">onecold</span>(d)]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>3-element Vector{String}:
 "exchange_rate"
 "card_not_working"
 "apple_pay_or_google_pay"</code></pre>
</div>
</div>
</section>
<section id="mlj-interface" class="level2">
<h2 class="anchored" data-anchor-id="mlj-interface">üîÅ <code>MLJ</code> Interface</h2>
<p>Since our package is interfaced to <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ.jl</code></a>, we need to define a wrapper model that conforms to the <code>MLJ</code> interface. In order to add the model for general use, we would probably go through <a href="https://github.com/FluxML/MLJFlux.jl"><code>MLJFlux.jl</code></a>, but for this tutorial, we will make our life easy and simply overload the <code>MLJBase.fit</code> and <code>MLJBase.predict</code> methods. Since the model from HF is already pre-trained and we are not interested in further fine-tuning, we will simply return the model object in the <code>MLJBase.fit</code> method. The <code>MLJBase.predict</code> method will then take the model object and the query and return the predicted probabilities. We also need to define the <code>MLJBase.target_scitype</code> and <code>MLJBase.predict_mode</code> methods. The former tells <code>MLJ</code> what the output type of the model is, and the latter can be used to retrieve the label with the highest predicted probability.</p>
<div id="8636c199" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">struct</span> IntentClassifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;:</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;"> MLJBase.Probabilistic</span></span>
<span id="cb3-2">    tkr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">TextEncoders.AbstractTransformerTextEncoder</span></span>
<span id="cb3-3">    mod<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">HuggingFace.HGFRobertaForSequenceClassification</span></span>
<span id="cb3-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-5"></span>
<span id="cb3-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">IntentClassifier</span>(;</span>
<span id="cb3-7">    tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">TextEncoders.AbstractTransformerTextEncoder</span>, </span>
<span id="cb3-8">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">HuggingFace.HGFRobertaForSequenceClassification</span>,</span>
<span id="cb3-9">)</span>
<span id="cb3-10">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">IntentClassifier</span>(tkr, mod)</span>
<span id="cb3-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">get_hidden_state</span>(clf<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">IntentClassifier</span>, query<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Union{AbstractString, Vector{&lt;:AbstractString}}</span>)</span>
<span id="cb3-14">    token <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">encode</span>(clf.tkr, query)</span>
<span id="cb3-15">    hidden_state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.mod.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">model</span>(token).hidden_state</span>
<span id="cb3-16">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> hidden_state</span>
<span id="cb3-17"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-18"></span>
<span id="cb3-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This doesn't actually retrain the model, but it retrieves the classifier object</span></span>
<span id="cb3-20"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit</span>(clf<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">IntentClassifier</span>, verbosity, X, y)</span>
<span id="cb3-21">    cache<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">nothing</span></span>
<span id="cb3-22">    report<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">nothing</span></span>
<span id="cb3-23">    fitresult <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> clf.mod.cls, labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">levels</span>(y))</span>
<span id="cb3-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> fitresult, cache, report</span>
<span id="cb3-25"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-26"></span>
<span id="cb3-27"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(clf<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">IntentClassifier</span>, fitresult, Xnew)</span>
<span id="cb3-28">    output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fitresult.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">clf</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">get_hidden_state</span>(clf, Xnew))</span>
<span id="cb3-29">    pÃÇ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">UnivariateFinite</span>(fitresult.labels,<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">softmax</span>(output.logit)<span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">',pool=missing)</span></span>
<span id="cb3-30">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> pÃÇ</span>
<span id="cb3-31"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-32"></span>
<span id="cb3-33">MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">target_scitype</span>(clf<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">IntentClassifier</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractVector</span>{<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;:</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Finite</span>}</span>
<span id="cb3-34"></span>
<span id="cb3-35">MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict_mode</span>(clf<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">IntentClassifier</span>, fitresult, Xnew) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mode</span>.(MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(clf, fitresult, Xnew))</span></code></pre></div>
</div>
<p>To test that everything is working as expected, we fit the model and generated predictions for a subset of the test data:</p>
<div id="a3fc6050" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">IntentClassifier</span>(tkr, mod)</span>
<span id="cb4-2">top_n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb4-3">fitresult, _, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit</span>(clf, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">nothing</span>, y_test[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>top_n])</span>
<span id="cb4-4"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@time</span> yÃÇ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(clf, fitresult, queries_test[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>top_n]);</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  6.818024 seconds (11.29 M allocations: 799.165 MiB, 2.47% gc time, 91.04% compilation time)</code></pre>
</div>
</div>
</section>
<section id="conformal-chatbot" class="level2">
<h2 class="anchored" data-anchor-id="conformal-chatbot">ü§ñ Conformal Chatbot</h2>
<p>To turn the wrapped, pre-trained model into a conformal intent classifier, we can now rely on standard API calls. We first wrap our atomic model where we also specify the desired coverage rate and method. Since even simple forward passes are computationally expensive for our (small) LLM, we rely on Simple Inductive Conformal Classification.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1">conf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_model</span>(clf; coverage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>, method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>simple_inductive, train_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_ratio)</span>
<span id="cb6-2">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(conf_model, queries, y)</span>
<span id="cb6-3"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@time</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach)</span>
<span id="cb6-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Serialization</span>.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">serialize</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dev/artifacts/models/banking77/simple_inductive.jls"</span>, mach)</span></code></pre></div>
<p>Finally, we use our conformal LLM to build a simple yet powerful chatbot that runs directly in the Julia REPL. Without dwelling on the details too much, the <code>conformal_chatbot</code> works as follows:</p>
<ol type="1">
<li>Prompt user to explain their intent.</li>
<li>Feed user input through conformal LLM and present the output to the user.</li>
<li>If the conformal prediction set includes more than one label, prompt the user to either refine their input or choose one of the options included in the set.</li>
</ol>
<div id="d18b5d29" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Serialization</span>.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">deserialize</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"blog/posts/conformal-llm/simple_inductive.jls"</span>)</span>
<span id="cb7-2"></span>
<span id="cb7-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">prediction_set</span>(mach, query<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">String</span>)</span>
<span id="cb7-4">    pÃÇ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(mach, query)[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb7-5">    probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pdf</span>.(pÃÇ, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">collect</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">77</span>))</span>
<span id="cb7-6">    in_set <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">findall</span>(probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.!=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb7-7">    labels_in_set <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> labels[in_set]</span>
<span id="cb7-8">    probs_in_set <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> probs[in_set]</span>
<span id="cb7-9">    _order <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sortperm</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>probs_in_set)</span>
<span id="cb7-10">    plt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> UnicodePlots.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">barplot</span>(labels_in_set[_order], probs_in_set[_order], title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Possible Intents"</span>)</span>
<span id="cb7-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> labels_in_set, plt</span>
<span id="cb7-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb7-13"></span>
<span id="cb7-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_chatbot</span>()</span>
<span id="cb7-15">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"üëã Hi, I'm a Julia, your conformal chatbot. I'm here to help you with your banking query. Ask me anything or type 'exit' to exit ...</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb7-16">    completed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">false</span></span>
<span id="cb7-17">    queries <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span></span>
<span id="cb7-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">while</span> !completed</span>
<span id="cb7-19">        query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">readline</span>()</span>
<span id="cb7-20">        queries <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> queries <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">","</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> query</span>
<span id="cb7-21">        labels, plt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">prediction_set</span>(mach, queries)</span>
<span id="cb7-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">length</span>(labels) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-23">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ü§î Hmmm ... I can think of several options here. If any of these applies, simply type the corresponding number (e.g. '1' for the first option). Otherwise, can you refine your question, please?</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb7-24">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(plt)</span>
<span id="cb7-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span></span>
<span id="cb7-26">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ü•≥ I think you mean </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(labels[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">. Correct?"</span>)</span>
<span id="cb7-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb7-28"></span>
<span id="cb7-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Exit:</span></span>
<span id="cb7-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"exit"</span></span>
<span id="cb7-31">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"üëã Bye!"</span>)</span>
<span id="cb7-32">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">break</span></span>
<span id="cb7-33">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb7-34">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">‚àà</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">string</span>.(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">collect</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">77</span>))</span>
<span id="cb7-35">            <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"üëç Great! You've chosen '</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(labels[<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">parse</span>(<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Int64</span>, query)])<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'. I'm glad I could help you. Have a nice day!"</span>)</span>
<span id="cb7-36">            completed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb7-37">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb7-38">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb7-39"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
</div>
<p>Below we show the output for two example queries. The first one is very ambiguous. As expected, the size of the prediction set is therefore large.</p>
<div id="0fd4b42b" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">ambiguous_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"transfer mondey?"</span></span>
<span id="cb8-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">prediction_set</span>(mach, ambiguous_query)[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<div class="ansi-escaped-output">
<pre>                                                        <span class="ansi-bright-white-fg ansi-bold">Possible Intents</span>              
                                           <span class="ansi-bright-black-fg">‚îå                                        ‚îê</span> 
                   beneficiary_not_allowed <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.150517 <span class="ansi-bright-black-fg"> </span> 
   balance_not_updated_after_bank_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.111409         <span class="ansi-bright-black-fg"> </span> 
                     transfer_into_account <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0939535           <span class="ansi-bright-black-fg"> </span> 
        transfer_not_received_by_recipient <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.091163             <span class="ansi-bright-black-fg"> </span> 
            top_up_by_bank_transfer_charge <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.089306             <span class="ansi-bright-black-fg"> </span> 
                           failed_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0888322            <span class="ansi-bright-black-fg"> </span> 
                           transfer_timing <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0641952                 <span class="ansi-bright-black-fg"> </span> 
                      transfer_fee_charged <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0361131                       <span class="ansi-bright-black-fg"> </span> 
                          pending_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0270795                         <span class="ansi-bright-black-fg"> </span> 
                           receiving_money <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0252126                         <span class="ansi-bright-black-fg"> </span> 
                         declined_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†</span> 0.0164443                           <span class="ansi-bright-black-fg"> </span> 
                           cancel_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†</span> 0.0150444                           <span class="ansi-bright-black-fg"> </span> 
                                           <span class="ansi-bright-black-fg">‚îî                                        ‚îò</span> </pre>
</div>
</div>
</div>
<p>The more refined version of the prompt yields a smaller prediction set: less ambiguous prompts result in lower predictive uncertainty.</p>
<div id="ab02cc12" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb9-1">refined_query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"I tried to transfer money to my friend, but it failed."</span></span>
<span id="cb9-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">prediction_set</span>(mach, refined_query)[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div class="ansi-escaped-output">
<pre>                                                        <span class="ansi-bright-white-fg ansi-bold">Possible Intents</span>              
                                           <span class="ansi-bright-black-fg">‚îå                                        ‚îê</span> 
                           failed_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.59042 <span class="ansi-bright-black-fg"> </span> 
                   beneficiary_not_allowed <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.139806                        <span class="ansi-bright-black-fg"> </span> 
        transfer_not_received_by_recipient <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†</span> 0.0449783                            <span class="ansi-bright-black-fg"> </span> 
   balance_not_updated_after_bank_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†</span> 0.037894                             <span class="ansi-bright-black-fg"> </span> 
                         declined_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†</span> 0.0232856                             <span class="ansi-bright-black-fg"> </span> 
                     transfer_into_account <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†</span> 0.0108771                             <span class="ansi-bright-black-fg"> </span> 
                           cancel_transfer <span class="ansi-bright-black-fg">‚î§</span> 0.00876369                             <span class="ansi-bright-black-fg"> </span> 
                                           <span class="ansi-bright-black-fg">‚îî                                        ‚îò</span> </pre>
</div>
</div>
</div>
<p>Below we include a short demo video that shows the REPL-based chatbot in action.</p>
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-llm/www/demo.gif" class="img-fluid"></p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">üåØ Wrapping Up</h2>
<p>This work was done in collaboration with colleagues at ING as part of the ING Analytics 2023 Experiment Week. Our team demonstrated that Conformal Prediction provides a powerful and principled alternative to top-<em>K</em> intent classification. We won the first prize by popular vote.</p>
<p>There are a lot of things that can be improved. As far as LLMs are concerned, we have of course used a fairly small model here. In terms of Conformal Prediction, we have relied on simple inductive conformal classification. This is a good starting point, but there are more advanced methods available (and implemented in the package). Another thing we did not take into consideration here is that we have many outcome classes and may in practice be interested in achieving class-conditional coverage. Stay tuned for more!</p>
</section>
<section id="references" class="level2">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">üéì References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-casanueva2020efficient" class="csl-entry">
Casanueva, I√±igo, Tadas Temƒçinas, Daniela Gerz, Matthew Henderson, and Ivan Vuliƒá. 2020. <span>‚ÄúEfficient <span>Intent</span> <span>Detection</span> with <span>Dual</span> <span>Sentence</span> <span>Encoders</span>.‚Äù</span> In <em>Proceedings of the 2nd <span>Workshop</span> on <span>Natural</span> <span>Language</span> <span>Processing</span> for <span>Conversational</span> <span>AI</span></em>, 38‚Äì45. Online: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2020.nlp4convai-1.5">https://doi.org/10.18653/v1/2020.nlp4convai-1.5</a>.
</div>
<div id="ref-liu2019roberta" class="csl-entry">
Liu, Yinhan, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. <span>‚Äú<span>RoBERTa</span>: <span>A</span> <span>Robustly</span> <span>Optimized</span> <span>BERT</span> <span>Pretraining</span> <span>Approach</span>.‚Äù</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1907.11692">https://doi.org/10.48550/arXiv.1907.11692</a>.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2023,
  author = {Altmeyer, Patrick},
  title = {Building a {Conformal} {Chatbot} in {Julia}},
  date = {2023-07-05},
  url = {https://www.paltmeyer.com/blog//blog/posts/conformal-llm},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2023" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2023. <span>‚ÄúBuilding a Conformal Chatbot in
Julia.‚Äù</span> July 5, 2023. <a href="https://www.paltmeyer.com/blog//blog/posts/conformal-llm">https://www.paltmeyer.com/blog//blog/posts/conformal-llm</a>.
</div></div></section></div> ]]></description>
  <category>conformal prediction</category>
  <category>transformers</category>
  <category>llm</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/conformal-llm/index.html</guid>
  <pubDate>Wed, 05 Jul 2023 04:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/conformal-llm/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>An Accessible Intro to Laplace Approximations in Julia for Bayesian Deep Learning</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <dc:creator>Severin Bratus</dc:creator>
  <dc:creator>Mark Ardman</dc:creator>
  <dc:creator>Adelina Cazacu</dc:creator>
  <dc:creator>Andrei Ionescu</dc:creator>
  <dc:creator>Ivan Makarov</dc:creator>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/guest-students-laplace/index.html</link>
  <description><![CDATA[ 



<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Guest Blog Post
</div>
</div>
<div class="callout-body-container callout-body">
<p>This blog post was originally written by Severin Bratus and colleagues from TU Delft and published on <a href="https://medium.com/@sbratus/an-introduction-to-laplace-approximations-for-bayesian-deep-learning-in-julia-c5a30cfaf7b5">Medium</a>. This version of the post includes only minor edits. If you would like to contribute a guest blog post, please get in touch.</p>
</div>
</div>
<p>This post summarizes a quarter-long second-year BSc coursework project at TU Delft. Our team of five students has made multiple improvements to <a href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl">LaplaceRedux.jl</a>, due to Patrick Altmeyer. Inspired by its Pythonic counterpart, <a href="https://github.com/AlexImmer/Laplace">laplacet-torch</a>, this Julia library aims to provide low-overhead Bayesian uncertainty calibration to deep neural networks via Laplace Approximations <span class="citation" data-cites="daxberger2021laplace">(Daxberger et al. 2021)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/guest-students-laplace/www/intro.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">A nice image to attract your attention. The exact inverse Fisher information matrix for a MNIST classifier network (left), its block-diagonal and tri-block-diagonal approximations (middle), and the absolute error (right). Source: Martens &amp; Grosse (2015)</figcaption>
</figure>
</div>
<p>We will begin by demystifying the technical terms in the last sentence, in order to explain our contributions to the library and highlight some impressions from the experience. Note that our team has begun working on this PhD-tier subject only having had some introductory courses on probability and statistics, machine learning, and computational intelligence, without any prior exposure to Julia.</p>
<section id="bayesian-learning" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-learning">Bayesian Learning</h2>
<p>Uncertainty calibration remains a crucial issue in safety-critical applications of modern AI, as, for instance, in autonomous driving. You would want your car autopilot not only to make accurate predictions but also to indicate when a model prediction is uncertain, to give control back to the human driver.</p>
<p>A model is well-calibrated if the confidence of a prediction matches its true error rate. Note that you can have well-fit models that are badly calibrated, and <em>vice versa</em> (just like in life, you meet smart people, yet annoyingly arrogant).</p>
<p>The standard deep learning training process of gradient descent converges at a weight configuration that minimizes the loss function. The model obtained may be great, yet it is only a point estimate of what the weight parameters should look like.</p>
<p>However, with the sheer immensity of the weight space, neural networks are probably underspecified by the data (or, overfit). As neural networks can approximate highly complex functions, many weight configurations would yield roughly the same training loss, yet with varying abilities to generalize outside the training dataset. This is why there are so many regularization methods out there, to keep the models simpler. One radical, yet effective approach is described by <span class="citation" data-cites="lecun1989optimal">LeCun, Denker, and Solla (1989)</span>:</p>
<blockquote class="blockquote">
<p>‚Ä¶ it is possible to take a perfectly reasonable network, delete half (or more) of the weights and wind up with a network that works just as well, or better.</p>
</blockquote>
<div id="fig-loss" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/guest-students-laplace/www/grad_desc.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: The loss landscape. One can imagine gradient descent as a particle, let‚Äôs say a ball, or a grain of sand, rolling to the bottom of a pit. Then for Bayesian Learning, we have as if a pile of sand poured around at that bottom point, with the pile being thicker where loss is lower. This proverbial sand pile would represent the posterior parameter distribution. Figure due to <span class="citation" data-cites="amini2019spatial">Amini et al. (2019)</span></figcaption>
</figure>
</div>
<p>The way gradient is usually illustrated is with a picture like the one shown in Figure&nbsp;1 above a curved terrain of the loss function across the parameter space. Each point of the horizontal plane corresponds to some configuration of parameters. Gradient descent seeks the point at the bottom of this terrain, as the point with the lowest loss, however as the loss-curvature is highly non-convex and high-dimensional there are many directions in which we could move and still maintain a low loss. Thus instead of a singular point we would like to specify a probability distribution around that optimal point. Bayesian methods, and in particular Laplace Approximations, allow us to do this!</p>
<p>Firstly, the Bayesian approach to neural network uncertainty calibration is that of modelling the posterior using Bayes‚Äô Theorem:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(%5Ctheta%20%5Cmid%20%5Cmathcal%7BD%7D)%20=%20%5Ctfrac%7B1%7D%7BZ%7D%20%5C,p(%5Cmathcal%7BD%7D%20%5Cmid%20%5Ctheta)%20%5C,%20p(%5Ctheta),%20%5Cqquad%20Z:=%20p(%5Cmathcal%7BD%7D)%20=%20%5Ctextstyle%5Cint%20p(%5Cmathcal%7BD%7D%20%5Cmid%20%5Ctheta)%20%5C,%20p(%5Ctheta)%20%5C,d%5Ctheta%0A"></p>
<p>Here <img src="https://latex.codecogs.com/png.latex?p(%5Cmathcal%7BD%7D%20%5Cmid%20%5Ctheta)"> is the likelihood of the data given by the parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta">. The prior distribution <img src="https://latex.codecogs.com/png.latex?p(%5Ctheta)"> specifies our beliefs about what the model parameters would be prior to observing the data. Finally, the intractable constant <img src="https://latex.codecogs.com/png.latex?Z"> is called the evidence: it characterizes the probability of observing <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> as a whole, across all possible parameter settings (see <a href="../../../blog/posts/effortsless-bayesian-dl/index.html">here</a> for details).</p>
<p>For models returning a probability distribution (e.g.&nbsp;classifiers), the loss is commonly defined as the negative log-likelihood. Thus if gradient descent minimizes loss, it maximizes the likelihood, producing the maximum likelihood estimate (MLE), which (assuming a uniform prior) also maximizes the posterior. This is why we call this point the <em>maximum a posteriori</em>, or the MAP. It makes sense to model this point as the mode of the posterior distribution, which could, for example, be a normal Gaussian distribution (see also the introductory <a href="../../../blog/posts/effortsless-bayesian-dl/index.html">post</a> on this blog).</p>
</section>
<section id="laplace-approximations" class="level2">
<h2 class="anchored" data-anchor-id="laplace-approximations">Laplace Approximations</h2>
<p>We do this by a simple-yet-smart trick introduced back in the late 18th century by Pierre-Simon Laplace, the self-proclaimed ‚Äúgreatest French mathematician of his time‚Äù. In general, the Laplace Approximation (LA) aims to find a Gaussian approximation to a probability density (in our case, the posterior) defined over a set of continuous variables (in our case, the weights) <span class="citation" data-cites="bishop2006pattern">(Bishop 2006)</span>. We can then estimate the loss (negative log-likelihood) as its second-order Taylor expansion:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(%5Cmathcal%7BD%7D;%20%5Ctheta)%20%5Capprox%20%5Cmathcal%7BL%7D(%5Cmathcal%7BD%7D;%20%5Ctheta_%5Ctext%7BMAP%7D)%20+%20%5Ctfrac%7B1%7D%7B2%7D%20(%5Ctheta%20-%20%5Ctheta_%5Ctext%7BMAP%7D)%5E%5Cintercal%20%5Cleft(%20%5Cnabla%5E2%20_%5Ctheta%20%5Cmathcal%7BL%7D(%5Cmathcal%7BD%7D;%20%5Ctheta)%20%5Cvert_%7B%5Ctheta_%5Ctext%7BMAP%7D%7D%20%5Cright)(%5Ctheta%20-%20%5Ctheta_%5Ctext%7BMAP%7D)%0A"></p>
<p>Note that the first-order Taylor term vanishes at the MAP since it contains the gradient, and the gradient is zero at MAP, since MAP is a maximum, by definition. What remains is the constant (zeroth-order) term, and the second-order term, containing the Hessian, which is a matrix of partial second-order derivatives.</p>
<p>Then from this approximation, we can derive the long-sought multivariate normal distribution with the MAP as the mean, and the inverted Hessian as the covariance:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(%5Ctheta%20%5Cmid%20%5Cmathcal%7BD%7D)%20%5Capprox%20N(%5Ctheta;%20%5Ctheta_%5Ctext%7BMAP%7D,%20%5CvarSigma)%20%5Cqquad%5Ctext%7Bwith%7D%5Cqquad%20%5CvarSigma%20:=%20%5Cleft(%20%5Cnabla%5E2_%5Ctheta%20%5Cmathcal%7BL%7D(%5Cmathcal%7BD%7D;%5Ctheta)%20%5Cvert_%7B%5Ctheta_%5Ctext%7BMAP%7D%7D%20%5Cright)%5E%7B-1%7D%0A"></p>
<p>The evidence <img src="https://latex.codecogs.com/png.latex?Z"> is now also tractably approximated in closed form, allowing us to apply the Bayes‚Äô theorem, to obtain the posterior distribution <img src="https://latex.codecogs.com/png.latex?p(%5Ctheta%20%5Cmid%20%5Cmathcal%7BD%7D)">. We can then express the <em>posterior predictive</em> distribution, for an input <img src="https://latex.codecogs.com/png.latex?x_*">, prediction <img src="https://latex.codecogs.com/png.latex?f(x_*)">, to obtain the probability for an output <img src="https://latex.codecogs.com/png.latex?y">.</p>
<p>The evidence <img src="https://latex.codecogs.com/png.latex?Z"> is now also tractably approximated in closed form, allowing us to apply the Bayes‚Äô theorem, to obtain the posterior distribution <img src="https://latex.codecogs.com/png.latex?p(%5Ctheta%20%5Cmid%20%5Cmathcal%7BD%7D)">. We can then express the posterior predictive distribution, to obtain the probability for an output <img src="https://latex.codecogs.com/png.latex?y">, given a prediction <img src="https://latex.codecogs.com/png.latex?f(x_*)"> for an input <img src="https://latex.codecogs.com/png.latex?x_*">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(y%20%5Cmid%20f(x_*),%20%5Cmathcal%7BD%7D)%20=%20%5Cint%20p(y%20%5Cmid%20f_%5Ctheta(x_*))%20%5C,%20p(%5Ctheta%20%5Cmid%20%5Cmathcal%7BD%7D)%20%5C,d%5Ctheta%0A"></p>
<p>This is what we are really after, after all ‚Äî instead of giving one singular point-estimate prediction <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7By%7D%20=%20f(x_*)">, we make the neural network give a distribution over <img src="https://latex.codecogs.com/png.latex?y">.</p>
<p>However, since the Hessian, a square matrix, defines the covariance between all model parameters (upon inversion), of which there may be millions or billions, the computation and storage of the Hessian (not to speak of inversion!) become intractable, as its size scales quadratically with the number of parameters involved. Thus to apply Laplace approximations to large models, we must make some simplifications ‚Äî which brings us to‚Ä¶</p>
</section>
<section id="hessian-approximations" class="level2">
<h2 class="anchored" data-anchor-id="hessian-approximations">Hessian approximations</h2>
<p>Multiple techniques to approximate the Hessian have arisen from a field adjacent, yet distinct from Bayesian learning ‚Äî that of second-order optimization, where Hessians are used to accelerate gradient descent convergence.</p>
<p>One such approximation is the Fisher information matrix, or simply the Fisher:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AF%20:=%20%5Ctextstyle%5Csum_%7Bn=1%7D%5EN%20%5Cmathbb%7BE%7D_%7B%5Cwidehat%7By%7D%20%5Csim%20p(y%20%5Cmid%20f_%5Ctheta(x_n))%7D%20%5Cleft%5B%20%20gg%5E%5Cintercal%20%5Cright%5D%20%5Cquad%5Ctext%7Bwith%7D%5Cquad%20g%20=%20%5Cnabla_%5Ctheta%20%5Clog%20p(%5Cwidehat%7By%7D%20%5Cmid%20f_%5Ctheta(x_n))%20%5Clarge%5Cvert_%7B%5Ctheta_%5Ctext%7BMAP%7D%7D%0A"></p>
<p>Note that if instead of sampling the prediction <img src="https://latex.codecogs.com/png.latex?%5Cwidehat%7By%7D%20~%20p(y%20%5Cmid%20f(x_n))"> from the model-defined distribution, we take the actual training-set label <img src="https://latex.codecogs.com/png.latex?y_n">, the resulting matrix is called the empirical Fisher, which is distinct from the Fisher, yet aligns with it under some conditions, and does <em>not</em> generally capture second-order information. See Kunstner et al.&nbsp;(2019) for an excellent discussion on the distinction.</p>
<p>Instead of the Fisher, one can use the Generalized Gauss-Newton (GGN):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AG%20:=%20%5Ctextstyle%5Csum_%7Bn=1%7D%5EN%20J(x_n)%20%5Cleft(%20%5Cnabla%5E2_%7Bf%7D%20%5Clog%20p(y_n%20%5Cmid%20f)%20%5CLarge%5Cvert_%7Bf=f_%7B%5Ctheta_%5Ctext%7Bmap%7D%7D(x_n)%7D%20%5Cright)%20J(x_n)%5E%5Cintercal%0A%5Ctext%7Bwith%7D%5Cqquad%20J(x_n)%20:=%20%5Cnabla_%5Ctheta%20f_%5Ctheta(x_n)%20%5Cvert_%7B%5Ctheta_%5Ctext%7Bmap%7D%7D%0A"></p>
<p>Here <img src="https://latex.codecogs.com/png.latex?J(x_n)"> represents the Jacobian of the model output w.r.t. the parameters. The middle factor <img src="https://latex.codecogs.com/png.latex?%5Cnabla%5E2%20%E2%80%A6"> is a Hessian of log-likelihood of <img src="https://latex.codecogs.com/png.latex?y_n"> w.r.t. model output. Note that the model does not necessarily output ready target probabilities ‚Äî for instance, classifiers output <em>logits</em>, values that define a probability distribution only after the application of the soft-max.</p>
<p>Unlike the Fisher, GGN does not require the network to define a probabilistic model on its output <span class="citation" data-cites="botev2017practical">(Botev, Ritter, and Barber 2017)</span>. For models defining an exponential family distribution over the output, the two coincide <span class="citation" data-cites="kunstner2020limitations">(Kunstner, Balles, and Hennig 2020)</span>. This applies to classifiers since they define a categorical distribution over the output, but not to simple regression models.</p>
<p>These matrices are quadratically large, it is infeasible to store them in full. The simplest estimation is to model the matrix as a diagonal ‚Äî however one can easily contemplate how crude this approximation can be: for 100 parameters, only 1% of the full Hessian is captured.</p>
<p>A more sophisticated approach, due to Martens and Grosse (2015), is inspired by the observation that in practice the covariance matrices (i.e.&nbsp;inverted Hessians) for neural networks are block-diagonal-dominant. Thus we can effectively model the covariance matrix (and hence the Fisher) as a block-diagonal matrix, where blocks correspond to parameters grouped by layers. Additionally, each block is decomposed into two Kronecker factors, reducing the size of data stored several magnitudes more, at a cost of another assumption.</p>
<p>Lastly, a novel approach is to <em>sketch</em> a low-rank approximation of the Fisher <span class="citation" data-cites="sharma2021sketching">(Sharma, Azizan, and Pavone 2021)</span>. Figure&nbsp;2 shows four Hessian approximation structures:</p>
<div id="fig-fact" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/guest-students-laplace/www/fact.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: (a) Hessian in full, intractable for large networks. (b) Low-rank. (c) Kronecker-factored Approximate Curvature, a block-diagonal method. (d) Diagonal. Source: <span class="citation" data-cites="daxberger2021laplace">Daxberger et al. (2021)</span></figcaption>
</figure>
</div>
<p>It is also possible to cut the costs by treating only a subset of the model parameters, i.e.&nbsp;a subnetwork, probabilistically, fixing the remaining parameters at their MAP-estimated values. One special case of subnetwork Laplace that was found to perform well in practice is last-layer Laplace, where the selected subnetwork contains only the weights and biases of the last layer.</p>
</section>
<section id="our-contributions-to-laplaceredux.jl" class="level2">
<h2 class="anchored" data-anchor-id="our-contributions-to-laplaceredux.jl">Our contributions to LaplaceRedux.jl</h2>
<p>In the scope of the project we have added support for: - multi-class classification, in addition to regression and binary classification; - GGN, in addition to empirical Fisher; - hardware-parallelized batched computation of both the empirical Fisher and the GGN; - subnetwork and last-layer Laplace; - KFAC for multi-class classification with Fisher; and - interfacing with MLJ, a common machine learning framework for Julia.</p>
<p>We have also made quality assurance / quality-of-life additions to the repository, adding: - a formatting check in the CI/CD pipeline; - an extensive test suite comparing the results of LaplaceRedux.jl against those of its Python counter-part package laplace-torch; and - a benchmark pipeline tracking possible downturns in performance.</p>
</section>
<section id="methodology" class="level2">
<h2 class="anchored" data-anchor-id="methodology">Methodology</h2>
<p>We adhered to the Agile/Scrum practices, with two-week-long sprints, and weekly meetings with our formal client, Patrick Altmeyer. We have prioritized the expected requirements by the Moscow method into must-, could-, should-, and won‚Äôt-haves. This is all fairly standard for BSc software projects at TU Delft. By the end of the project, we have completed all of our self-assigned must-haves and should-haves.</p>
</section>
<section id="pain-points" class="level2">
<h2 class="anchored" data-anchor-id="pain-points">Pain Points</h2>
<p>Here we list some obstacles we have encountered along the way: - Julia is slow to compile and load dependencies on less powerful machines. - Stack traces are sometimes rather obscure, though it seems to be the price to pay for macros. - <code>Zygote.jl</code>, the automatic differentiation library, is <a href="https://github.com/FluxML/Zygote.jl/issues/1268">not self-autodifferentiable</a> ‚Äì it cannot differentiate its own functions. We would want this since we apply <code>Zygote.jacobians</code> when making predictions with the LA. - There is no accessible tool reporting branch coverage on tests ‚Äì only line coverage is available. - Limited LSP and Unicode support for Jupyter Lab. - Conversion between Flux and ONNX is <a href="https://github.com/FluxML/ONNX.jl">not yet implemented</a>. - There is no extension library for Zygote equivalent to BackPACK or ASDL for second-order information.</p>
<ul>
<li><code>Zygote.jl</code>, the automatic differentiation library, is not self-autodifferentiable: <a href="https://github.com/FluxML/Zygote.jl/issues/1268">issue</a>. We would want this since we apply <code>Zygote.jacobians</code> when making predictions with the LA.</li>
<li>There is no accessible tool reporting branch coverage on tests ‚Äì only line coverage is available.</li>
<li>Limited LSP and Unicode support for Jupyter Lab.</li>
<li>No conversion between Flux and ONNX is implemented yet <a href="https://github.com/FluxML/ONNX.jl">ONNX.jl</a></li>
<li>There is no extension library for Zygote equivalent to <a href="https://github.com/f-dangel/backpack">BackPACK</a> or <a href="https://github.com/kazukiosawa/asdl/">ASDL</a> for second-order information.</li>
</ul>
</section>
<section id="highlights" class="level2">
<h2 class="anchored" data-anchor-id="highlights">Highlights</h2>
<p>And here is what we found refreshing: - Metaprogramming and first-class support for macros are something completely different for students who are used to Java &amp; Python. - The Julia standard API, and Flux/Zygote, are fairly straightforward to use, and well-thought-out for numerical computing and machine learning.</p>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>We have covered some elements of the theory behind Laplace Approximations, laid down our additions to the <code>LaplaceRedux.jl</code> package, and brought out some difficulties we, as complete newcomers to Julia, came across. Hope you have enjoyed the tour, and hopefully it has intrigued you enough to look deeper into Bayesian learning and/or Julia since both are developing at a lively pace. You can check out LaplaceRedux on the JuliaTrustworthyAI GitHub page here. Contributions and comments are welcome!</p>
</section>
<section id="acknowedgements" class="level2">
<h2 class="anchored" data-anchor-id="acknowedgements">Acknowedgements</h2>
<p>Our team members are Mark Ardman, Severin Bratus, Adelina Cazacu, Andrei Ionescu, and Ivan Makarov. We would like to thank Patrick Altmeyer for the opportunity to work on this unique project and for the continuous guidance throughout the development process. We are also grateful to Sebastijan Dumanƒçiƒá, our coach, Sven van der Voort, our TA mentor, and Antony Bartlett, our supporting advisor.</p>
</section>
<section id="references" class="level2">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-amini2019spatial" class="csl-entry">
Amini, Alexander, Ava Soleimany, Sertac Karaman, and Daniela Rus. 2019. <span>‚ÄúSpatial <span>Uncertainty</span> <span>Sampling</span> for <span>End</span>-to-<span>End</span> <span>Control</span>.‚Äù</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1805.04829">https://doi.org/10.48550/arXiv.1805.04829</a>.
</div>
<div id="ref-bishop2006pattern" class="csl-entry">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. <span>springer</span>.
</div>
<div id="ref-botev2017practical" class="csl-entry">
Botev, Aleksandar, Hippolyt Ritter, and David Barber. 2017. <span>‚ÄúPractical <span>Gauss</span>-<span>Newton</span> <span>Optimisation</span> for <span>Deep</span> <span>Learning</span>.‚Äù</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1706.03662">https://doi.org/10.48550/arXiv.1706.03662</a>.
</div>
<div id="ref-daxberger2021laplace" class="csl-entry">
Daxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. <span>‚ÄúLaplace <span>Redux-Effortless Bayesian Deep Learning</span>.‚Äù</span> <em>Advances in Neural Information Processing Systems</em> 34.
</div>
<div id="ref-kunstner2020limitations" class="csl-entry">
Kunstner, Frederik, Lukas Balles, and Philipp Hennig. 2020. <span>‚ÄúLimitations of the <span>Empirical</span> <span>Fisher</span> <span>Approximation</span> for <span>Natural</span> <span>Gradient</span> <span>Descent</span>.‚Äù</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1905.12558">https://doi.org/10.48550/arXiv.1905.12558</a>.
</div>
<div id="ref-lecun1989optimal" class="csl-entry">
LeCun, Yann, John Denker, and Sara Solla. 1989. <span>‚ÄúOptimal <span>Brain</span> <span>Damage</span>.‚Äù</span> In <em>Advances in <span>Neural</span> <span>Information</span> <span>Processing</span> <span>Systems</span></em>. Vol. 2. Morgan-Kaufmann. <a href="https://proceedings.neurips.cc/paper/1989/hash/6c9882bbac1c7093bd25041881277658-Abstract.html">https://proceedings.neurips.cc/paper/1989/hash/6c9882bbac1c7093bd25041881277658-Abstract.html</a>.
</div>
<div id="ref-sharma2021sketching" class="csl-entry">
Sharma, Apoorva, Navid Azizan, and Marco Pavone. 2021. <span>‚ÄúSketching <span>Curvature</span> for <span>Efficient</span> <span>Out</span>-of-<span>Distribution</span> <span>Detection</span> for <span>Deep</span> <span>Neural</span> <span>Networks</span>.‚Äù</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2102.12567">https://doi.org/10.48550/arXiv.2102.12567</a>.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2023,
  author = {Altmeyer, Patrick and Bratus, Severin and Ardman, Mark and
    Cazacu, Adelina and Ionescu, Andrei and Makarov, Ivan and Altmeyer,
    Patrick},
  title = {An {Accessible} {Intro} to {Laplace} {Approximations} in
    {Julia} for {Bayesian} {Deep} {Learning}},
  date = {2023-07-04},
  url = {https://www.paltmeyer.com/blog//blog/posts/guest-students-laplace},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2023" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick, Severin Bratus, Mark Ardman, Adelina Cazacu, Andrei
Ionescu, Ivan Makarov, and Patrick Altmeyer. 2023. <span>‚ÄúAn Accessible
Intro to Laplace Approximations in Julia for Bayesian Deep
Learning.‚Äù</span> July 4, 2023. <a href="https://www.paltmeyer.com/blog//blog/posts/guest-students-laplace">https://www.paltmeyer.com/blog//blog/posts/guest-students-laplace</a>.
</div></div></section></div> ]]></description>
  <category>bayesian deep learning</category>
  <category>laplace approximation</category>
  <category>guest post</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/guest-students-laplace/index.html</guid>
  <pubDate>Tue, 04 Jul 2023 04:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/guest-students-laplace/www/intro.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>A Leap of Faith into Julia‚Äôs Metaverse</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/meta-programming/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/meta-programming/www/intro.png" class="figure-img">
<figcaption class="figure-caption">
A leap of faith into Julia‚Äôs metaverse.
</figcaption>
</figure>
</div>
<p>On this blog, I typically talk about things that I have <em>some</em> understanding of. In this post, I want to try something a little different and instead cover a topic that I am utterly <em>clueless</em> about. There‚Äôs an interesting aspect about Julia, which I know embarrassingly little about at this point: <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/">Metaprogramming</a>.</p>
<p>Having worked with Julia for about 1.5 years now, I have so far employed a successful strategy of occasionally taking a glimpse at that part of the Julia documentation and then deciding to go back to pretending it never existed. Meanwhile, <a href="https://twitter.com/kdpsinghlab">Karandeep Singh</a> has stepped on the Julia scence around 5 minutes ago and already developed a package that literally oozes macro: <a href="https://kdpsingh.github.io/Tidier.jl/dev/">Tidier.jl</a>. The package API is such a joy to work with that I have felt inspired to finally take a serious look at what metaprogramming is all about.</p>
<p>My goal for this post is to get to the point where I can confidently write my first macro for <a href="https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl"><code>CounterfactualExplanations.jl</code></a> - more on this below! If you are as clueless and curious about the topic as I am, then follow along on a journey into the metaverse. Buckle in though, it‚Äôs going to be a bumpy ride! You have been warned.</p>
<section id="all-right-where-to-start" class="level2">
<h2 class="anchored" data-anchor-id="all-right-where-to-start">ü§î All right, where to start?</h2>
<p>You guessed it, we‚Äôll start with the official Julia <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/">documentation</a> on the topic:</p>
<blockquote class="blockquote">
<p>Like Lisp, Julia represents its own code as a data structure of the language itself.</p>
</blockquote>
<p>Hmmm ‚Ä¶ I know nothing about Lisp and this is already beyond me. Code as a data structure?</p>
<p>Let‚Äôs first try to understand what exactly metaprogramming is, outside of Julia and Lisp. We‚Äôll take a quick detour before we‚Äôre back. <a href="https://en.wikipedia.org/wiki/Metaprogramming#:~:text=Metaprogramming%20is%20a%20programming%20technique,even%20modify%20itself%20while%20running.">Wikipedia</a> has the following to say on the topic:</p>
<blockquote class="blockquote">
<p>Metaprogramming is a programming technique in which computer programs have the ability to treat other programs as their data.</p>
</blockquote>
<p>Right ‚Ä¶ What about ChatGPT? I wanted to try out <a href="https://github.com/ThatcherC/ReplGPT.jl">ReplGPT</a> anyway so here goes<sup>1</sup>:</p>
<pre class="julia-repl"><code>julia&gt; using ReplGPT
ChatGPT&gt; Hey hey, can you please explain metaprogramming to me (I have no computer science background, but am experienced with programming and data science)
  Metaprogramming is a programming technique where a program is capable of creating or manipulating code at
  runtime. It involves writing computer programs that create, modify, or analyze other computer programs or data
  about those programs.</code></pre>
<p>So, in layman‚Äôs terms, metaprogramming involves code that generates code - I guess we really have entered the metaverse!</p>
</section>
<section id="julia-docs" class="level2">
<h2 class="anchored" data-anchor-id="julia-docs">üìñ Julia docs</h2>
<p>Let‚Äôs head back to the Julia <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/">documentation (v1.8)</a> and look at the first couple of examples.</p>
<section id="code-as-data-structures" class="level3">
<h3 class="anchored" data-anchor-id="code-as-data-structures">Code as Data Structures</h3>
<p>Skipping the details here, it turns out that when I write <code>1 + 1</code> in the REPL, Julia first parses this program as a string <code>"1 + 1</code> into an expression <code>ex=:(1 + 1)::Expr</code>, which is then evaluated <code>eval(ex)</code> (Figure&nbsp;1). I‚Äôve used a <code>quote</code> here to generate the expression because I‚Äôve used <strong>quoting</strong> before for use with <code>Documenter.jl</code>.</p>
<div id="fig-code" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/meta-programming/www/code-as-data.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Key concept: code as a data structure.</figcaption>
</figure>
</div>
<p>And if I understand this correctly, the expression <code>ex::Expr</code> is literally <strong>code as a data structure</strong>:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1">ex <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]))</span>
<span id="cb2-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dump</span>(ex)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Expr
  head: Symbol call
  args: Array{Any}((2,))
    1: Symbol sum
    2: Expr
      head: Symbol vect
      args: Array{Any}((3,))
        1: Int64 1
        2: Int64 2
        3: Int64 3</code></pre>
</div>
</div>
<p>That data structure can be ‚Äúmanipulated from within the language‚Äù.</p>
<p>Let‚Äôs try that! Currently, evaluating this expression yields the <code>sum</code> of the <code>Array</code>:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eval</span>(ex)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>6</code></pre>
</div>
</div>
<p>Upon manipulation (that sounds weird!), we have:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1">ex.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>maximum</span>
<span id="cb6-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eval</span>(ex)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>3</code></pre>
</div>
</div>
<p>Ok ok, things are starting to make sense now!</p>
</section>
<section id="interpolation" class="level3">
<h3 class="anchored" data-anchor-id="interpolation">Interpolation</h3>
<p>Back to the Julia documentation and next on the agenda we have <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#man-expression-interpolation">Interpolation</a>. Skipping the details again, it seems like I can interpolate an expression much like strings. Using interpolation I can recreate the expression from above as follows:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">fun <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> maximum</span>
<span id="cb8-2">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]</span>
<span id="cb8-3">ex_from_ex_interpoliation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fun</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>x))</span>
<span id="cb8-4">a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eval</span>(ex_from_ex_interpoliation)</span></code></pre></div>
</div>
<p>Using string interpolation is quite similar:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb9-1">fun <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> maximum</span>
<span id="cb9-2">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]</span>
<span id="cb9-3">ex_from_string_interpolation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Meta</span>.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">parse</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>fun<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>x<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span>)</span>
<span id="cb9-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eval</span>(ex_from_string_interpolation) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>true</code></pre>
</div>
</div>
<p>And much like with function arguments, we can also use splatting:</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eval</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">zeros</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>)))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>1√ó2√ó3 Array{Float64, 3}:
[:, :, 1] =
 0.0  0.0

[:, :, 2] =
 0.0  0.0

[:, :, 3] =
 0.0  0.0</code></pre>
</div>
</div>
<p>Next off, we have <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#Nested-quote"><strong>nested quotes</strong></a>. I can‚Äôt see myself using these anytime soon but anyway it seems that for each <code>$</code> sign that we prepend to <code>x</code>, an evaluation is trigged:</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb13-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eval</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">quote</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">quote</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$$:</span>(x) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<div class="ansi-escaped-output">
<pre>quote
    <span class="ansi-bright-black-fg">#= In[34]:2 =#</span>
    [1, 2, 3]
end</pre>
</div>
</div>
</div>
<p>Moving on, we have <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#man-quote-node"><code>QuoteNodes</code></a>, which I will steer clear of because I probably won‚Äôt be doing any super advanced metaprogramming anytime soon. The next two sections on <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#Evaluating-expressions">evaluating expressions</a> and <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#Functions-on-Expressions">functions on <code>Expr</code>essions</a> also look somewhat more involved than what I need right now, but I expect I‚Äôll find myself back here when I write that first macro for <a href="https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl"><code>CounterfactualExplanations.jl</code></a>.</p>
</section>
<section id="macros" class="level3">
<h3 class="anchored" data-anchor-id="macros">Macros</h3>
<p>Ahhh, I see we‚Äôve finally arrived in <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#man-macros">Macroland</a>!</p>
<blockquote class="blockquote">
<p>A macro maps a tuple of arguments to a returned expression, and the resulting expression is compiled directly rather than requiring a runtime eval call.</p>
</blockquote>
<div class="quarto-figure quarto-figure-right">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/meta-programming/www/macroland.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Arrived in Macroland.</figcaption>
</figure>
</div>
<p>Let‚Äôs see if we can make sense of this as we move on. The <code>Hello, world!</code> example makes the concept quite clear:</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb14-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">macro</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sayhello</span>(name)</span>
<span id="cb14-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>( <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hello, "</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>name) )   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># return the expression ...</span></span>
<span id="cb14-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb14-4"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@sayhello</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"reader"</span>                          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... to be immediately compiled.</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Hello, reader</code></pre>
</div>
</div>
<p>It seems that a macro is a way to build and return expressions inside a block (a bit like a function) but on call that expression is immediately evaluated. In other words, we can use macros to write code that generates code that is then evaluated.</p>
<p>To fully grasp the next <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#Hold-up:-why-macros?">part</a>, I should have not skipped the part on <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#Functions-on-Expressions">functions on <code>Expr</code>essions</a>. We‚Äôll leave that little nugget for Future Me. That same guy will also have to suffer the consequences of Present Me merely skimming the details in the next <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#Macro-invocation">section</a> on macro invocation. Present Me is impatient and overly confident in the level of knowledge that we have just acquired about metaprogramming.</p>
<p>Let‚Äôs get ahead of ourselves and meet the final boss of the metaverse: an Advanced Macro.</p>
</section>
</section>
<section id="build-an-advanced-macro" class="level2">
<h2 class="anchored" data-anchor-id="build-an-advanced-macro">üî• BUILD AN ADVANCED MACRO</h2>
<p>I‚Äôll leave it to you to thoroughly read that section in the Julia <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#Building-an-advanced-macro">docs</a>. Here, we‚Äôll jump straight into building the macro I want to have for <a href="https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl"><code>CounterfactualExplanations.jl</code></a>. I now think it‚Äôll be less involved than I thought ‚Äî optimism in the face of uncertainty!</p>
<div class="quarto-figure quarto-figure-right">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/meta-programming/www/final-boss.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Advanced Macro: the final boss.</figcaption>
</figure>
</div>
<section id="from-off-the-shelf-counterfactual-generators" class="level3">
<h3 class="anchored" data-anchor-id="from-off-the-shelf-counterfactual-generators">From Off-the-Shelf Counterfactual Generators ‚Ä¶</h3>
<p><a href="https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl"><code>CounterfactualExplanations.jl</code></a> is a package for generating Counterfactual Explanations for predictive models <img src="https://latex.codecogs.com/png.latex?f:%20%5Cmathcal%7BX%7D%20%5Cmapsto%20%5Cmathcal%7BY%7D">. This is a relatively recent approach to Explainable AI that I am (probably a little too) excited about and won‚Äôt dwell on here. For what follows, it suffices to say that generating Counterfactual Explanations can be seen as a generative modelling task because it involves generating samples in the input space: <img src="https://latex.codecogs.com/png.latex?x%20%5Csim%20%5Cmathcal%7BX%7D">. To this end, the package has previously shipped with a number of <code>Generators</code>: composite types that contain information about how counterfactuals ought to be generated.</p>
<p>This has allowed users to specify the type of generator they want to use by instantiating it. For example, the DiCE generator by <span class="citation" data-cites="mothilal2020explaining">Mothilal, Sharma, and Tan (2020)</span> could (and still can) be instantiated as follows:</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb16-1">generator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">DiCEGenerator</span>()</span></code></pre></div>
</div>
<p>This has been a straightforward way for users to use off-the-shelf counterfactual generators. But relying on separate composite types for this task may have been an overkill. In fact, all this time there was some untapped potential here, as we will see next.</p>
</section>
<section id="to-composable-generators" class="level3">
<h3 class="anchored" data-anchor-id="to-composable-generators">‚Ä¶ To Composable Generators</h3>
<p>One of my key objectives for the package has always been composability. It turns out that many of the various counterfactual generators that have been proposed in the literature, essentially do the same thing: they optimize an objective function. In <span class="citation" data-cites="altmeyer2023endogenous">Altmeyer et al. (2023)</span>, we denote that objective formally as follows,</p>
<p><span id="eq-general"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmathbf%7Bs%7D%5E%5Cprime%20&amp;=%20%5Carg%20%5Cmin_%7B%5Cmathbf%7Bs%7D%5E%5Cprime%20%5Cin%20%5Cmathcal%7BS%7D%7D%20%5Cleft%5C%7B%20%20%7B%5Ctext%7Byloss%7D(M(f(%5Cmathbf%7Bs%7D%5E%5Cprime)),y%5E*)%7D+%20%5Clambda%20%7B%5Ctext%7Bcost%7D(f(%5Cmathbf%7Bs%7D%5E%5Cprime))%20%7D%20%20%5Cright%5C%7D%0A%5Cend%7Baligned%7D%0A%5Ctag%7B1%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Byloss%7D"> denotes the main loss function and <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bcost%7D"> is a penalty term. I won‚Äôt cover this in any more detail here, but you can read about it in the package <a href="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/v0.1/explanation/generators/overview/#Gradient-based-Counterfactual-Generators">docs</a>. The important thing is that Equation&nbsp;1 very closely describes how counterfactual search is actually implemented in the package.</p>
<p>In other words, all generators currently implemented share a common starting point. They largely just vary in the exact way the objective function is specified. This gives rise to an interesting idea:</p>
<blockquote class="blockquote">
<p>Why not compose generators that combine ideas from different off-the-shelf generators?</p>
</blockquote>
<p>I want to give users an easy way to do that, without having to build custom <code>Generator</code> types from scratch. This (I think) is a good use case for metaprogramming.</p>
<p>Let‚Äôs try and see if we can make that work. We‚Äôll simply extend <code>CounterfactualExplanations</code> right here in this repo hosting the blog (easily done in Julia) and provided everything works out well create a pull request. I already have a GitHub <a href="https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl/issues/118">issue</a> for this with a linked branch, so that‚Äôs the one I‚Äôll use in my environment:</p>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb17-1">(metaprogramming) pkg<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> add https<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">://</span>github.com<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>JuliaTrustworthyAI<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>CounterfactualExplanations.jl<span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#118-add-losses-and-penalties-modules-or-group-under-objectives-module</span></span>
<span id="cb17-2">julia<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">CounterfactualExplanations</span></span></code></pre></div>
<p>By the time you‚Äôre reading this, all changes to that branch will have hopefully already been committed and merged.</p>
<p>Let‚Äôs start by instantiating a generic generator:</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb18-1">generator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">GenericGenerator</span>()</span></code></pre></div>
</div>
<p>Our goal is to create macros that build expressions that, when evaluated, mutate the <code>generator</code> instance.</p>
</section>
<section id="define-your-objective" class="level3">
<h3 class="anchored" data-anchor-id="define-your-objective">Define your <code>@objective</code></h3>
<p>Our first and most important macro shall define the counterfactual search objective. In particular, the <code>@objective</code> macro should accept an expression that looks much like the right-hand-side of Equation&nbsp;1, which is essentially just a weighted sum.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/meta-programming/www/objective.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Sketch of the envisioned <code>@objective</code> macro.</figcaption>
</figure>
</div>
<p>Let‚Äôs start with that part. Naively, we could begin by writing it out very literally:</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb19-1">ex <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(yloss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> Œª<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>cost)</span>
<span id="cb19-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eval</span>(ex)</span></code></pre></div>
<p>Of course, evaluating this expression throws an error because none of the variables are actually defined. Let‚Äôs work on that ‚Ä¶</p>
<p>For the loss and penalty functions, we will use methods available from the <code>CounterfactualExplanations.Objectives</code> module, while for <img src="https://latex.codecogs.com/png.latex?%5Clambda"> we will use a literal:</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb20-1">ex <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(logitbinarycrossentropy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> distance_l2)</span></code></pre></div>
</div>
<p>Let‚Äôs try to make sense of the data structure we have created:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb21-1">ex.args</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>3-element Vector{Any}:
 :+
 :logitbinarycrossentropy
 :(0.1distance_l2)</code></pre>
</div>
</div>
<p>My first naive approach is shown below. It errors because I forgot to interpolate the variables inside the <code>quote</code>.</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb23-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">macro</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">objective</span>(generator, ex)</span>
<span id="cb23-2">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb23-3">    ex_penalty <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]</span>
<span id="cb23-4">    Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex_penalty.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb23-5">    cost <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex_penalty.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]</span>
<span id="cb23-6">    ex_generator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">quote</span> </span>
<span id="cb23-7">        generator.loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> loss</span>
<span id="cb23-8">        generator.cost <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cost</span>
<span id="cb23-9">        generator.Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Œª</span>
<span id="cb23-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb23-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> ex_generator</span>
<span id="cb23-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
<p>Having fixed that below, I still get an error because <code>loss</code> and <code>cost</code> functions are not part of the global scope. I am pretty sure that this error would have occurred anyway and has nothing to do with the fact that I‚Äôm writing a macro.</p>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb24-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">macro</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">objective</span>(generator, ex)</span>
<span id="cb24-2">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb24-3">    ex_penalty <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]</span>
<span id="cb24-4">    Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex_penalty.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb24-5">    cost <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex_penalty.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]</span>
<span id="cb24-6">    ex_generator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">quote</span> </span>
<span id="cb24-7">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>generator.loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>loss</span>
<span id="cb24-8">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>generator.cost <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>cost</span>
<span id="cb24-9">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>generator.Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>Œª</span>
<span id="cb24-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb24-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> ex_generator</span>
<span id="cb24-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
<p>Instead of importing the functions, I just get them explicitly from the <code>Objectives</code> module,</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb25-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">macro</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">objective</span>(generator, ex)</span>
<span id="cb25-2">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getfield</span>(CounterfactualExplanations.Objectives, ex.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb25-3">    ex_penalty <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]</span>
<span id="cb25-4">    Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex_penalty.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb25-5">    cost <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getfield</span>(CounterfactualExplanations.Objectives, ex_penalty.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb25-6">    ex_generator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">quote</span> </span>
<span id="cb25-7">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>generator.loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>loss</span>
<span id="cb25-8">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>generator.penalty <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>cost</span>
<span id="cb25-9">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>generator.Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>Œª</span>
<span id="cb25-10">        generator</span>
<span id="cb25-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb25-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> ex_generator</span>
<span id="cb25-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
</div>
<p>and, finally, this works:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb26-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@objective</span>(generator, logitbinarycrossentropy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>distance_l2)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>Generator(Flux.Losses.logitbinarycrossentropy, CounterfactualExplanations.Objectives.distance_l2, 0.1, false, Flux.Optimise.Descent(0.1))</code></pre>
</div>
</div>
<p>But what about adding multiple penalties? The DiCE generator, for example, also takes into account how diverse the counterfactual explanations are <span class="citation" data-cites="mothilal2020explaining">(Mothilal, Sharma, and Tan 2020)</span>. The corresponding penalty is called <code>ddp_diversity</code>. Let‚Äôs start with the expression again:</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb28-1">ex <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(logitbinarycrossentropy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>distance_l2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>ddp_diversity)</span>
<span id="cb28-2">ex.args</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>4-element Vector{Any}:
 :+
 :logitbinarycrossentropy
 :(0.1distance_l2)
 :(1.0ddp_diversity)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="cell-output cell-output-display" data-execution_count="43">
<p>This time there‚Äôs a second nested <code>Expr</code>ession among the arguments: <code>:(1.0ddp_diversity)</code>.</p>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb30-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">macro</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">objective</span>(generator, ex)</span>
<span id="cb30-2">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getfield</span>(CounterfactualExplanations.Objectives, ex.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb30-3">    Œõ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Vector</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">{AbstractFloat}</span>()</span>
<span id="cb30-4">    costs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Vector</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">{Function}</span>()</span>
<span id="cb30-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">length</span>(ex.args)</span>
<span id="cb30-6">        ex_penalty <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex.args[i]</span>
<span id="cb30-7">        Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ex_penalty.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb30-8">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">push!</span>(Œõ, Œª)</span>
<span id="cb30-9">        cost <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">getfield</span>(CounterfactualExplanations.Objectives, ex_penalty.args[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb30-10">        <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">push!</span>(costs, cost)</span>
<span id="cb30-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb30-12">    ex_generator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">quote</span> </span>
<span id="cb30-13">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>generator.loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>loss</span>
<span id="cb30-14">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>generator.penalty <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>costs</span>
<span id="cb30-15">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>generator.Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>Œõ</span>
<span id="cb30-16">        generator</span>
<span id="cb30-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb30-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> ex_generator</span>
<span id="cb30-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
</div>
<p>That works well,</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb31-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@objective</span>(generator, logitbinarycrossentropy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>distance_l2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>ddp_diversity)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>Generator(Flux.Losses.logitbinarycrossentropy, Function[CounterfactualExplanations.Objectives.distance_l2, CounterfactualExplanations.Objectives.ddp_diversity], AbstractFloat[0.05, 1.0], false, Flux.Optimise.Descent(0.1))</code></pre>
</div>
</div>
<p>but we should still make sure that this <code>generator</code> is also compatible with our package. Below we go through some of the typical workflows associated with Counterfactual Explanations. Firstly, we load some synthetic data and fit a black-box model to it.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb33-1">n_dim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb33-2">n_classes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb33-3">n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span></span>
<span id="cb33-4">model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>MLP</span>
<span id="cb33-5">counterfactual_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CounterfactualExplanations.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">load_blobs</span>(n_samples; k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_dim, centers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_classes)</span>
<span id="cb33-6">M <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit_model</span>(counterfactual_data, model_name)</span>
<span id="cb33-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(M, counterfactual_data)</span></code></pre></div>
</div>
<p>Next, we begin by specifying our target and factual label. We then draw a random sample from the non-target (factual) class.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Factual and target:</span></span>
<span id="cb34-2">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb34-3">factual <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb34-4">chosen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rand</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">findall</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict_label</span>(M, counterfactual_data) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.==</span> factual))</span>
<span id="cb34-5">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select_factual</span>(counterfactual_data,chosen)</span></code></pre></div>
</div>
<p>Finally, we use our <code>generator</code> to generate counterfactuals:</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb35-1">ce <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">generate_counterfactual</span>(</span>
<span id="cb35-2">    x, target, counterfactual_data, M, generator;</span>
<span id="cb35-3">    num_counterfactuals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,</span>
<span id="cb35-4">    converge_when <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>generator_conditions</span>
<span id="cb35-5">)</span></code></pre></div>
</div>
<p>It worked! üéâ The resulting counterfactual search is illustrated in Figure&nbsp;2. I may have overspecified the size of the <code>ddp_diversity</code> penalty a little bit here, but it sure makes for a cool chart!</p>
<div class="cell" data-execution_count="23">
<div class="cell-output cell-output-display" data-execution_count="49">
<div id="fig-search" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/meta-programming/index_files/figure-html/fig-search-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Counterfactual search using our composed generator.</figcaption>
</figure>
</div>
</div>
</div>
<p>Time for me to add this all to <a href="https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl"><code>CounterfactualExplanations.jl</code></a> ‚Ä¶ ‚è≥</p>
</section>
</section>
<section id="hygiene" class="level2">
<h2 class="anchored" data-anchor-id="hygiene">üßº Hygiene</h2>
<p>‚Ä¶ aaand I‚Äôm back. There was one thing I had ignored that ended up causing a minor complication: macro <a href="https://docs.julialang.org/en/v1.8/manual/metaprogramming/#Hygiene">hygiene</a>.</p>
<p>Again, I‚Äôll leave it to you to read up on the details, but the bottom line is that when writing macros, we need to keep variable scopes in mind. <a href="https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl"><code>CounterfactualExplanations.jl</code></a> is composed of various (sub)modules, and when I initially added the macro to the <code>CounterfactualExplanations.Generators</code> module, it errored.</p>
<p>The problem was (I believe) that the <code>generator</code> variable existed in the global scope (<code>Main</code>) but it was not accessible for the <code>@objective</code> macro that at runtime lives in <code>Main.Generators</code>. Fortunately, it is easy to make the variable accessible by wrapping it inside an <code>esc()</code> call:</p>
<blockquote class="blockquote">
<p>This escaping mechanism can be used to ‚Äúviolate‚Äù hygiene when necessary, in order to introduce or manipulate user variables.</p>
</blockquote>
<p>This may not be the ideal way to do this, and as always, if you have any suggestions I‚Äôd be happy to hear about them.</p>
<p>If you want to find out more about how macros can now be used to easily compose counterfactual generators, check out the new section in the package <a href="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/v0.1/tutorials/generators/">documentation</a>.</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">üåØ Wrapping Up</h2>
<p>In this blog post, I‚Äôve done something I usually try to avoid: talk about things I don‚Äôt know. Metaprogramming is an exciting topic and if you‚Äôre still here, you just got to experience it through the lens of an absolute novice. During our leap of faith into Julia‚Äôs metaverse we‚Äôve learned the following things:</p>
<ol type="1">
<li>Code in Julia is internally represented as a mutable data structure.</li>
<li>Macros are a way to take such data structures and transform them before they get evaluated at runtime.</li>
<li>An important thing to keep in mind when writing macros is variable scopes.</li>
</ol>
<p>Throughout this post, I have skipped various important details that (I think) were not immediately relevant to the goal I had in mind: adding my first macro to <a href="https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl"><code>CounterfactualExplanations.jl</code></a>. In the future, I may write about this topic again and cover some of these missing details (hopefully with a bit more insight at that point!).</p>
</section>
<section id="references" class="level2">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">üéì References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-altmeyer2023endogenous" class="csl-entry">
Altmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia Liem. 2023. <span>‚ÄúEndogenous <span>Macrodynamics</span> in <span>Algorithmic</span> <span>Recourse</span>.‚Äù</span> In <em>First <span>IEEE</span> <span>Conference</span> on <span>Secure</span> and <span>Trustworthy</span> <span>Machine</span> <span>Learning</span></em>.
</div>
<div id="ref-mothilal2020explaining" class="csl-entry">
Mothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. <span>‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù</span> In <em>Proceedings of the 2020 <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 607‚Äì17.
</div>
</div></section><aside id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>A very cool package! Funny story, though, I somehow managed to commit my OpenAI API key to GitHub on the first go (<a href="https://github.com/ThatcherC/ReplGPT.jl/issues/8">developing</a>)‚Ü©Ô∏é</p></li>
</ol>
</aside><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2023,
  author = {Altmeyer, Patrick},
  title = {A {Leap} of {Faith} into {Julia‚Äôs} {Metaverse}},
  date = {2023-03-13},
  url = {https://www.paltmeyer.com/blog//blog/posts/meta-programming},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2023" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2023. <span>‚ÄúA Leap of Faith into Julia‚Äôs
Metaverse.‚Äù</span> March 13, 2023. <a href="https://www.paltmeyer.com/blog//blog/posts/meta-programming">https://www.paltmeyer.com/blog//blog/posts/meta-programming</a>.
</div></div></section></div> ]]></description>
  <category>metaprogramming</category>
  <category>macros</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/meta-programming/index.html</guid>
  <pubDate>Mon, 13 Mar 2023 04:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/meta-programming/www/intro.png" medium="image" type="image/png" height="141" width="144"/>
</item>
<item>
  <title>Quarto on Steroids: Advanced Customization through Quarto Extensions</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/quarto-extensions/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/quarto-extensions/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
A TU Delft Theme for Quarto.
</figcaption>
</figure>
</div>
<p>I‚Äôve said it before and I‚Äôll say it again: <a href="https://quarto.org/">Quarto</a> is amazing! Since the beginning of my PhD I haven‚Äôt used any other tool for prototyping, writing and publishing any of my work.<sup>1</sup> That work has included: this website, presentations, academic articles, notebooks and more. By highlighting useful features of Quarto in articles like this one, I hope to encourage more people to try it out.</p>
<p>While I‚Äôm convinced that Quarto can be useful in almost any context including industry, I realize that certain obstacles may have so far prevented some of you from using it. One such obstacle concerns custom formats: the standard Quarto formats for HTML, PDF, Revealjs, etc. are slick but minimalistic. For many formats, there are various themes to choose from, but they too lack personal touch (or corporate identity in the industry setting).</p>
<p>At first sight, traditional publishing tools like MS Office seem to have an edge here: customization is made easy through GUIs and standardization through templates is possible to a certain degree. I understand the appeal but still would encourage you to look beyond MS Word, Powerpoint and Beamer presentations. To this end, I‚Äôve put together this short tutorial that explains how I have built and contributed a <a href="https://github.com/pat-alt/quarto-tudelft">TU Delft theme</a> for Revealjs. If nothing else, this theme can be used by my colleagues at Delft University of Technology to create beautiful, Delft-styled presentations with ease.</p>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">üìñ Background</h2>
<p>Advanced and reproducible customization in Quarto is done through <a href="https://quarto.org/docs/extensions/">Quarto Extensions</a>:</p>
<blockquote class="blockquote">
<p>‚ÄúQuarto Extensions are a powerful way to modify or extend the behavior of Quarto, and can be created and distributed by anyone.‚Äù</p>
<p>‚Äî Quarto team</p>
</blockquote>
<p>Users can already utilize several open-sourced extensions that add <a href="https://quarto.org/docs/extensions/listing-filters.html">filters</a>, <a href="https://quarto.org/docs/extensions/listing-journals.html">journal article formats</a> and other <a href="https://quarto.org/docs/extensions/listing-formats.html">custom formats</a>. As we will see, it is very straightforward to contribute extensions, so the list of available extensions is growing quickly.</p>
</section>
<section id="contributing-quarto-extensions" class="level2">
<h2 class="anchored" data-anchor-id="contributing-quarto-extensions">ü´¥ Contributing Quarto Extensions</h2>
<p>Normally, I would start by explaining how to use Quarto Extensions, but in this particular case the user and developer experience is so close that I‚Äôll jump straight into development.</p>
<section id="setup" class="level3">
<h3 class="anchored" data-anchor-id="setup">Setup</h3>
<p>To get started with building the TU Delft Custom Format I followed the official <a href="https://quarto.org/docs/extensions/formats.html#quick-start">Quarto docs</a>. I first used the appropriate Quarto command, which initiates an interactive process in the command line:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">$</span> quarto create extension format:revealjs</span>
<span id="cb1-2"> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">?</span> Extension Name ‚Ä∫ lexdoc</span></code></pre></div>
<p>Once done, the basic folder structure for my extension was set up and ready to be pushed to a remote Github repository for distribution: <a href="https://github.com/pat-alt/quarto-tudelft">https://github.com/pat-alt/quarto-tudelft</a>. Even though I had not yet added any custom formatting rules, anyone would now be able to use this empty extension for their work.</p>
</section>
<section id="adding-rules" class="level3">
<h3 class="anchored" data-anchor-id="adding-rules">Adding Rules</h3>
<p>To actually add some custom formatting rules to the extension I started working on the files contained in <code>_extensions/tudelft/</code>. Using my institution‚Äôs PowerPoint template as a reference, I previewed the <code>template.qmd</code> file and simply made appropriate adjustments to the <a href="https://github.com/pat-alt/quarto-tudelft/blob/main/_extensions/tudelft/custom.scss"><code>_extensions/tudelft/custom.scss</code></a> and <a href="https://github.com/pat-alt/quarto-tudelft/blob/main/_extensions/tudelft/_extension.yml"><code>_extensions/tudelft/_extension.yml</code></a> files until I was satisfied. To help me in that process, I took inspiration from various existing Revealjs extensions all listed in the <a href="https://github.com/mcanouil/awesome-quarto#presentations">awesome-quarto</a> repository.</p>
<p>I am no expert in CSS (far from it!), so this was very much trial-and-error based, but I got there eventually. One feature I am particularly happy about is the custom transition slides: by default all slides at level 1, so slides that initiate a new section,</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode md code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;"># Transition Slide</span></span></code></pre></div>
<p>will be formatted in a standardized way. The relevant CSS rule can be found <a href="https://github.com/pat-alt/quarto-tudelft/blob/b324cee4a6860a5ed5385dc607330d49de052875/_extensions/tudelft/custom.scss#L96">here</a></p>
</section>
<section id="adding-assets" class="level3">
<h3 class="anchored" data-anchor-id="adding-assets">Adding Assets</h3>
<p>The Reavealjs template also includes a few images, which I have lifted from my institution‚Äôs PowerPoint template. To make sure that these images are also available locally when users install the template, any resources need to be stored inside the theme directory <code>_extensions/tudelft/</code>. I have had some issues pointing to the right location of these images in the <a href="https://github.com/pat-alt/quarto-tudelft/blob/main/_extensions/tudelft/custom.scss">_extensions/tudelft/custom.scss</a> and <a href="https://github.com/pat-alt/quarto-tudelft/blob/main/_extensions/tudelft/_extension.yml">_extensions/tudelft/_extension.yml</a> file. At the time of writing this, the image URLs are pointing to their remote location on Github (see <a href="https://github.com/pat-alt/quarto-tudelft/blob/b324cee4a6860a5ed5385dc607330d49de052875/_extensions/tudelft/custom.scss#L12">here</a>). This works, but probably isn‚Äôt ideal, so any suggestions are welcome.</p>
</section>
</section>
<section id="example-presentation---using-quarto-extensions" class="level2">
<h2 class="anchored" data-anchor-id="example-presentation---using-quarto-extensions">üìã Example Presentation - Using Quarto Extensions</h2>
<p>In February, 2023, I will present a research paper on Algorithmic Recourse at the first IEEE Conference on Secure and Trustworthy Machine Learning: <a href="https://satml.org/">SaTML 2023</a>. This was a good incentive for me to build a TU Delft Theme once for this occasion and then be able to reuse it again in the future.</p>
<blockquote class="blockquote">
<p>With the template built and distributed, how do you actually use it?</p>
</blockquote>
<p>This part is truly a walk in the park. As outlined in the <a href="https://github.com/pat-alt/quarto-tudelft">README</a> users can either work directly with the template,</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">quarto</span> use template pat-alt/quarto-tudelft</span></code></pre></div>
<p>or add the template to an existing Quarto project:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode zsh code-with-copy"><code class="sourceCode zsh"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">quarto</span> add pat-alt/quarto-tudelft</span></code></pre></div>
<p>The first option will get you started with a working document straight away. For my paper presentation, I worked with the second option. At the time of writing, I am building and hosting all of my presentations in my website repository (the repo that also builds this very article you‚Äôre reading): <a href="https://github.com/pat-alt/pat-alt.github.io">https://github.com/pat-alt/pat-alt.github.io</a>.</p>
<p>With the extension added to the project, I can now use it anywhere within that project by simply specifying,</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb5-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> tudelft-revealjs</span></span></code></pre></div>
<p>in the YAML header of my Quarto document where <code>tudelft-revealjs</code> is just the name of the custom format.</p>
<p>It gets better ‚Ä¶ The extension can be extended further by providing yet another <a href="https://github.com/pat-alt/pat-alt.github.io/blob/b6207a616f6ef9c7ec09cf8ad3383db788b9148b/content/talks/posts/2023-ieee-satml/custom.scss#L1">custom style sheet</a>, as I have done for my paper presentation:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span></span>
<span id="cb6-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tudelft-revealjs</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb6-3"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> custom.scss</span></span></code></pre></div>
<p>Check out the final presentation <a href="../../../content/talks/posts/2023-ieee-satml/presentation.html" target="_blank">here</a> or see the embedded version below:</p>
<iframe src="https://www.paltmeyer.com/content/talks/posts/2023-ieee-satml/presentation.html#/title-slide" width="100%" height="350">
</iframe>


</section>


<div id="quarto-appendix" class="default"><aside id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Not entirely true: I‚Äôve also used <code>Pluto.jl</code> üéà and had to resort to <code>.Rmd</code> in one particular case.‚Ü©Ô∏é</p></li>
</ol>
</aside><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2023,
  author = {Altmeyer, Patrick},
  title = {Quarto on {Steroids:} {Advanced} {Customization} Through
    {Quarto} {Extensions}},
  date = {2023-01-16},
  url = {https://www.paltmeyer.com/blog//blog/posts/quarto-extensions},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2023" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2023. <span>‚ÄúQuarto on Steroids: Advanced
Customization Through Quarto Extensions.‚Äù</span> January 16, 2023. <a href="https://www.paltmeyer.com/blog//blog/posts/quarto-extensions">https://www.paltmeyer.com/blog//blog/posts/quarto-extensions</a>.
</div></div></section></div> ]]></description>
  <category>Quarto</category>
  <category>reproducibility</category>
  <category>open-source</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/quarto-extensions/index.html</guid>
  <pubDate>Mon, 16 Jan 2023 05:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/quarto-extensions/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Prediction Intervals for any Regression Model</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Conformal Prediction intervals for different<br>coverage rates. As coverage grows, so does<br>the width of the prediction interval.
</figcaption>
</figure>
</div>
<p>This is the third (and for now final) part of a series of posts that introduce Conformal Prediction in Julia using <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>. The first <a href="../../../blog/posts/conformal-prediction/index.html">post</a> introduced Conformal Prediction for supervised classification tasks: we learned that conformal classifiers produce set-valued predictions that are guaranteed to include the true label of a new sample with a certain probability. In the second <a href="../conformal-image-classifier/">post</a> we applied these ideas to a more hands-on example: we saw how easy it is to use <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> to conformalize a Deep Learning image classifier.</p>
<p>In this post, we will look at regression models instead, that is supervised learning tasks involving a continuous outcome variable. Regression tasks are as ubiquitous as classification tasks. For example, we might be interested in using a machine learning model to predict house prices or the inflation rate of the Euro or the parameter size of the next large language model. In fact, many readers may be more familiar with regression models than classification, in which case it may also be easier for you to understand Conformal Prediction (CP) in this context.</p>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">üìñ Background</h2>
<p>Before we start, let‚Äôs briefly recap what CP is all about. Don‚Äôt worry, we‚Äôre not about to deep-dive into methodology. But just to give you a high-level description upfront:</p>
<blockquote class="blockquote">
<p>Conformal prediction (a.k.a. conformal inference) is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions.</p>
<p>‚Äî <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span> (<a href="https://arxiv.org/pdf/2107.07511.pdf">arXiv</a>)</p>
</blockquote>
<p>Intuitively, CP works under the premise of turning heuristic notions of uncertainty into rigorous uncertainty estimates through repeated sampling or the use of dedicated calibration data.</p>
<p>In what follows we will explore what CP can do by going through a standard machine learning workflow using <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ.jl</code></a> and <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>. There will be less focus on how exactly CP works, but references will point you to additional resources.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interactive Version
</div>
</div>
<div class="callout-body-container callout-body">
<p>This post is also available as a fully interactive <a href="https://github.com/fonsp/Pluto.jl"><code>Pluto.jl</code></a> üéà notebook hosted on <a href="https://mybinder.org/">binder</a>: <a href="https://binder.plutojl.org/v0.19.12/open?url=https%253A%252F%252Fraw.githubusercontent.com%252Fpat-alt%252FConformalPrediction.jl%252Fmain%252Fdocs%252Fpluto%252Fintro.jl" target="_blank"><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/https:/mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder"></a></p>
<p>In my own experience, this may take some time to load, certainly long enough to get yourself a hot beverage ‚òï or first read on here. But I promise you that the wait is worth it!</p>
</div>
</div>
</section>
<section id="data" class="level2">
<h2 class="anchored" data-anchor-id="data">üìà Data</h2>
<p>Most machine learning workflows start with data. For illustrative purposes we will work with synthetic data. The helper function below can be used to generate some regression data.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">get_data</span>(;N<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, xmax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.0</span>, noise<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, fun<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Function</span>=<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fun</span>(X) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sin</span>(X))</span>
<span id="cb1-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Inputs:</span></span>
<span id="cb1-3">    d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Distributions.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Uniform</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>xmax, xmax)</span>
<span id="cb1-4">    X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rand</span>(d, N)</span>
<span id="cb1-5">    X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">table</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">reshape</span>(X, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb1-6"></span>
<span id="cb1-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Outputs:</span></span>
<span id="cb1-8">    Œµ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">randn</span>(N) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.*</span> noise</span>
<span id="cb1-9">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> @.(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fun</span>(X.x1)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> Œµ</span>
<span id="cb1-10">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">vec</span>(y)</span>
<span id="cb1-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> X, y</span>
<span id="cb1-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
</div>
<p>Figure&nbsp;1 illustrates our observations (dots) along with the ground-truth mapping from inputs to outputs (line). We have defined that mapping <img src="https://latex.codecogs.com/png.latex?f:%20%5Cmathcal%7BX%7D%20%5Cmapsto%20%5Cmathcal%7BY%7D"> as follows:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">f</span>(X) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cos</span>(X)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-display" data-execution_count="5">
<div id="fig-data" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index_files/figure-html/fig-data-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Some synthetic regression data. Observations are shown as dots. The ground-truth mapping from inputs to outputs is shown as a dashed line.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="model-training-using-mlj" class="level2">
<h2 class="anchored" data-anchor-id="model-training-using-mlj">üèãÔ∏è Model Training using <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ</code></a></h2>
<p><a href="(https://github.com/juliatrustworthyai/ConformalPrediction.jl)"><code>ConformalPrediction.jl</code></a> is interfaced to <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ.jl</code></a> <span class="citation" data-cites="blaom2020mlj">(Blaom et al. 2020)</span>: a comprehensive Machine Learning Framework for Julia. <code>MLJ.jl</code> provides a large and growing suite of popular machine learning models that can be used for supervised and unsupervised tasks. Conformal Prediction is a model-agnostic approach to uncertainty quantification, so it can be applied to any common supervised machine learning model.</p>
<p>The interface to <code>MLJ.jl</code> therefore seems natural: any (supervised) <code>MLJ.jl</code> model can now be conformalized using <code>ConformalPrediction.jl</code>. By leveraging existing <code>MLJ.jl</code> functionality for common tasks like training, prediction and model evaluation, this package is light-weight and scalable. Now let‚Äôs see how all of that works ‚Ä¶</p>
<p>To start with, let‚Äôs split our data into a training and test set:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1">train, test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">partition</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eachindex</span>(y), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">true</span>)</span></code></pre></div>
</div>
<p>Now let‚Äôs define a model for our regression task:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1">Model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@load</span> KNNRegressor pkg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> NearestNeighborModels</span>
<span id="cb4-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Model</span>()</span></code></pre></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Have it your way!
</div>
</div>
<div class="callout-body-container callout-body">
<p>Think this dataset is too simple? Wondering why on earth I‚Äôm not using XGBoost for this task? In the interactive <a href="https://binder.plutojl.org/v0.19.12/open?url=https%253A%252F%252Fraw.githubusercontent.com%252Fpat-alt%252FConformalPrediction.jl%252Fmain%252Fdocs%252Fpluto%252Fintro.jl" target="_blank">version</a> of this post you have full control over the data and the model. Try it out!</p>
</div>
</div>
<p>Using standard <code>MLJ.jl</code> workflows let us now first train the unconformalized model. We first wrap our model in data:</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1">mach_raw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(model, X, y)</span></code></pre></div>
</div>
<p>Then we fit the machine to the training data:</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1">MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach_raw, rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train, verbosity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
</div>
<p>Figure&nbsp;2 below shows the resulting point predictions for the test data set:</p>
<div class="cell" data-execution_count="9">
<div class="cell-output cell-output-display" data-execution_count="10">
<div id="fig-point" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index_files/figure-html/fig-point-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Point predictions for our machine learning model.</figcaption>
</figure>
</div>
</div>
</div>
<p>How is our model doing? It‚Äôs never quite right, of course, since predictions are estimates and therefore uncertain. Let‚Äôs see how we can use Conformal Prediction to express that uncertainty.</p>
</section>
<section id="conformalizing-the-model" class="level2">
<h2 class="anchored" data-anchor-id="conformalizing-the-model">üî• Conformalizing the Model</h2>
<p>We can turn our <code>model</code> into a conformalized model in just one line of code:</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1">conf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_model</span>(model)</span></code></pre></div>
</div>
<p>By default <code>conformal_model</code> creates an Inductive Conformal Regressor (more on this below) when called on a <code>&lt;:Deterministic</code> model. This behaviour can be changed by using the optional <code>method</code> key argument.</p>
<p>To train our conformal model we can once again rely on standard <code>MLJ.jl</code> workflows. We first wrap our model in data:</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(conf_model, X, y)</span></code></pre></div>
</div>
<p>Then we fit the machine to the data:</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb9-1">MLJBase.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train, verbosity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
</div>
<p>Now let us look at the predictions for our test data again. The chart below shows the results for our conformalized model. Predictions from conformal regressors are range-valued: for each new sample the model returns an interval <img src="https://latex.codecogs.com/png.latex?(y_%7B%5Ctext%7Blb%7D%7D,y_%7B%5Ctext%7Bub%7D%7D)%5Cin%5Cmathcal%7BY%7D"> that covers the test sample with a user-specified probability <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)">, where <img src="https://latex.codecogs.com/png.latex?%5Calpha"> is the expected error rate. This is known as the <strong>marginal coverage guarantee</strong> and it is proven to hold under the assumption that training and test data are exchangeable.</p>
<div class="cell" data-execution_count="13">
<div class="cell-output cell-output-display" data-execution_count="14">
<div id="fig-interval" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index_files/figure-html/fig-interval-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Prediction intervals for our conformalized machine learning model.</figcaption>
</figure>
</div>
</div>
</div>
<p>Intuitively, a higher coverage rate leads to larger prediction intervals: since a larger interval covers a larger subspace of <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BY%7D">, it is more likely to cover the true value.</p>
<p>I don‚Äôt expect you to believe me that the marginal coverage property really holds. In fact, I couldn‚Äôt believe it myself when I first learned about it. If you like mathematical proofs, you can find one in this <a href="https://arxiv.org/pdf/2107.07511.pdf">tutorial</a>, for example. If you like convincing yourself through empirical observations, read on below ‚Ä¶</p>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">üßê Evaluation</h2>
<p>To verify the marginal coverage property empirically we can look at the empirical coverage rate of our conformal predictor (see Section 3 of the <a href="https://arxiv.org/pdf/2107.07511.pdf">tutorial</a> for details). To this end our package provides a custom performance measure <code>emp_coverage</code> that is compatible with <code>MLJ.jl</code> model evaluation workflows. In particular, we will call <code>evaluate!</code> on our conformal model using <code>emp_coverage</code> as our performance metric. The resulting empirical coverage rate should then be close to the desired level of coverage.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb10-1">model_evaluation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span></span>
<span id="cb10-2">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">evaluate!</span>(_mach, operation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>MLJBase.predict, measure<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>emp_coverage, verbosity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb10-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Empirical coverage: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(model_evaluation.measurement[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], digits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb10-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Coverage per fold: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>.(model_evaluation.per_fold[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], digits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Empirical coverage: 0.902</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Coverage per fold: [0.94, 0.904, 0.874, 0.874, 0.898, 0.922]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="cell-output cell-output-display" data-execution_count="18">
<blockquote class="blockquote">
<p>‚úÖ ‚úÖ ‚úÖ Great! We got an empirical coverage rate that is slightly higher than desired üòÅ ‚Ä¶ but why isn‚Äôt it exactly the same?</p>
</blockquote>
<p>In most cases it will be slightly higher than desired, since <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)"> is a lower bound. But note that it can also be slightly lower than desired. That is because the coverage property is ‚Äúmarginal‚Äù in the sense that the probability is averaged over the randomness in the data. For most purposes a large enough calibration set size (<img src="https://latex.codecogs.com/png.latex?n%3E1000">) mitigates that randomness enough. Depending on your choices above, the calibration set may be quite small (set to 500), which can lead to <strong>coverage slack</strong> (see Section 3 in the <a href="https://arxiv.org/pdf/2107.07511.pdf">tutorial</a>).</p>
</div>
</div>
<section id="so-whats-happening-under-the-hood" class="level3">
<h3 class="anchored" data-anchor-id="so-whats-happening-under-the-hood"><em>So what‚Äôs happening under the hood?</em></h3>
<p>Inductive Conformal Prediction (also referred to as Split Conformal Prediction) broadly speaking works as follows:</p>
<ol type="1">
<li>Partition the training into a proper training set and a separate calibration set</li>
<li>Train the machine learning model on the proper training set.</li>
<li>Using some heuristic notion of uncertainty (e.g., absolute error in the regression case), compute nonconformity scores using the calibration data and the fitted model.</li>
<li>For the given coverage ratio compute the corresponding quantile of the empirical distribution of nonconformity scores.</li>
<li>For the given quantile and test sample <img src="https://latex.codecogs.com/png.latex?X_%7B%5Ctext%7Btest%7D%7D">, form the corresponding conformal prediction set like so: <img src="https://latex.codecogs.com/png.latex?C(X_%7B%5Ctext%7Btest%7D%7D)=%5C%7By:s(X_%7B%5Ctext%7Btest%7D%7D,y)%20%5Cle%20%5Chat%7Bq%7D%5C%7D"></li>
</ol>
</section>
</section>
<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">üîÉ Recap</h2>
<p>This has been a super quick tour of <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>. We have seen how the package naturally integrates with <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ.jl</code></a>, allowing users to generate rigorous predictive uncertainty estimates for any supervised machine learning model.</p>
<section id="are-we-done" class="level3">
<h3 class="anchored" data-anchor-id="are-we-done"><em>Are we done?</em></h3>
<p>Quite cool, right? Using a single API call we are able to generate rigorous prediction intervals for all kinds of different regression models. Have we just solved predictive uncertainty quantification once and for all? Do we even need to bother with anything else? Conformal Prediction is a very useful tool, but like so many other things, it is not the final answer to all our problems. In fact, let‚Äôs see if we can take CP to its limits.</p>
<p>The helper function to generate data from above takes an optional argument <code>xmax</code>. By increasing that value, we effectively expand the domain of our input. Let‚Äôs do that and see how our conformal model does on this new out-of-domain data.</p>
<div class="cell" data-execution_count="18">
<div class="cell-output cell-output-display" data-execution_count="19">
<div id="fig-ood" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index_files/figure-html/fig-ood-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Prediction intervals for our conformalized machine learning model applied to out-of-domain data.</figcaption>
</figure>
</div>
</div>
</div>
<blockquote class="blockquote">
<p>Whooooops ü§ï ‚Ä¶ looks like we‚Äôre in trouble: in Figure&nbsp;4 the prediction intervals do not cover out-of-domain test samples well. What happened here?</p>
</blockquote>
<p>By expanding the domain of out inputs, we have violated the exchangeability assumption. When that assumption is violated, the marginal coverage property does not hold. But do not despair! There are ways to deal with this.</p>
</section>
</section>
<section id="read-on" class="level2">
<h2 class="anchored" data-anchor-id="read-on">üìö Read on</h2>
<p>If you are curious to find out more, be sure to read on in the <a href="https://www.paltmeyer.com/ConformalPrediction.jl/stable/">docs</a>. There are also a number of useful resources to learn more about Conformal Prediction, a few of which I have listed below:</p>
<ul>
<li><em>A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification</em> by Angelopoulos and Bates (<a href="https://arxiv.org/pdf/2107.07511.pdf">2022</a>).</li>
<li><em>Awesome Conformal Prediction</em> repository by Manokhin (<a href="https://github.com/valeman/awesome-conformal-prediction">2022</a>)</li>
<li><strong>MAPIE</strong>: a comprehensive Python <a href="https://mapie.readthedocs.io/en/latest/index.html">library</a> for conformal prediction.</li>
<li>My previous two blog posts.</li>
</ul>
<p>Enjoy!</p>
</section>
<section id="references" class="level2">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-angelopoulos2021gentle" class="csl-entry">
Angelopoulos, Anastasios N., and Stephen Bates. 2021. <span>‚ÄúA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.‚Äù</span> <a href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>.
</div>
<div id="ref-blaom2020mlj" class="csl-entry">
Blaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. <span>‚Äú<span>MLJ</span>: <span>A Julia</span> Package for Composable Machine Learning.‚Äù</span> <em>Journal of Open Source Software</em> 5 (55): 2704. <a href="https://doi.org/10.21105/joss.02704">https://doi.org/10.21105/joss.02704</a>.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {Prediction {Intervals} for Any {Regression} {Model}},
  date = {2022-12-12},
  url = {https://www.paltmeyer.com/blog//blog/posts/conformal-regression},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2022. <span>‚ÄúPrediction Intervals for Any Regression
Model.‚Äù</span> December 12, 2022. <a href="https://www.paltmeyer.com/blog//blog/posts/conformal-regression">https://www.paltmeyer.com/blog//blog/posts/conformal-regression</a>.
</div></div></section></div> ]]></description>
  <category>probabilistic programming</category>
  <category>uncertainty</category>
  <category>conformal prediction</category>
  <category>regression</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/conformal-regression/index.html</guid>
  <pubDate>Mon, 12 Dec 2022 05:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/conformal-regression/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>How to Conformalize a Deep Image Classifier</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Conformalized prediction sets for a<br>simple Deep Image Classifier.
</figcaption>
</figure>
</div>
<p>Deep Learning is popular and ‚Äî for some tasks like image classification ‚Äî remarkably powerful. But it is also well-known that Deep Neural Networks (DNN) can be unstable <span class="citation" data-cites="goodfellow2014explaining">(Goodfellow, Shlens, and Szegedy 2014)</span> and poorly calibrated. Conformal Prediction can be used to mitigate these pitfalls.</p>
<p>In the <a href="../../../blog/posts/conformal-prediction/index.html">first part</a> of this series of posts on Conformal Prediction, we looked at the basic underlying methodology and how CP can be implemented in Julia using <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>. This second part of the series is a more goal-oriented how-to guide: it demonstrates how you can conformalize a deep learning image classifier built in <code>Flux.jl</code> in just a few lines of code.</p>
<p>Since this is meant to be more of a hands-on article, we will avoid diving too deeply into methodological concepts. If you need more colour on this, be sure to check out the <a href="../../../blog/posts/conformal-prediction/index.html">first article</a> on this topic and also <span class="citation" data-cites="angelopoulos2021gentle">A. N. Angelopoulos and Bates (2021)</span>. For a more formal treatment of Conformal Prediction see also <span class="citation" data-cites="angelopoulos2022uncertainty">A. Angelopoulos et al. (2022)</span>.</p>
<section id="the-task-at-hand" class="level2">
<h2 class="anchored" data-anchor-id="the-task-at-hand">üéØ The Task at Hand</h2>
<p>The task at hand is to predict the labels of handwritten images of digits using the famous MNIST dataset <span class="citation" data-cites="lecun1998mnist">(LeCun 1998)</span>. Importing this popular machine learning dataset in Julia is made remarkably easy through <code>MLDatasets.jl</code>:</p>
<div id="bd034eae" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">MLDatasets</span></span>
<span id="cb1-2">N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb1-3">Xraw, yraw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">MNIST</span>(split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>train)[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>]</span>
<span id="cb1-4">Xraw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Xraw[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>N]</span>
<span id="cb1-5">yraw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> yraw[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>N]</span></code></pre></div>
</div>
<p>Figure&nbsp;1 below shows a few random samples from the training data:</p>
<div id="cell-fig-samples" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">MLJ</span></span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Images</span></span>
<span id="cb2-3">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">map</span>(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">convert2image</span>(MNIST, x), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eachslice</span>(Xraw, dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb2-4">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">coerce</span>(yraw, Multiclass)</span>
<span id="cb2-5"></span>
<span id="cb2-6">n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb2-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mosaic</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rand</span>(X, n_samples)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>, ncol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_samples)</span></code></pre></div>
<div id="fig-samples" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/data:image/png;base64,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" class="figure-img">
<figcaption class="figure-caption">Figure&nbsp;1: Random samples from the MNIST dataset.</figcaption>
</figure>
</div>
</div>
</section>
<section id="building-the-network" class="level2">
<h2 class="anchored" data-anchor-id="building-the-network">üöß Building the Network</h2>
<p>To model the mapping from image inputs to labels will rely on a simple Multi-Layer Perceptron (MLP). A great Julia library for Deep Learning is <code>Flux.jl</code>. But wait ‚Ä¶ doesn‚Äôt <code>ConformalPrediction.jl</code> work with models trained in <code>MLJ.jl</code>? That‚Äôs right, but fortunately there exists a <code>Flux.jl</code> interface to <code>MLJ.jl</code>, namely <code>MLJFlux.jl</code>. The interface is still in its early stages, but already very powerful and easily accessible for anyone (like myself) who is used to building Neural Networks in <code>Flux.jl</code>.</p>
<p>In <code>Flux.jl</code>, you could build an MLP for this task as follows,</p>
<div id="54a23c26" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Flux</span></span>
<span id="cb3-2"></span>
<span id="cb3-3">mlp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Chain</span>(</span>
<span id="cb3-4">    Flux.flatten,</span>
<span id="cb3-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Dense</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">prod</span>((<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>)), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, relu),</span>
<span id="cb3-6">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Dense</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb3-7">)</span></code></pre></div>
</div>
<p>where <code>(28,28)</code> is just the input dimension (28x28 pixel images). Since we have ten digits, our output dimension is ten.<sup>1</sup></p>
<p>We can do the exact same thing in <code>MLJFlux.jl</code> as follows,</p>
<div id="d8c0328d" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">MLJFlux</span></span>
<span id="cb4-2"></span>
<span id="cb4-3">builder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MLJFlux.<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@builder</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Chain</span>(</span>
<span id="cb4-4">    Flux.flatten,</span>
<span id="cb4-5">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Dense</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">prod</span>(n_in), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, relu),</span>
<span id="cb4-6">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Dense</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, n_out)</span>
<span id="cb4-7">)</span></code></pre></div>
</div>
<p>where here we rely on the <code>@builder</code> macro to make the transition from <code>Flux.jl</code> to <code>MLJ.jl</code> as seamless as possible. Finally, <code>MLJFlux.jl</code> already comes with a number of helper functions to define plain-vanilla networks. In this case, we will use the <code>ImageClassifier</code> with our custom builder and cross-entropy loss:</p>
<div id="f86f7202" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1">ImageClassifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@load</span> ImageClassifier</span>
<span id="cb5-2">clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ImageClassifier</span>(</span>
<span id="cb5-3">    builder<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>builder,</span>
<span id="cb5-4">    epochs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,</span>
<span id="cb5-5">    loss<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Flux.crossentropy</span>
<span id="cb5-6">)</span></code></pre></div>
</div>
<p>The generated instance <code>clf</code> is a model (in the <code>MLJ.jl</code> sense) so from this point on we can rely on standard <code>MLJ.jl</code> workflows. For example, we can wrap our model in data to create a machine and then evaluate it on a holdout set as follows:</p>
<div id="dde6d57d" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(clf, X, y)</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">evaluate!</span>(</span>
<span id="cb6-4">    mach,</span>
<span id="cb6-5">    resampling<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Holdout</span>(rng<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>, fraction_train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>),</span>
<span id="cb6-6">    operation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>predict_mode,</span>
<span id="cb6-7">    measure<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[accuracy]</span>
<span id="cb6-8">)</span></code></pre></div>
</div>
<p>The accuracy of our very simple model is not amazing, but good enough for the purpose of this tutorial. For each image, our MLP returns a softmax output for each possible digit: 0,1,2,3,‚Ä¶,9. Since each individual softmax output is valued between zero and one, <img src="https://latex.codecogs.com/png.latex?y_k%5Cin(0,1)">, this is commonly interpreted as a probability: <img src="https://latex.codecogs.com/png.latex?y_k%20%5Ccoloneqq%20p(y=k%7CX)">. Edge cases ‚Äì that is values close to either zero or one ‚Äì indicate high predictive certainty. But this is only a heuristic notion of predictive uncertainty <span class="citation" data-cites="angelopoulos2021gentle">(A. N. Angelopoulos and Bates 2021)</span>. Next, we will turn this heuristic notion of uncertainty into a rigorous one using Conformal Prediction.</p>
</section>
<section id="conformalizing-the-network" class="level2">
<h2 class="anchored" data-anchor-id="conformalizing-the-network">üî• Conformalizing the Network</h2>
<p>Since <code>clf</code> is a model, it is also compatible with our package: <code>ConformalPrediction.jl</code>. To conformalize our MLP, we therefore only need to call <code>conformal_model(clf)</code>. Since the generated instance <code>conf_model</code> is also just a model, we can still rely on standard <code>MLJ.jl</code> workflows. Below we first wrap it in data and then fit it. Aaaand ‚Ä¶ we‚Äôre done! Let‚Äôs look at the results in the next section.</p>
<div id="d2083aac" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">ConformalPrediction</span></span>
<span id="cb7-2">conf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_model</span>(clf; method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>simple_inductive, coverage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.95</span>)</span>
<span id="cb7-3">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(conf_model, X, y)</span>
<span id="cb7-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach)</span></code></pre></div>
</div>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">üìä Results</h2>
<p>Figure&nbsp;2 below presents the results. Figure&nbsp;2 (a) displays highly certain predictions, now defined in the rigorous sense of Conformal Prediction: in each case, the conformal set (just beneath the image) includes only one label.</p>
<p>Figure&nbsp;2 (b) and Figure&nbsp;2 (c) display increasingly uncertain predictions of set size two and three, respectively. They demonstrate that CP is well equipped to deal with samples characterized by high aleatoric uncertainty: digits four (4), seven (7) and nine (9) share certain similarities. So do digits five (5) and six (6) as well as three (3) and eight (8). These may be hard to distinguish from each other even after seeing many examples (and even for a human). It is therefore unsurprising to see that these digits often end up together in conformal sets.</p>
<div id="fig-plots" class="cell quarto-layout-panel" data-execution_count="10">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="fig-plots-1" class="quarto-figure quarto-figure-center anchored" style="flex-basis: 100.0%;justify-content: center;">
<figure class="figure">
<!--?xml version="1.0" encoding="utf-8"?-->
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" width="900" height="300" viewbox="0 0 3600 1200">
<defs>
  <clippath id="clip120">
    <rect x="0" y="0" width="3600" height="1200"></rect>
  </clippath>
</defs>
<path clip-path="url(#clip120)" d="M0 1200 L3600 1200 L3600 0 L0 0  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip121">
    <rect x="720" y="0" width="2521" height="1200"></rect>
  </clippath>
</defs>
<path clip-path="url(#clip120)" d="M47.2441 1011.02 L1152.76 1011.02 L1152.76 47.2441 L47.2441 47.2441  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip122">
    <rect x="47" y="47" width="1107" height="965"></rect>
  </clippath>
</defs>
<g clip-path="url(#clip122)">
<image width="964" height="964" href="data:image/png;base64,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" transform="translate(118, 47)"></image>
</g>
<path clip-path="url(#clip120)" d="M349.949 1031.2 L349.949 1039.21 Q346.113 1035.64 341.749 1033.87 Q337.423 1032.1 332.533 1032.1 Q322.904 1032.1 317.788 1038.01 Q312.672 1043.88 312.672 1055.01 Q312.672 1066.11 317.788 1072.01 Q322.904 1077.88 332.533 1077.88 Q337.423 1077.88 341.749 1076.11 Q346.113 1074.35 349.949 1070.77 L349.949 1078.71 Q345.962 1081.42 341.486 1082.77 Q337.047 1084.13 332.082 1084.13 Q319.33 1084.13 311.995 1076.34 Q304.66 1068.52 304.66 1055.01 Q304.66 1041.47 311.995 1033.68 Q319.33 1025.86 332.082 1025.86 Q337.123 1025.86 341.561 1027.21 Q346.037 1028.53 349.949 1031.2 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M362.287 1048.05 L410.51 1048.05 L410.51 1054.37 L362.287 1054.37 L362.287 1048.05 M362.287 1063.4 L410.51 1063.4 L410.51 1069.79 L362.287 1069.79 L362.287 1063.4 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M458.057 1090.18 L458.057 1095.6 L455.724 1095.6 Q446.358 1095.6 443.161 1092.82 Q440.001 1090.03 440.001 1081.72 L440.001 1072.73 Q440.001 1067.05 437.97 1064.87 Q435.939 1062.69 430.597 1062.69 L428.303 1062.69 L428.303 1057.31 L430.597 1057.31 Q435.976 1057.31 437.97 1055.16 Q440.001 1052.98 440.001 1047.38 L440.001 1038.35 Q440.001 1030.04 443.161 1027.29 Q446.358 1024.51 455.724 1024.51 L458.057 1024.51 L458.057 1029.88 L455.499 1029.88 Q450.195 1029.88 448.577 1031.54 Q446.96 1033.19 446.96 1038.5 L446.96 1047.83 Q446.96 1053.73 445.23 1056.4 Q443.537 1059.07 439.399 1060.01 Q443.575 1061.03 445.267 1063.7 Q446.96 1066.37 446.96 1072.24 L446.96 1081.57 Q446.96 1086.87 448.577 1088.53 Q450.195 1090.18 455.499 1090.18 L458.057 1090.18 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M474.006 1026.88 L510.116 1026.88 L510.116 1030.11 L489.729 1083.04 L481.792 1083.04 L500.976 1033.27 L474.006 1033.27 L474.006 1026.88 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M565.073 1024.58 Q560.032 1033.23 557.587 1041.7 Q555.142 1050.16 555.142 1058.85 Q555.142 1067.54 557.587 1076.08 Q560.07 1084.58 565.073 1093.19 L559.054 1093.19 Q553.412 1084.35 550.591 1075.81 Q547.807 1067.27 547.807 1058.85 Q547.807 1050.46 550.591 1041.96 Q553.374 1033.46 559.054 1024.58 L565.073 1024.58 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M580.796 1076.64 L593.209 1076.64 L593.209 1033.8 L579.705 1036.5 L579.705 1029.58 L593.134 1026.88 L600.732 1026.88 L600.732 1076.64 L613.145 1076.64 L613.145 1083.04 L580.796 1083.04 L580.796 1076.64 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M644.742 1031.88 Q638.874 1031.88 635.903 1037.67 Q632.969 1043.43 632.969 1055.01 Q632.969 1066.56 635.903 1072.35 Q638.874 1078.11 644.742 1078.11 Q650.648 1078.11 653.582 1072.35 Q656.554 1066.56 656.554 1055.01 Q656.554 1043.43 653.582 1037.67 Q650.648 1031.88 644.742 1031.88 M644.742 1025.86 Q654.184 1025.86 659.149 1033.35 Q664.152 1040.79 664.152 1055.01 Q664.152 1069.19 659.149 1076.68 Q654.184 1084.13 644.742 1084.13 Q635.301 1084.13 630.298 1076.68 Q625.333 1069.19 625.333 1055.01 Q625.333 1040.79 630.298 1033.35 Q635.301 1025.86 644.742 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M693.755 1031.88 Q687.887 1031.88 684.916 1037.67 Q681.982 1043.43 681.982 1055.01 Q681.982 1066.56 684.916 1072.35 Q687.887 1078.11 693.755 1078.11 Q699.661 1078.11 702.595 1072.35 Q705.567 1066.56 705.567 1055.01 Q705.567 1043.43 702.595 1037.67 Q699.661 1031.88 693.755 1031.88 M693.755 1025.86 Q703.197 1025.86 708.162 1033.35 Q713.165 1040.79 713.165 1055.01 Q713.165 1069.19 708.162 1076.68 Q703.197 1084.13 693.755 1084.13 Q684.314 1084.13 679.311 1076.68 Q674.346 1069.19 674.346 1055.01 Q674.346 1040.79 679.311 1033.35 Q684.314 1025.86 693.755 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M774.29 1058.32 Q771.018 1058.32 769.137 1061.11 Q767.294 1063.89 767.294 1068.85 Q767.294 1073.74 769.137 1076.57 Q771.018 1079.35 774.29 1079.35 Q777.488 1079.35 779.331 1076.57 Q781.212 1073.74 781.212 1068.85 Q781.212 1063.93 779.331 1061.14 Q777.488 1058.32 774.29 1058.32 M774.29 1053.54 Q780.234 1053.54 783.732 1057.68 Q787.23 1061.82 787.23 1068.85 Q787.23 1075.89 783.694 1080.03 Q780.196 1084.13 774.29 1084.13 Q768.272 1084.13 764.774 1080.03 Q761.275 1075.89 761.275 1068.85 Q761.275 1061.78 764.774 1057.68 Q768.309 1053.54 774.29 1053.54 M735.471 1030.64 Q732.236 1030.64 730.355 1033.46 Q728.512 1036.24 728.512 1041.13 Q728.512 1046.1 730.355 1048.88 Q732.199 1051.66 735.471 1051.66 Q738.744 1051.66 740.587 1048.88 Q742.468 1046.1 742.468 1041.13 Q742.468 1036.28 740.587 1033.46 Q738.706 1030.64 735.471 1030.64 M769.438 1025.86 L775.456 1025.86 L740.324 1084.13 L734.305 1084.13 L769.438 1025.86 M735.471 1025.86 Q741.414 1025.86 744.95 1030 Q748.486 1034.1 748.486 1041.13 Q748.486 1048.24 744.95 1052.34 Q741.452 1056.44 735.471 1056.44 Q729.49 1056.44 725.992 1052.34 Q722.531 1048.2 722.531 1041.13 Q722.531 1034.14 726.03 1030 Q729.528 1025.86 735.471 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M797.65 1024.58 L803.668 1024.58 Q809.31 1033.46 812.094 1041.96 Q814.915 1050.46 814.915 1058.85 Q814.915 1067.27 812.094 1075.81 Q809.31 1084.35 803.668 1093.19 L797.65 1093.19 Q802.652 1084.58 805.097 1076.08 Q807.58 1067.54 807.58 1058.85 Q807.58 1050.16 805.097 1041.7 Q802.652 1033.23 797.65 1024.58 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M831.165 1090.18 L833.798 1090.18 Q839.064 1090.18 840.644 1088.56 Q842.262 1086.95 842.262 1081.57 L842.262 1072.24 Q842.262 1066.37 843.954 1063.7 Q845.647 1061.03 849.822 1060.01 Q845.647 1059.07 843.954 1056.4 Q842.262 1053.73 842.262 1047.83 L842.262 1038.5 Q842.262 1033.16 840.644 1031.54 Q839.064 1029.88 833.798 1029.88 L831.165 1029.88 L831.165 1024.51 L833.535 1024.51 Q842.901 1024.51 846.023 1027.29 Q849.183 1030.04 849.183 1038.35 L849.183 1047.38 Q849.183 1052.98 851.214 1055.16 Q853.245 1057.31 858.587 1057.31 L860.919 1057.31 L860.919 1062.69 L858.587 1062.69 Q853.245 1062.69 851.214 1064.87 Q849.183 1067.05 849.183 1072.73 L849.183 1081.72 Q849.183 1090.03 846.023 1092.82 Q842.901 1095.6 833.535 1095.6 L831.165 1095.6 L831.165 1090.18 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M451.098 1171.19 Q448.164 1178.71 445.38 1181.01 Q442.597 1183.3 437.932 1183.3 L432.403 1183.3 L432.403 1177.51 L436.465 1177.51 Q439.324 1177.51 440.904 1176.15 Q442.484 1174.8 444.402 1169.76 L445.643 1166.6 L428.604 1125.15 L435.939 1125.15 L449.104 1158.1 L462.269 1125.15 L469.604 1125.15 L451.098 1171.19 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M486.005 1113.18 L486.005 1125.15 L500.261 1125.15 L500.261 1130.52 L486.005 1130.52 L486.005 1153.4 Q486.005 1158.55 487.397 1160.02 Q488.826 1161.48 493.152 1161.48 L500.261 1161.48 L500.261 1167.28 L493.152 1167.28 Q485.14 1167.28 482.093 1164.3 Q479.046 1161.29 479.046 1153.4 L479.046 1130.52 L473.968 1130.52 L473.968 1125.15 L479.046 1125.15 L479.046 1113.18 L486.005 1113.18 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M533.777 1131.62 Q532.611 1130.94 531.219 1130.64 Q529.865 1130.3 528.21 1130.3 Q522.341 1130.3 519.182 1134.14 Q516.06 1137.94 516.06 1145.08 L516.06 1167.28 L509.101 1167.28 L509.101 1125.15 L516.06 1125.15 L516.06 1131.69 Q518.241 1127.85 521.74 1126.01 Q525.238 1124.13 530.241 1124.13 Q530.955 1124.13 531.821 1124.24 Q532.686 1124.32 533.739 1124.51 L533.777 1131.62 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M540.322 1150.65 L540.322 1125.15 L547.243 1125.15 L547.243 1150.39 Q547.243 1156.37 549.575 1159.38 Q551.907 1162.35 556.572 1162.35 Q562.176 1162.35 565.411 1158.77 Q568.684 1155.2 568.684 1149.03 L568.684 1125.15 L575.605 1125.15 L575.605 1167.28 L568.684 1167.28 L568.684 1160.81 Q566.164 1164.64 562.816 1166.52 Q559.506 1168.37 555.105 1168.37 Q547.845 1168.37 544.083 1163.85 Q540.322 1159.34 540.322 1150.65 M557.738 1124.13 L557.738 1124.13 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M625.897 1144.48 L625.897 1147.87 L594.074 1147.87 Q594.526 1155.01 598.362 1158.77 Q602.237 1162.5 609.121 1162.5 Q613.108 1162.5 616.832 1161.52 Q620.593 1160.54 624.28 1158.59 L624.28 1165.13 Q620.556 1166.71 616.644 1167.54 Q612.732 1168.37 608.707 1168.37 Q598.626 1168.37 592.72 1162.5 Q586.852 1156.63 586.852 1146.62 Q586.852 1136.28 592.419 1130.22 Q598.024 1124.13 607.503 1124.13 Q616.004 1124.13 620.932 1129.62 Q625.897 1135.08 625.897 1144.48 M618.976 1142.45 Q618.901 1136.77 615.778 1133.38 Q612.694 1130 607.578 1130 Q601.785 1130 598.287 1133.27 Q594.827 1136.54 594.3 1142.49 L618.976 1142.45 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M638.16 1132.29 L686.383 1132.29 L686.383 1138.61 L638.16 1138.61 L638.16 1132.29 M638.16 1147.64 L686.383 1147.64 L686.383 1154.03 L638.16 1154.03 L638.16 1147.64 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M700.865 1111.12 L736.976 1111.12 L736.976 1114.35 L716.588 1167.28 L708.651 1167.28 L727.835 1117.51 L700.865 1117.51 L700.865 1111.12 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1247.24 1011.02 L2352.76 1011.02 L2352.76 47.2441 L1247.24 47.2441  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip123">
    <rect x="1247" y="47" width="1107" height="965"></rect>
  </clippath>
</defs>
<g clip-path="url(#clip123)">
<image width="964" height="964" href="data:image/png;base64,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" transform="translate(1318, 47)"></image>
</g>
<path clip-path="url(#clip120)" d="M1549.95 1031.2 L1549.95 1039.21 Q1546.11 1035.64 1541.75 1033.87 Q1537.42 1032.1 1532.53 1032.1 Q1522.9 1032.1 1517.79 1038.01 Q1512.67 1043.88 1512.67 1055.01 Q1512.67 1066.11 1517.79 1072.01 Q1522.9 1077.88 1532.53 1077.88 Q1537.42 1077.88 1541.75 1076.11 Q1546.11 1074.35 1549.95 1070.77 L1549.95 1078.71 Q1545.96 1081.42 1541.49 1082.77 Q1537.05 1084.13 1532.08 1084.13 Q1519.33 1084.13 1512 1076.34 Q1504.66 1068.52 1504.66 1055.01 Q1504.66 1041.47 1512 1033.68 Q1519.33 1025.86 1532.08 1025.86 Q1537.12 1025.86 1541.56 1027.21 Q1546.04 1028.53 1549.95 1031.2 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1562.29 1048.05 L1610.51 1048.05 L1610.51 1054.37 L1562.29 1054.37 L1562.29 1048.05 M1562.29 1063.4 L1610.51 1063.4 L1610.51 1069.79 L1562.29 1069.79 L1562.29 1063.4 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1658.06 1090.18 L1658.06 1095.6 L1655.72 1095.6 Q1646.36 1095.6 1643.16 1092.82 Q1640 1090.03 1640 1081.72 L1640 1072.73 Q1640 1067.05 1637.97 1064.87 Q1635.94 1062.69 1630.6 1062.69 L1628.3 1062.69 L1628.3 1057.31 L1630.6 1057.31 Q1635.98 1057.31 1637.97 1055.16 Q1640 1052.98 1640 1047.38 L1640 1038.35 Q1640 1030.04 1643.16 1027.29 Q1646.36 1024.51 1655.72 1024.51 L1658.06 1024.51 L1658.06 1029.88 L1655.5 1029.88 Q1650.19 1029.88 1648.58 1031.54 Q1646.96 1033.19 1646.96 1038.5 L1646.96 1047.83 Q1646.96 1053.73 1645.23 1056.4 Q1643.54 1059.07 1639.4 1060.01 Q1643.57 1061.03 1645.27 1063.7 Q1646.96 1066.37 1646.96 1072.24 L1646.96 1081.57 Q1646.96 1086.87 1648.58 1088.53 Q1650.19 1090.18 1655.5 1090.18 L1658.06 1090.18 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1692.17 1056.37 Q1686.76 1056.37 1683.64 1059.26 Q1680.55 1062.16 1680.55 1067.24 Q1680.55 1072.31 1683.64 1075.21 Q1686.76 1078.11 1692.17 1078.11 Q1697.59 1078.11 1700.71 1075.21 Q1703.83 1072.28 1703.83 1067.24 Q1703.83 1062.16 1700.71 1059.26 Q1697.63 1056.37 1692.17 1056.37 M1684.58 1053.13 Q1679.69 1051.93 1676.94 1048.58 Q1674.23 1045.23 1674.23 1040.42 Q1674.23 1033.68 1679.01 1029.77 Q1683.82 1025.86 1692.17 1025.86 Q1700.56 1025.86 1705.34 1029.77 Q1710.12 1033.68 1710.12 1040.42 Q1710.12 1045.23 1707.37 1048.58 Q1704.66 1051.93 1699.81 1053.13 Q1705.3 1054.41 1708.35 1058.13 Q1711.43 1061.86 1711.43 1067.24 Q1711.43 1075.4 1706.43 1079.76 Q1701.46 1084.13 1692.17 1084.13 Q1682.88 1084.13 1677.88 1079.76 Q1672.91 1075.4 1672.91 1067.24 Q1672.91 1061.86 1676 1058.13 Q1679.08 1054.41 1684.58 1053.13 M1681.79 1041.13 Q1681.79 1045.5 1684.5 1047.94 Q1687.25 1050.39 1692.17 1050.39 Q1697.06 1050.39 1699.81 1047.94 Q1702.59 1045.5 1702.59 1041.13 Q1702.59 1036.77 1699.81 1034.32 Q1697.06 1031.88 1692.17 1031.88 Q1687.25 1031.88 1684.5 1034.32 Q1681.79 1036.77 1681.79 1041.13 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1765.07 1024.58 Q1760.03 1033.23 1757.59 1041.7 Q1755.14 1050.16 1755.14 1058.85 Q1755.14 1067.54 1757.59 1076.08 Q1760.07 1084.58 1765.07 1093.19 L1759.05 1093.19 Q1753.41 1084.35 1750.59 1075.81 Q1747.81 1067.27 1747.81 1058.85 Q1747.81 1050.46 1750.59 1041.96 Q1753.37 1033.46 1759.05 1024.58 L1765.07 1024.58 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1780.8 1076.64 L1793.21 1076.64 L1793.21 1033.8 L1779.71 1036.5 L1779.71 1029.58 L1793.13 1026.88 L1800.73 1026.88 L1800.73 1076.64 L1813.15 1076.64 L1813.15 1083.04 L1780.8 1083.04 L1780.8 1076.64 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1844.74 1031.88 Q1838.87 1031.88 1835.9 1037.67 Q1832.97 1043.43 1832.97 1055.01 Q1832.97 1066.56 1835.9 1072.35 Q1838.87 1078.11 1844.74 1078.11 Q1850.65 1078.11 1853.58 1072.35 Q1856.55 1066.56 1856.55 1055.01 Q1856.55 1043.43 1853.58 1037.67 Q1850.65 1031.88 1844.74 1031.88 M1844.74 1025.86 Q1854.18 1025.86 1859.15 1033.35 Q1864.15 1040.79 1864.15 1055.01 Q1864.15 1069.19 1859.15 1076.68 Q1854.18 1084.13 1844.74 1084.13 Q1835.3 1084.13 1830.3 1076.68 Q1825.33 1069.19 1825.33 1055.01 Q1825.33 1040.79 1830.3 1033.35 Q1835.3 1025.86 1844.74 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1893.76 1031.88 Q1887.89 1031.88 1884.92 1037.67 Q1881.98 1043.43 1881.98 1055.01 Q1881.98 1066.56 1884.92 1072.35 Q1887.89 1078.11 1893.76 1078.11 Q1899.66 1078.11 1902.6 1072.35 Q1905.57 1066.56 1905.57 1055.01 Q1905.57 1043.43 1902.6 1037.67 Q1899.66 1031.88 1893.76 1031.88 M1893.76 1025.86 Q1903.2 1025.86 1908.16 1033.35 Q1913.17 1040.79 1913.17 1055.01 Q1913.17 1069.19 1908.16 1076.68 Q1903.2 1084.13 1893.76 1084.13 Q1884.31 1084.13 1879.31 1076.68 Q1874.35 1069.19 1874.35 1055.01 Q1874.35 1040.79 1879.31 1033.35 Q1884.31 1025.86 1893.76 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1974.29 1058.32 Q1971.02 1058.32 1969.14 1061.11 Q1967.29 1063.89 1967.29 1068.85 Q1967.29 1073.74 1969.14 1076.57 Q1971.02 1079.35 1974.29 1079.35 Q1977.49 1079.35 1979.33 1076.57 Q1981.21 1073.74 1981.21 1068.85 Q1981.21 1063.93 1979.33 1061.14 Q1977.49 1058.32 1974.29 1058.32 M1974.29 1053.54 Q1980.23 1053.54 1983.73 1057.68 Q1987.23 1061.82 1987.23 1068.85 Q1987.23 1075.89 1983.69 1080.03 Q1980.2 1084.13 1974.29 1084.13 Q1968.27 1084.13 1964.77 1080.03 Q1961.28 1075.89 1961.28 1068.85 Q1961.28 1061.78 1964.77 1057.68 Q1968.31 1053.54 1974.29 1053.54 M1935.47 1030.64 Q1932.24 1030.64 1930.36 1033.46 Q1928.51 1036.24 1928.51 1041.13 Q1928.51 1046.1 1930.36 1048.88 Q1932.2 1051.66 1935.47 1051.66 Q1938.74 1051.66 1940.59 1048.88 Q1942.47 1046.1 1942.47 1041.13 Q1942.47 1036.28 1940.59 1033.46 Q1938.71 1030.64 1935.47 1030.64 M1969.44 1025.86 L1975.46 1025.86 L1940.32 1084.13 L1934.31 1084.13 L1969.44 1025.86 M1935.47 1025.86 Q1941.41 1025.86 1944.95 1030 Q1948.49 1034.1 1948.49 1041.13 Q1948.49 1048.24 1944.95 1052.34 Q1941.45 1056.44 1935.47 1056.44 Q1929.49 1056.44 1925.99 1052.34 Q1922.53 1048.2 1922.53 1041.13 Q1922.53 1034.14 1926.03 1030 Q1929.53 1025.86 1935.47 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1997.65 1024.58 L2003.67 1024.58 Q2009.31 1033.46 2012.09 1041.96 Q2014.92 1050.46 2014.92 1058.85 Q2014.92 1067.27 2012.09 1075.81 Q2009.31 1084.35 2003.67 1093.19 L1997.65 1093.19 Q2002.65 1084.58 2005.1 1076.08 Q2007.58 1067.54 2007.58 1058.85 Q2007.58 1050.16 2005.1 1041.7 Q2002.65 1033.23 1997.65 1024.58 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2031.17 1090.18 L2033.8 1090.18 Q2039.06 1090.18 2040.64 1088.56 Q2042.26 1086.95 2042.26 1081.57 L2042.26 1072.24 Q2042.26 1066.37 2043.95 1063.7 Q2045.65 1061.03 2049.82 1060.01 Q2045.65 1059.07 2043.95 1056.4 Q2042.26 1053.73 2042.26 1047.83 L2042.26 1038.5 Q2042.26 1033.16 2040.64 1031.54 Q2039.06 1029.88 2033.8 1029.88 L2031.17 1029.88 L2031.17 1024.51 L2033.53 1024.51 Q2042.9 1024.51 2046.02 1027.29 Q2049.18 1030.04 2049.18 1038.35 L2049.18 1047.38 Q2049.18 1052.98 2051.21 1055.16 Q2053.25 1057.31 2058.59 1057.31 L2060.92 1057.31 L2060.92 1062.69 L2058.59 1062.69 Q2053.25 1062.69 2051.21 1064.87 Q2049.18 1067.05 2049.18 1072.73 L2049.18 1081.72 Q2049.18 1090.03 2046.02 1092.82 Q2042.9 1095.6 2033.53 1095.6 L2031.17 1095.6 L2031.17 1090.18 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1650.44 1171.19 Q1647.51 1178.71 1644.72 1181.01 Q1641.94 1183.3 1637.27 1183.3 L1631.74 1183.3 L1631.74 1177.51 L1635.81 1177.51 Q1638.67 1177.51 1640.25 1176.15 Q1641.83 1174.8 1643.74 1169.76 L1644.99 1166.6 L1627.95 1125.15 L1635.28 1125.15 L1648.45 1158.1 L1661.61 1125.15 L1668.95 1125.15 L1650.44 1171.19 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1685.35 1113.18 L1685.35 1125.15 L1699.6 1125.15 L1699.6 1130.52 L1685.35 1130.52 L1685.35 1153.4 Q1685.35 1158.55 1686.74 1160.02 Q1688.17 1161.48 1692.49 1161.48 L1699.6 1161.48 L1699.6 1167.28 L1692.49 1167.28 Q1684.48 1167.28 1681.43 1164.3 Q1678.39 1161.29 1678.39 1153.4 L1678.39 1130.52 L1673.31 1130.52 L1673.31 1125.15 L1678.39 1125.15 L1678.39 1113.18 L1685.35 1113.18 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1733.12 1131.62 Q1731.95 1130.94 1730.56 1130.64 Q1729.21 1130.3 1727.55 1130.3 Q1721.68 1130.3 1718.52 1134.14 Q1715.4 1137.94 1715.4 1145.08 L1715.4 1167.28 L1708.44 1167.28 L1708.44 1125.15 L1715.4 1125.15 L1715.4 1131.69 Q1717.58 1127.85 1721.08 1126.01 Q1724.58 1124.13 1729.58 1124.13 Q1730.3 1124.13 1731.16 1124.24 Q1732.03 1124.32 1733.08 1124.51 L1733.12 1131.62 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1739.66 1150.65 L1739.66 1125.15 L1746.58 1125.15 L1746.58 1150.39 Q1746.58 1156.37 1748.92 1159.38 Q1751.25 1162.35 1755.91 1162.35 Q1761.52 1162.35 1764.75 1158.77 Q1768.03 1155.2 1768.03 1149.03 L1768.03 1125.15 L1774.95 1125.15 L1774.95 1167.28 L1768.03 1167.28 L1768.03 1160.81 Q1765.51 1164.64 1762.16 1166.52 Q1758.85 1168.37 1754.45 1168.37 Q1747.19 1168.37 1743.42 1163.85 Q1739.66 1159.34 1739.66 1150.65 M1757.08 1124.13 L1757.08 1124.13 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1825.24 1144.48 L1825.24 1147.87 L1793.42 1147.87 Q1793.87 1155.01 1797.7 1158.77 Q1801.58 1162.5 1808.46 1162.5 Q1812.45 1162.5 1816.17 1161.52 Q1819.93 1160.54 1823.62 1158.59 L1823.62 1165.13 Q1819.9 1166.71 1815.99 1167.54 Q1812.07 1168.37 1808.05 1168.37 Q1797.97 1168.37 1792.06 1162.5 Q1786.19 1156.63 1786.19 1146.62 Q1786.19 1136.28 1791.76 1130.22 Q1797.37 1124.13 1806.84 1124.13 Q1815.35 1124.13 1820.27 1129.62 Q1825.24 1135.08 1825.24 1144.48 M1818.32 1142.45 Q1818.24 1136.77 1815.12 1133.38 Q1812.04 1130 1806.92 1130 Q1801.13 1130 1797.63 1133.27 Q1794.17 1136.54 1793.64 1142.49 L1818.32 1142.45 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1837.5 1132.29 L1885.72 1132.29 L1885.72 1138.61 L1837.5 1138.61 L1837.5 1132.29 M1837.5 1147.64 L1885.72 1147.64 L1885.72 1154.03 L1837.5 1154.03 L1837.5 1147.64 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M1918.37 1140.61 Q1912.96 1140.61 1909.84 1143.5 Q1906.75 1146.4 1906.75 1151.48 Q1906.75 1156.55 1909.84 1159.45 Q1912.96 1162.35 1918.37 1162.35 Q1923.79 1162.35 1926.91 1159.45 Q1930.04 1156.52 1930.04 1151.48 Q1930.04 1146.4 1926.91 1143.5 Q1923.83 1140.61 1918.37 1140.61 M1910.78 1137.37 Q1905.89 1136.17 1903.14 1132.82 Q1900.43 1129.47 1900.43 1124.66 Q1900.43 1117.92 1905.21 1114.01 Q1910.02 1110.1 1918.37 1110.1 Q1926.76 1110.1 1931.54 1114.01 Q1936.32 1117.92 1936.32 1124.66 Q1936.32 1129.47 1933.57 1132.82 Q1930.86 1136.17 1926.01 1137.37 Q1931.5 1138.65 1934.55 1142.37 Q1937.63 1146.1 1937.63 1151.48 Q1937.63 1159.64 1932.63 1164 Q1927.67 1168.37 1918.37 1168.37 Q1909.08 1168.37 1904.08 1164 Q1899.12 1159.64 1899.12 1151.48 Q1899.12 1146.1 1902.2 1142.37 Q1905.28 1138.65 1910.78 1137.37 M1907.99 1125.37 Q1907.99 1129.74 1910.7 1132.18 Q1913.45 1134.63 1918.37 1134.63 Q1923.26 1134.63 1926.01 1132.18 Q1928.79 1129.74 1928.79 1125.37 Q1928.79 1121.01 1926.01 1118.56 Q1923.26 1116.12 1918.37 1116.12 Q1913.45 1116.12 1910.7 1118.56 Q1907.99 1121.01 1907.99 1125.37 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2447.24 1011.02 L3552.76 1011.02 L3552.76 47.2441 L2447.24 47.2441  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip124">
    <rect x="2447" y="47" width="1107" height="965"></rect>
  </clippath>
</defs>
<g clip-path="url(#clip124)">
<image width="964" height="964" href="data:image/png;base64,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" transform="translate(2518, 47)"></image>
</g>
<path clip-path="url(#clip120)" d="M2749.95 1031.2 L2749.95 1039.21 Q2746.11 1035.64 2741.75 1033.87 Q2737.42 1032.1 2732.53 1032.1 Q2722.9 1032.1 2717.79 1038.01 Q2712.67 1043.88 2712.67 1055.01 Q2712.67 1066.11 2717.79 1072.01 Q2722.9 1077.88 2732.53 1077.88 Q2737.42 1077.88 2741.75 1076.11 Q2746.11 1074.35 2749.95 1070.77 L2749.95 1078.71 Q2745.96 1081.42 2741.49 1082.77 Q2737.05 1084.13 2732.08 1084.13 Q2719.33 1084.13 2712 1076.34 Q2704.66 1068.52 2704.66 1055.01 Q2704.66 1041.47 2712 1033.68 Q2719.33 1025.86 2732.08 1025.86 Q2737.12 1025.86 2741.56 1027.21 Q2746.04 1028.53 2749.95 1031.2 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2762.29 1048.05 L2810.51 1048.05 L2810.51 1054.37 L2762.29 1054.37 L2762.29 1048.05 M2762.29 1063.4 L2810.51 1063.4 L2810.51 1069.79 L2762.29 1069.79 L2762.29 1063.4 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2858.06 1090.18 L2858.06 1095.6 L2855.72 1095.6 Q2846.36 1095.6 2843.16 1092.82 Q2840 1090.03 2840 1081.72 L2840 1072.73 Q2840 1067.05 2837.97 1064.87 Q2835.94 1062.69 2830.6 1062.69 L2828.3 1062.69 L2828.3 1057.31 L2830.6 1057.31 Q2835.98 1057.31 2837.97 1055.16 Q2840 1052.98 2840 1047.38 L2840 1038.35 Q2840 1030.04 2843.16 1027.29 Q2846.36 1024.51 2855.72 1024.51 L2858.06 1024.51 L2858.06 1029.88 L2855.5 1029.88 Q2850.19 1029.88 2848.58 1031.54 Q2846.96 1033.19 2846.96 1038.5 L2846.96 1047.83 Q2846.96 1053.73 2845.23 1056.4 Q2843.54 1059.07 2839.4 1060.01 Q2843.57 1061.03 2845.27 1063.7 Q2846.96 1066.37 2846.96 1072.24 L2846.96 1081.57 Q2846.96 1086.87 2848.58 1088.53 Q2850.19 1090.18 2855.5 1090.18 L2858.06 1090.18 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2892.17 1031.88 Q2886.31 1031.88 2883.33 1037.67 Q2880.4 1043.43 2880.4 1055.01 Q2880.4 1066.56 2883.33 1072.35 Q2886.31 1078.11 2892.17 1078.11 Q2898.08 1078.11 2901.01 1072.35 Q2903.99 1066.56 2903.99 1055.01 Q2903.99 1043.43 2901.01 1037.67 Q2898.08 1031.88 2892.17 1031.88 M2892.17 1025.86 Q2901.62 1025.86 2906.58 1033.35 Q2911.58 1040.79 2911.58 1055.01 Q2911.58 1069.19 2906.58 1076.68 Q2901.62 1084.13 2892.17 1084.13 Q2882.73 1084.13 2877.73 1076.68 Q2872.76 1069.19 2872.76 1055.01 Q2872.76 1040.79 2877.73 1033.35 Q2882.73 1025.86 2892.17 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2965.07 1024.58 Q2960.03 1033.23 2957.59 1041.7 Q2955.14 1050.16 2955.14 1058.85 Q2955.14 1067.54 2957.59 1076.08 Q2960.07 1084.58 2965.07 1093.19 L2959.05 1093.19 Q2953.41 1084.35 2950.59 1075.81 Q2947.81 1067.27 2947.81 1058.85 Q2947.81 1050.46 2950.59 1041.96 Q2953.37 1033.46 2959.05 1024.58 L2965.07 1024.58 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2980.8 1076.64 L2993.21 1076.64 L2993.21 1033.8 L2979.71 1036.5 L2979.71 1029.58 L2993.13 1026.88 L3000.73 1026.88 L3000.73 1076.64 L3013.15 1076.64 L3013.15 1083.04 L2980.8 1083.04 L2980.8 1076.64 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M3044.74 1031.88 Q3038.87 1031.88 3035.9 1037.67 Q3032.97 1043.43 3032.97 1055.01 Q3032.97 1066.56 3035.9 1072.35 Q3038.87 1078.11 3044.74 1078.11 Q3050.65 1078.11 3053.58 1072.35 Q3056.55 1066.56 3056.55 1055.01 Q3056.55 1043.43 3053.58 1037.67 Q3050.65 1031.88 3044.74 1031.88 M3044.74 1025.86 Q3054.18 1025.86 3059.15 1033.35 Q3064.15 1040.79 3064.15 1055.01 Q3064.15 1069.19 3059.15 1076.68 Q3054.18 1084.13 3044.74 1084.13 Q3035.3 1084.13 3030.3 1076.68 Q3025.33 1069.19 3025.33 1055.01 Q3025.33 1040.79 3030.3 1033.35 Q3035.3 1025.86 3044.74 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M3093.76 1031.88 Q3087.89 1031.88 3084.92 1037.67 Q3081.98 1043.43 3081.98 1055.01 Q3081.98 1066.56 3084.92 1072.35 Q3087.89 1078.11 3093.76 1078.11 Q3099.66 1078.11 3102.6 1072.35 Q3105.57 1066.56 3105.57 1055.01 Q3105.57 1043.43 3102.6 1037.67 Q3099.66 1031.88 3093.76 1031.88 M3093.76 1025.86 Q3103.2 1025.86 3108.16 1033.35 Q3113.17 1040.79 3113.17 1055.01 Q3113.17 1069.19 3108.16 1076.68 Q3103.2 1084.13 3093.76 1084.13 Q3084.31 1084.13 3079.31 1076.68 Q3074.35 1069.19 3074.35 1055.01 Q3074.35 1040.79 3079.31 1033.35 Q3084.31 1025.86 3093.76 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M3174.29 1058.32 Q3171.02 1058.32 3169.14 1061.11 Q3167.29 1063.89 3167.29 1068.85 Q3167.29 1073.74 3169.14 1076.57 Q3171.02 1079.35 3174.29 1079.35 Q3177.49 1079.35 3179.33 1076.57 Q3181.21 1073.74 3181.21 1068.85 Q3181.21 1063.93 3179.33 1061.14 Q3177.49 1058.32 3174.29 1058.32 M3174.29 1053.54 Q3180.23 1053.54 3183.73 1057.68 Q3187.23 1061.82 3187.23 1068.85 Q3187.23 1075.89 3183.69 1080.03 Q3180.2 1084.13 3174.29 1084.13 Q3168.27 1084.13 3164.77 1080.03 Q3161.28 1075.89 3161.28 1068.85 Q3161.28 1061.78 3164.77 1057.68 Q3168.31 1053.54 3174.29 1053.54 M3135.47 1030.64 Q3132.24 1030.64 3130.36 1033.46 Q3128.51 1036.24 3128.51 1041.13 Q3128.51 1046.1 3130.36 1048.88 Q3132.2 1051.66 3135.47 1051.66 Q3138.74 1051.66 3140.59 1048.88 Q3142.47 1046.1 3142.47 1041.13 Q3142.47 1036.28 3140.59 1033.46 Q3138.71 1030.64 3135.47 1030.64 M3169.44 1025.86 L3175.46 1025.86 L3140.32 1084.13 L3134.31 1084.13 L3169.44 1025.86 M3135.47 1025.86 Q3141.41 1025.86 3144.95 1030 Q3148.49 1034.1 3148.49 1041.13 Q3148.49 1048.24 3144.95 1052.34 Q3141.45 1056.44 3135.47 1056.44 Q3129.49 1056.44 3125.99 1052.34 Q3122.53 1048.2 3122.53 1041.13 Q3122.53 1034.14 3126.03 1030 Q3129.53 1025.86 3135.47 1025.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M3197.65 1024.58 L3203.67 1024.58 Q3209.31 1033.46 3212.09 1041.96 Q3214.92 1050.46 3214.92 1058.85 Q3214.92 1067.27 3212.09 1075.81 Q3209.31 1084.35 3203.67 1093.19 L3197.65 1093.19 Q3202.65 1084.58 3205.1 1076.08 Q3207.58 1067.54 3207.58 1058.85 Q3207.58 1050.16 3205.1 1041.7 Q3202.65 1033.23 3197.65 1024.58 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M3231.17 1090.18 L3233.8 1090.18 Q3239.06 1090.18 3240.64 1088.56 Q3242.26 1086.95 3242.26 1081.57 L3242.26 1072.24 Q3242.26 1066.37 3243.95 1063.7 Q3245.65 1061.03 3249.82 1060.01 Q3245.65 1059.07 3243.95 1056.4 Q3242.26 1053.73 3242.26 1047.83 L3242.26 1038.5 Q3242.26 1033.16 3240.64 1031.54 Q3239.06 1029.88 3233.8 1029.88 L3231.17 1029.88 L3231.17 1024.51 L3233.53 1024.51 Q3242.9 1024.51 3246.02 1027.29 Q3249.18 1030.04 3249.18 1038.35 L3249.18 1047.38 Q3249.18 1052.98 3251.21 1055.16 Q3253.25 1057.31 3258.59 1057.31 L3260.92 1057.31 L3260.92 1062.69 L3258.59 1062.69 Q3253.25 1062.69 3251.21 1064.87 Q3249.18 1067.05 3249.18 1072.73 L3249.18 1081.72 Q3249.18 1090.03 3246.02 1092.82 Q3242.9 1095.6 3233.53 1095.6 L3231.17 1095.6 L3231.17 1090.18 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2850.36 1171.19 Q2847.43 1178.71 2844.65 1181.01 Q2841.86 1183.3 2837.2 1183.3 L2831.67 1183.3 L2831.67 1177.51 L2835.73 1177.51 Q2838.59 1177.51 2840.17 1176.15 Q2841.75 1174.8 2843.67 1169.76 L2844.91 1166.6 L2827.87 1125.15 L2835.21 1125.15 L2848.37 1158.1 L2861.54 1125.15 L2868.87 1125.15 L2850.36 1171.19 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2885.27 1113.18 L2885.27 1125.15 L2899.53 1125.15 L2899.53 1130.52 L2885.27 1130.52 L2885.27 1153.4 Q2885.27 1158.55 2886.66 1160.02 Q2888.09 1161.48 2892.42 1161.48 L2899.53 1161.48 L2899.53 1167.28 L2892.42 1167.28 Q2884.41 1167.28 2881.36 1164.3 Q2878.31 1161.29 2878.31 1153.4 L2878.31 1130.52 L2873.23 1130.52 L2873.23 1125.15 L2878.31 1125.15 L2878.31 1113.18 L2885.27 1113.18 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2933.04 1131.62 Q2931.88 1130.94 2930.49 1130.64 Q2929.13 1130.3 2927.48 1130.3 Q2921.61 1130.3 2918.45 1134.14 Q2915.33 1137.94 2915.33 1145.08 L2915.33 1167.28 L2908.37 1167.28 L2908.37 1125.15 L2915.33 1125.15 L2915.33 1131.69 Q2917.51 1127.85 2921.01 1126.01 Q2924.5 1124.13 2929.51 1124.13 Q2930.22 1124.13 2931.09 1124.24 Q2931.95 1124.32 2933.01 1124.51 L2933.04 1131.62 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M2939.59 1150.65 L2939.59 1125.15 L2946.51 1125.15 L2946.51 1150.39 Q2946.51 1156.37 2948.84 1159.38 Q2951.17 1162.35 2955.84 1162.35 Q2961.44 1162.35 2964.68 1158.77 Q2967.95 1155.2 2967.95 1149.03 L2967.95 1125.15 L2974.87 1125.15 L2974.87 1167.28 L2967.95 1167.28 L2967.95 1160.81 Q2965.43 1164.64 2962.08 1166.52 Q2958.77 1168.37 2954.37 1168.37 Q2947.11 1168.37 2943.35 1163.85 Q2939.59 1159.34 2939.59 1150.65 M2957 1124.13 L2957 1124.13 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M3025.16 1144.48 L3025.16 1147.87 L2993.34 1147.87 Q2993.79 1155.01 2997.63 1158.77 Q3001.5 1162.5 3008.39 1162.5 Q3012.37 1162.5 3016.1 1161.52 Q3019.86 1160.54 3023.55 1158.59 L3023.55 1165.13 Q3019.82 1166.71 3015.91 1167.54 Q3012 1168.37 3007.97 1168.37 Q2997.89 1168.37 2991.99 1162.5 Q2986.12 1156.63 2986.12 1146.62 Q2986.12 1136.28 2991.69 1130.22 Q2997.29 1124.13 3006.77 1124.13 Q3015.27 1124.13 3020.2 1129.62 Q3025.16 1135.08 3025.16 1144.48 M3018.24 1142.45 Q3018.17 1136.77 3015.04 1133.38 Q3011.96 1130 3006.84 1130 Q3001.05 1130 2997.55 1133.27 Q2994.09 1136.54 2993.57 1142.49 L3018.24 1142.45 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M3037.43 1132.29 L3085.65 1132.29 L3085.65 1138.61 L3037.43 1138.61 L3037.43 1132.29 M3037.43 1147.64 L3085.65 1147.64 L3085.65 1154.03 L3037.43 1154.03 L3037.43 1147.64 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip120)" d="M3118.3 1116.12 Q3112.43 1116.12 3109.46 1121.91 Q3106.53 1127.67 3106.53 1139.25 Q3106.53 1150.8 3109.46 1156.59 Q3112.43 1162.35 3118.3 1162.35 Q3124.21 1162.35 3127.14 1156.59 Q3130.11 1150.8 3130.11 1139.25 Q3130.11 1127.67 3127.14 1121.91 Q3124.21 1116.12 3118.3 1116.12 M3118.3 1110.1 Q3127.74 1110.1 3132.71 1117.59 Q3137.71 1125.03 3137.71 1139.25 Q3137.71 1153.43 3132.71 1160.92 Q3127.74 1168.37 3118.3 1168.37 Q3108.86 1168.37 3103.86 1160.92 Q3098.89 1153.43 3098.89 1139.25 Q3098.89 1125.03 3103.86 1117.59 Q3108.86 1110.1 3118.3 1110.1 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path></svg>
<figcaption class="figure-caption">(a) Randomly selected prediction sets of size <img src="https://latex.codecogs.com/png.latex?%7CC%7C=1">.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="fig-plots-2" class="quarto-figure quarto-figure-center anchored" style="flex-basis: 100.0%;justify-content: center;">
<figure class="figure">
<!--?xml version="1.0" encoding="utf-8"?-->
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" width="900" height="300" viewbox="0 0 3600 1200">
<defs>
  <clippath id="clip180">
    <rect x="0" y="0" width="3600" height="1200"></rect>
  </clippath>
</defs>
<path clip-path="url(#clip180)" d="M0 1200 L3600 1200 L3600 0 L0 0  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip181">
    <rect x="720" y="0" width="2521" height="1200"></rect>
  </clippath>
</defs>
<path clip-path="url(#clip180)" d="M47.2441 1011.02 L1152.76 1011.02 L1152.76 47.2441 L47.2441 47.2441  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip182">
    <rect x="47" y="47" width="1107" height="965"></rect>
  </clippath>
</defs>
<g clip-path="url(#clip182)">
<image width="964" height="964" href="data:image/png;base64,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" transform="translate(118, 47)"></image>
</g>
<path clip-path="url(#clip180)" d="M249.805 1036.27 L249.805 1043.66 Q246.264 1040.37 242.236 1038.73 Q238.243 1037.1 233.729 1037.1 Q224.84 1037.1 220.118 1042.55 Q215.396 1047.97 215.396 1058.25 Q215.396 1068.49 220.118 1073.94 Q224.84 1079.36 233.729 1079.36 Q238.243 1079.36 242.236 1077.73 Q246.264 1076.09 249.805 1072.8 L249.805 1080.12 Q246.125 1082.62 241.993 1083.87 Q237.896 1085.12 233.312 1085.12 Q221.542 1085.12 214.771 1077.93 Q208 1070.71 208 1058.25 Q208 1045.75 214.771 1038.56 Q221.542 1031.34 233.312 1031.34 Q237.965 1031.34 242.062 1032.59 Q246.194 1033.8 249.805 1036.27 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M261.194 1051.82 L305.708 1051.82 L305.708 1057.66 L261.194 1057.66 L261.194 1051.82 M261.194 1065.99 L305.708 1065.99 L305.708 1071.89 L261.194 1071.89 L261.194 1065.99 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M349.596 1090.71 L349.596 1095.71 L347.444 1095.71 Q338.798 1095.71 335.847 1093.14 Q332.93 1090.57 332.93 1082.9 L332.93 1074.6 Q332.93 1069.36 331.055 1067.34 Q329.18 1065.33 324.249 1065.33 L322.131 1065.33 L322.131 1060.37 L324.249 1060.37 Q329.215 1060.37 331.055 1058.39 Q332.93 1056.37 332.93 1051.2 L332.93 1042.87 Q332.93 1035.19 335.847 1032.66 Q338.798 1030.09 347.444 1030.09 L349.596 1030.09 L349.596 1035.05 L347.235 1035.05 Q342.34 1035.05 340.847 1036.58 Q339.353 1038.11 339.353 1043 L339.353 1051.62 Q339.353 1057.07 337.756 1059.53 Q336.194 1062 332.374 1062.87 Q336.228 1063.8 337.791 1066.27 Q339.353 1068.73 339.353 1074.15 L339.353 1082.76 Q339.353 1087.66 340.847 1089.18 Q342.34 1090.71 347.235 1090.71 L349.596 1090.71 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M364.319 1032.28 L397.652 1032.28 L397.652 1035.26 L378.832 1084.12 L371.506 1084.12 L389.214 1038.18 L364.319 1038.18 L364.319 1032.28 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M448.381 1030.16 Q443.728 1038.14 441.471 1045.96 Q439.214 1053.77 439.214 1061.79 Q439.214 1069.81 441.471 1077.69 Q443.763 1085.54 448.381 1093.49 L442.825 1093.49 Q437.617 1085.33 435.013 1077.45 Q432.443 1069.57 432.443 1061.79 Q432.443 1054.05 435.013 1046.2 Q437.582 1038.35 442.825 1030.16 L448.381 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M461.888 1083.04 L461.888 1076.65 Q464.526 1077.9 467.235 1078.56 Q469.943 1079.22 472.547 1079.22 Q479.492 1079.22 483.137 1074.57 Q486.818 1069.88 487.339 1060.37 Q485.325 1063.35 482.235 1064.95 Q479.144 1066.55 475.394 1066.55 Q467.617 1066.55 463.068 1061.86 Q458.554 1057.14 458.554 1048.98 Q458.554 1040.99 463.276 1036.16 Q467.999 1031.34 475.846 1031.34 Q484.839 1031.34 489.561 1038.25 Q494.318 1045.12 494.318 1058.25 Q494.318 1070.5 488.485 1077.83 Q482.686 1085.12 472.86 1085.12 Q470.221 1085.12 467.512 1084.6 Q464.804 1084.08 461.888 1083.04 M475.846 1061.06 Q480.568 1061.06 483.311 1057.83 Q486.089 1054.6 486.089 1048.98 Q486.089 1043.39 483.311 1040.16 Q480.568 1036.89 475.846 1036.89 Q471.124 1036.89 468.346 1040.16 Q465.603 1043.39 465.603 1048.98 Q465.603 1054.6 468.346 1057.83 Q471.124 1061.06 475.846 1061.06 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M521.922 1059.5 Q516.922 1059.5 514.04 1062.17 Q511.193 1064.84 511.193 1069.53 Q511.193 1074.22 514.04 1076.89 Q516.922 1079.57 521.922 1079.57 Q526.922 1079.57 529.804 1076.89 Q532.686 1074.18 532.686 1069.53 Q532.686 1064.84 529.804 1062.17 Q526.957 1059.5 521.922 1059.5 M514.908 1056.51 Q510.394 1055.4 507.859 1052.31 Q505.36 1049.22 505.36 1044.78 Q505.36 1038.56 509.769 1034.95 Q514.214 1031.34 521.922 1031.34 Q529.665 1031.34 534.075 1034.95 Q538.484 1038.56 538.484 1044.78 Q538.484 1049.22 535.95 1052.31 Q533.45 1055.4 528.97 1056.51 Q534.04 1057.69 536.852 1061.13 Q539.7 1064.57 539.7 1069.53 Q539.7 1077.07 535.082 1081.09 Q530.498 1085.12 521.922 1085.12 Q513.346 1085.12 508.728 1081.09 Q504.144 1077.07 504.144 1069.53 Q504.144 1064.57 506.991 1061.13 Q509.839 1057.69 514.908 1056.51 M512.339 1045.44 Q512.339 1049.46 514.839 1051.72 Q517.373 1053.98 521.922 1053.98 Q526.436 1053.98 528.97 1051.72 Q531.54 1049.46 531.54 1045.44 Q531.54 1041.41 528.97 1039.15 Q526.436 1036.89 521.922 1036.89 Q517.373 1036.89 514.839 1039.15 Q512.339 1041.41 512.339 1045.44 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M596.262 1061.3 Q593.241 1061.3 591.505 1063.87 Q589.804 1066.44 589.804 1071.03 Q589.804 1075.54 591.505 1078.14 Q593.241 1080.71 596.262 1080.71 Q599.213 1080.71 600.915 1078.14 Q602.651 1075.54 602.651 1071.03 Q602.651 1066.48 600.915 1063.91 Q599.213 1061.3 596.262 1061.3 M596.262 1056.89 Q601.748 1056.89 604.977 1060.71 Q608.206 1064.53 608.206 1071.03 Q608.206 1077.52 604.942 1081.34 Q601.713 1085.12 596.262 1085.12 Q590.706 1085.12 587.477 1081.34 Q584.248 1077.52 584.248 1071.03 Q584.248 1064.5 587.477 1060.71 Q590.741 1056.89 596.262 1056.89 M560.429 1035.75 Q557.443 1035.75 555.706 1038.35 Q554.005 1040.92 554.005 1045.44 Q554.005 1050.02 555.706 1052.59 Q557.408 1055.16 560.429 1055.16 Q563.449 1055.16 565.151 1052.59 Q566.887 1050.02 566.887 1045.44 Q566.887 1040.96 565.151 1038.35 Q563.415 1035.75 560.429 1035.75 M591.783 1031.34 L597.338 1031.34 L564.908 1085.12 L559.352 1085.12 L591.783 1031.34 M560.429 1031.34 Q565.915 1031.34 569.179 1035.16 Q572.442 1038.94 572.442 1045.44 Q572.442 1052 569.179 1055.78 Q565.949 1059.57 560.429 1059.57 Q554.908 1059.57 551.679 1055.78 Q548.484 1051.96 548.484 1045.44 Q548.484 1038.98 551.713 1035.16 Q554.943 1031.34 560.429 1031.34 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M617.824 1030.16 L623.38 1030.16 Q628.588 1038.35 631.157 1046.2 Q633.762 1054.05 633.762 1061.79 Q633.762 1069.57 631.157 1077.45 Q628.588 1085.33 623.38 1093.49 L617.824 1093.49 Q622.442 1085.54 624.699 1077.69 Q626.991 1069.81 626.991 1061.79 Q626.991 1053.77 624.699 1045.96 Q622.442 1038.14 617.824 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M648.206 1075.3 L655.532 1075.3 L655.532 1081.27 L649.838 1092.38 L645.359 1092.38 L648.206 1081.27 L648.206 1075.3 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M692.893 1083.04 L692.893 1076.65 Q695.532 1077.9 698.24 1078.56 Q700.949 1079.22 703.553 1079.22 Q710.497 1079.22 714.143 1074.57 Q717.824 1069.88 718.344 1060.37 Q716.331 1063.35 713.24 1064.95 Q710.15 1066.55 706.4 1066.55 Q698.622 1066.55 694.074 1061.86 Q689.56 1057.14 689.56 1048.98 Q689.56 1040.99 694.282 1036.16 Q699.004 1031.34 706.851 1031.34 Q715.844 1031.34 720.567 1038.25 Q725.324 1045.12 725.324 1058.25 Q725.324 1070.5 719.49 1077.83 Q713.692 1085.12 703.865 1085.12 Q701.227 1085.12 698.518 1084.6 Q695.81 1084.08 692.893 1083.04 M706.851 1061.06 Q711.574 1061.06 714.317 1057.83 Q717.094 1054.6 717.094 1048.98 Q717.094 1043.39 714.317 1040.16 Q711.574 1036.89 706.851 1036.89 Q702.129 1036.89 699.352 1040.16 Q696.608 1043.39 696.608 1048.98 Q696.608 1054.6 699.352 1057.83 Q702.129 1061.06 706.851 1061.06 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M774.976 1030.16 Q770.323 1038.14 768.066 1045.96 Q765.81 1053.77 765.81 1061.79 Q765.81 1069.81 768.066 1077.69 Q770.358 1085.54 774.976 1093.49 L769.421 1093.49 Q764.212 1085.33 761.608 1077.45 Q759.039 1069.57 759.039 1061.79 Q759.039 1054.05 761.608 1046.2 Q764.178 1038.35 769.421 1030.16 L774.976 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M794.316 1078.21 L818.795 1078.21 L818.795 1084.12 L785.879 1084.12 L785.879 1078.21 Q789.872 1074.08 796.747 1067.14 Q803.657 1060.16 805.427 1058.14 Q808.795 1054.36 810.115 1051.75 Q811.469 1049.12 811.469 1046.58 Q811.469 1042.45 808.552 1039.84 Q805.67 1037.24 801.018 1037.24 Q797.719 1037.24 794.039 1038.39 Q790.393 1039.53 786.226 1041.86 L786.226 1034.78 Q790.462 1033.07 794.143 1032.21 Q797.823 1031.34 800.879 1031.34 Q808.934 1031.34 813.726 1035.37 Q818.518 1039.39 818.518 1046.13 Q818.518 1049.32 817.302 1052.21 Q816.122 1055.05 812.962 1058.94 Q812.094 1059.95 807.441 1064.78 Q802.788 1069.57 794.316 1078.21 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M877.614 1061.3 Q874.594 1061.3 872.858 1063.87 Q871.156 1066.44 871.156 1071.03 Q871.156 1075.54 872.858 1078.14 Q874.594 1080.71 877.614 1080.71 Q880.566 1080.71 882.267 1078.14 Q884.003 1075.54 884.003 1071.03 Q884.003 1066.48 882.267 1063.91 Q880.566 1061.3 877.614 1061.3 M877.614 1056.89 Q883.101 1056.89 886.33 1060.71 Q889.559 1064.53 889.559 1071.03 Q889.559 1077.52 886.295 1081.34 Q883.066 1085.12 877.614 1085.12 Q872.059 1085.12 868.83 1081.34 Q865.601 1077.52 865.601 1071.03 Q865.601 1064.5 868.83 1060.71 Q872.094 1056.89 877.614 1056.89 M841.781 1035.75 Q838.795 1035.75 837.059 1038.35 Q835.358 1040.92 835.358 1045.44 Q835.358 1050.02 837.059 1052.59 Q838.761 1055.16 841.781 1055.16 Q844.802 1055.16 846.504 1052.59 Q848.24 1050.02 848.24 1045.44 Q848.24 1040.96 846.504 1038.35 Q844.767 1035.75 841.781 1035.75 M873.135 1031.34 L878.691 1031.34 L846.26 1085.12 L840.705 1085.12 L873.135 1031.34 M841.781 1031.34 Q847.267 1031.34 850.531 1035.16 Q853.795 1038.94 853.795 1045.44 Q853.795 1052 850.531 1055.78 Q847.302 1059.57 841.781 1059.57 Q836.261 1059.57 833.031 1055.78 Q829.837 1051.96 829.837 1045.44 Q829.837 1038.98 833.066 1035.16 Q836.295 1031.34 841.781 1031.34 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M899.177 1030.16 L904.732 1030.16 Q909.941 1038.35 912.51 1046.2 Q915.114 1054.05 915.114 1061.79 Q915.114 1069.57 912.51 1077.45 Q909.941 1085.33 904.732 1093.49 L899.177 1093.49 Q903.795 1085.54 906.052 1077.69 Q908.343 1069.81 908.343 1061.79 Q908.343 1053.77 906.052 1045.96 Q903.795 1038.14 899.177 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M930.114 1090.71 L932.545 1090.71 Q937.406 1090.71 938.864 1089.22 Q940.357 1087.73 940.357 1082.76 L940.357 1074.15 Q940.357 1068.73 941.92 1066.27 Q943.482 1063.8 947.336 1062.87 Q943.482 1062 941.92 1059.53 Q940.357 1057.07 940.357 1051.62 L940.357 1043 Q940.357 1038.07 938.864 1036.58 Q937.406 1035.05 932.545 1035.05 L930.114 1035.05 L930.114 1030.09 L932.302 1030.09 Q940.947 1030.09 943.829 1032.66 Q946.746 1035.19 946.746 1042.87 L946.746 1051.2 Q946.746 1056.37 948.621 1058.39 Q950.496 1060.37 955.427 1060.37 L957.579 1060.37 L957.579 1065.33 L955.427 1065.33 Q950.496 1065.33 948.621 1067.34 Q946.746 1069.36 946.746 1074.6 L946.746 1082.9 Q946.746 1090.57 943.829 1093.14 Q940.947 1095.71 932.302 1095.71 L930.114 1095.71 L930.114 1090.71 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M461.228 1165.49 Q458.519 1172.43 455.95 1174.55 Q453.381 1176.67 449.075 1176.67 L443.971 1176.67 L443.971 1171.32 L447.721 1171.32 Q450.36 1171.32 451.818 1170.07 Q453.276 1168.82 455.047 1164.17 L456.193 1161.25 L440.464 1122.99 L447.235 1122.99 L459.388 1153.4 L471.54 1122.99 L478.311 1122.99 L461.228 1165.49 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M493.45 1111.95 L493.45 1122.99 L506.61 1122.99 L506.61 1127.95 L493.45 1127.95 L493.45 1149.06 Q493.45 1153.82 494.735 1155.17 Q496.054 1156.53 500.047 1156.53 L506.61 1156.53 L506.61 1161.88 L500.047 1161.88 Q492.651 1161.88 489.839 1159.13 Q487.026 1156.35 487.026 1149.06 L487.026 1127.95 L482.339 1127.95 L482.339 1122.99 L487.026 1122.99 L487.026 1111.95 L493.45 1111.95 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M537.547 1128.96 Q536.47 1128.33 535.186 1128.06 Q533.936 1127.74 532.408 1127.74 Q526.991 1127.74 524.075 1131.29 Q521.193 1134.79 521.193 1141.39 L521.193 1161.88 L514.769 1161.88 L514.769 1122.99 L521.193 1122.99 L521.193 1129.03 Q523.207 1125.49 526.436 1123.79 Q529.665 1122.05 534.283 1122.05 Q534.943 1122.05 535.741 1122.15 Q536.54 1122.22 537.512 1122.4 L537.547 1128.96 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M543.588 1146.53 L543.588 1122.99 L549.977 1122.99 L549.977 1146.29 Q549.977 1151.81 552.13 1154.58 Q554.283 1157.33 558.588 1157.33 Q563.762 1157.33 566.748 1154.03 Q569.769 1150.73 569.769 1145.04 L569.769 1122.99 L576.158 1122.99 L576.158 1161.88 L569.769 1161.88 L569.769 1155.9 Q567.443 1159.44 564.352 1161.18 Q561.297 1162.88 557.234 1162.88 Q550.533 1162.88 547.061 1158.72 Q543.588 1154.55 543.588 1146.53 M559.665 1122.05 L559.665 1122.05 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M622.581 1140.83 L622.581 1143.96 L593.206 1143.96 Q593.623 1150.56 597.165 1154.03 Q600.741 1157.47 607.095 1157.47 Q610.776 1157.47 614.213 1156.56 Q617.685 1155.66 621.088 1153.85 L621.088 1159.9 Q617.651 1161.35 614.039 1162.12 Q610.428 1162.88 606.713 1162.88 Q597.408 1162.88 591.956 1157.47 Q586.54 1152.05 586.54 1142.81 Q586.54 1133.26 591.678 1127.67 Q596.852 1122.05 605.602 1122.05 Q613.449 1122.05 617.998 1127.12 Q622.581 1132.15 622.581 1140.83 M616.192 1138.96 Q616.123 1133.72 613.241 1130.59 Q610.394 1127.47 605.671 1127.47 Q600.324 1127.47 597.095 1130.49 Q593.901 1133.51 593.415 1138.99 L616.192 1138.96 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M633.9 1129.58 L678.414 1129.58 L678.414 1135.42 L633.9 1135.42 L633.9 1129.58 M633.9 1143.75 L678.414 1143.75 L678.414 1149.65 L633.9 1149.65 L633.9 1143.75 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M691.782 1110.04 L725.115 1110.04 L725.115 1113.02 L706.296 1161.88 L698.97 1161.88 L716.678 1115.94 L691.782 1115.94 L691.782 1110.04 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1247.24 1011.02 L2352.76 1011.02 L2352.76 47.2441 L1247.24 47.2441  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip183">
    <rect x="1247" y="47" width="1107" height="965"></rect>
  </clippath>
</defs>
<g clip-path="url(#clip183)">
<image width="964" height="964" href="data:image/png;base64,
iVBORw0KGgoAAAANSUhEUgAAA8QAAAPECAYAAABorPL3AAAY9UlEQVR4nO3ZsYoehRrH4Vl3SEyl
YLoUxk1nK4KVglFrm0XihXkdpkzhCgmyQUJQBLHzArQKRNCAn8UHO3COyNF48n7J73mu4F/NzG/e
o2VZdgsAAADEvDQ9AAAAACYIYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAA
SBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIA
AACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmC
GAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABA
kiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMA
AJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLE
AAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACS
BDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAA
gCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAG
AAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAk
iAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAA
JAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEA
AABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRB
DAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAg
SRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEA
AEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAli
AAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJ
ghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAA
QNI6PQAAAJ5br746vWDz8cfTC5aj11+fnnBh99ln0xP2fvppegF/wYUYAACAJEEMAABAkiAGAAAg
SRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEA
AEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAli
AAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJ
6/QAAAD42y5fnl6w9+mn0ws2V69OL1h2jx9PT9j8+uv0Ap4DLsQAAAAkCWIAAACSBDEAAABJghgA
AIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIg
BgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQ
JIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAA
ACSt0wMAAHhOXLkyvWDzySfTC/auXp1esHnyZHrBsjx4ML1g8+jR9AKeAy7EAAAAJAliAAAAkgQx
AAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAk
QQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAA
IEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgB
AABIEsQAAAAkCWIAAACS1ukBAAD8hRs3phdsTk+nF1w4unx5esKyLMuy2+2mJ2zu3JlesCwPH04v
gL/FhRgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRB
DAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAg
SRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEA
AEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQNI6PQAA4CBduza9YO/mzekFm0uXphccntu3
pxdsvvtuegE8d1yIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQ
JIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAA
ACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQx
AAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkrdMDAAD+yzvvTC9Ylps3pxcs
y7IsR6vPtT+zu3dvesLet99OLwCeggsxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABI
EsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAA
AJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIY
AACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJ6/QAAOBAnJxML9i8
9970gmU5Pp5esCzLsux2u+kJm/Pz6QWbs7PpBcALwIUYAACAJEEMAABAkiAGAAAgSRADAACQJIgB
AABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJ
YgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAA
SYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJ6/QAAEi7cmV6
webWrekFm+Pj6QWH4/796QWbL76YXgDwr3IhBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQx
AAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAk
QQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAA
IEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQtE4P
AIARN25ML9g7PZ1ecOFoPZzPgt1uNz1hWb7/fnrB3v370ws2v/8+vQDgX+VCDAAAQJIgBgAAIEkQ
AwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABI
EsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAA
AJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIY
AACAJEEMAABA0jo9AICQt9+eXrC5eXN6wd6lS9MLDtP5+fSCZfnqq+kFe7/8Mr0A4IXlQgwAAECS
IAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAA
kCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQA
AAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIE
MQAAAEmCGAAAgCRBDAAAQJIgBgAAIGmdHgDAM3JyMr1gWT76aHrBhaPVK/A/7e7dm56wOTubXgBA
gAsxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgA
AIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIg
BgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQ
JIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAICkdXoAwAvv5GR6wd7p6fSCZTk+nl5wYff48fSE
va+/nl6wuXt3egEAPFMuxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSI
AQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAk
CWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAA
AEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASFqnBwD8X1y7Nr1gc+vW9IK94+PpBcvy5Mn0
gs2DB9ML9u7enV4AAFkuxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSI
AQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAk
CWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAA
AEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJK3TA4AXyMsvTy/YvP/+9IILR+th
PGp3u930hGW5c2d6webhw+kFAMAwF2IAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAk
iAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAA
JAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEA
AABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEnr9ADgBfLB
B9MLNm+8Mb3g8JyfTy9Ylm++mV4AAHDBhRgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAA
ACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQx
AAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAk
QQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQNI6PQB4
Sm++Ob3gwtFbb01POEi7e/emJ+ydnU0vAAA4KC7EAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABA
kiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMA
AJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLE
AAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkrdMD4Ll1
/fr0gr0PP5xecGG3201P2Pzww/SCzdnZ9AIAAP6ECzEAAABJghgAAIAkQQwAAECSIAYAACBJEAMA
AJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLE
AAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACS
BDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAA
gKR1egD8Iy8dwL+cd9+dXrD3yivTCzY//ji9YPP559MLAAA4cAdQFQAAAPDsCWIAAACSBDEAAABJ
ghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAA
QJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRAD
AACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEha
pwfAP/Laa9MLluX69ekFez//PL1gc/v29ILNb79NLwAA4MC5EAMAAJAkiAEAAEgSxAAAACQJYgAA
AJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIY
AACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECS
IAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAA
kCSIAQAASFqnBwBP6csvpxdsHj2aXgAAAP8zF2IAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJ
EAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAA
SBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIA
AACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJKOlmXZTY8A
AACAZ82FGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACA
JEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYA
ACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSI
AQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAk
CWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAA
AEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEM
AABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIAAACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJ
EAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmCGAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAA
SBLEAAAAJAliAAAAkgQxAAAASYIYAACAJEEMAABAkiAGAAAgSRADAACQJIgBAABIEsQAAAAkCWIA
AACSBDEAAABJghgAAIAkQQwAAECSIAYAACBJEAMAAJAkiAEAAEgSxAAAACQJYgAAAJIEMQAAAEmC
GAAAgCRBDAAAQJIgBgAAIEkQAwAAkCSIAQAASBLEAAAAJAliAAAAkv4A3XR5beO14yUAAAAASUVO
RK5CYII=
" transform="translate(1318, 47)"></image>
</g>
<path clip-path="url(#clip180)" d="M1427.18 1036.27 L1427.18 1043.66 Q1423.64 1040.37 1419.61 1038.73 Q1415.62 1037.1 1411.11 1037.1 Q1402.22 1037.1 1397.5 1042.55 Q1392.77 1047.97 1392.77 1058.25 Q1392.77 1068.49 1397.5 1073.94 Q1402.22 1079.36 1411.11 1079.36 Q1415.62 1079.36 1419.61 1077.73 Q1423.64 1076.09 1427.18 1072.8 L1427.18 1080.12 Q1423.5 1082.62 1419.37 1083.87 Q1415.27 1085.12 1410.69 1085.12 Q1398.92 1085.12 1392.15 1077.93 Q1385.38 1070.71 1385.38 1058.25 Q1385.38 1045.75 1392.15 1038.56 Q1398.92 1031.34 1410.69 1031.34 Q1415.34 1031.34 1419.44 1032.59 Q1423.57 1033.8 1427.18 1036.27 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1438.57 1051.82 L1483.09 1051.82 L1483.09 1057.66 L1438.57 1057.66 L1438.57 1051.82 M1438.57 1065.99 L1483.09 1065.99 L1483.09 1071.89 L1438.57 1071.89 L1438.57 1065.99 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1526.98 1090.71 L1526.98 1095.71 L1524.82 1095.71 Q1516.18 1095.71 1513.23 1093.14 Q1510.31 1090.57 1510.31 1082.9 L1510.31 1074.6 Q1510.31 1069.36 1508.43 1067.34 Q1506.56 1065.33 1501.63 1065.33 L1499.51 1065.33 L1499.51 1060.37 L1501.63 1060.37 Q1506.59 1060.37 1508.43 1058.39 Q1510.31 1056.37 1510.31 1051.2 L1510.31 1042.87 Q1510.31 1035.19 1513.23 1032.66 Q1516.18 1030.09 1524.82 1030.09 L1526.98 1030.09 L1526.98 1035.05 L1524.61 1035.05 Q1519.72 1035.05 1518.23 1036.58 Q1516.73 1038.11 1516.73 1043 L1516.73 1051.62 Q1516.73 1057.07 1515.13 1059.53 Q1513.57 1062 1509.75 1062.87 Q1513.61 1063.8 1515.17 1066.27 Q1516.73 1068.73 1516.73 1074.15 L1516.73 1082.76 Q1516.73 1087.66 1518.23 1089.18 Q1519.72 1090.71 1524.61 1090.71 L1526.98 1090.71 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1544.68 1078.21 L1556.14 1078.21 L1556.14 1038.66 L1543.68 1041.16 L1543.68 1034.78 L1556.07 1032.28 L1563.09 1032.28 L1563.09 1078.21 L1574.54 1078.21 L1574.54 1084.12 L1544.68 1084.12 L1544.68 1078.21 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1625.76 1030.16 Q1621.11 1038.14 1618.85 1045.96 Q1616.59 1053.77 1616.59 1061.79 Q1616.59 1069.81 1618.85 1077.69 Q1621.14 1085.54 1625.76 1093.49 L1620.2 1093.49 Q1615 1085.33 1612.39 1077.45 Q1609.82 1069.57 1609.82 1061.79 Q1609.82 1054.05 1612.39 1046.2 Q1614.96 1038.35 1620.2 1030.16 L1625.76 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1640.27 1078.21 L1651.73 1078.21 L1651.73 1038.66 L1639.27 1041.16 L1639.27 1034.78 L1651.66 1032.28 L1658.68 1032.28 L1658.68 1078.21 L1670.13 1078.21 L1670.13 1084.12 L1640.27 1084.12 L1640.27 1078.21 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1703.57 1038.39 L1685.86 1066.06 L1703.57 1066.06 L1703.57 1038.39 M1701.73 1032.28 L1710.55 1032.28 L1710.55 1066.06 L1717.95 1066.06 L1717.95 1071.89 L1710.55 1071.89 L1710.55 1084.12 L1703.57 1084.12 L1703.57 1071.89 L1680.17 1071.89 L1680.17 1065.12 L1701.73 1032.28 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1773.64 1061.3 Q1770.62 1061.3 1768.88 1063.87 Q1767.18 1066.44 1767.18 1071.03 Q1767.18 1075.54 1768.88 1078.14 Q1770.62 1080.71 1773.64 1080.71 Q1776.59 1080.71 1778.29 1078.14 Q1780.03 1075.54 1780.03 1071.03 Q1780.03 1066.48 1778.29 1063.91 Q1776.59 1061.3 1773.64 1061.3 M1773.64 1056.89 Q1779.13 1056.89 1782.36 1060.71 Q1785.58 1064.53 1785.58 1071.03 Q1785.58 1077.52 1782.32 1081.34 Q1779.09 1085.12 1773.64 1085.12 Q1768.08 1085.12 1764.86 1081.34 Q1761.63 1077.52 1761.63 1071.03 Q1761.63 1064.5 1764.86 1060.71 Q1768.12 1056.89 1773.64 1056.89 M1737.81 1035.75 Q1734.82 1035.75 1733.09 1038.35 Q1731.38 1040.92 1731.38 1045.44 Q1731.38 1050.02 1733.09 1052.59 Q1734.79 1055.16 1737.81 1055.16 Q1740.83 1055.16 1742.53 1052.59 Q1744.27 1050.02 1744.27 1045.44 Q1744.27 1040.96 1742.53 1038.35 Q1740.79 1035.75 1737.81 1035.75 M1769.16 1031.34 L1774.72 1031.34 L1742.29 1085.12 L1736.73 1085.12 L1769.16 1031.34 M1737.81 1031.34 Q1743.29 1031.34 1746.56 1035.16 Q1749.82 1038.94 1749.82 1045.44 Q1749.82 1052 1746.56 1055.78 Q1743.33 1059.57 1737.81 1059.57 Q1732.29 1059.57 1729.06 1055.78 Q1725.86 1051.96 1725.86 1045.44 Q1725.86 1038.98 1729.09 1035.16 Q1732.32 1031.34 1737.81 1031.34 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1795.2 1030.16 L1800.76 1030.16 Q1805.97 1038.35 1808.54 1046.2 Q1811.14 1054.05 1811.14 1061.79 Q1811.14 1069.57 1808.54 1077.45 Q1805.97 1085.33 1800.76 1093.49 L1795.2 1093.49 Q1799.82 1085.54 1802.08 1077.69 Q1804.37 1069.81 1804.37 1061.79 Q1804.37 1053.77 1802.08 1045.96 Q1799.82 1038.14 1795.2 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1825.58 1075.3 L1832.91 1075.3 L1832.91 1081.27 L1827.22 1092.38 L1822.74 1092.38 L1825.58 1081.27 L1825.58 1075.3 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1885.06 1059.5 Q1880.06 1059.5 1877.18 1062.17 Q1874.33 1064.84 1874.33 1069.53 Q1874.33 1074.22 1877.18 1076.89 Q1880.06 1079.57 1885.06 1079.57 Q1890.06 1079.57 1892.95 1076.89 Q1895.83 1074.18 1895.83 1069.53 Q1895.83 1064.84 1892.95 1062.17 Q1890.1 1059.5 1885.06 1059.5 M1878.05 1056.51 Q1873.54 1055.4 1871 1052.31 Q1868.5 1049.22 1868.5 1044.78 Q1868.5 1038.56 1872.91 1034.95 Q1877.36 1031.34 1885.06 1031.34 Q1892.81 1031.34 1897.22 1034.95 Q1901.63 1038.56 1901.63 1044.78 Q1901.63 1049.22 1899.09 1052.31 Q1896.59 1055.4 1892.11 1056.51 Q1897.18 1057.69 1899.99 1061.13 Q1902.84 1064.57 1902.84 1069.53 Q1902.84 1077.07 1898.22 1081.09 Q1893.64 1085.12 1885.06 1085.12 Q1876.49 1085.12 1871.87 1081.09 Q1867.29 1077.07 1867.29 1069.53 Q1867.29 1064.57 1870.13 1061.13 Q1872.98 1057.69 1878.05 1056.51 M1875.48 1045.44 Q1875.48 1049.46 1877.98 1051.72 Q1880.51 1053.98 1885.06 1053.98 Q1889.58 1053.98 1892.11 1051.72 Q1894.68 1049.46 1894.68 1045.44 Q1894.68 1041.41 1892.11 1039.15 Q1889.58 1036.89 1885.06 1036.89 Q1880.51 1036.89 1877.98 1039.15 Q1875.48 1041.41 1875.48 1045.44 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1952.35 1030.16 Q1947.7 1038.14 1945.45 1045.96 Q1943.19 1053.77 1943.19 1061.79 Q1943.19 1069.81 1945.45 1077.69 Q1947.74 1085.54 1952.35 1093.49 L1946.8 1093.49 Q1941.59 1085.33 1938.99 1077.45 Q1936.42 1069.57 1936.42 1061.79 Q1936.42 1054.05 1938.99 1046.2 Q1941.56 1038.35 1946.8 1030.16 L1952.35 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1980.65 1059.5 Q1975.65 1059.5 1972.77 1062.17 Q1969.92 1064.84 1969.92 1069.53 Q1969.92 1074.22 1972.77 1076.89 Q1975.65 1079.57 1980.65 1079.57 Q1985.65 1079.57 1988.54 1076.89 Q1991.42 1074.18 1991.42 1069.53 Q1991.42 1064.84 1988.54 1062.17 Q1985.69 1059.5 1980.65 1059.5 M1973.64 1056.51 Q1969.13 1055.4 1966.59 1052.31 Q1964.09 1049.22 1964.09 1044.78 Q1964.09 1038.56 1968.5 1034.95 Q1972.94 1031.34 1980.65 1031.34 Q1988.4 1031.34 1992.81 1034.95 Q1997.22 1038.56 1997.22 1044.78 Q1997.22 1049.22 1994.68 1052.31 Q1992.18 1055.4 1987.7 1056.51 Q1992.77 1057.69 1995.58 1061.13 Q1998.43 1064.57 1998.43 1069.53 Q1998.43 1077.07 1993.81 1081.09 Q1989.23 1085.12 1980.65 1085.12 Q1972.08 1085.12 1967.46 1081.09 Q1962.88 1077.07 1962.88 1069.53 Q1962.88 1064.57 1965.72 1061.13 Q1968.57 1057.69 1973.64 1056.51 M1971.07 1045.44 Q1971.07 1049.46 1973.57 1051.72 Q1976.1 1053.98 1980.65 1053.98 Q1985.17 1053.98 1987.7 1051.72 Q1990.27 1049.46 1990.27 1045.44 Q1990.27 1041.41 1987.7 1039.15 Q1985.17 1036.89 1980.65 1036.89 Q1976.1 1036.89 1973.57 1039.15 Q1971.07 1041.41 1971.07 1045.44 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2010.97 1032.28 L2038.5 1032.28 L2038.5 1038.18 L2017.39 1038.18 L2017.39 1050.89 Q2018.92 1050.37 2020.44 1050.12 Q2021.97 1049.84 2023.5 1049.84 Q2032.18 1049.84 2037.25 1054.6 Q2042.32 1059.36 2042.32 1067.48 Q2042.32 1075.85 2037.11 1080.5 Q2031.9 1085.12 2022.42 1085.12 Q2019.16 1085.12 2015.76 1084.57 Q2012.39 1084.01 2008.78 1082.9 L2008.78 1075.85 Q2011.9 1077.55 2015.24 1078.39 Q2018.57 1079.22 2022.28 1079.22 Q2028.29 1079.22 2031.8 1076.06 Q2035.31 1072.9 2035.31 1067.48 Q2035.31 1062.07 2031.8 1058.91 Q2028.29 1055.75 2022.28 1055.75 Q2019.47 1055.75 2016.66 1056.37 Q2013.88 1057 2010.97 1058.32 L2010.97 1032.28 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2100.24 1061.3 Q2097.22 1061.3 2095.48 1063.87 Q2093.78 1066.44 2093.78 1071.03 Q2093.78 1075.54 2095.48 1078.14 Q2097.22 1080.71 2100.24 1080.71 Q2103.19 1080.71 2104.89 1078.14 Q2106.62 1075.54 2106.62 1071.03 Q2106.62 1066.48 2104.89 1063.91 Q2103.19 1061.3 2100.24 1061.3 M2100.24 1056.89 Q2105.72 1056.89 2108.95 1060.71 Q2112.18 1064.53 2112.18 1071.03 Q2112.18 1077.52 2108.92 1081.34 Q2105.69 1085.12 2100.24 1085.12 Q2094.68 1085.12 2091.45 1081.34 Q2088.22 1077.52 2088.22 1071.03 Q2088.22 1064.5 2091.45 1060.71 Q2094.72 1056.89 2100.24 1056.89 M2064.4 1035.75 Q2061.42 1035.75 2059.68 1038.35 Q2057.98 1040.92 2057.98 1045.44 Q2057.98 1050.02 2059.68 1052.59 Q2061.38 1055.16 2064.4 1055.16 Q2067.42 1055.16 2069.12 1052.59 Q2070.86 1050.02 2070.86 1045.44 Q2070.86 1040.96 2069.12 1038.35 Q2067.39 1035.75 2064.4 1035.75 M2095.76 1031.34 L2101.31 1031.34 L2068.88 1085.12 L2063.33 1085.12 L2095.76 1031.34 M2064.4 1031.34 Q2069.89 1031.34 2073.15 1035.16 Q2076.42 1038.94 2076.42 1045.44 Q2076.42 1052 2073.15 1055.78 Q2069.92 1059.57 2064.4 1059.57 Q2058.88 1059.57 2055.65 1055.78 Q2052.46 1051.96 2052.46 1045.44 Q2052.46 1038.98 2055.69 1035.16 Q2058.92 1031.34 2064.4 1031.34 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2121.8 1030.16 L2127.35 1030.16 Q2132.56 1038.35 2135.13 1046.2 Q2137.74 1054.05 2137.74 1061.79 Q2137.74 1069.57 2135.13 1077.45 Q2132.56 1085.33 2127.35 1093.49 L2121.8 1093.49 Q2126.42 1085.54 2128.67 1077.69 Q2130.96 1069.81 2130.96 1061.79 Q2130.96 1053.77 2128.67 1045.96 Q2126.42 1038.14 2121.8 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2152.74 1090.71 L2155.17 1090.71 Q2160.03 1090.71 2161.49 1089.22 Q2162.98 1087.73 2162.98 1082.76 L2162.98 1074.15 Q2162.98 1068.73 2164.54 1066.27 Q2166.1 1063.8 2169.96 1062.87 Q2166.1 1062 2164.54 1059.53 Q2162.98 1057.07 2162.98 1051.62 L2162.98 1043 Q2162.98 1038.07 2161.49 1036.58 Q2160.03 1035.05 2155.17 1035.05 L2152.74 1035.05 L2152.74 1030.09 L2154.92 1030.09 Q2163.57 1030.09 2166.45 1032.66 Q2169.37 1035.19 2169.37 1042.87 L2169.37 1051.2 Q2169.37 1056.37 2171.24 1058.39 Q2173.12 1060.37 2178.05 1060.37 L2180.2 1060.37 L2180.2 1065.33 L2178.05 1065.33 Q2173.12 1065.33 2171.24 1067.34 Q2169.37 1069.36 2169.37 1074.6 L2169.37 1082.9 Q2169.37 1090.57 2166.45 1093.14 Q2163.57 1095.71 2154.92 1095.71 L2152.74 1095.71 L2152.74 1090.71 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1661.47 1165.49 Q1658.76 1172.43 1656.19 1174.55 Q1653.62 1176.67 1649.32 1176.67 L1644.21 1176.67 L1644.21 1171.32 L1647.96 1171.32 Q1650.6 1171.32 1652.06 1170.07 Q1653.52 1168.82 1655.29 1164.17 L1656.44 1161.25 L1640.71 1122.99 L1647.48 1122.99 L1659.63 1153.4 L1671.78 1122.99 L1678.55 1122.99 L1661.47 1165.49 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1693.69 1111.95 L1693.69 1122.99 L1706.85 1122.99 L1706.85 1127.95 L1693.69 1127.95 L1693.69 1149.06 Q1693.69 1153.82 1694.98 1155.17 Q1696.3 1156.53 1700.29 1156.53 L1706.85 1156.53 L1706.85 1161.88 L1700.29 1161.88 Q1692.89 1161.88 1690.08 1159.13 Q1687.27 1156.35 1687.27 1149.06 L1687.27 1127.95 L1682.58 1127.95 L1682.58 1122.99 L1687.27 1122.99 L1687.27 1111.95 L1693.69 1111.95 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1737.79 1128.96 Q1736.71 1128.33 1735.43 1128.06 Q1734.18 1127.74 1732.65 1127.74 Q1727.23 1127.74 1724.32 1131.29 Q1721.44 1134.79 1721.44 1141.39 L1721.44 1161.88 L1715.01 1161.88 L1715.01 1122.99 L1721.44 1122.99 L1721.44 1129.03 Q1723.45 1125.49 1726.68 1123.79 Q1729.91 1122.05 1734.53 1122.05 Q1735.19 1122.05 1735.98 1122.15 Q1736.78 1122.22 1737.76 1122.4 L1737.79 1128.96 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1743.83 1146.53 L1743.83 1122.99 L1750.22 1122.99 L1750.22 1146.29 Q1750.22 1151.81 1752.37 1154.58 Q1754.53 1157.33 1758.83 1157.33 Q1764.01 1157.33 1766.99 1154.03 Q1770.01 1150.73 1770.01 1145.04 L1770.01 1122.99 L1776.4 1122.99 L1776.4 1161.88 L1770.01 1161.88 L1770.01 1155.9 Q1767.69 1159.44 1764.6 1161.18 Q1761.54 1162.88 1757.48 1162.88 Q1750.78 1162.88 1747.3 1158.72 Q1743.83 1154.55 1743.83 1146.53 M1759.91 1122.05 L1759.91 1122.05 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1822.82 1140.83 L1822.82 1143.96 L1793.45 1143.96 Q1793.87 1150.56 1797.41 1154.03 Q1800.98 1157.47 1807.34 1157.47 Q1811.02 1157.47 1814.46 1156.56 Q1817.93 1155.66 1821.33 1153.85 L1821.33 1159.9 Q1817.89 1161.35 1814.28 1162.12 Q1810.67 1162.88 1806.96 1162.88 Q1797.65 1162.88 1792.2 1157.47 Q1786.78 1152.05 1786.78 1142.81 Q1786.78 1133.26 1791.92 1127.67 Q1797.1 1122.05 1805.85 1122.05 Q1813.69 1122.05 1818.24 1127.12 Q1822.82 1132.15 1822.82 1140.83 M1816.44 1138.96 Q1816.37 1133.72 1813.48 1130.59 Q1810.64 1127.47 1805.91 1127.47 Q1800.57 1127.47 1797.34 1130.49 Q1794.14 1133.51 1793.66 1138.99 L1816.44 1138.96 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1834.14 1129.58 L1878.66 1129.58 L1878.66 1135.42 L1834.14 1135.42 L1834.14 1129.58 M1834.14 1143.75 L1878.66 1143.75 L1878.66 1149.65 L1834.14 1149.65 L1834.14 1143.75 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M1895.01 1155.97 L1906.47 1155.97 L1906.47 1116.42 L1894 1118.92 L1894 1112.54 L1906.4 1110.04 L1913.41 1110.04 L1913.41 1155.97 L1924.87 1155.97 L1924.87 1161.88 L1895.01 1161.88 L1895.01 1155.97 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2447.24 1011.02 L3552.76 1011.02 L3552.76 47.2441 L2447.24 47.2441  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip184">
    <rect x="2447" y="47" width="1107" height="965"></rect>
  </clippath>
</defs>
<g clip-path="url(#clip184)">
<image width="964" height="964" href="data:image/png;base64,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" transform="translate(2518, 47)"></image>
</g>
<path clip-path="url(#clip180)" d="M2627.18 1036.27 L2627.18 1043.66 Q2623.64 1040.37 2619.61 1038.73 Q2615.62 1037.1 2611.11 1037.1 Q2602.22 1037.1 2597.5 1042.55 Q2592.77 1047.97 2592.77 1058.25 Q2592.77 1068.49 2597.5 1073.94 Q2602.22 1079.36 2611.11 1079.36 Q2615.62 1079.36 2619.61 1077.73 Q2623.64 1076.09 2627.18 1072.8 L2627.18 1080.12 Q2623.5 1082.62 2619.37 1083.87 Q2615.27 1085.12 2610.69 1085.12 Q2598.92 1085.12 2592.15 1077.93 Q2585.38 1070.71 2585.38 1058.25 Q2585.38 1045.75 2592.15 1038.56 Q2598.92 1031.34 2610.69 1031.34 Q2615.34 1031.34 2619.44 1032.59 Q2623.57 1033.8 2627.18 1036.27 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2638.57 1051.82 L2683.09 1051.82 L2683.09 1057.66 L2638.57 1057.66 L2638.57 1051.82 M2638.57 1065.99 L2683.09 1065.99 L2683.09 1071.89 L2638.57 1071.89 L2638.57 1065.99 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2726.98 1090.71 L2726.98 1095.71 L2724.82 1095.71 Q2716.18 1095.71 2713.23 1093.14 Q2710.31 1090.57 2710.31 1082.9 L2710.31 1074.6 Q2710.31 1069.36 2708.43 1067.34 Q2706.56 1065.33 2701.63 1065.33 L2699.51 1065.33 L2699.51 1060.37 L2701.63 1060.37 Q2706.59 1060.37 2708.43 1058.39 Q2710.31 1056.37 2710.31 1051.2 L2710.31 1042.87 Q2710.31 1035.19 2713.23 1032.66 Q2716.18 1030.09 2724.82 1030.09 L2726.98 1030.09 L2726.98 1035.05 L2724.61 1035.05 Q2719.72 1035.05 2718.23 1036.58 Q2716.73 1038.11 2716.73 1043 L2716.73 1051.62 Q2716.73 1057.07 2715.13 1059.53 Q2713.57 1062 2709.75 1062.87 Q2713.61 1063.8 2715.17 1066.27 Q2716.73 1068.73 2716.73 1074.15 L2716.73 1082.76 Q2716.73 1087.66 2718.23 1089.18 Q2719.72 1090.71 2724.61 1090.71 L2726.98 1090.71 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2743.54 1032.28 L2771.07 1032.28 L2771.07 1038.18 L2749.96 1038.18 L2749.96 1050.89 Q2751.49 1050.37 2753.02 1050.12 Q2754.54 1049.84 2756.07 1049.84 Q2764.75 1049.84 2769.82 1054.6 Q2774.89 1059.36 2774.89 1067.48 Q2774.89 1075.85 2769.68 1080.5 Q2764.47 1085.12 2755 1085.12 Q2751.73 1085.12 2748.33 1084.57 Q2744.96 1084.01 2741.35 1082.9 L2741.35 1075.85 Q2744.47 1077.55 2747.81 1078.39 Q2751.14 1079.22 2754.86 1079.22 Q2760.86 1079.22 2764.37 1076.06 Q2767.88 1072.9 2767.88 1067.48 Q2767.88 1062.07 2764.37 1058.91 Q2760.86 1055.75 2754.86 1055.75 Q2752.04 1055.75 2749.23 1056.37 Q2746.45 1057 2743.54 1058.32 L2743.54 1032.28 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2825.76 1030.16 Q2821.11 1038.14 2818.85 1045.96 Q2816.59 1053.77 2816.59 1061.79 Q2816.59 1069.81 2818.85 1077.69 Q2821.14 1085.54 2825.76 1093.49 L2820.2 1093.49 Q2815 1085.33 2812.39 1077.45 Q2809.82 1069.57 2809.82 1061.79 Q2809.82 1054.05 2812.39 1046.2 Q2814.96 1038.35 2820.2 1030.16 L2825.76 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2854.06 1059.5 Q2849.06 1059.5 2846.18 1062.17 Q2843.33 1064.84 2843.33 1069.53 Q2843.33 1074.22 2846.18 1076.89 Q2849.06 1079.57 2854.06 1079.57 Q2859.06 1079.57 2861.94 1076.89 Q2864.82 1074.18 2864.82 1069.53 Q2864.82 1064.84 2861.94 1062.17 Q2859.09 1059.5 2854.06 1059.5 M2847.04 1056.51 Q2842.53 1055.4 2840 1052.31 Q2837.5 1049.22 2837.5 1044.78 Q2837.5 1038.56 2841.9 1034.95 Q2846.35 1031.34 2854.06 1031.34 Q2861.8 1031.34 2866.21 1034.95 Q2870.62 1038.56 2870.62 1044.78 Q2870.62 1049.22 2868.09 1052.31 Q2865.59 1055.4 2861.11 1056.51 Q2866.18 1057.69 2868.99 1061.13 Q2871.84 1064.57 2871.84 1069.53 Q2871.84 1077.07 2867.22 1081.09 Q2862.63 1085.12 2854.06 1085.12 Q2845.48 1085.12 2840.86 1081.09 Q2836.28 1077.07 2836.28 1069.53 Q2836.28 1064.57 2839.13 1061.13 Q2841.97 1057.69 2847.04 1056.51 M2844.47 1045.44 Q2844.47 1049.46 2846.97 1051.72 Q2849.51 1053.98 2854.06 1053.98 Q2858.57 1053.98 2861.11 1051.72 Q2863.68 1049.46 2863.68 1045.44 Q2863.68 1041.41 2861.11 1039.15 Q2858.57 1036.89 2854.06 1036.89 Q2849.51 1036.89 2846.97 1039.15 Q2844.47 1041.41 2844.47 1045.44 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2905.55 1056.16 Q2910.59 1057.24 2913.4 1060.64 Q2916.24 1064.05 2916.24 1069.05 Q2916.24 1076.72 2910.97 1080.92 Q2905.69 1085.12 2895.97 1085.12 Q2892.7 1085.12 2889.23 1084.46 Q2885.79 1083.84 2882.11 1082.55 L2882.11 1075.78 Q2885.03 1077.48 2888.5 1078.35 Q2891.97 1079.22 2895.76 1079.22 Q2902.36 1079.22 2905.79 1076.62 Q2909.27 1074.01 2909.27 1069.05 Q2909.27 1064.46 2906.04 1061.89 Q2902.84 1059.29 2897.11 1059.29 L2891.07 1059.29 L2891.07 1053.53 L2897.39 1053.53 Q2902.56 1053.53 2905.31 1051.48 Q2908.05 1049.39 2908.05 1045.5 Q2908.05 1041.51 2905.2 1039.39 Q2902.39 1037.24 2897.11 1037.24 Q2894.23 1037.24 2890.93 1037.87 Q2887.63 1038.49 2883.68 1039.81 L2883.68 1033.56 Q2887.67 1032.45 2891.14 1031.89 Q2894.65 1031.34 2897.74 1031.34 Q2905.72 1031.34 2910.38 1034.98 Q2915.03 1038.59 2915.03 1044.78 Q2915.03 1049.08 2912.56 1052.07 Q2910.1 1055.02 2905.55 1056.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2973.64 1061.3 Q2970.62 1061.3 2968.88 1063.87 Q2967.18 1066.44 2967.18 1071.03 Q2967.18 1075.54 2968.88 1078.14 Q2970.62 1080.71 2973.64 1080.71 Q2976.59 1080.71 2978.29 1078.14 Q2980.03 1075.54 2980.03 1071.03 Q2980.03 1066.48 2978.29 1063.91 Q2976.59 1061.3 2973.64 1061.3 M2973.64 1056.89 Q2979.13 1056.89 2982.36 1060.71 Q2985.58 1064.53 2985.58 1071.03 Q2985.58 1077.52 2982.32 1081.34 Q2979.09 1085.12 2973.64 1085.12 Q2968.08 1085.12 2964.86 1081.34 Q2961.63 1077.52 2961.63 1071.03 Q2961.63 1064.5 2964.86 1060.71 Q2968.12 1056.89 2973.64 1056.89 M2937.81 1035.75 Q2934.82 1035.75 2933.09 1038.35 Q2931.38 1040.92 2931.38 1045.44 Q2931.38 1050.02 2933.09 1052.59 Q2934.79 1055.16 2937.81 1055.16 Q2940.83 1055.16 2942.53 1052.59 Q2944.27 1050.02 2944.27 1045.44 Q2944.27 1040.96 2942.53 1038.35 Q2940.79 1035.75 2937.81 1035.75 M2969.16 1031.34 L2974.72 1031.34 L2942.29 1085.12 L2936.73 1085.12 L2969.16 1031.34 M2937.81 1031.34 Q2943.29 1031.34 2946.56 1035.16 Q2949.82 1038.94 2949.82 1045.44 Q2949.82 1052 2946.56 1055.78 Q2943.33 1059.57 2937.81 1059.57 Q2932.29 1059.57 2929.06 1055.78 Q2925.86 1051.96 2925.86 1045.44 Q2925.86 1038.98 2929.09 1035.16 Q2932.32 1031.34 2937.81 1031.34 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2995.2 1030.16 L3000.76 1030.16 Q3005.97 1038.35 3008.54 1046.2 Q3011.14 1054.05 3011.14 1061.79 Q3011.14 1069.57 3008.54 1077.45 Q3005.97 1085.33 3000.76 1093.49 L2995.2 1093.49 Q2999.82 1085.54 3002.08 1077.69 Q3004.37 1069.81 3004.37 1061.79 Q3004.37 1053.77 3002.08 1045.96 Q2999.82 1038.14 2995.2 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3025.58 1075.3 L3032.91 1075.3 L3032.91 1081.27 L3027.22 1092.38 L3022.74 1092.38 L3025.58 1081.27 L3025.58 1075.3 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3085.06 1059.5 Q3080.06 1059.5 3077.18 1062.17 Q3074.33 1064.84 3074.33 1069.53 Q3074.33 1074.22 3077.18 1076.89 Q3080.06 1079.57 3085.06 1079.57 Q3090.06 1079.57 3092.95 1076.89 Q3095.83 1074.18 3095.83 1069.53 Q3095.83 1064.84 3092.95 1062.17 Q3090.1 1059.5 3085.06 1059.5 M3078.05 1056.51 Q3073.54 1055.4 3071 1052.31 Q3068.5 1049.22 3068.5 1044.78 Q3068.5 1038.56 3072.91 1034.95 Q3077.36 1031.34 3085.06 1031.34 Q3092.81 1031.34 3097.22 1034.95 Q3101.63 1038.56 3101.63 1044.78 Q3101.63 1049.22 3099.09 1052.31 Q3096.59 1055.4 3092.11 1056.51 Q3097.18 1057.69 3099.99 1061.13 Q3102.84 1064.57 3102.84 1069.53 Q3102.84 1077.07 3098.22 1081.09 Q3093.64 1085.12 3085.06 1085.12 Q3076.49 1085.12 3071.87 1081.09 Q3067.29 1077.07 3067.29 1069.53 Q3067.29 1064.57 3070.13 1061.13 Q3072.98 1057.69 3078.05 1056.51 M3075.48 1045.44 Q3075.48 1049.46 3077.98 1051.72 Q3080.51 1053.98 3085.06 1053.98 Q3089.58 1053.98 3092.11 1051.72 Q3094.68 1049.46 3094.68 1045.44 Q3094.68 1041.41 3092.11 1039.15 Q3089.58 1036.89 3085.06 1036.89 Q3080.51 1036.89 3077.98 1039.15 Q3075.48 1041.41 3075.48 1045.44 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3152.35 1030.16 Q3147.7 1038.14 3145.45 1045.96 Q3143.19 1053.77 3143.19 1061.79 Q3143.19 1069.81 3145.45 1077.69 Q3147.74 1085.54 3152.35 1093.49 L3146.8 1093.49 Q3141.59 1085.33 3138.99 1077.45 Q3136.42 1069.57 3136.42 1061.79 Q3136.42 1054.05 3138.99 1046.2 Q3141.56 1038.35 3146.8 1030.16 L3152.35 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3166.87 1078.21 L3178.33 1078.21 L3178.33 1038.66 L3165.86 1041.16 L3165.86 1034.78 L3178.26 1032.28 L3185.27 1032.28 L3185.27 1078.21 L3196.73 1078.21 L3196.73 1084.12 L3166.87 1084.12 L3166.87 1078.21 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3210.97 1032.28 L3238.5 1032.28 L3238.5 1038.18 L3217.39 1038.18 L3217.39 1050.89 Q3218.92 1050.37 3220.44 1050.12 Q3221.97 1049.84 3223.5 1049.84 Q3232.18 1049.84 3237.25 1054.6 Q3242.32 1059.36 3242.32 1067.48 Q3242.32 1075.85 3237.11 1080.5 Q3231.9 1085.12 3222.42 1085.12 Q3219.16 1085.12 3215.76 1084.57 Q3212.39 1084.01 3208.78 1082.9 L3208.78 1075.85 Q3211.9 1077.55 3215.24 1078.39 Q3218.57 1079.22 3222.28 1079.22 Q3228.29 1079.22 3231.8 1076.06 Q3235.31 1072.9 3235.31 1067.48 Q3235.31 1062.07 3231.8 1058.91 Q3228.29 1055.75 3222.28 1055.75 Q3219.47 1055.75 3216.66 1056.37 Q3213.88 1057 3210.97 1058.32 L3210.97 1032.28 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3300.24 1061.3 Q3297.22 1061.3 3295.48 1063.87 Q3293.78 1066.44 3293.78 1071.03 Q3293.78 1075.54 3295.48 1078.14 Q3297.22 1080.71 3300.24 1080.71 Q3303.19 1080.71 3304.89 1078.14 Q3306.62 1075.54 3306.62 1071.03 Q3306.62 1066.48 3304.89 1063.91 Q3303.19 1061.3 3300.24 1061.3 M3300.24 1056.89 Q3305.72 1056.89 3308.95 1060.71 Q3312.18 1064.53 3312.18 1071.03 Q3312.18 1077.52 3308.92 1081.34 Q3305.69 1085.12 3300.24 1085.12 Q3294.68 1085.12 3291.45 1081.34 Q3288.22 1077.52 3288.22 1071.03 Q3288.22 1064.5 3291.45 1060.71 Q3294.72 1056.89 3300.24 1056.89 M3264.4 1035.75 Q3261.42 1035.75 3259.68 1038.35 Q3257.98 1040.92 3257.98 1045.44 Q3257.98 1050.02 3259.68 1052.59 Q3261.38 1055.16 3264.4 1055.16 Q3267.42 1055.16 3269.12 1052.59 Q3270.86 1050.02 3270.86 1045.44 Q3270.86 1040.96 3269.12 1038.35 Q3267.39 1035.75 3264.4 1035.75 M3295.76 1031.34 L3301.31 1031.34 L3268.88 1085.12 L3263.33 1085.12 L3295.76 1031.34 M3264.4 1031.34 Q3269.89 1031.34 3273.15 1035.16 Q3276.42 1038.94 3276.42 1045.44 Q3276.42 1052 3273.15 1055.78 Q3269.92 1059.57 3264.4 1059.57 Q3258.88 1059.57 3255.65 1055.78 Q3252.46 1051.96 3252.46 1045.44 Q3252.46 1038.98 3255.69 1035.16 Q3258.92 1031.34 3264.4 1031.34 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3321.8 1030.16 L3327.35 1030.16 Q3332.56 1038.35 3335.13 1046.2 Q3337.74 1054.05 3337.74 1061.79 Q3337.74 1069.57 3335.13 1077.45 Q3332.56 1085.33 3327.35 1093.49 L3321.8 1093.49 Q3326.42 1085.54 3328.67 1077.69 Q3330.96 1069.81 3330.96 1061.79 Q3330.96 1053.77 3328.67 1045.96 Q3326.42 1038.14 3321.8 1030.16 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3352.74 1090.71 L3355.17 1090.71 Q3360.03 1090.71 3361.49 1089.22 Q3362.98 1087.73 3362.98 1082.76 L3362.98 1074.15 Q3362.98 1068.73 3364.54 1066.27 Q3366.1 1063.8 3369.96 1062.87 Q3366.1 1062 3364.54 1059.53 Q3362.98 1057.07 3362.98 1051.62 L3362.98 1043 Q3362.98 1038.07 3361.49 1036.58 Q3360.03 1035.05 3355.17 1035.05 L3352.74 1035.05 L3352.74 1030.09 L3354.92 1030.09 Q3363.57 1030.09 3366.45 1032.66 Q3369.37 1035.19 3369.37 1042.87 L3369.37 1051.2 Q3369.37 1056.37 3371.24 1058.39 Q3373.12 1060.37 3378.05 1060.37 L3380.2 1060.37 L3380.2 1065.33 L3378.05 1065.33 Q3373.12 1065.33 3371.24 1067.34 Q3369.37 1069.36 3369.37 1074.6 L3369.37 1082.9 Q3369.37 1090.57 3366.45 1093.14 Q3363.57 1095.71 3354.92 1095.71 L3352.74 1095.71 L3352.74 1090.71 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2861.3 1165.49 Q2858.59 1172.43 2856.02 1174.55 Q2853.45 1176.67 2849.14 1176.67 L2844.04 1176.67 L2844.04 1171.32 L2847.79 1171.32 Q2850.43 1171.32 2851.89 1170.07 Q2853.35 1168.82 2855.12 1164.17 L2856.26 1161.25 L2840.53 1122.99 L2847.3 1122.99 L2859.46 1153.4 L2871.61 1122.99 L2878.38 1122.99 L2861.3 1165.49 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2893.52 1111.95 L2893.52 1122.99 L2906.68 1122.99 L2906.68 1127.95 L2893.52 1127.95 L2893.52 1149.06 Q2893.52 1153.82 2894.8 1155.17 Q2896.12 1156.53 2900.12 1156.53 L2906.68 1156.53 L2906.68 1161.88 L2900.12 1161.88 Q2892.72 1161.88 2889.91 1159.13 Q2887.1 1156.35 2887.1 1149.06 L2887.1 1127.95 L2882.41 1127.95 L2882.41 1122.99 L2887.1 1122.99 L2887.1 1111.95 L2893.52 1111.95 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2937.62 1128.96 Q2936.54 1128.33 2935.26 1128.06 Q2934.01 1127.74 2932.48 1127.74 Q2927.06 1127.74 2924.14 1131.29 Q2921.26 1134.79 2921.26 1141.39 L2921.26 1161.88 L2914.84 1161.88 L2914.84 1122.99 L2921.26 1122.99 L2921.26 1129.03 Q2923.28 1125.49 2926.51 1123.79 Q2929.73 1122.05 2934.35 1122.05 Q2935.01 1122.05 2935.81 1122.15 Q2936.61 1122.22 2937.58 1122.4 L2937.62 1128.96 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M2943.66 1146.53 L2943.66 1122.99 L2950.05 1122.99 L2950.05 1146.29 Q2950.05 1151.81 2952.2 1154.58 Q2954.35 1157.33 2958.66 1157.33 Q2963.83 1157.33 2966.82 1154.03 Q2969.84 1150.73 2969.84 1145.04 L2969.84 1122.99 L2976.23 1122.99 L2976.23 1161.88 L2969.84 1161.88 L2969.84 1155.9 Q2967.51 1159.44 2964.42 1161.18 Q2961.37 1162.88 2957.3 1162.88 Q2950.6 1162.88 2947.13 1158.72 Q2943.66 1154.55 2943.66 1146.53 M2959.73 1122.05 L2959.73 1122.05 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3022.65 1140.83 L3022.65 1143.96 L2993.28 1143.96 Q2993.69 1150.56 2997.23 1154.03 Q3000.81 1157.47 3007.16 1157.47 Q3010.85 1157.47 3014.28 1156.56 Q3017.75 1155.66 3021.16 1153.85 L3021.16 1159.9 Q3017.72 1161.35 3014.11 1162.12 Q3010.5 1162.88 3006.78 1162.88 Q2997.48 1162.88 2992.03 1157.47 Q2986.61 1152.05 2986.61 1142.81 Q2986.61 1133.26 2991.75 1127.67 Q2996.92 1122.05 3005.67 1122.05 Q3013.52 1122.05 3018.07 1127.12 Q3022.65 1132.15 3022.65 1140.83 M3016.26 1138.96 Q3016.19 1133.72 3013.31 1130.59 Q3010.46 1127.47 3005.74 1127.47 Q3000.39 1127.47 2997.16 1130.49 Q2993.97 1133.51 2993.48 1138.99 L3016.26 1138.96 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3033.97 1129.58 L3078.48 1129.58 L3078.48 1135.42 L3033.97 1135.42 L3033.97 1129.58 M3033.97 1143.75 L3078.48 1143.75 L3078.48 1149.65 L3033.97 1149.65 L3033.97 1143.75 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip180)" d="M3093.69 1110.04 L3121.23 1110.04 L3121.23 1115.94 L3100.12 1115.94 L3100.12 1128.65 Q3101.64 1128.13 3103.17 1127.88 Q3104.7 1127.6 3106.23 1127.6 Q3114.91 1127.6 3119.98 1132.36 Q3125.05 1137.12 3125.05 1145.24 Q3125.05 1153.61 3119.84 1158.26 Q3114.63 1162.88 3105.15 1162.88 Q3101.89 1162.88 3098.48 1162.33 Q3095.12 1161.77 3091.5 1160.66 L3091.5 1153.61 Q3094.63 1155.31 3097.96 1156.15 Q3101.3 1156.98 3105.01 1156.98 Q3111.02 1156.98 3114.53 1153.82 Q3118.03 1150.66 3118.03 1145.24 Q3118.03 1139.83 3114.53 1136.67 Q3111.02 1133.51 3105.01 1133.51 Q3102.2 1133.51 3099.39 1134.13 Q3096.61 1134.76 3093.69 1136.08 L3093.69 1110.04 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path></svg>
<figcaption class="figure-caption">(b) Randomly selected prediction sets of size <img src="https://latex.codecogs.com/png.latex?%7CC%7C=2">.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="fig-plots-3" class="quarto-figure quarto-figure-center anchored" style="flex-basis: 100.0%;justify-content: center;">
<figure class="figure">
<!--?xml version="1.0" encoding="utf-8"?-->
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" width="900" height="300" viewbox="0 0 3600 1200">
<defs>
  <clippath id="clip240">
    <rect x="0" y="0" width="3600" height="1200"></rect>
  </clippath>
</defs>
<path clip-path="url(#clip240)" d="M0 1200 L3600 1200 L3600 0 L0 0  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip241">
    <rect x="720" y="0" width="2521" height="1200"></rect>
  </clippath>
</defs>
<path clip-path="url(#clip240)" d="M47.2441 1011.02 L1152.76 1011.02 L1152.76 47.2441 L47.2441 47.2441  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip242">
    <rect x="47" y="47" width="1107" height="965"></rect>
  </clippath>
</defs>
<g clip-path="url(#clip242)">
<image width="964" height="964" href="data:image/png;base64,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" transform="translate(118, 47)"></image>
</g>
<path clip-path="url(#clip240)" d="M127.864 1041.34 L127.864 1048.12 Q124.618 1045.09 120.926 1043.6 Q117.266 1042.1 113.128 1042.1 Q104.98 1042.1 100.651 1047.1 Q96.3224 1052.06 96.3224 1061.48 Q96.3224 1070.87 100.651 1075.87 Q104.98 1080.83 113.128 1080.83 Q117.266 1080.83 120.926 1079.34 Q124.618 1077.84 127.864 1074.82 L127.864 1081.54 Q124.491 1083.83 120.703 1084.97 Q116.947 1086.12 112.746 1086.12 Q101.956 1086.12 95.7494 1079.53 Q89.5429 1072.91 89.5429 1061.48 Q89.5429 1050.02 95.7494 1043.44 Q101.956 1036.82 112.746 1036.82 Q117.011 1036.82 120.767 1037.96 Q124.554 1039.08 127.864 1041.34 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M138.304 1055.59 L179.108 1055.59 L179.108 1060.94 L138.304 1060.94 L138.304 1055.59 M138.304 1068.58 L179.108 1068.58 L179.108 1073.99 L138.304 1073.99 L138.304 1068.58 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M219.34 1091.24 L219.34 1095.83 L217.366 1095.83 Q209.441 1095.83 206.736 1093.47 Q204.062 1091.12 204.062 1084.08 L204.062 1076.47 Q204.062 1071.67 202.343 1069.82 Q200.624 1067.98 196.105 1067.98 L194.163 1067.98 L194.163 1063.42 L196.105 1063.42 Q200.656 1063.42 202.343 1061.61 Q204.062 1059.76 204.062 1055.02 L204.062 1047.38 Q204.062 1040.35 206.736 1038.03 Q209.441 1035.67 217.366 1035.67 L219.34 1035.67 L219.34 1040.22 L217.175 1040.22 Q212.687 1040.22 211.319 1041.62 Q209.95 1043.02 209.95 1047.51 L209.95 1055.4 Q209.95 1060.4 208.486 1062.66 Q207.054 1064.92 203.553 1065.72 Q207.086 1066.58 208.518 1068.84 Q209.95 1071.1 209.95 1076.06 L209.95 1083.95 Q209.95 1088.44 211.319 1089.84 Q212.687 1091.24 217.175 1091.24 L219.34 1091.24 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M239.996 1079.78 L262.435 1079.78 L262.435 1085.2 L232.262 1085.2 L232.262 1079.78 Q235.922 1076 242.224 1069.63 Q248.558 1063.23 250.181 1061.39 Q253.269 1057.92 254.478 1055.53 Q255.72 1053.11 255.72 1050.79 Q255.72 1047 253.046 1044.61 Q250.404 1042.23 246.139 1042.23 Q243.116 1042.23 239.742 1043.28 Q236.4 1044.33 232.58 1046.46 L232.58 1039.97 Q236.463 1038.41 239.837 1037.61 Q243.211 1036.82 246.012 1036.82 Q253.396 1036.82 257.788 1040.51 Q262.181 1044.2 262.181 1050.37 Q262.181 1053.3 261.067 1055.94 Q259.985 1058.55 257.088 1062.12 Q256.293 1063.04 252.028 1067.47 Q247.763 1071.86 239.996 1079.78 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M309.892 1035.73 Q305.627 1043.05 303.558 1050.22 Q301.489 1057.38 301.489 1064.73 Q301.489 1072.08 303.558 1079.31 Q305.659 1086.5 309.892 1093.79 L304.799 1093.79 Q300.025 1086.31 297.638 1079.08 Q295.283 1071.86 295.283 1064.73 Q295.283 1057.63 297.638 1050.44 Q299.993 1043.25 304.799 1035.73 L309.892 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M335.832 1062.63 Q331.249 1062.63 328.607 1065.08 Q325.997 1067.53 325.997 1071.83 Q325.997 1076.12 328.607 1078.58 Q331.249 1081.03 335.832 1081.03 Q340.415 1081.03 343.057 1078.58 Q345.699 1076.09 345.699 1071.83 Q345.699 1067.53 343.057 1065.08 Q340.447 1062.63 335.832 1062.63 M329.403 1059.89 Q325.265 1058.87 322.942 1056.04 Q320.65 1053.21 320.65 1049.13 Q320.65 1043.44 324.692 1040.13 Q328.766 1036.82 335.832 1036.82 Q342.93 1036.82 346.972 1040.13 Q351.014 1043.44 351.014 1049.13 Q351.014 1053.21 348.691 1056.04 Q346.399 1058.87 342.293 1059.89 Q346.94 1060.97 349.518 1064.12 Q352.128 1067.28 352.128 1071.83 Q352.128 1078.73 347.895 1082.43 Q343.694 1086.12 335.832 1086.12 Q327.97 1086.12 323.737 1082.43 Q319.536 1078.73 319.536 1071.83 Q319.536 1067.28 322.146 1064.12 Q324.756 1060.97 329.403 1059.89 M327.047 1049.74 Q327.047 1053.43 329.339 1055.5 Q331.663 1057.57 335.832 1057.57 Q339.97 1057.57 342.293 1055.5 Q344.649 1053.43 344.649 1049.74 Q344.649 1046.05 342.293 1043.98 Q339.97 1041.91 335.832 1041.91 Q331.663 1041.91 329.339 1043.98 Q327.047 1046.05 327.047 1049.74 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M377.305 1041.91 Q372.339 1041.91 369.825 1046.81 Q367.342 1051.68 367.342 1061.48 Q367.342 1071.25 369.825 1076.16 Q372.339 1081.03 377.305 1081.03 Q382.302 1081.03 384.784 1076.16 Q387.299 1071.25 387.299 1061.48 Q387.299 1051.68 384.784 1046.81 Q382.302 1041.91 377.305 1041.91 M377.305 1036.82 Q385.294 1036.82 389.495 1043.15 Q393.728 1049.45 393.728 1061.48 Q393.728 1073.48 389.495 1079.82 Q385.294 1086.12 377.305 1086.12 Q369.316 1086.12 365.082 1079.82 Q360.881 1073.48 360.881 1061.48 Q360.881 1049.45 365.082 1043.15 Q369.316 1036.82 377.305 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M445.45 1064.28 Q442.68 1064.28 441.089 1066.64 Q439.529 1068.99 439.529 1073.2 Q439.529 1077.33 441.089 1079.72 Q442.68 1082.08 445.45 1082.08 Q448.155 1082.08 449.715 1079.72 Q451.306 1077.33 451.306 1073.2 Q451.306 1069.03 449.715 1066.67 Q448.155 1064.28 445.45 1064.28 M445.45 1060.24 Q450.478 1060.24 453.438 1063.74 Q456.399 1067.24 456.399 1073.2 Q456.399 1079.15 453.407 1082.65 Q450.447 1086.12 445.45 1086.12 Q440.357 1086.12 437.397 1082.65 Q434.437 1079.15 434.437 1073.2 Q434.437 1067.21 437.397 1063.74 Q440.389 1060.24 445.45 1060.24 M412.602 1040.86 Q409.865 1040.86 408.274 1043.25 Q406.714 1045.6 406.714 1049.74 Q406.714 1053.94 408.274 1056.3 Q409.833 1058.65 412.602 1058.65 Q415.372 1058.65 416.931 1056.3 Q418.523 1053.94 418.523 1049.74 Q418.523 1045.63 416.931 1043.25 Q415.34 1040.86 412.602 1040.86 M441.344 1036.82 L446.436 1036.82 L416.708 1086.12 L411.616 1086.12 L441.344 1036.82 M412.602 1036.82 Q417.631 1036.82 420.623 1040.32 Q423.615 1043.79 423.615 1049.74 Q423.615 1055.75 420.623 1059.22 Q417.663 1062.69 412.602 1062.69 Q407.542 1062.69 404.582 1059.22 Q401.653 1055.72 401.653 1049.74 Q401.653 1043.82 404.614 1040.32 Q407.574 1036.82 412.602 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M465.215 1035.73 L470.308 1035.73 Q475.082 1043.25 477.437 1050.44 Q479.824 1057.63 479.824 1064.73 Q479.824 1071.86 477.437 1079.08 Q475.082 1086.31 470.308 1093.79 L465.215 1093.79 Q469.448 1086.5 471.517 1079.31 Q473.618 1072.08 473.618 1064.73 Q473.618 1057.38 471.517 1050.22 Q469.448 1043.05 465.215 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M493.065 1077.11 L499.781 1077.11 L499.781 1082.59 L494.561 1092.77 L490.455 1092.77 L493.065 1082.59 L493.065 1077.11 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M553.316 1059.57 Q557.932 1060.56 560.51 1063.68 Q563.12 1066.8 563.12 1071.38 Q563.12 1078.42 558.282 1082.27 Q553.444 1086.12 544.532 1086.12 Q541.54 1086.12 538.357 1085.51 Q535.206 1084.94 531.832 1083.76 L531.832 1077.56 Q534.506 1079.12 537.689 1079.91 Q540.871 1080.71 544.341 1080.71 Q550.388 1080.71 553.539 1078.32 Q556.722 1075.93 556.722 1071.38 Q556.722 1067.18 553.762 1064.83 Q550.834 1062.44 545.582 1062.44 L540.044 1062.44 L540.044 1057.15 L545.837 1057.15 Q550.579 1057.15 553.094 1055.28 Q555.608 1053.37 555.608 1049.8 Q555.608 1046.14 552.998 1044.2 Q550.42 1042.23 545.582 1042.23 Q542.94 1042.23 539.917 1042.8 Q536.893 1043.37 533.264 1044.58 L533.264 1038.85 Q536.925 1037.83 540.108 1037.33 Q543.322 1036.82 546.155 1036.82 Q553.476 1036.82 557.741 1040.16 Q562.006 1043.47 562.006 1049.13 Q562.006 1053.08 559.746 1055.82 Q557.486 1058.52 553.316 1059.57 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M609.271 1035.73 Q605.006 1043.05 602.937 1050.22 Q600.868 1057.38 600.868 1064.73 Q600.868 1072.08 602.937 1079.31 Q605.038 1086.5 609.271 1093.79 L604.178 1093.79 Q599.404 1086.31 597.017 1079.08 Q594.662 1071.86 594.662 1064.73 Q594.662 1057.63 597.017 1050.44 Q599.372 1043.25 604.178 1035.73 L609.271 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M622.575 1079.78 L633.079 1079.78 L633.079 1043.53 L621.652 1045.82 L621.652 1039.97 L633.015 1037.68 L639.444 1037.68 L639.444 1079.78 L649.948 1079.78 L649.948 1085.2 L622.575 1085.2 L622.575 1079.78 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M661.311 1037.68 L691.866 1037.68 L691.866 1040.41 L674.615 1085.2 L667.899 1085.2 L684.132 1043.09 L661.311 1043.09 L661.311 1037.68 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M744.829 1064.28 Q742.06 1064.28 740.468 1066.64 Q738.909 1068.99 738.909 1073.2 Q738.909 1077.33 740.468 1079.72 Q742.06 1082.08 744.829 1082.08 Q747.534 1082.08 749.094 1079.72 Q750.685 1077.33 750.685 1073.2 Q750.685 1069.03 749.094 1066.67 Q747.534 1064.28 744.829 1064.28 M744.829 1060.24 Q749.858 1060.24 752.818 1063.74 Q755.778 1067.24 755.778 1073.2 Q755.778 1079.15 752.786 1082.65 Q749.826 1086.12 744.829 1086.12 Q739.736 1086.12 736.776 1082.65 Q733.816 1079.15 733.816 1073.2 Q733.816 1067.21 736.776 1063.74 Q739.768 1060.24 744.829 1060.24 M711.982 1040.86 Q709.244 1040.86 707.653 1043.25 Q706.093 1045.6 706.093 1049.74 Q706.093 1053.94 707.653 1056.3 Q709.213 1058.65 711.982 1058.65 Q714.751 1058.65 716.31 1056.3 Q717.902 1053.94 717.902 1049.74 Q717.902 1045.63 716.31 1043.25 Q714.719 1040.86 711.982 1040.86 M740.723 1036.82 L745.815 1036.82 L716.088 1086.12 L710.995 1086.12 L740.723 1036.82 M711.982 1036.82 Q717.011 1036.82 720.002 1040.32 Q722.994 1043.79 722.994 1049.74 Q722.994 1055.75 720.002 1059.22 Q717.042 1062.69 711.982 1062.69 Q706.921 1062.69 703.961 1059.22 Q701.033 1055.72 701.033 1049.74 Q701.033 1043.82 703.993 1040.32 Q706.953 1036.82 711.982 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M764.594 1035.73 L769.687 1035.73 Q774.461 1043.25 776.816 1050.44 Q779.204 1057.63 779.204 1064.73 Q779.204 1071.86 776.816 1079.08 Q774.461 1086.31 769.687 1093.79 L764.594 1093.79 Q768.827 1086.5 770.896 1079.31 Q772.997 1072.08 772.997 1064.73 Q772.997 1057.38 770.896 1050.22 Q768.827 1043.05 764.594 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M792.444 1077.11 L799.16 1077.11 L799.16 1082.59 L793.94 1092.77 L789.834 1092.77 L792.444 1082.59 L792.444 1077.11 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M850.881 1043.28 L834.649 1068.64 L850.881 1068.64 L850.881 1043.28 M849.194 1037.68 L857.279 1037.68 L857.279 1068.64 L864.058 1068.64 L864.058 1073.99 L857.279 1073.99 L857.279 1085.2 L850.881 1085.2 L850.881 1073.99 L829.429 1073.99 L829.429 1067.79 L849.194 1037.68 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M908.65 1035.73 Q904.385 1043.05 902.316 1050.22 Q900.247 1057.38 900.247 1064.73 Q900.247 1072.08 902.316 1079.31 Q904.417 1086.5 908.65 1093.79 L903.558 1093.79 Q898.783 1086.31 896.396 1079.08 Q894.041 1071.86 894.041 1064.73 Q894.041 1057.63 896.396 1050.44 Q898.751 1043.25 903.558 1035.73 L908.65 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M926.379 1079.78 L948.818 1079.78 L948.818 1085.2 L918.644 1085.2 L918.644 1079.78 Q922.305 1076 928.607 1069.63 Q934.941 1063.23 936.564 1061.39 Q939.651 1057.92 940.861 1055.53 Q942.102 1053.11 942.102 1050.79 Q942.102 1047 939.428 1044.61 Q936.787 1042.23 932.522 1042.23 Q929.498 1042.23 926.124 1043.28 Q922.782 1044.33 918.963 1046.46 L918.963 1039.97 Q922.846 1038.41 926.22 1037.61 Q929.593 1036.82 932.394 1036.82 Q939.778 1036.82 944.171 1040.51 Q948.563 1044.2 948.563 1050.37 Q948.563 1053.3 947.449 1055.94 Q946.367 1058.55 943.471 1062.12 Q942.675 1063.04 938.41 1067.47 Q934.145 1071.86 926.379 1079.78 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1002.74 1064.28 Q999.966 1064.28 998.375 1066.64 Q996.815 1068.99 996.815 1073.2 Q996.815 1077.33 998.375 1079.72 Q999.966 1082.08 1002.74 1082.08 Q1005.44 1082.08 1007 1079.72 Q1008.59 1077.33 1008.59 1073.2 Q1008.59 1069.03 1007 1066.67 Q1005.44 1064.28 1002.74 1064.28 M1002.74 1060.24 Q1007.76 1060.24 1010.72 1063.74 Q1013.68 1067.24 1013.68 1073.2 Q1013.68 1079.15 1010.69 1082.65 Q1007.73 1086.12 1002.74 1086.12 Q997.643 1086.12 994.683 1082.65 Q991.723 1079.15 991.723 1073.2 Q991.723 1067.21 994.683 1063.74 Q997.675 1060.24 1002.74 1060.24 M969.888 1040.86 Q967.151 1040.86 965.56 1043.25 Q964 1045.6 964 1049.74 Q964 1053.94 965.56 1056.3 Q967.119 1058.65 969.888 1058.65 Q972.657 1058.65 974.217 1056.3 Q975.808 1053.94 975.808 1049.74 Q975.808 1045.63 974.217 1043.25 Q972.626 1040.86 969.888 1040.86 M998.629 1036.82 L1003.72 1036.82 L973.994 1086.12 L968.902 1086.12 L998.629 1036.82 M969.888 1036.82 Q974.917 1036.82 977.909 1040.32 Q980.901 1043.79 980.901 1049.74 Q980.901 1055.75 977.909 1059.22 Q974.949 1062.69 969.888 1062.69 Q964.828 1062.69 961.867 1059.22 Q958.939 1055.72 958.939 1049.74 Q958.939 1043.82 961.899 1040.32 Q964.859 1036.82 969.888 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1022.5 1035.73 L1027.59 1035.73 Q1032.37 1043.25 1034.72 1050.44 Q1037.11 1057.63 1037.11 1064.73 Q1037.11 1071.86 1034.72 1079.08 Q1032.37 1086.31 1027.59 1093.79 L1022.5 1093.79 Q1026.73 1086.5 1028.8 1079.31 Q1030.9 1072.08 1030.9 1064.73 Q1030.9 1057.38 1028.8 1050.22 Q1026.73 1043.05 1022.5 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1050.86 1091.24 L1053.09 1091.24 Q1057.54 1091.24 1058.88 1089.87 Q1060.25 1088.51 1060.25 1083.95 L1060.25 1076.06 Q1060.25 1071.1 1061.68 1068.84 Q1063.11 1066.58 1066.65 1065.72 Q1063.11 1064.92 1061.68 1062.66 Q1060.25 1060.4 1060.25 1055.4 L1060.25 1047.51 Q1060.25 1042.99 1058.88 1041.62 Q1057.54 1040.22 1053.09 1040.22 L1050.86 1040.22 L1050.86 1035.67 L1052.87 1035.67 Q1060.79 1035.67 1063.43 1038.03 Q1066.11 1040.35 1066.11 1047.38 L1066.11 1055.02 Q1066.11 1059.76 1067.82 1061.61 Q1069.54 1063.42 1074.06 1063.42 L1076.04 1063.42 L1076.04 1067.98 L1074.06 1067.98 Q1069.54 1067.98 1067.82 1069.82 Q1066.11 1071.67 1066.11 1076.47 L1066.11 1084.08 Q1066.11 1091.12 1063.43 1093.47 Q1060.79 1095.83 1052.87 1095.83 L1050.86 1095.83 L1050.86 1091.24 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M471.835 1159.79 Q469.353 1166.15 466.997 1168.09 Q464.642 1170.03 460.695 1170.03 L456.017 1170.03 L456.017 1165.13 L459.454 1165.13 Q461.873 1165.13 463.21 1163.99 Q464.547 1162.84 466.17 1158.58 L467.22 1155.9 L452.802 1120.83 L459.008 1120.83 L470.148 1148.71 L481.288 1120.83 L487.495 1120.83 L471.835 1159.79 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M501.372 1110.71 L501.372 1120.83 L513.435 1120.83 L513.435 1125.38 L501.372 1125.38 L501.372 1144.73 Q501.372 1149.09 502.55 1150.33 Q503.759 1151.57 507.42 1151.57 L513.435 1151.57 L513.435 1156.48 L507.42 1156.48 Q500.64 1156.48 498.062 1153.96 Q495.484 1151.41 495.484 1144.73 L495.484 1125.38 L491.187 1125.38 L491.187 1120.83 L495.484 1120.83 L495.484 1110.71 L501.372 1110.71 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M541.795 1126.3 Q540.808 1125.73 539.63 1125.47 Q538.484 1125.19 537.084 1125.19 Q532.119 1125.19 529.445 1128.43 Q526.803 1131.65 526.803 1137.7 L526.803 1156.48 L520.915 1156.48 L520.915 1120.83 L526.803 1120.83 L526.803 1126.37 Q528.649 1123.12 531.609 1121.56 Q534.569 1119.97 538.803 1119.97 Q539.407 1119.97 540.139 1120.06 Q540.871 1120.13 541.763 1120.29 L541.795 1126.3 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M547.333 1142.41 L547.333 1120.83 L553.189 1120.83 L553.189 1142.18 Q553.189 1147.25 555.162 1149.79 Q557.136 1152.31 561.083 1152.31 Q565.825 1152.31 568.562 1149.28 Q571.331 1146.26 571.331 1141.04 L571.331 1120.83 L577.188 1120.83 L577.188 1156.48 L571.331 1156.48 L571.331 1151 Q569.199 1154.25 566.366 1155.84 Q563.565 1157.4 559.841 1157.4 Q553.698 1157.4 550.516 1153.58 Q547.333 1149.76 547.333 1142.41 M562.069 1119.97 L562.069 1119.97 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M619.743 1137.19 L619.743 1140.05 L592.816 1140.05 Q593.198 1146.1 596.444 1149.28 Q599.722 1152.43 605.547 1152.43 Q608.921 1152.43 612.072 1151.61 Q615.255 1150.78 618.374 1149.12 L618.374 1154.66 Q615.223 1156 611.913 1156.7 Q608.603 1157.4 605.197 1157.4 Q596.667 1157.4 591.67 1152.43 Q586.705 1147.47 586.705 1139 Q586.705 1130.25 591.415 1125.12 Q596.158 1119.97 604.178 1119.97 Q611.372 1119.97 615.541 1124.62 Q619.743 1129.23 619.743 1137.19 M613.886 1135.47 Q613.822 1130.66 611.181 1127.8 Q608.571 1124.93 604.242 1124.93 Q599.34 1124.93 596.38 1127.7 Q593.452 1130.47 593.007 1135.5 L613.886 1135.47 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M630.119 1126.87 L670.923 1126.87 L670.923 1132.22 L630.119 1132.22 L630.119 1126.87 M630.119 1139.86 L670.923 1139.86 L670.923 1145.27 L630.119 1145.27 L630.119 1139.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M690.338 1151.06 L712.777 1151.06 L712.777 1156.48 L682.604 1156.48 L682.604 1151.06 Q686.264 1147.28 692.566 1140.91 Q698.9 1134.51 700.523 1132.67 Q703.611 1129.2 704.82 1126.81 Q706.062 1124.39 706.062 1122.07 Q706.062 1118.28 703.388 1115.89 Q700.746 1113.51 696.481 1113.51 Q693.457 1113.51 690.084 1114.56 Q686.742 1115.61 682.922 1117.74 L682.922 1111.25 Q686.805 1109.69 690.179 1108.89 Q693.553 1108.1 696.354 1108.1 Q703.738 1108.1 708.13 1111.79 Q712.523 1115.48 712.523 1121.65 Q712.523 1124.58 711.409 1127.22 Q710.327 1129.83 707.43 1133.4 Q706.634 1134.32 702.369 1138.75 Q698.104 1143.14 690.338 1151.06 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1247.24 1011.02 L2352.76 1011.02 L2352.76 47.2441 L1247.24 47.2441  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip243">
    <rect x="1247" y="47" width="1107" height="965"></rect>
  </clippath>
</defs>
<g clip-path="url(#clip243)">
<image width="964" height="964" href="data:image/png;base64,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" transform="translate(1318, 47)"></image>
</g>
<path clip-path="url(#clip240)" d="M1348.6 1041.34 L1348.6 1048.12 Q1345.35 1045.09 1341.66 1043.6 Q1338 1042.1 1333.86 1042.1 Q1325.72 1042.1 1321.39 1047.1 Q1317.06 1052.06 1317.06 1061.48 Q1317.06 1070.87 1321.39 1075.87 Q1325.72 1080.83 1333.86 1080.83 Q1338 1080.83 1341.66 1079.34 Q1345.35 1077.84 1348.6 1074.82 L1348.6 1081.54 Q1345.23 1083.83 1341.44 1084.97 Q1337.68 1086.12 1333.48 1086.12 Q1322.69 1086.12 1316.49 1079.53 Q1310.28 1072.91 1310.28 1061.48 Q1310.28 1050.02 1316.49 1043.44 Q1322.69 1036.82 1333.48 1036.82 Q1337.75 1036.82 1341.5 1037.96 Q1345.29 1039.08 1348.6 1041.34 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1359.04 1055.59 L1399.84 1055.59 L1399.84 1060.94 L1359.04 1060.94 L1359.04 1055.59 M1359.04 1068.58 L1399.84 1068.58 L1399.84 1073.99 L1359.04 1073.99 L1359.04 1068.58 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1440.08 1091.24 L1440.08 1095.83 L1438.1 1095.83 Q1430.18 1095.83 1427.47 1093.47 Q1424.8 1091.12 1424.8 1084.08 L1424.8 1076.47 Q1424.8 1071.67 1423.08 1069.82 Q1421.36 1067.98 1416.84 1067.98 L1414.9 1067.98 L1414.9 1063.42 L1416.84 1063.42 Q1421.39 1063.42 1423.08 1061.61 Q1424.8 1059.76 1424.8 1055.02 L1424.8 1047.38 Q1424.8 1040.35 1427.47 1038.03 Q1430.18 1035.67 1438.1 1035.67 L1440.08 1035.67 L1440.08 1040.22 L1437.91 1040.22 Q1433.42 1040.22 1432.06 1041.62 Q1430.69 1043.02 1430.69 1047.51 L1430.69 1055.4 Q1430.69 1060.4 1429.22 1062.66 Q1427.79 1064.92 1424.29 1065.72 Q1427.82 1066.58 1429.25 1068.84 Q1430.69 1071.1 1430.69 1076.06 L1430.69 1083.95 Q1430.69 1088.44 1432.06 1089.84 Q1433.42 1091.24 1437.91 1091.24 L1440.08 1091.24 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1468.94 1041.91 Q1463.98 1041.91 1461.46 1046.81 Q1458.98 1051.68 1458.98 1061.48 Q1458.98 1071.25 1461.46 1076.16 Q1463.98 1081.03 1468.94 1081.03 Q1473.94 1081.03 1476.42 1076.16 Q1478.94 1071.25 1478.94 1061.48 Q1478.94 1051.68 1476.42 1046.81 Q1473.94 1041.91 1468.94 1041.91 M1468.94 1036.82 Q1476.93 1036.82 1481.13 1043.15 Q1485.37 1049.45 1485.37 1061.48 Q1485.37 1073.48 1481.13 1079.82 Q1476.93 1086.12 1468.94 1086.12 Q1460.96 1086.12 1456.72 1079.82 Q1452.52 1073.48 1452.52 1061.48 Q1452.52 1049.45 1456.72 1043.15 Q1460.96 1036.82 1468.94 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1530.63 1035.73 Q1526.36 1043.05 1524.29 1050.22 Q1522.23 1057.38 1522.23 1064.73 Q1522.23 1072.08 1524.29 1079.31 Q1526.39 1086.5 1530.63 1093.79 L1525.54 1093.79 Q1520.76 1086.31 1518.37 1079.08 Q1516.02 1071.86 1516.02 1064.73 Q1516.02 1057.63 1518.37 1050.44 Q1520.73 1043.25 1525.54 1035.73 L1530.63 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1548.36 1079.78 L1570.8 1079.78 L1570.8 1085.2 L1540.62 1085.2 L1540.62 1079.78 Q1544.28 1076 1550.58 1069.63 Q1556.92 1063.23 1558.54 1061.39 Q1561.63 1057.92 1562.84 1055.53 Q1564.08 1053.11 1564.08 1050.79 Q1564.08 1047 1561.41 1044.61 Q1558.76 1042.23 1554.5 1042.23 Q1551.48 1042.23 1548.1 1043.28 Q1544.76 1044.33 1540.94 1046.46 L1540.94 1039.97 Q1544.82 1038.41 1548.2 1037.61 Q1551.57 1036.82 1554.37 1036.82 Q1561.76 1036.82 1566.15 1040.51 Q1570.54 1044.2 1570.54 1050.37 Q1570.54 1053.3 1569.43 1055.94 Q1568.34 1058.55 1565.45 1062.12 Q1564.65 1063.04 1560.39 1067.47 Q1556.12 1071.86 1548.36 1079.78 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1624.71 1064.28 Q1621.94 1064.28 1620.35 1066.64 Q1618.79 1068.99 1618.79 1073.2 Q1618.79 1077.33 1620.35 1079.72 Q1621.94 1082.08 1624.71 1082.08 Q1627.42 1082.08 1628.98 1079.72 Q1630.57 1077.33 1630.57 1073.2 Q1630.57 1069.03 1628.98 1066.67 Q1627.42 1064.28 1624.71 1064.28 M1624.71 1060.24 Q1629.74 1060.24 1632.7 1063.74 Q1635.66 1067.24 1635.66 1073.2 Q1635.66 1079.15 1632.67 1082.65 Q1629.71 1086.12 1624.71 1086.12 Q1619.62 1086.12 1616.66 1082.65 Q1613.7 1079.15 1613.7 1073.2 Q1613.7 1067.21 1616.66 1063.74 Q1619.65 1060.24 1624.71 1060.24 M1591.87 1040.86 Q1589.13 1040.86 1587.54 1043.25 Q1585.98 1045.6 1585.98 1049.74 Q1585.98 1053.94 1587.54 1056.3 Q1589.1 1058.65 1591.87 1058.65 Q1594.64 1058.65 1596.19 1056.3 Q1597.79 1053.94 1597.79 1049.74 Q1597.79 1045.63 1596.19 1043.25 Q1594.6 1040.86 1591.87 1040.86 M1620.61 1036.82 L1625.7 1036.82 L1595.97 1086.12 L1590.88 1086.12 L1620.61 1036.82 M1591.87 1036.82 Q1596.9 1036.82 1599.89 1040.32 Q1602.88 1043.79 1602.88 1049.74 Q1602.88 1055.75 1599.89 1059.22 Q1596.93 1062.69 1591.87 1062.69 Q1586.81 1062.69 1583.85 1059.22 Q1580.92 1055.72 1580.92 1049.74 Q1580.92 1043.82 1583.88 1040.32 Q1586.84 1036.82 1591.87 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1644.48 1035.73 L1649.57 1035.73 Q1654.35 1043.25 1656.7 1050.44 Q1659.09 1057.63 1659.09 1064.73 Q1659.09 1071.86 1656.7 1079.08 Q1654.35 1086.31 1649.57 1093.79 L1644.48 1093.79 Q1648.71 1086.5 1650.78 1079.31 Q1652.88 1072.08 1652.88 1064.73 Q1652.88 1057.38 1650.78 1050.22 Q1648.71 1043.05 1644.48 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1672.33 1077.11 L1679.04 1077.11 L1679.04 1082.59 L1673.82 1092.77 L1669.72 1092.77 L1672.33 1082.59 L1672.33 1077.11 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1713.16 1037.68 L1738.4 1037.68 L1738.4 1043.09 L1719.05 1043.09 L1719.05 1054.74 Q1720.45 1054.26 1721.85 1054.04 Q1723.25 1053.78 1724.65 1053.78 Q1732.61 1053.78 1737.26 1058.14 Q1741.91 1062.5 1741.91 1069.95 Q1741.91 1077.62 1737.13 1081.89 Q1732.36 1086.12 1723.67 1086.12 Q1720.68 1086.12 1717.56 1085.61 Q1714.47 1085.1 1711.16 1084.08 L1711.16 1077.62 Q1714.02 1079.18 1717.08 1079.94 Q1720.14 1080.71 1723.54 1080.71 Q1729.05 1080.71 1732.26 1077.81 Q1735.48 1074.91 1735.48 1069.95 Q1735.48 1064.98 1732.26 1062.09 Q1729.05 1059.19 1723.54 1059.19 Q1720.96 1059.19 1718.38 1059.76 Q1715.84 1060.34 1713.16 1061.55 L1713.16 1037.68 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1788.53 1035.73 Q1784.27 1043.05 1782.2 1050.22 Q1780.13 1057.38 1780.13 1064.73 Q1780.13 1072.08 1782.2 1079.31 Q1784.3 1086.5 1788.53 1093.79 L1783.44 1093.79 Q1778.67 1086.31 1776.28 1079.08 Q1773.93 1071.86 1773.93 1064.73 Q1773.93 1057.63 1776.28 1050.44 Q1778.64 1043.25 1783.44 1035.73 L1788.53 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1820.2 1059.57 Q1824.82 1060.56 1827.4 1063.68 Q1830.01 1066.8 1830.01 1071.38 Q1830.01 1078.42 1825.17 1082.27 Q1820.33 1086.12 1811.42 1086.12 Q1808.43 1086.12 1805.24 1085.51 Q1802.09 1084.94 1798.72 1083.76 L1798.72 1077.56 Q1801.39 1079.12 1804.58 1079.91 Q1807.76 1080.71 1811.23 1080.71 Q1817.28 1080.71 1820.43 1078.32 Q1823.61 1075.93 1823.61 1071.38 Q1823.61 1067.18 1820.65 1064.83 Q1817.72 1062.44 1812.47 1062.44 L1806.93 1062.44 L1806.93 1057.15 L1812.72 1057.15 Q1817.47 1057.15 1819.98 1055.28 Q1822.5 1053.37 1822.5 1049.8 Q1822.5 1046.14 1819.89 1044.2 Q1817.31 1042.23 1812.47 1042.23 Q1809.83 1042.23 1806.8 1042.8 Q1803.78 1043.37 1800.15 1044.58 L1800.15 1038.85 Q1803.81 1037.83 1807 1037.33 Q1810.21 1036.82 1813.04 1036.82 Q1820.36 1036.82 1824.63 1040.16 Q1828.89 1043.47 1828.89 1049.13 Q1828.89 1053.08 1826.63 1055.82 Q1824.37 1058.52 1820.2 1059.57 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1882.62 1064.28 Q1879.85 1064.28 1878.26 1066.64 Q1876.7 1068.99 1876.7 1073.2 Q1876.7 1077.33 1878.26 1079.72 Q1879.85 1082.08 1882.62 1082.08 Q1885.33 1082.08 1886.88 1079.72 Q1888.48 1077.33 1888.48 1073.2 Q1888.48 1069.03 1886.88 1066.67 Q1885.33 1064.28 1882.62 1064.28 M1882.62 1060.24 Q1887.65 1060.24 1890.61 1063.74 Q1893.57 1067.24 1893.57 1073.2 Q1893.57 1079.15 1890.58 1082.65 Q1887.62 1086.12 1882.62 1086.12 Q1877.53 1086.12 1874.57 1082.65 Q1871.61 1079.15 1871.61 1073.2 Q1871.61 1067.21 1874.57 1063.74 Q1877.56 1060.24 1882.62 1060.24 M1849.77 1040.86 Q1847.04 1040.86 1845.44 1043.25 Q1843.88 1045.6 1843.88 1049.74 Q1843.88 1053.94 1845.44 1056.3 Q1847 1058.65 1849.77 1058.65 Q1852.54 1058.65 1854.1 1056.3 Q1855.69 1053.94 1855.69 1049.74 Q1855.69 1045.63 1854.1 1043.25 Q1852.51 1040.86 1849.77 1040.86 M1878.51 1036.82 L1883.61 1036.82 L1853.88 1086.12 L1848.79 1086.12 L1878.51 1036.82 M1849.77 1036.82 Q1854.8 1036.82 1857.79 1040.32 Q1860.79 1043.79 1860.79 1049.74 Q1860.79 1055.75 1857.79 1059.22 Q1854.83 1062.69 1849.77 1062.69 Q1844.71 1062.69 1841.75 1059.22 Q1838.82 1055.72 1838.82 1049.74 Q1838.82 1043.82 1841.78 1040.32 Q1844.74 1036.82 1849.77 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1902.39 1035.73 L1907.48 1035.73 Q1912.25 1043.25 1914.61 1050.44 Q1916.99 1057.63 1916.99 1064.73 Q1916.99 1071.86 1914.61 1079.08 Q1912.25 1086.31 1907.48 1093.79 L1902.39 1093.79 Q1906.62 1086.5 1908.69 1079.31 Q1910.79 1072.08 1910.79 1064.73 Q1910.79 1057.38 1908.69 1050.22 Q1906.62 1043.05 1902.39 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1930.24 1077.11 L1936.95 1077.11 L1936.95 1082.59 L1931.73 1092.77 L1927.63 1092.77 L1930.24 1082.59 L1930.24 1077.11 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1985.55 1058.87 Q1981.22 1058.87 1978.68 1061.83 Q1976.16 1064.79 1976.16 1069.95 Q1976.16 1075.07 1978.68 1078.07 Q1981.22 1081.03 1985.55 1081.03 Q1989.88 1081.03 1992.4 1078.07 Q1994.94 1075.07 1994.94 1069.95 Q1994.94 1064.79 1992.4 1061.83 Q1989.88 1058.87 1985.55 1058.87 M1998.32 1038.73 L1998.32 1044.58 Q1995.9 1043.44 1993.41 1042.83 Q1990.96 1042.23 1988.55 1042.23 Q1982.18 1042.23 1978.81 1046.52 Q1975.46 1050.82 1974.99 1059.51 Q1976.86 1056.74 1979.7 1055.28 Q1982.53 1053.78 1985.94 1053.78 Q1993.1 1053.78 1997.23 1058.14 Q2001.4 1062.47 2001.4 1069.95 Q2001.4 1077.27 1997.08 1081.69 Q1992.75 1086.12 1985.55 1086.12 Q1977.31 1086.12 1972.95 1079.82 Q1968.59 1073.48 1968.59 1061.48 Q1968.59 1050.22 1973.94 1043.53 Q1979.28 1036.82 1988.29 1036.82 Q1990.71 1036.82 1993.16 1037.29 Q1995.64 1037.77 1998.32 1038.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2046.44 1035.73 Q2042.18 1043.05 2040.11 1050.22 Q2038.04 1057.38 2038.04 1064.73 Q2038.04 1072.08 2040.11 1079.31 Q2042.21 1086.5 2046.44 1093.79 L2041.35 1093.79 Q2036.57 1086.31 2034.19 1079.08 Q2031.83 1071.86 2031.83 1064.73 Q2031.83 1057.63 2034.19 1050.44 Q2036.54 1043.25 2041.35 1035.73 L2046.44 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2058.82 1084.21 L2058.82 1078.35 Q2061.24 1079.5 2063.72 1080.1 Q2066.21 1080.71 2068.59 1080.71 Q2074.96 1080.71 2078.3 1076.44 Q2081.68 1072.15 2082.15 1063.42 Q2080.31 1066.16 2077.47 1067.63 Q2074.64 1069.09 2071.2 1069.09 Q2064.07 1069.09 2059.9 1064.79 Q2055.77 1060.46 2055.77 1052.98 Q2055.77 1045.66 2060.1 1041.24 Q2064.42 1036.82 2071.62 1036.82 Q2079.86 1036.82 2084.19 1043.15 Q2088.55 1049.45 2088.55 1061.48 Q2088.55 1072.72 2083.2 1079.43 Q2077.89 1086.12 2068.88 1086.12 Q2066.46 1086.12 2063.98 1085.64 Q2061.5 1085.16 2058.82 1084.21 M2071.62 1064.06 Q2075.95 1064.06 2078.46 1061.1 Q2081.01 1058.14 2081.01 1052.98 Q2081.01 1047.86 2078.46 1044.9 Q2075.95 1041.91 2071.62 1041.91 Q2067.29 1041.91 2064.74 1044.9 Q2062.23 1047.86 2062.23 1052.98 Q2062.23 1058.14 2064.74 1061.1 Q2067.29 1064.06 2071.62 1064.06 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2100.17 1037.68 L2125.41 1037.68 L2125.41 1043.09 L2106.06 1043.09 L2106.06 1054.74 Q2107.46 1054.26 2108.86 1054.04 Q2110.26 1053.78 2111.66 1053.78 Q2119.62 1053.78 2124.26 1058.14 Q2128.91 1062.5 2128.91 1069.95 Q2128.91 1077.62 2124.13 1081.89 Q2119.36 1086.12 2110.67 1086.12 Q2107.68 1086.12 2104.56 1085.61 Q2101.47 1085.1 2098.16 1084.08 L2098.16 1077.62 Q2101.03 1079.18 2104.08 1079.94 Q2107.14 1080.71 2110.54 1080.71 Q2116.05 1080.71 2119.26 1077.81 Q2122.48 1074.91 2122.48 1069.95 Q2122.48 1064.98 2119.26 1062.09 Q2116.05 1059.19 2110.54 1059.19 Q2107.97 1059.19 2105.39 1059.76 Q2102.84 1060.34 2100.17 1061.55 L2100.17 1037.68 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2182 1064.28 Q2179.23 1064.28 2177.64 1066.64 Q2176.08 1068.99 2176.08 1073.2 Q2176.08 1077.33 2177.64 1079.72 Q2179.23 1082.08 2182 1082.08 Q2184.7 1082.08 2186.26 1079.72 Q2187.86 1077.33 2187.86 1073.2 Q2187.86 1069.03 2186.26 1066.67 Q2184.7 1064.28 2182 1064.28 M2182 1060.24 Q2187.03 1060.24 2189.99 1063.74 Q2192.95 1067.24 2192.95 1073.2 Q2192.95 1079.15 2189.96 1082.65 Q2187 1086.12 2182 1086.12 Q2176.91 1086.12 2173.95 1082.65 Q2170.99 1079.15 2170.99 1073.2 Q2170.99 1067.21 2173.95 1063.74 Q2176.94 1060.24 2182 1060.24 M2149.15 1040.86 Q2146.41 1040.86 2144.82 1043.25 Q2143.26 1045.6 2143.26 1049.74 Q2143.26 1053.94 2144.82 1056.3 Q2146.38 1058.65 2149.15 1058.65 Q2151.92 1058.65 2153.48 1056.3 Q2155.07 1053.94 2155.07 1049.74 Q2155.07 1045.63 2153.48 1043.25 Q2151.89 1040.86 2149.15 1040.86 M2177.89 1036.82 L2182.99 1036.82 L2153.26 1086.12 L2148.17 1086.12 L2177.89 1036.82 M2149.15 1036.82 Q2154.18 1036.82 2157.17 1040.32 Q2160.16 1043.79 2160.16 1049.74 Q2160.16 1055.75 2157.17 1059.22 Q2154.21 1062.69 2149.15 1062.69 Q2144.09 1062.69 2141.13 1059.22 Q2138.2 1055.72 2138.2 1049.74 Q2138.2 1043.82 2141.16 1040.32 Q2144.12 1036.82 2149.15 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2201.76 1035.73 L2206.86 1035.73 Q2211.63 1043.25 2213.99 1050.44 Q2216.37 1057.63 2216.37 1064.73 Q2216.37 1071.86 2213.99 1079.08 Q2211.63 1086.31 2206.86 1093.79 L2201.76 1093.79 Q2206 1086.5 2208.07 1079.31 Q2210.17 1072.08 2210.17 1064.73 Q2210.17 1057.38 2208.07 1050.22 Q2206 1043.05 2201.76 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2230.12 1091.24 L2232.35 1091.24 Q2236.81 1091.24 2238.14 1089.87 Q2239.51 1088.51 2239.51 1083.95 L2239.51 1076.06 Q2239.51 1071.1 2240.95 1068.84 Q2242.38 1066.58 2245.91 1065.72 Q2242.38 1064.92 2240.95 1062.66 Q2239.51 1060.4 2239.51 1055.4 L2239.51 1047.51 Q2239.51 1042.99 2238.14 1041.62 Q2236.81 1040.22 2232.35 1040.22 L2230.12 1040.22 L2230.12 1035.67 L2232.13 1035.67 Q2240.05 1035.67 2242.7 1038.03 Q2245.37 1040.35 2245.37 1047.38 L2245.37 1055.02 Q2245.37 1059.76 2247.09 1061.61 Q2248.81 1063.42 2253.33 1063.42 L2255.3 1063.42 L2255.3 1067.98 L2253.33 1067.98 Q2248.81 1067.98 2247.09 1069.82 Q2245.37 1071.67 2245.37 1076.47 L2245.37 1084.08 Q2245.37 1091.12 2242.7 1093.47 Q2240.05 1095.83 2232.13 1095.83 L2230.12 1095.83 L2230.12 1091.24 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1670.63 1159.79 Q1668.14 1166.15 1665.79 1168.09 Q1663.43 1170.03 1659.49 1170.03 L1654.81 1170.03 L1654.81 1165.13 L1658.24 1165.13 Q1660.66 1165.13 1662 1163.99 Q1663.34 1162.84 1664.96 1158.58 L1666.01 1155.9 L1651.59 1120.83 L1657.8 1120.83 L1668.94 1148.71 L1680.08 1120.83 L1686.29 1120.83 L1670.63 1159.79 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1700.16 1110.71 L1700.16 1120.83 L1712.23 1120.83 L1712.23 1125.38 L1700.16 1125.38 L1700.16 1144.73 Q1700.16 1149.09 1701.34 1150.33 Q1702.55 1151.57 1706.21 1151.57 L1712.23 1151.57 L1712.23 1156.48 L1706.21 1156.48 Q1699.43 1156.48 1696.85 1153.96 Q1694.27 1151.41 1694.27 1144.73 L1694.27 1125.38 L1689.98 1125.38 L1689.98 1120.83 L1694.27 1120.83 L1694.27 1110.71 L1700.16 1110.71 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1740.59 1126.3 Q1739.6 1125.73 1738.42 1125.47 Q1737.27 1125.19 1735.87 1125.19 Q1730.91 1125.19 1728.24 1128.43 Q1725.59 1131.65 1725.59 1137.7 L1725.59 1156.48 L1719.71 1156.48 L1719.71 1120.83 L1725.59 1120.83 L1725.59 1126.37 Q1727.44 1123.12 1730.4 1121.56 Q1733.36 1119.97 1737.59 1119.97 Q1738.2 1119.97 1738.93 1120.06 Q1739.66 1120.13 1740.55 1120.29 L1740.59 1126.3 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1746.12 1142.41 L1746.12 1120.83 L1751.98 1120.83 L1751.98 1142.18 Q1751.98 1147.25 1753.95 1149.79 Q1755.93 1152.31 1759.87 1152.31 Q1764.62 1152.31 1767.35 1149.28 Q1770.12 1146.26 1770.12 1141.04 L1770.12 1120.83 L1775.98 1120.83 L1775.98 1156.48 L1770.12 1156.48 L1770.12 1151 Q1767.99 1154.25 1765.16 1155.84 Q1762.36 1157.4 1758.63 1157.4 Q1752.49 1157.4 1749.31 1153.58 Q1746.12 1149.76 1746.12 1142.41 M1760.86 1119.97 L1760.86 1119.97 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1818.53 1137.19 L1818.53 1140.05 L1791.61 1140.05 Q1791.99 1146.1 1795.23 1149.28 Q1798.51 1152.43 1804.34 1152.43 Q1807.71 1152.43 1810.86 1151.61 Q1814.05 1150.78 1817.16 1149.12 L1817.16 1154.66 Q1814.01 1156 1810.7 1156.7 Q1807.39 1157.4 1803.99 1157.4 Q1795.46 1157.4 1790.46 1152.43 Q1785.5 1147.47 1785.5 1139 Q1785.5 1130.25 1790.21 1125.12 Q1794.95 1119.97 1802.97 1119.97 Q1810.16 1119.97 1814.33 1124.62 Q1818.53 1129.23 1818.53 1137.19 M1812.68 1135.47 Q1812.61 1130.66 1809.97 1127.8 Q1807.36 1124.93 1803.03 1124.93 Q1798.13 1124.93 1795.17 1127.7 Q1792.24 1130.47 1791.8 1135.5 L1812.68 1135.47 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1828.91 1126.87 L1869.71 1126.87 L1869.71 1132.22 L1828.91 1132.22 L1828.91 1126.87 M1828.91 1139.86 L1869.71 1139.86 L1869.71 1145.27 L1828.91 1145.27 L1828.91 1139.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M1898.14 1130.15 Q1893.81 1130.15 1891.26 1133.11 Q1888.75 1136.07 1888.75 1141.23 Q1888.75 1146.35 1891.26 1149.35 Q1893.81 1152.31 1898.14 1152.31 Q1902.46 1152.31 1904.98 1149.35 Q1907.53 1146.35 1907.53 1141.23 Q1907.53 1136.07 1904.98 1133.11 Q1902.46 1130.15 1898.14 1130.15 M1910.9 1110.01 L1910.9 1115.86 Q1908.48 1114.72 1906 1114.11 Q1903.55 1113.51 1901.13 1113.51 Q1894.76 1113.51 1891.39 1117.8 Q1888.05 1122.1 1887.57 1130.79 Q1889.45 1128.02 1892.28 1126.56 Q1895.11 1125.06 1898.52 1125.06 Q1905.68 1125.06 1909.82 1129.42 Q1913.99 1133.75 1913.99 1141.23 Q1913.99 1148.55 1909.66 1152.97 Q1905.33 1157.4 1898.14 1157.4 Q1889.89 1157.4 1885.53 1151.1 Q1881.17 1144.76 1881.17 1132.76 Q1881.17 1121.5 1886.52 1114.81 Q1891.87 1108.1 1900.87 1108.1 Q1903.29 1108.1 1905.74 1108.57 Q1908.23 1109.05 1910.9 1110.01 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2447.24 1011.02 L3552.76 1011.02 L3552.76 47.2441 L2447.24 47.2441  Z" fill="#000000" fill-rule="evenodd" fill-opacity="1"></path>
<defs>
  <clippath id="clip244">
    <rect x="2447" y="47" width="1107" height="965"></rect>
  </clippath>
</defs>
<g clip-path="url(#clip244)">
<image width="964" height="964" href="data:image/png;base64,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" transform="translate(2518, 47)"></image>
</g>
<path clip-path="url(#clip240)" d="M2548.6 1041.34 L2548.6 1048.12 Q2545.35 1045.09 2541.66 1043.6 Q2538 1042.1 2533.86 1042.1 Q2525.72 1042.1 2521.39 1047.1 Q2517.06 1052.06 2517.06 1061.48 Q2517.06 1070.87 2521.39 1075.87 Q2525.72 1080.83 2533.86 1080.83 Q2538 1080.83 2541.66 1079.34 Q2545.35 1077.84 2548.6 1074.82 L2548.6 1081.54 Q2545.23 1083.83 2541.44 1084.97 Q2537.68 1086.12 2533.48 1086.12 Q2522.69 1086.12 2516.49 1079.53 Q2510.28 1072.91 2510.28 1061.48 Q2510.28 1050.02 2516.49 1043.44 Q2522.69 1036.82 2533.48 1036.82 Q2537.75 1036.82 2541.5 1037.96 Q2545.29 1039.08 2548.6 1041.34 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2559.04 1055.59 L2599.84 1055.59 L2599.84 1060.94 L2559.04 1060.94 L2559.04 1055.59 M2559.04 1068.58 L2599.84 1068.58 L2599.84 1073.99 L2559.04 1073.99 L2559.04 1068.58 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2640.08 1091.24 L2640.08 1095.83 L2638.1 1095.83 Q2630.18 1095.83 2627.47 1093.47 Q2624.8 1091.12 2624.8 1084.08 L2624.8 1076.47 Q2624.8 1071.67 2623.08 1069.82 Q2621.36 1067.98 2616.84 1067.98 L2614.9 1067.98 L2614.9 1063.42 L2616.84 1063.42 Q2621.39 1063.42 2623.08 1061.61 Q2624.8 1059.76 2624.8 1055.02 L2624.8 1047.38 Q2624.8 1040.35 2627.47 1038.03 Q2630.18 1035.67 2638.1 1035.67 L2640.08 1035.67 L2640.08 1040.22 L2637.91 1040.22 Q2633.42 1040.22 2632.06 1041.62 Q2630.69 1043.02 2630.69 1047.51 L2630.69 1055.4 Q2630.69 1060.4 2629.22 1062.66 Q2627.79 1064.92 2624.29 1065.72 Q2627.82 1066.58 2629.25 1068.84 Q2630.69 1071.1 2630.69 1076.06 L2630.69 1083.95 Q2630.69 1088.44 2632.06 1089.84 Q2633.42 1091.24 2637.91 1091.24 L2640.08 1091.24 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2655.26 1037.68 L2680.5 1037.68 L2680.5 1043.09 L2661.15 1043.09 L2661.15 1054.74 Q2662.55 1054.26 2663.95 1054.04 Q2665.35 1053.78 2666.75 1053.78 Q2674.71 1053.78 2679.35 1058.14 Q2684 1062.5 2684 1069.95 Q2684 1077.62 2679.23 1081.89 Q2674.45 1086.12 2665.76 1086.12 Q2662.77 1086.12 2659.65 1085.61 Q2656.56 1085.1 2653.25 1084.08 L2653.25 1077.62 Q2656.12 1079.18 2659.17 1079.94 Q2662.23 1080.71 2665.63 1080.71 Q2671.14 1080.71 2674.36 1077.81 Q2677.57 1074.91 2677.57 1069.95 Q2677.57 1064.98 2674.36 1062.09 Q2671.14 1059.19 2665.63 1059.19 Q2663.06 1059.19 2660.48 1059.76 Q2657.93 1060.34 2655.26 1061.55 L2655.26 1037.68 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2730.63 1035.73 Q2726.36 1043.05 2724.29 1050.22 Q2722.23 1057.38 2722.23 1064.73 Q2722.23 1072.08 2724.29 1079.31 Q2726.39 1086.5 2730.63 1093.79 L2725.54 1093.79 Q2720.76 1086.31 2718.37 1079.08 Q2716.02 1071.86 2716.02 1064.73 Q2716.02 1057.63 2718.37 1050.44 Q2720.73 1043.25 2725.54 1035.73 L2730.63 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2762.3 1059.57 Q2766.91 1060.56 2769.49 1063.68 Q2772.1 1066.8 2772.1 1071.38 Q2772.1 1078.42 2767.26 1082.27 Q2762.42 1086.12 2753.51 1086.12 Q2750.52 1086.12 2747.34 1085.51 Q2744.19 1084.94 2740.81 1083.76 L2740.81 1077.56 Q2743.49 1079.12 2746.67 1079.91 Q2749.85 1080.71 2753.32 1080.71 Q2759.37 1080.71 2762.52 1078.32 Q2765.7 1075.93 2765.7 1071.38 Q2765.7 1067.18 2762.74 1064.83 Q2759.81 1062.44 2754.56 1062.44 L2749.02 1062.44 L2749.02 1057.15 L2754.82 1057.15 Q2759.56 1057.15 2762.07 1055.28 Q2764.59 1053.37 2764.59 1049.8 Q2764.59 1046.14 2761.98 1044.2 Q2759.4 1042.23 2754.56 1042.23 Q2751.92 1042.23 2748.9 1042.8 Q2745.87 1043.37 2742.25 1044.58 L2742.25 1038.85 Q2745.91 1037.83 2749.09 1037.33 Q2752.3 1036.82 2755.14 1036.82 Q2762.46 1036.82 2766.72 1040.16 Q2770.99 1043.47 2770.99 1049.13 Q2770.99 1053.08 2768.73 1055.82 Q2766.47 1058.52 2762.3 1059.57 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2824.71 1064.28 Q2821.94 1064.28 2820.35 1066.64 Q2818.79 1068.99 2818.79 1073.2 Q2818.79 1077.33 2820.35 1079.72 Q2821.94 1082.08 2824.71 1082.08 Q2827.42 1082.08 2828.98 1079.72 Q2830.57 1077.33 2830.57 1073.2 Q2830.57 1069.03 2828.98 1066.67 Q2827.42 1064.28 2824.71 1064.28 M2824.71 1060.24 Q2829.74 1060.24 2832.7 1063.74 Q2835.66 1067.24 2835.66 1073.2 Q2835.66 1079.15 2832.67 1082.65 Q2829.71 1086.12 2824.71 1086.12 Q2819.62 1086.12 2816.66 1082.65 Q2813.7 1079.15 2813.7 1073.2 Q2813.7 1067.21 2816.66 1063.74 Q2819.65 1060.24 2824.71 1060.24 M2791.87 1040.86 Q2789.13 1040.86 2787.54 1043.25 Q2785.98 1045.6 2785.98 1049.74 Q2785.98 1053.94 2787.54 1056.3 Q2789.1 1058.65 2791.87 1058.65 Q2794.64 1058.65 2796.19 1056.3 Q2797.79 1053.94 2797.79 1049.74 Q2797.79 1045.63 2796.19 1043.25 Q2794.6 1040.86 2791.87 1040.86 M2820.61 1036.82 L2825.7 1036.82 L2795.97 1086.12 L2790.88 1086.12 L2820.61 1036.82 M2791.87 1036.82 Q2796.9 1036.82 2799.89 1040.32 Q2802.88 1043.79 2802.88 1049.74 Q2802.88 1055.75 2799.89 1059.22 Q2796.93 1062.69 2791.87 1062.69 Q2786.81 1062.69 2783.85 1059.22 Q2780.92 1055.72 2780.92 1049.74 Q2780.92 1043.82 2783.88 1040.32 Q2786.84 1036.82 2791.87 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2844.48 1035.73 L2849.57 1035.73 Q2854.35 1043.25 2856.7 1050.44 Q2859.09 1057.63 2859.09 1064.73 Q2859.09 1071.86 2856.7 1079.08 Q2854.35 1086.31 2849.57 1093.79 L2844.48 1093.79 Q2848.71 1086.5 2850.78 1079.31 Q2852.88 1072.08 2852.88 1064.73 Q2852.88 1057.38 2850.78 1050.22 Q2848.71 1043.05 2844.48 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2872.33 1077.11 L2879.04 1077.11 L2879.04 1082.59 L2873.82 1092.77 L2869.72 1092.77 L2872.33 1082.59 L2872.33 1077.11 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2927.65 1058.87 Q2923.32 1058.87 2920.77 1061.83 Q2918.26 1064.79 2918.26 1069.95 Q2918.26 1075.07 2920.77 1078.07 Q2923.32 1081.03 2927.65 1081.03 Q2931.98 1081.03 2934.49 1078.07 Q2937.04 1075.07 2937.04 1069.95 Q2937.04 1064.79 2934.49 1061.83 Q2931.98 1058.87 2927.65 1058.87 M2940.41 1038.73 L2940.41 1044.58 Q2937.99 1043.44 2935.51 1042.83 Q2933.06 1042.23 2930.64 1042.23 Q2924.27 1042.23 2920.9 1046.52 Q2917.56 1050.82 2917.08 1059.51 Q2918.96 1056.74 2921.79 1055.28 Q2924.62 1053.78 2928.03 1053.78 Q2935.19 1053.78 2939.33 1058.14 Q2943.5 1062.47 2943.5 1069.95 Q2943.5 1077.27 2939.17 1081.69 Q2934.84 1086.12 2927.65 1086.12 Q2919.4 1086.12 2915.04 1079.82 Q2910.68 1073.48 2910.68 1061.48 Q2910.68 1050.22 2916.03 1043.53 Q2921.38 1036.82 2930.38 1036.82 Q2932.8 1036.82 2935.25 1037.29 Q2937.74 1037.77 2940.41 1038.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2988.53 1035.73 Q2984.27 1043.05 2982.2 1050.22 Q2980.13 1057.38 2980.13 1064.73 Q2980.13 1072.08 2982.2 1079.31 Q2984.3 1086.5 2988.53 1093.79 L2983.44 1093.79 Q2978.67 1086.31 2976.28 1079.08 Q2973.93 1071.86 2973.93 1064.73 Q2973.93 1057.63 2976.28 1050.44 Q2978.64 1043.25 2983.44 1035.73 L2988.53 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3000.92 1084.21 L3000.92 1078.35 Q3003.33 1079.5 3005.82 1080.1 Q3008.3 1080.71 3010.69 1080.71 Q3017.05 1080.71 3020.4 1076.44 Q3023.77 1072.15 3024.25 1063.42 Q3022.4 1066.16 3019.57 1067.63 Q3016.73 1069.09 3013.3 1069.09 Q3006.17 1069.09 3002 1064.79 Q2997.86 1060.46 2997.86 1052.98 Q2997.86 1045.66 3002.19 1041.24 Q3006.52 1036.82 3013.71 1036.82 Q3021.95 1036.82 3026.28 1043.15 Q3030.64 1049.45 3030.64 1061.48 Q3030.64 1072.72 3025.3 1079.43 Q3019.98 1086.12 3010.97 1086.12 Q3008.55 1086.12 3006.07 1085.64 Q3003.59 1085.16 3000.92 1084.21 M3013.71 1064.06 Q3018.04 1064.06 3020.55 1061.1 Q3023.1 1058.14 3023.1 1052.98 Q3023.1 1047.86 3020.55 1044.9 Q3018.04 1041.91 3013.71 1041.91 Q3009.38 1041.91 3006.84 1044.9 Q3004.32 1047.86 3004.32 1052.98 Q3004.32 1058.14 3006.84 1061.1 Q3009.38 1064.06 3013.71 1064.06 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3061.68 1059.57 Q3066.29 1060.56 3068.87 1063.68 Q3071.48 1066.8 3071.48 1071.38 Q3071.48 1078.42 3066.64 1082.27 Q3061.8 1086.12 3052.89 1086.12 Q3049.9 1086.12 3046.72 1085.51 Q3043.57 1084.94 3040.19 1083.76 L3040.19 1077.56 Q3042.87 1079.12 3046.05 1079.91 Q3049.23 1080.71 3052.7 1080.71 Q3058.75 1080.71 3061.9 1078.32 Q3065.08 1075.93 3065.08 1071.38 Q3065.08 1067.18 3062.12 1064.83 Q3059.19 1062.44 3053.94 1062.44 L3048.4 1062.44 L3048.4 1057.15 L3054.2 1057.15 Q3058.94 1057.15 3061.45 1055.28 Q3063.97 1053.37 3063.97 1049.8 Q3063.97 1046.14 3061.36 1044.2 Q3058.78 1042.23 3053.94 1042.23 Q3051.3 1042.23 3048.28 1042.8 Q3045.25 1043.37 3041.62 1044.58 L3041.62 1038.85 Q3045.28 1037.83 3048.47 1037.33 Q3051.68 1036.82 3054.52 1036.82 Q3061.84 1036.82 3066.1 1040.16 Q3070.37 1043.47 3070.37 1049.13 Q3070.37 1053.08 3068.11 1055.82 Q3065.85 1058.52 3061.68 1059.57 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3124.09 1064.28 Q3121.32 1064.28 3119.73 1066.64 Q3118.17 1068.99 3118.17 1073.2 Q3118.17 1077.33 3119.73 1079.72 Q3121.32 1082.08 3124.09 1082.08 Q3126.8 1082.08 3128.36 1079.72 Q3129.95 1077.33 3129.95 1073.2 Q3129.95 1069.03 3128.36 1066.67 Q3126.8 1064.28 3124.09 1064.28 M3124.09 1060.24 Q3129.12 1060.24 3132.08 1063.74 Q3135.04 1067.24 3135.04 1073.2 Q3135.04 1079.15 3132.05 1082.65 Q3129.09 1086.12 3124.09 1086.12 Q3119 1086.12 3116.04 1082.65 Q3113.08 1079.15 3113.08 1073.2 Q3113.08 1067.21 3116.04 1063.74 Q3119.03 1060.24 3124.09 1060.24 M3091.25 1040.86 Q3088.51 1040.86 3086.92 1043.25 Q3085.36 1045.6 3085.36 1049.74 Q3085.36 1053.94 3086.92 1056.3 Q3088.48 1058.65 3091.25 1058.65 Q3094.01 1058.65 3095.57 1056.3 Q3097.17 1053.94 3097.17 1049.74 Q3097.17 1045.63 3095.57 1043.25 Q3093.98 1040.86 3091.25 1040.86 M3119.99 1036.82 L3125.08 1036.82 L3095.35 1086.12 L3090.26 1086.12 L3119.99 1036.82 M3091.25 1036.82 Q3096.27 1036.82 3099.27 1040.32 Q3102.26 1043.79 3102.26 1049.74 Q3102.26 1055.75 3099.27 1059.22 Q3096.31 1062.69 3091.25 1062.69 Q3086.18 1062.69 3083.22 1059.22 Q3080.3 1055.72 3080.3 1049.74 Q3080.3 1043.82 3083.26 1040.32 Q3086.22 1036.82 3091.25 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3143.86 1035.73 L3148.95 1035.73 Q3153.72 1043.25 3156.08 1050.44 Q3158.47 1057.63 3158.47 1064.73 Q3158.47 1071.86 3156.08 1079.08 Q3153.72 1086.31 3148.95 1093.79 L3143.86 1093.79 Q3148.09 1086.5 3150.16 1079.31 Q3152.26 1072.08 3152.26 1064.73 Q3152.26 1057.38 3150.16 1050.22 Q3148.09 1043.05 3143.86 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3171.71 1077.11 L3178.42 1077.11 L3178.42 1082.59 L3173.2 1092.77 L3169.1 1092.77 L3171.71 1082.59 L3171.71 1077.11 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3226.23 1062.63 Q3221.65 1062.63 3219.01 1065.08 Q3216.4 1067.53 3216.4 1071.83 Q3216.4 1076.12 3219.01 1078.58 Q3221.65 1081.03 3226.23 1081.03 Q3230.81 1081.03 3233.46 1078.58 Q3236.1 1076.09 3236.1 1071.83 Q3236.1 1067.53 3233.46 1065.08 Q3230.85 1062.63 3226.23 1062.63 M3219.8 1059.89 Q3215.66 1058.87 3213.34 1056.04 Q3211.05 1053.21 3211.05 1049.13 Q3211.05 1043.44 3215.09 1040.13 Q3219.16 1036.82 3226.23 1036.82 Q3233.33 1036.82 3237.37 1040.13 Q3241.41 1043.44 3241.41 1049.13 Q3241.41 1053.21 3239.09 1056.04 Q3236.8 1058.87 3232.69 1059.89 Q3237.34 1060.97 3239.92 1064.12 Q3242.53 1067.28 3242.53 1071.83 Q3242.53 1078.73 3238.29 1082.43 Q3234.09 1086.12 3226.23 1086.12 Q3218.37 1086.12 3214.14 1082.43 Q3209.93 1078.73 3209.93 1071.83 Q3209.93 1067.28 3212.54 1064.12 Q3215.15 1060.97 3219.8 1059.89 M3217.45 1049.74 Q3217.45 1053.43 3219.74 1055.5 Q3222.06 1057.57 3226.23 1057.57 Q3230.37 1057.57 3232.69 1055.5 Q3235.05 1053.43 3235.05 1049.74 Q3235.05 1046.05 3232.69 1043.98 Q3230.37 1041.91 3226.23 1041.91 Q3222.06 1041.91 3219.74 1043.98 Q3217.45 1046.05 3217.45 1049.74 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3287.91 1035.73 Q3283.65 1043.05 3281.58 1050.22 Q3279.51 1057.38 3279.51 1064.73 Q3279.51 1072.08 3281.58 1079.31 Q3283.68 1086.5 3287.91 1093.79 L3282.82 1093.79 Q3278.05 1086.31 3275.66 1079.08 Q3273.3 1071.86 3273.3 1064.73 Q3273.3 1057.63 3275.66 1050.44 Q3278.02 1043.25 3282.82 1035.73 L3287.91 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3319.58 1059.57 Q3324.2 1060.56 3326.78 1063.68 Q3329.39 1066.8 3329.39 1071.38 Q3329.39 1078.42 3324.55 1082.27 Q3319.71 1086.12 3310.8 1086.12 Q3307.81 1086.12 3304.62 1085.51 Q3301.47 1084.94 3298.1 1083.76 L3298.1 1077.56 Q3300.77 1079.12 3303.96 1079.91 Q3307.14 1080.71 3310.61 1080.71 Q3316.66 1080.71 3319.81 1078.32 Q3322.99 1075.93 3322.99 1071.38 Q3322.99 1067.18 3320.03 1064.83 Q3317.1 1062.44 3311.85 1062.44 L3306.31 1062.44 L3306.31 1057.15 L3312.1 1057.15 Q3316.85 1057.15 3319.36 1055.28 Q3321.87 1053.37 3321.87 1049.8 Q3321.87 1046.14 3319.26 1044.2 Q3316.69 1042.23 3311.85 1042.23 Q3309.21 1042.23 3306.18 1042.8 Q3303.16 1043.37 3299.53 1044.58 L3299.53 1038.85 Q3303.19 1037.83 3306.37 1037.33 Q3309.59 1036.82 3312.42 1036.82 Q3319.74 1036.82 3324.01 1040.16 Q3328.27 1043.47 3328.27 1049.13 Q3328.27 1053.08 3326.01 1055.82 Q3323.75 1058.52 3319.58 1059.57 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3382 1064.28 Q3379.23 1064.28 3377.64 1066.64 Q3376.08 1068.99 3376.08 1073.2 Q3376.08 1077.33 3377.64 1079.72 Q3379.23 1082.08 3382 1082.08 Q3384.7 1082.08 3386.26 1079.72 Q3387.86 1077.33 3387.86 1073.2 Q3387.86 1069.03 3386.26 1066.67 Q3384.7 1064.28 3382 1064.28 M3382 1060.24 Q3387.03 1060.24 3389.99 1063.74 Q3392.95 1067.24 3392.95 1073.2 Q3392.95 1079.15 3389.96 1082.65 Q3387 1086.12 3382 1086.12 Q3376.91 1086.12 3373.95 1082.65 Q3370.99 1079.15 3370.99 1073.2 Q3370.99 1067.21 3373.95 1063.74 Q3376.94 1060.24 3382 1060.24 M3349.15 1040.86 Q3346.41 1040.86 3344.82 1043.25 Q3343.26 1045.6 3343.26 1049.74 Q3343.26 1053.94 3344.82 1056.3 Q3346.38 1058.65 3349.15 1058.65 Q3351.92 1058.65 3353.48 1056.3 Q3355.07 1053.94 3355.07 1049.74 Q3355.07 1045.63 3353.48 1043.25 Q3351.89 1040.86 3349.15 1040.86 M3377.89 1036.82 L3382.99 1036.82 L3353.26 1086.12 L3348.17 1086.12 L3377.89 1036.82 M3349.15 1036.82 Q3354.18 1036.82 3357.17 1040.32 Q3360.16 1043.79 3360.16 1049.74 Q3360.16 1055.75 3357.17 1059.22 Q3354.21 1062.69 3349.15 1062.69 Q3344.09 1062.69 3341.13 1059.22 Q3338.2 1055.72 3338.2 1049.74 Q3338.2 1043.82 3341.16 1040.32 Q3344.12 1036.82 3349.15 1036.82 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3401.76 1035.73 L3406.86 1035.73 Q3411.63 1043.25 3413.99 1050.44 Q3416.37 1057.63 3416.37 1064.73 Q3416.37 1071.86 3413.99 1079.08 Q3411.63 1086.31 3406.86 1093.79 L3401.76 1093.79 Q3406 1086.5 3408.07 1079.31 Q3410.17 1072.08 3410.17 1064.73 Q3410.17 1057.38 3408.07 1050.22 Q3406 1043.05 3401.76 1035.73 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3430.12 1091.24 L3432.35 1091.24 Q3436.81 1091.24 3438.14 1089.87 Q3439.51 1088.51 3439.51 1083.95 L3439.51 1076.06 Q3439.51 1071.1 3440.95 1068.84 Q3442.38 1066.58 3445.91 1065.72 Q3442.38 1064.92 3440.95 1062.66 Q3439.51 1060.4 3439.51 1055.4 L3439.51 1047.51 Q3439.51 1042.99 3438.14 1041.62 Q3436.81 1040.22 3432.35 1040.22 L3430.12 1040.22 L3430.12 1035.67 L3432.13 1035.67 Q3440.05 1035.67 3442.7 1038.03 Q3445.37 1040.35 3445.37 1047.38 L3445.37 1055.02 Q3445.37 1059.76 3447.09 1061.61 Q3448.81 1063.42 3453.33 1063.42 L3455.3 1063.42 L3455.3 1067.98 L3453.33 1067.98 Q3448.81 1067.98 3447.09 1069.82 Q3445.37 1071.67 3445.37 1076.47 L3445.37 1084.08 Q3445.37 1091.12 3442.7 1093.47 Q3440.05 1095.83 3432.13 1095.83 L3430.12 1095.83 L3430.12 1091.24 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2870.63 1159.79 Q2868.14 1166.15 2865.79 1168.09 Q2863.43 1170.03 2859.49 1170.03 L2854.81 1170.03 L2854.81 1165.13 L2858.24 1165.13 Q2860.66 1165.13 2862 1163.99 Q2863.34 1162.84 2864.96 1158.58 L2866.01 1155.9 L2851.59 1120.83 L2857.8 1120.83 L2868.94 1148.71 L2880.08 1120.83 L2886.29 1120.83 L2870.63 1159.79 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2900.16 1110.71 L2900.16 1120.83 L2912.23 1120.83 L2912.23 1125.38 L2900.16 1125.38 L2900.16 1144.73 Q2900.16 1149.09 2901.34 1150.33 Q2902.55 1151.57 2906.21 1151.57 L2912.23 1151.57 L2912.23 1156.48 L2906.21 1156.48 Q2899.43 1156.48 2896.85 1153.96 Q2894.27 1151.41 2894.27 1144.73 L2894.27 1125.38 L2889.98 1125.38 L2889.98 1120.83 L2894.27 1120.83 L2894.27 1110.71 L2900.16 1110.71 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2940.59 1126.3 Q2939.6 1125.73 2938.42 1125.47 Q2937.27 1125.19 2935.87 1125.19 Q2930.91 1125.19 2928.24 1128.43 Q2925.59 1131.65 2925.59 1137.7 L2925.59 1156.48 L2919.71 1156.48 L2919.71 1120.83 L2925.59 1120.83 L2925.59 1126.37 Q2927.44 1123.12 2930.4 1121.56 Q2933.36 1119.97 2937.59 1119.97 Q2938.2 1119.97 2938.93 1120.06 Q2939.66 1120.13 2940.55 1120.29 L2940.59 1126.3 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M2946.12 1142.41 L2946.12 1120.83 L2951.98 1120.83 L2951.98 1142.18 Q2951.98 1147.25 2953.95 1149.79 Q2955.93 1152.31 2959.87 1152.31 Q2964.62 1152.31 2967.35 1149.28 Q2970.12 1146.26 2970.12 1141.04 L2970.12 1120.83 L2975.98 1120.83 L2975.98 1156.48 L2970.12 1156.48 L2970.12 1151 Q2967.99 1154.25 2965.16 1155.84 Q2962.36 1157.4 2958.63 1157.4 Q2952.49 1157.4 2949.31 1153.58 Q2946.12 1149.76 2946.12 1142.41 M2960.86 1119.97 L2960.86 1119.97 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3018.53 1137.19 L3018.53 1140.05 L2991.61 1140.05 Q2991.99 1146.1 2995.23 1149.28 Q2998.51 1152.43 3004.34 1152.43 Q3007.71 1152.43 3010.86 1151.61 Q3014.05 1150.78 3017.16 1149.12 L3017.16 1154.66 Q3014.01 1156 3010.7 1156.7 Q3007.39 1157.4 3003.99 1157.4 Q2995.46 1157.4 2990.46 1152.43 Q2985.5 1147.47 2985.5 1139 Q2985.5 1130.25 2990.21 1125.12 Q2994.95 1119.97 3002.97 1119.97 Q3010.16 1119.97 3014.33 1124.62 Q3018.53 1129.23 3018.53 1137.19 M3012.68 1135.47 Q3012.61 1130.66 3009.97 1127.8 Q3007.36 1124.93 3003.03 1124.93 Q2998.13 1124.93 2995.17 1127.7 Q2992.24 1130.47 2991.8 1135.5 L3012.68 1135.47 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3028.91 1126.87 L3069.71 1126.87 L3069.71 1132.22 L3028.91 1132.22 L3028.91 1126.87 M3028.91 1139.86 L3069.71 1139.86 L3069.71 1145.27 L3028.91 1145.27 L3028.91 1139.86 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip240)" d="M3098.14 1130.15 Q3093.81 1130.15 3091.26 1133.11 Q3088.75 1136.07 3088.75 1141.23 Q3088.75 1146.35 3091.26 1149.35 Q3093.81 1152.31 3098.14 1152.31 Q3102.46 1152.31 3104.98 1149.35 Q3107.53 1146.35 3107.53 1141.23 Q3107.53 1136.07 3104.98 1133.11 Q3102.46 1130.15 3098.14 1130.15 M3110.9 1110.01 L3110.9 1115.86 Q3108.48 1114.72 3106 1114.11 Q3103.55 1113.51 3101.13 1113.51 Q3094.76 1113.51 3091.39 1117.8 Q3088.05 1122.1 3087.57 1130.79 Q3089.45 1128.02 3092.28 1126.56 Q3095.11 1125.06 3098.52 1125.06 Q3105.68 1125.06 3109.82 1129.42 Q3113.99 1133.75 3113.99 1141.23 Q3113.99 1148.55 3109.66 1152.97 Q3105.33 1157.4 3098.14 1157.4 Q3089.89 1157.4 3085.53 1151.1 Q3081.17 1144.76 3081.17 1132.76 Q3081.17 1121.5 3086.52 1114.81 Q3091.87 1108.1 3100.87 1108.1 Q3103.29 1108.1 3105.74 1108.57 Q3108.23 1109.05 3110.9 1110.01 Z" fill="#ffffff" fill-rule="nonzero" fill-opacity="1"></path></svg>
<figcaption class="figure-caption">(c) Randomly selected prediction sets of size <img src="https://latex.codecogs.com/png.latex?%7CC%7C=3">.</figcaption>
</figure>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Conformalized predictions from an image classifier.</figcaption><p></p>
</figure>
</div>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">üßê Evaluation</h2>
<p>To evaluate the performance of conformal models, specific performance measures can be used to assess if the model is correctly specified and well-calibrated <span class="citation" data-cites="angelopoulos2021gentle">(A. N. Angelopoulos and Bates 2021)</span>. We will look at this in some more detail in another post in the future. For now, just be aware that these measures are already available in <code>ConformalPrediction.jl</code> and we will briefly showcase them here.</p>
<p>As for many other things, <code>ConformalPrediction.jl</code> taps into the existing functionality of <code>MLJ.jl</code> for model evaluation. In particular, we will see below how we can use the generic <code>evaluate!</code> method on our machine. To assess the correctness of our conformal predictor, we can compute the empirical coverage rate using the custom performance measure <code>emp_coverage</code>. With respect to model calibration we will look at the model‚Äôs conditional coverage. For adaptive, well-calibrated conformal models, conditional coverage is high. One general go-to measure for assessing conditional coverage is size-stratified coverage. The custom measure for this purpose is just called <code>size_stratified_coverage</code>, aliased by <code>ssc</code>.</p>
<p>The code below implements the model evaluation using cross-validation. The Simple Inductive Classifier that we used above is not adaptive and hence the attained conditional coverage is low compared to the overall empirical coverage, which is close to <img src="https://latex.codecogs.com/png.latex?0.95">, so in line with the desired coverage rate specified above.</p>
<div id="553ad995" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">_eval <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">evaluate!</span>(</span>
<span id="cb8-2">    mach,</span>
<span id="cb8-3">    resampling<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">CV</span>(),</span>
<span id="cb8-4">    operation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>predict,</span>
<span id="cb8-5">    measure<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[emp_coverage, ssc]</span>
<span id="cb8-6">)</span>
<span id="cb8-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">display</span>(_eval)</span>
<span id="cb8-8"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Empirical coverage: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(_eval.measurement[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], digits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb8-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SSC: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(_eval.measurement[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], digits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="ansi-escaped-output">
<pre>PerformanceEvaluation object with these fields:
  measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows
Extract:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ measure                                      ‚îÇ operation ‚îÇ measurement ‚îÇ 1.9 ‚ãØ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ ConformalPrediction.emp_coverage             ‚îÇ predict   ‚îÇ 0.95        ‚îÇ 0.0 ‚ãØ
‚îÇ ConformalPrediction.size_stratified_coverage ‚îÇ predict   ‚îÇ 0.867       ‚îÇ 0.0 ‚ãØ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span class="ansi-cyan-fg">                                                               2 columns omitted</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Empirical coverage: 0.95
SSC: 0.867</code></pre>
</div>
</div>
<p>We can attain higher adaptivity (SSC) when using adaptive prediction sets:</p>
<div id="5136749f" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb10-1">conf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_model</span>(clf; method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>adaptive_inductive, coverage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.95</span>)</span>
<span id="cb10-2">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(conf_model, X, y)</span>
<span id="cb10-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach)</span>
<span id="cb10-4">_eval <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">evaluate!</span>(</span>
<span id="cb10-5">    mach,</span>
<span id="cb10-6">    resampling<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">CV</span>(),</span>
<span id="cb10-7">    operation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>predict,</span>
<span id="cb10-8">    measure<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[emp_coverage, ssc]</span>
<span id="cb10-9">)</span>
<span id="cb10-10">results[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>adaptive_inductive] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mach</span>
<span id="cb10-11"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">display</span>(_eval)</span>
<span id="cb10-12"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Empirical coverage: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(_eval.measurement[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], digits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb10-13"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">println</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SSC: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(_eval.measurement[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], digits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="ansi-escaped-output">
<pre>PerformanceEvaluation object with these fields:
  measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows
Extract:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ measure                                      ‚îÇ operation ‚îÇ measurement ‚îÇ 1.9 ‚ãØ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚îÇ ConformalPrediction.emp_coverage             ‚îÇ predict   ‚îÇ 0.994       ‚îÇ 0.0 ‚ãØ
‚îÇ ConformalPrediction.size_stratified_coverage ‚îÇ predict   ‚îÇ 0.97        ‚îÇ 0.0 ‚ãØ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span class="ansi-cyan-fg">                                                               2 columns omitted</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Empirical coverage: 0.994
SSC: 0.97</code></pre>
</div>
</div>
<p>We can also have a look at the resulting set size for both approaches using a custom <code>Plots.jl</code> recipe (fig-setsize). In line with the above, the spread is wider for the adaptive approach, which reflects that ‚Äúthe procedure is effectively distinguishing between easy and hard inputs‚Äù <span class="citation" data-cites="angelopoulos2021gentle">(A. N. Angelopoulos and Bates 2021)</span>.</p>
<div id="cell-fig-setsize" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb12-1">plt_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb12-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (_mod, mach) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> results</span>
<span id="cb12-3">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">push!</span>(plt_list, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bar</span>(mach.model, mach.fitresult, X; title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">String</span>(_mod)))</span>
<span id="cb12-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb12-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(plt_list<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">800</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>))</span>
<span id="cb12-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(plt_list<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">800</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>),bg_colour<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>transparent)</span></code></pre></div>
<div id="fig-setsize" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<!--?xml version="1.0" encoding="utf-8"?-->
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" width="800" height="300" viewbox="0 0 3200 1200">
<defs>
  <clippath id="clip330">
    <rect x="0" y="0" width="3200" height="1200"></rect>
  </clippath>
</defs>
<defs>
  <clippath id="clip331">
    <rect x="640" y="0" width="2241" height="1200"></rect>
  </clippath>
</defs>
<defs>
  <clippath id="clip332">
    <rect x="178" y="97" width="1374" height="1014"></rect>
  </clippath>
</defs>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="356.247,1110.43 356.247,97.0121 "></polyline>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="610.882,1110.43 610.882,97.0121 "></polyline>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="865.517,1110.43 865.517,97.0121 "></polyline>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1120.15,1110.43 1120.15,97.0121 "></polyline>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1374.79,1110.43 1374.79,97.0121 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="178.857,1110.43 1552.18,1110.43 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="356.247,1110.43 356.247,1091.53 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="610.882,1110.43 610.882,1091.53 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="865.517,1110.43 865.517,1091.53 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1120.15,1110.43 1120.15,1091.53 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1374.79,1110.43 1374.79,1091.53 "></polyline>
<path clip-path="url(#clip330)" d="M269.659 1141.26 L269.659 1176.81 L266.707 1176.81 L266.707 1141.26 L269.659 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M297.072 1144.5 L297.072 1148.2 Q295.301 1146.55 293.287 1145.74 Q291.29 1144.92 289.033 1144.92 Q284.589 1144.92 282.228 1147.65 Q279.867 1150.36 279.867 1155.49 Q279.867 1160.62 282.228 1163.34 Q284.589 1166.05 289.033 1166.05 Q291.29 1166.05 293.287 1165.23 Q295.301 1164.42 297.072 1162.77 L297.072 1166.43 Q295.231 1167.68 293.165 1168.31 Q291.117 1168.93 288.825 1168.93 Q282.94 1168.93 279.554 1165.34 Q276.169 1161.73 276.169 1155.49 Q276.169 1149.24 279.554 1145.65 Q282.94 1142.04 288.825 1142.04 Q291.151 1142.04 293.2 1142.66 Q295.266 1143.27 297.072 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M306.464 1141.26 L306.464 1176.81 L303.513 1176.81 L303.513 1141.26 L306.464 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M328.235 1157.54 Q328.356 1158.83 329.45 1160.91 Q330.735 1163.32 333.165 1164.68 Q335.544 1166 338.113 1166.01 L350.214 1166.01 L350.214 1168.78 L338.113 1168.78 Q334.78 1168.78 331.689 1167.06 Q328.617 1165.34 326.967 1162.28 Q325.318 1159.23 325.318 1155.98 Q325.318 1152.77 326.967 1149.71 Q328.617 1146.66 331.689 1144.92 Q334.78 1143.18 338.113 1143.18 L350.214 1143.18 L350.214 1145.95 L338.113 1145.95 Q335.544 1145.96 333.165 1147.3 Q330.752 1148.67 329.45 1151.07 Q328.339 1153.15 328.183 1154.76 L350.214 1154.76 L350.214 1157.54 L328.235 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M367.609 1141.41 L374.97 1141.41 L374.97 1143.9 L370.804 1143.9 L370.804 1170.63 L374.97 1170.63 L374.97 1173.12 L367.609 1173.12 L367.609 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M385.248 1165.48 L397.488 1165.48 L397.488 1168.43 L381.029 1168.43 L381.029 1165.48 Q383.026 1163.41 386.463 1159.94 Q389.918 1156.45 390.804 1155.44 Q392.488 1153.55 393.147 1152.25 Q393.825 1150.93 393.825 1149.66 Q393.825 1147.59 392.366 1146.29 Q390.925 1144.99 388.599 1144.99 Q386.95 1144.99 385.109 1145.56 Q383.286 1146.14 381.203 1147.3 L381.203 1143.76 Q383.321 1142.91 385.161 1142.47 Q387.002 1142.04 388.529 1142.04 Q392.557 1142.04 394.953 1144.05 Q397.349 1146.07 397.349 1149.43 Q397.349 1151.03 396.741 1152.47 Q396.151 1153.9 394.571 1155.84 Q394.137 1156.34 391.811 1158.76 Q389.484 1161.15 385.248 1165.48 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M405.213 1164.02 L408.877 1164.02 L408.877 1167 L406.029 1172.56 L403.79 1172.56 L405.213 1167 L405.213 1164.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M426.776 1154.45 Q429.293 1154.99 430.699 1156.69 Q432.123 1158.39 432.123 1160.89 Q432.123 1164.73 429.484 1166.83 Q426.845 1168.93 421.984 1168.93 Q420.352 1168.93 418.616 1168.6 Q416.897 1168.29 415.057 1167.65 L415.057 1164.26 Q416.515 1165.11 418.251 1165.55 Q419.988 1165.98 421.88 1165.98 Q425.179 1165.98 426.897 1164.68 Q428.633 1163.38 428.633 1160.89 Q428.633 1158.6 427.019 1157.32 Q425.422 1156.01 422.557 1156.01 L419.536 1156.01 L419.536 1153.13 L422.696 1153.13 Q425.283 1153.13 426.654 1152.11 Q428.026 1151.07 428.026 1149.12 Q428.026 1147.13 426.602 1146.07 Q425.196 1144.99 422.557 1144.99 Q421.116 1144.99 419.467 1145.3 Q417.817 1145.62 415.838 1146.28 L415.838 1143.15 Q417.835 1142.59 419.571 1142.32 Q421.324 1142.04 422.87 1142.04 Q426.863 1142.04 429.189 1143.86 Q431.515 1145.67 431.515 1148.76 Q431.515 1150.91 430.283 1152.4 Q429.05 1153.88 426.776 1154.45 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M445.786 1141.41 L445.786 1173.12 L438.425 1173.12 L438.425 1170.63 L442.574 1170.63 L442.574 1143.9 L438.425 1143.9 L438.425 1141.41 L445.786 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M524.294 1141.26 L524.294 1176.81 L521.343 1176.81 L521.343 1141.26 L524.294 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M551.707 1144.5 L551.707 1148.2 Q549.936 1146.55 547.922 1145.74 Q545.926 1144.92 543.669 1144.92 Q539.224 1144.92 536.863 1147.65 Q534.502 1150.36 534.502 1155.49 Q534.502 1160.62 536.863 1163.34 Q539.224 1166.05 543.669 1166.05 Q545.926 1166.05 547.922 1165.23 Q549.936 1164.42 551.707 1162.77 L551.707 1166.43 Q549.867 1167.68 547.801 1168.31 Q545.752 1168.93 543.46 1168.93 Q537.575 1168.93 534.19 1165.34 Q530.804 1161.73 530.804 1155.49 Q530.804 1149.24 534.19 1145.65 Q537.575 1142.04 543.46 1142.04 Q545.787 1142.04 547.835 1142.66 Q549.901 1143.27 551.707 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M561.099 1141.26 L561.099 1176.81 L558.148 1176.81 L558.148 1141.26 L561.099 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M582.87 1157.54 Q582.991 1158.83 584.085 1160.91 Q585.37 1163.32 587.8 1164.68 Q590.179 1166 592.748 1166.01 L604.849 1166.01 L604.849 1168.78 L592.748 1168.78 Q589.415 1168.78 586.325 1167.06 Q583.252 1165.34 581.603 1162.28 Q579.953 1159.23 579.953 1155.98 Q579.953 1152.77 581.603 1149.71 Q583.252 1146.66 586.325 1144.92 Q589.415 1143.18 592.748 1143.18 L604.849 1143.18 L604.849 1145.95 L592.748 1145.95 Q590.179 1145.96 587.8 1147.3 Q585.387 1148.67 584.085 1151.07 Q582.974 1153.15 582.818 1154.76 L604.849 1154.76 L604.849 1157.54 L582.87 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M622.245 1141.41 L629.606 1141.41 L629.606 1143.9 L625.439 1143.9 L625.439 1170.63 L629.606 1170.63 L629.606 1173.12 L622.245 1173.12 L622.245 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M646.498 1145.56 L637.644 1159.4 L646.498 1159.4 L646.498 1145.56 M645.578 1142.51 L649.988 1142.51 L649.988 1159.4 L653.686 1159.4 L653.686 1162.32 L649.988 1162.32 L649.988 1168.43 L646.498 1168.43 L646.498 1162.32 L634.797 1162.32 L634.797 1158.93 L645.578 1142.51 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M659.849 1164.02 L663.512 1164.02 L663.512 1167 L660.665 1172.56 L658.425 1172.56 L659.849 1167 L659.849 1164.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M670.821 1142.51 L684.588 1142.51 L684.588 1145.46 L674.033 1145.46 L674.033 1151.81 Q674.797 1151.55 675.56 1151.43 Q676.324 1151.29 677.088 1151.29 Q681.428 1151.29 683.963 1153.67 Q686.498 1156.05 686.498 1160.11 Q686.498 1164.3 683.894 1166.62 Q681.29 1168.93 676.55 1168.93 Q674.918 1168.93 673.217 1168.65 Q671.533 1168.38 669.727 1167.82 L669.727 1164.3 Q671.29 1165.15 672.956 1165.56 Q674.623 1165.98 676.481 1165.98 Q679.484 1165.98 681.237 1164.4 Q682.991 1162.82 682.991 1160.11 Q682.991 1157.4 681.237 1155.82 Q679.484 1154.24 676.481 1154.24 Q675.074 1154.24 673.668 1154.56 Q672.279 1154.87 670.821 1155.53 L670.821 1142.51 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M700.421 1141.41 L700.421 1173.12 L693.06 1173.12 L693.06 1170.63 L697.21 1170.63 L697.21 1143.9 L693.06 1143.9 L693.06 1141.41 L700.421 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M778.929 1141.26 L778.929 1176.81 L775.978 1176.81 L775.978 1141.26 L778.929 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M806.342 1144.5 L806.342 1148.2 Q804.571 1146.55 802.558 1145.74 Q800.561 1144.92 798.304 1144.92 Q793.86 1144.92 791.499 1147.65 Q789.138 1150.36 789.138 1155.49 Q789.138 1160.62 791.499 1163.34 Q793.86 1166.05 798.304 1166.05 Q800.561 1166.05 802.558 1165.23 Q804.571 1164.42 806.342 1162.77 L806.342 1166.43 Q804.502 1167.68 802.436 1168.31 Q800.387 1168.93 798.096 1168.93 Q792.21 1168.93 788.825 1165.34 Q785.44 1161.73 785.44 1155.49 Q785.44 1149.24 788.825 1145.65 Q792.21 1142.04 798.096 1142.04 Q800.422 1142.04 802.471 1142.66 Q804.537 1143.27 806.342 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M815.735 1141.26 L815.735 1176.81 L812.783 1176.81 L812.783 1141.26 L815.735 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M837.505 1157.54 Q837.627 1158.83 838.721 1160.91 Q840.005 1163.32 842.436 1164.68 Q844.814 1166 847.384 1166.01 L859.484 1166.01 L859.484 1168.78 L847.384 1168.78 Q844.05 1168.78 840.96 1167.06 Q837.887 1165.34 836.238 1162.28 Q834.589 1159.23 834.589 1155.98 Q834.589 1152.77 836.238 1149.71 Q837.887 1146.66 840.96 1144.92 Q844.05 1143.18 847.384 1143.18 L859.484 1143.18 L859.484 1145.95 L847.384 1145.95 Q844.814 1145.96 842.436 1147.3 Q840.023 1148.67 838.721 1151.07 Q837.609 1153.15 837.453 1154.76 L859.484 1154.76 L859.484 1157.54 L837.505 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M876.88 1141.41 L884.241 1141.41 L884.241 1143.9 L880.075 1143.9 L880.075 1170.63 L884.241 1170.63 L884.241 1173.12 L876.88 1173.12 L876.88 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M899.432 1154.07 Q897.071 1154.07 895.682 1155.68 Q894.311 1157.3 894.311 1160.11 Q894.311 1162.91 895.682 1164.54 Q897.071 1166.15 899.432 1166.15 Q901.793 1166.15 903.165 1164.54 Q904.554 1162.91 904.554 1160.11 Q904.554 1157.3 903.165 1155.68 Q901.793 1154.07 899.432 1154.07 M906.394 1143.08 L906.394 1146.28 Q905.074 1145.65 903.72 1145.32 Q902.383 1144.99 901.064 1144.99 Q897.592 1144.99 895.752 1147.33 Q893.929 1149.68 893.668 1154.42 Q894.693 1152.91 896.238 1152.11 Q897.783 1151.29 899.64 1151.29 Q903.547 1151.29 905.804 1153.67 Q908.078 1156.03 908.078 1160.11 Q908.078 1164.1 905.717 1166.52 Q903.356 1168.93 899.432 1168.93 Q894.936 1168.93 892.557 1165.49 Q890.179 1162.04 890.179 1155.49 Q890.179 1149.35 893.095 1145.7 Q896.012 1142.04 900.925 1142.04 Q902.245 1142.04 903.581 1142.3 Q904.936 1142.56 906.394 1143.08 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M914.484 1164.02 L918.147 1164.02 L918.147 1167 L915.3 1172.56 L913.06 1172.56 L914.484 1167 L914.484 1164.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M924.536 1142.51 L941.203 1142.51 L941.203 1144 L931.793 1168.43 L928.13 1168.43 L936.984 1145.46 L924.536 1145.46 L924.536 1142.51 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M955.057 1141.41 L955.057 1173.12 L947.696 1173.12 L947.696 1170.63 L951.845 1170.63 L951.845 1143.9 L947.696 1143.9 L947.696 1141.41 L955.057 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1033.56 1141.26 L1033.56 1176.81 L1030.61 1176.81 L1030.61 1141.26 L1033.56 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1060.98 1144.5 L1060.98 1148.2 Q1059.21 1146.55 1057.19 1145.74 Q1055.2 1144.92 1052.94 1144.92 Q1048.5 1144.92 1046.13 1147.65 Q1043.77 1150.36 1043.77 1155.49 Q1043.77 1160.62 1046.13 1163.34 Q1048.5 1166.05 1052.94 1166.05 Q1055.2 1166.05 1057.19 1165.23 Q1059.21 1164.42 1060.98 1162.77 L1060.98 1166.43 Q1059.14 1167.68 1057.07 1168.31 Q1055.02 1168.93 1052.73 1168.93 Q1046.85 1168.93 1043.46 1165.34 Q1040.07 1161.73 1040.07 1155.49 Q1040.07 1149.24 1043.46 1145.65 Q1046.85 1142.04 1052.73 1142.04 Q1055.06 1142.04 1057.11 1142.66 Q1059.17 1143.27 1060.98 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1070.37 1141.26 L1070.37 1176.81 L1067.42 1176.81 L1067.42 1141.26 L1070.37 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1092.14 1157.54 Q1092.26 1158.83 1093.36 1160.91 Q1094.64 1163.32 1097.07 1164.68 Q1099.45 1166 1102.02 1166.01 L1114.12 1166.01 L1114.12 1168.78 L1102.02 1168.78 Q1098.69 1168.78 1095.6 1167.06 Q1092.52 1165.34 1090.87 1162.28 Q1089.22 1159.23 1089.22 1155.98 Q1089.22 1152.77 1090.87 1149.71 Q1092.52 1146.66 1095.6 1144.92 Q1098.69 1143.18 1102.02 1143.18 L1114.12 1143.18 L1114.12 1145.95 L1102.02 1145.95 Q1099.45 1145.96 1097.07 1147.3 Q1094.66 1148.67 1093.36 1151.07 Q1092.24 1153.15 1092.09 1154.76 L1114.12 1154.76 L1114.12 1157.54 L1092.14 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1131.52 1141.41 L1138.88 1141.41 L1138.88 1143.9 L1134.71 1143.9 L1134.71 1170.63 L1138.88 1170.63 L1138.88 1173.12 L1131.52 1173.12 L1131.52 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1153.63 1156.12 Q1151.13 1156.12 1149.69 1157.46 Q1148.27 1158.79 1148.27 1161.14 Q1148.27 1163.48 1149.69 1164.82 Q1151.13 1166.15 1153.63 1166.15 Q1156.13 1166.15 1157.57 1164.82 Q1159.02 1163.46 1159.02 1161.14 Q1159.02 1158.79 1157.57 1157.46 Q1156.15 1156.12 1153.63 1156.12 M1150.13 1154.63 Q1147.87 1154.07 1146.6 1152.53 Q1145.35 1150.98 1145.35 1148.76 Q1145.35 1145.65 1147.56 1143.84 Q1149.78 1142.04 1153.63 1142.04 Q1157.5 1142.04 1159.71 1143.84 Q1161.91 1145.65 1161.91 1148.76 Q1161.91 1150.98 1160.65 1152.53 Q1159.4 1154.07 1157.16 1154.63 Q1159.69 1155.22 1161.1 1156.93 Q1162.52 1158.65 1162.52 1161.14 Q1162.52 1164.9 1160.21 1166.92 Q1157.92 1168.93 1153.63 1168.93 Q1149.35 1168.93 1147.04 1166.92 Q1144.74 1164.9 1144.74 1161.14 Q1144.74 1158.65 1146.17 1156.93 Q1147.59 1155.22 1150.13 1154.63 M1148.84 1149.09 Q1148.84 1151.1 1150.09 1152.23 Q1151.36 1153.36 1153.63 1153.36 Q1155.89 1153.36 1157.16 1152.23 Q1158.44 1151.1 1158.44 1149.09 Q1158.44 1147.07 1157.16 1145.95 Q1155.89 1144.82 1153.63 1144.82 Q1151.36 1144.82 1150.09 1145.95 Q1148.84 1147.07 1148.84 1149.09 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1169.12 1164.02 L1172.78 1164.02 L1172.78 1167 L1169.94 1172.56 L1167.7 1172.56 L1169.12 1167 L1169.12 1164.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1180.16 1167.89 L1180.16 1164.7 Q1181.48 1165.32 1182.83 1165.65 Q1184.19 1165.98 1185.49 1165.98 Q1188.96 1165.98 1190.79 1163.65 Q1192.63 1161.31 1192.89 1156.55 Q1191.88 1158.05 1190.33 1158.84 Q1188.79 1159.64 1186.91 1159.64 Q1183.03 1159.64 1180.75 1157.3 Q1178.49 1154.94 1178.49 1150.86 Q1178.49 1146.87 1180.86 1144.45 Q1183.22 1142.04 1187.14 1142.04 Q1191.64 1142.04 1194 1145.49 Q1196.38 1148.93 1196.38 1155.49 Q1196.38 1161.62 1193.46 1165.29 Q1190.56 1168.93 1185.65 1168.93 Q1184.33 1168.93 1182.97 1168.67 Q1181.62 1168.41 1180.16 1167.89 M1187.14 1156.9 Q1189.5 1156.9 1190.87 1155.29 Q1192.26 1153.67 1192.26 1150.86 Q1192.26 1148.06 1190.87 1146.45 Q1189.5 1144.82 1187.14 1144.82 Q1184.78 1144.82 1183.39 1146.45 Q1182.02 1148.06 1182.02 1150.86 Q1182.02 1153.67 1183.39 1155.29 Q1184.78 1156.9 1187.14 1156.9 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1209.69 1141.41 L1209.69 1173.12 L1202.33 1173.12 L1202.33 1170.63 L1206.48 1170.63 L1206.48 1143.9 L1202.33 1143.9 L1202.33 1141.41 L1209.69 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1293.85 1141.26 L1293.85 1176.81 L1290.9 1176.81 L1290.9 1141.26 L1293.85 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1321.26 1144.5 L1321.26 1148.2 Q1319.49 1146.55 1317.48 1145.74 Q1315.48 1144.92 1313.23 1144.92 Q1308.78 1144.92 1306.42 1147.65 Q1304.06 1150.36 1304.06 1155.49 Q1304.06 1160.62 1306.42 1163.34 Q1308.78 1166.05 1313.23 1166.05 Q1315.48 1166.05 1317.48 1165.23 Q1319.49 1164.42 1321.26 1162.77 L1321.26 1166.43 Q1319.42 1167.68 1317.36 1168.31 Q1315.31 1168.93 1313.02 1168.93 Q1307.13 1168.93 1303.75 1165.34 Q1300.36 1161.73 1300.36 1155.49 Q1300.36 1149.24 1303.75 1145.65 Q1307.13 1142.04 1313.02 1142.04 Q1315.34 1142.04 1317.39 1142.66 Q1319.46 1143.27 1321.26 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1330.66 1141.26 L1330.66 1176.81 L1327.7 1176.81 L1327.7 1141.26 L1330.66 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1352.43 1157.54 Q1352.55 1158.83 1353.64 1160.91 Q1354.93 1163.32 1357.36 1164.68 Q1359.74 1166 1362.31 1166.01 L1374.41 1166.01 L1374.41 1168.78 L1362.31 1168.78 Q1358.97 1168.78 1355.88 1167.06 Q1352.81 1165.34 1351.16 1162.28 Q1349.51 1159.23 1349.51 1155.98 Q1349.51 1152.77 1351.16 1149.71 Q1352.81 1146.66 1355.88 1144.92 Q1358.97 1143.18 1362.31 1143.18 L1374.41 1143.18 L1374.41 1145.95 L1362.31 1145.95 Q1359.74 1145.96 1357.36 1147.3 Q1354.94 1148.67 1353.64 1151.07 Q1352.53 1153.15 1352.37 1154.76 L1374.41 1154.76 L1374.41 1157.54 L1352.43 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1391.8 1141.41 L1399.16 1141.41 L1399.16 1143.9 L1395 1143.9 L1395 1170.63 L1399.16 1170.63 L1399.16 1173.12 L1391.8 1173.12 L1391.8 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1407.03 1165.48 L1412.76 1165.48 L1412.76 1145.7 L1406.52 1146.95 L1406.52 1143.76 L1412.72 1142.51 L1416.23 1142.51 L1416.23 1165.48 L1421.96 1165.48 L1421.96 1168.43 L1407.03 1168.43 L1407.03 1165.48 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1436.54 1144.82 Q1433.83 1144.82 1432.46 1147.49 Q1431.11 1150.15 1431.11 1155.49 Q1431.11 1160.82 1432.46 1163.5 Q1433.83 1166.15 1436.54 1166.15 Q1439.27 1166.15 1440.62 1163.5 Q1441.99 1160.82 1441.99 1155.49 Q1441.99 1150.15 1440.62 1147.49 Q1439.27 1144.82 1436.54 1144.82 M1436.54 1142.04 Q1440.9 1142.04 1443.19 1145.49 Q1445.5 1148.93 1445.5 1155.49 Q1445.5 1162.04 1443.19 1165.49 Q1440.9 1168.93 1436.54 1168.93 Q1432.18 1168.93 1429.87 1165.49 Q1427.58 1162.04 1427.58 1155.49 Q1427.58 1148.93 1429.87 1145.49 Q1432.18 1142.04 1436.54 1142.04 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1458.68 1141.41 L1458.68 1173.12 L1451.32 1173.12 L1451.32 1170.63 L1455.46 1170.63 L1455.46 1143.9 L1451.32 1143.9 L1451.32 1141.41 L1458.68 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="178.857,1081.75 1552.18,1081.75 "></polyline>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="178.857,873.909 1552.18,873.909 "></polyline>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="178.857,666.071 1552.18,666.071 "></polyline>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="178.857,458.234 1552.18,458.234 "></polyline>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="178.857,250.396 1552.18,250.396 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="178.857,1110.43 178.857,97.0121 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="178.857,1081.75 197.755,1081.75 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="178.857,873.909 197.755,873.909 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="178.857,666.071 197.755,666.071 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="178.857,458.234 197.755,458.234 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="178.857,250.396 197.755,250.396 "></polyline>
<path clip-path="url(#clip330)" d="M118.913 1067.54 Q115.302 1067.54 113.473 1071.11 Q111.668 1074.65 111.668 1081.78 Q111.668 1088.89 113.473 1092.45 Q115.302 1095.99 118.913 1095.99 Q122.547 1095.99 124.353 1092.45 Q126.182 1088.89 126.182 1081.78 Q126.182 1074.65 124.353 1071.11 Q122.547 1067.54 118.913 1067.54 M118.913 1063.84 Q124.723 1063.84 127.779 1068.45 Q130.857 1073.03 130.857 1081.78 Q130.857 1090.51 127.779 1095.11 Q124.723 1099.7 118.913 1099.7 Q113.103 1099.7 110.024 1095.11 Q106.969 1090.51 106.969 1081.78 Q106.969 1073.03 110.024 1068.45 Q113.103 1063.84 118.913 1063.84 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M78.7975 856.629 L97.1539 856.629 L97.1539 860.564 L83.0799 860.564 L83.0799 869.036 Q84.0984 868.689 85.1169 868.527 Q86.1354 868.342 87.1539 868.342 Q92.941 868.342 96.3206 871.513 Q99.7002 874.684 99.7002 880.101 Q99.7002 885.68 96.228 888.781 Q92.7558 891.86 86.4364 891.86 Q84.2604 891.86 81.9919 891.49 Q79.7466 891.119 77.3392 890.379 L77.3392 885.68 Q79.4225 886.814 81.6447 887.369 Q83.8669 887.925 86.3438 887.925 Q90.3484 887.925 92.6863 885.818 Q95.0243 883.712 95.0243 880.101 Q95.0243 876.49 92.6863 874.383 Q90.3484 872.277 86.3438 872.277 Q84.4688 872.277 82.5938 872.694 Q80.7419 873.11 78.7975 873.99 L78.7975 856.629 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M118.913 859.707 Q115.302 859.707 113.473 863.272 Q111.668 866.814 111.668 873.943 Q111.668 881.05 113.473 884.615 Q115.302 888.156 118.913 888.156 Q122.547 888.156 124.353 884.615 Q126.182 881.05 126.182 873.943 Q126.182 866.814 124.353 863.272 Q122.547 859.707 118.913 859.707 M118.913 856.004 Q124.723 856.004 127.779 860.61 Q130.857 865.194 130.857 873.943 Q130.857 882.67 127.779 887.277 Q124.723 891.86 118.913 891.86 Q113.103 891.86 110.024 887.277 Q106.969 882.67 106.969 873.943 Q106.969 865.194 110.024 860.61 Q113.103 856.004 118.913 856.004 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M49.3995 679.416 L57.0384 679.416 L57.0384 653.05 L48.7282 654.717 L48.7282 650.458 L56.9921 648.791 L61.668 648.791 L61.668 679.416 L69.3068 679.416 L69.3068 683.351 L49.3995 683.351 L49.3995 679.416 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M88.7512 651.87 Q85.1401 651.87 83.3114 655.435 Q81.5058 658.976 81.5058 666.106 Q81.5058 673.212 83.3114 676.777 Q85.1401 680.319 88.7512 680.319 Q92.3854 680.319 94.1909 676.777 Q96.0196 673.212 96.0196 666.106 Q96.0196 658.976 94.1909 655.435 Q92.3854 651.87 88.7512 651.87 M88.7512 648.166 Q94.5613 648.166 97.6169 652.773 Q100.696 657.356 100.696 666.106 Q100.696 674.833 97.6169 679.439 Q94.5613 684.023 88.7512 684.023 Q82.941 684.023 79.8623 679.439 Q76.8068 674.833 76.8068 666.106 Q76.8068 657.356 79.8623 652.773 Q82.941 648.166 88.7512 648.166 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M118.913 651.87 Q115.302 651.87 113.473 655.435 Q111.668 658.976 111.668 666.106 Q111.668 673.212 113.473 676.777 Q115.302 680.319 118.913 680.319 Q122.547 680.319 124.353 676.777 Q126.182 673.212 126.182 666.106 Q126.182 658.976 124.353 655.435 Q122.547 651.87 118.913 651.87 M118.913 648.166 Q124.723 648.166 127.779 652.773 Q130.857 657.356 130.857 666.106 Q130.857 674.833 127.779 679.439 Q124.723 684.023 118.913 684.023 Q113.103 684.023 110.024 679.439 Q106.969 674.833 106.969 666.106 Q106.969 657.356 110.024 652.773 Q113.103 648.166 118.913 648.166 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M49.3995 471.579 L57.0384 471.579 L57.0384 445.213 L48.7282 446.88 L48.7282 442.62 L56.9921 440.954 L61.668 440.954 L61.668 471.579 L69.3068 471.579 L69.3068 475.514 L49.3995 475.514 L49.3995 471.579 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M78.7975 440.954 L97.1539 440.954 L97.1539 444.889 L83.0799 444.889 L83.0799 453.361 Q84.0984 453.014 85.1169 452.852 Q86.1354 452.667 87.1539 452.667 Q92.941 452.667 96.3206 455.838 Q99.7002 459.009 99.7002 464.426 Q99.7002 470.005 96.228 473.106 Q92.7558 476.185 86.4364 476.185 Q84.2604 476.185 81.9919 475.815 Q79.7466 475.444 77.3392 474.704 L77.3392 470.005 Q79.4225 471.139 81.6447 471.694 Q83.8669 472.25 86.3438 472.25 Q90.3484 472.25 92.6863 470.143 Q95.0243 468.037 95.0243 464.426 Q95.0243 460.815 92.6863 458.708 Q90.3484 456.602 86.3438 456.602 Q84.4688 456.602 82.5938 457.018 Q80.7419 457.435 78.7975 458.315 L78.7975 440.954 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M118.913 444.032 Q115.302 444.032 113.473 447.597 Q111.668 451.139 111.668 458.268 Q111.668 465.375 113.473 468.94 Q115.302 472.481 118.913 472.481 Q122.547 472.481 124.353 468.94 Q126.182 465.375 126.182 458.268 Q126.182 451.139 124.353 447.597 Q122.547 444.032 118.913 444.032 M118.913 440.329 Q124.723 440.329 127.779 444.935 Q130.857 449.519 130.857 458.268 Q130.857 466.995 127.779 471.602 Q124.723 476.185 118.913 476.185 Q113.103 476.185 110.024 471.602 Q106.969 466.995 106.969 458.268 Q106.969 449.519 110.024 444.935 Q113.103 440.329 118.913 440.329 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M52.6171 263.741 L68.9365 263.741 L68.9365 267.676 L46.9921 267.676 L46.9921 263.741 Q49.6541 260.986 54.2375 256.357 Q58.8439 251.704 60.0245 250.361 Q62.2698 247.838 63.1494 246.102 Q64.0522 244.343 64.0522 242.653 Q64.0522 239.899 62.1078 238.162 Q60.1865 236.426 57.0847 236.426 Q54.8856 236.426 52.4319 237.19 Q50.0014 237.954 47.2236 239.505 L47.2236 234.783 Q50.0477 233.649 52.5014 233.07 Q54.955 232.491 56.9921 232.491 Q62.3624 232.491 65.5568 235.176 Q68.7513 237.862 68.7513 242.352 Q68.7513 244.482 67.9411 246.403 Q67.1541 248.301 65.0476 250.894 Q64.4689 251.565 61.367 254.783 Q58.2652 257.977 52.6171 263.741 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M88.7512 236.195 Q85.1401 236.195 83.3114 239.76 Q81.5058 243.301 81.5058 250.431 Q81.5058 257.537 83.3114 261.102 Q85.1401 264.644 88.7512 264.644 Q92.3854 264.644 94.1909 261.102 Q96.0196 257.537 96.0196 250.431 Q96.0196 243.301 94.1909 239.76 Q92.3854 236.195 88.7512 236.195 M88.7512 232.491 Q94.5613 232.491 97.6169 237.098 Q100.696 241.681 100.696 250.431 Q100.696 259.158 97.6169 263.764 Q94.5613 268.348 88.7512 268.348 Q82.941 268.348 79.8623 263.764 Q76.8068 259.158 76.8068 250.431 Q76.8068 241.681 79.8623 237.098 Q82.941 232.491 88.7512 232.491 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M118.913 236.195 Q115.302 236.195 113.473 239.76 Q111.668 243.301 111.668 250.431 Q111.668 257.537 113.473 261.102 Q115.302 264.644 118.913 264.644 Q122.547 264.644 124.353 261.102 Q126.182 257.537 126.182 250.431 Q126.182 243.301 124.353 239.76 Q122.547 236.195 118.913 236.195 M118.913 232.491 Q124.723 232.491 127.779 237.098 Q130.857 241.681 130.857 250.431 Q130.857 259.158 127.779 263.764 Q124.723 268.348 118.913 268.348 Q113.103 268.348 110.024 263.764 Q106.969 259.158 106.969 250.431 Q106.969 241.681 110.024 237.098 Q113.103 232.491 118.913 232.491 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M500.47 49.7694 Q491.437 49.7694 487.953 51.8354 Q484.469 53.9013 484.469 58.8839 Q484.469 62.8538 487.062 65.2034 Q489.695 67.5124 494.191 67.5124 Q500.389 67.5124 504.116 63.1374 Q507.883 58.7219 507.883 51.4303 L507.883 49.7694 L500.47 49.7694 M515.337 46.6907 L515.337 72.576 L507.883 72.576 L507.883 65.6895 Q505.331 69.8214 501.523 71.8063 Q497.715 73.7508 492.206 73.7508 Q485.239 73.7508 481.107 69.8619 Q477.015 65.9325 477.015 59.3701 Q477.015 51.7138 482.119 47.825 Q487.264 43.9361 497.432 43.9361 L507.883 43.9361 L507.883 43.2069 Q507.883 38.0623 504.48 35.2672 Q501.118 32.4315 495.001 32.4315 Q491.112 32.4315 487.426 33.3632 Q483.74 34.295 480.337 36.1584 L480.337 29.2718 Q484.428 27.692 488.277 26.9223 Q492.125 26.1121 495.771 26.1121 Q505.615 26.1121 510.476 31.2163 Q515.337 36.3204 515.337 46.6907 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M560.545 34.0924 L560.545 9.54393 L567.999 9.54393 L567.999 72.576 L560.545 72.576 L560.545 65.7705 Q558.195 69.8214 554.59 71.8063 Q551.025 73.7508 546.002 73.7508 Q537.779 73.7508 532.594 67.1883 Q527.449 60.6258 527.449 49.9314 Q527.449 39.2371 532.594 32.6746 Q537.779 26.1121 546.002 26.1121 Q551.025 26.1121 554.59 28.0971 Q558.195 30.0415 560.545 34.0924 M535.146 49.9314 Q535.146 58.1548 538.508 62.8538 Q541.911 67.5124 547.825 67.5124 Q553.739 67.5124 557.142 62.8538 Q560.545 58.1548 560.545 49.9314 Q560.545 41.7081 557.142 37.0496 Q553.739 32.3505 547.825 32.3505 Q541.911 32.3505 538.508 37.0496 Q535.146 41.7081 535.146 49.9314 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M603.971 49.7694 Q594.937 49.7694 591.453 51.8354 Q587.97 53.9013 587.97 58.8839 Q587.97 62.8538 590.562 65.2034 Q593.195 67.5124 597.692 67.5124 Q603.89 67.5124 607.616 63.1374 Q611.384 58.7219 611.384 51.4303 L611.384 49.7694 L603.971 49.7694 M618.837 46.6907 L618.837 72.576 L611.384 72.576 L611.384 65.6895 Q608.832 69.8214 605.024 71.8063 Q601.216 73.7508 595.707 73.7508 Q588.739 73.7508 584.607 69.8619 Q580.516 65.9325 580.516 59.3701 Q580.516 51.7138 585.62 47.825 Q590.765 43.9361 600.933 43.9361 L611.384 43.9361 L611.384 43.2069 Q611.384 38.0623 607.981 35.2672 Q604.619 32.4315 598.502 32.4315 Q594.613 32.4315 590.927 33.3632 Q587.24 34.295 583.838 36.1584 L583.838 29.2718 Q587.929 27.692 591.777 26.9223 Q595.626 26.1121 599.272 26.1121 Q609.115 26.1121 613.976 31.2163 Q618.837 36.3204 618.837 46.6907 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M641.401 65.7705 L641.401 89.8329 L633.907 89.8329 L633.907 27.2059 L641.401 27.2059 L641.401 34.0924 Q643.751 30.0415 647.315 28.0971 Q650.921 26.1121 655.903 26.1121 Q664.167 26.1121 669.312 32.6746 Q674.497 39.2371 674.497 49.9314 Q674.497 60.6258 669.312 67.1883 Q664.167 73.7508 655.903 73.7508 Q650.921 73.7508 647.315 71.8063 Q643.751 69.8214 641.401 65.7705 M666.76 49.9314 Q666.76 41.7081 663.357 37.0496 Q659.995 32.3505 654.08 32.3505 Q648.166 32.3505 644.763 37.0496 Q641.401 41.7081 641.401 49.9314 Q641.401 58.1548 644.763 62.8538 Q648.166 67.5124 654.08 67.5124 Q659.995 67.5124 663.357 62.8538 Q666.76 58.1548 666.76 49.9314 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M694.225 14.324 L694.225 27.2059 L709.578 27.2059 L709.578 32.9987 L694.225 32.9987 L694.225 57.6282 Q694.225 63.1779 695.724 64.7578 Q697.263 66.3376 701.922 66.3376 L709.578 66.3376 L709.578 72.576 L701.922 72.576 Q693.293 72.576 690.012 69.3758 Q686.731 66.1351 686.731 57.6282 L686.731 32.9987 L681.262 32.9987 L681.262 27.2059 L686.731 27.2059 L686.731 14.324 L694.225 14.324 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M719.381 27.2059 L726.835 27.2059 L726.835 72.576 L719.381 72.576 L719.381 27.2059 M719.381 9.54393 L726.835 9.54393 L726.835 18.9825 L719.381 18.9825 L719.381 9.54393 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M737.083 27.2059 L744.983 27.2059 L759.161 65.2844 L773.339 27.2059 L781.238 27.2059 L764.224 72.576 L754.097 72.576 L737.083 27.2059 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M830.335 48.0275 L830.335 51.6733 L796.065 51.6733 Q796.551 59.3701 800.683 63.421 Q804.855 67.4314 812.268 67.4314 Q816.562 67.4314 820.573 66.3781 Q824.623 65.3249 828.593 63.2184 L828.593 70.267 Q824.583 71.9684 820.37 72.8596 Q816.157 73.7508 811.823 73.7508 Q800.966 73.7508 794.606 67.4314 Q788.287 61.1119 788.287 50.3365 Q788.287 39.1965 794.282 32.6746 Q800.318 26.1121 810.526 26.1121 Q819.681 26.1121 824.988 32.0264 Q830.335 37.9003 830.335 48.0275 M822.882 45.84 Q822.801 39.7232 819.438 36.0774 Q816.117 32.4315 810.607 32.4315 Q804.369 32.4315 800.602 35.9558 Q796.875 39.4801 796.308 45.8805 L822.882 45.84 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M877.042 86.3491 L877.042 92.1419 L833.941 92.1419 L833.941 86.3491 L877.042 86.3491 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M884.05 27.2059 L891.504 27.2059 L891.504 72.576 L884.05 72.576 L884.05 27.2059 M884.05 9.54393 L891.504 9.54393 L891.504 18.9825 L884.05 18.9825 L884.05 9.54393 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M944.814 45.1919 L944.814 72.576 L937.36 72.576 L937.36 45.4349 Q937.36 38.994 934.849 35.7938 Q932.337 32.5936 927.314 32.5936 Q921.278 32.5936 917.794 36.4419 Q914.31 40.2903 914.31 46.9338 L914.31 72.576 L906.816 72.576 L906.816 27.2059 L914.31 27.2059 L914.31 34.2544 Q916.984 30.163 920.589 28.1376 Q924.235 26.1121 928.975 26.1121 Q936.793 26.1121 940.803 30.9732 Q944.814 35.7938 944.814 45.1919 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M989.536 34.0924 L989.536 9.54393 L996.989 9.54393 L996.989 72.576 L989.536 72.576 L989.536 65.7705 Q987.186 69.8214 983.581 71.8063 Q980.016 73.7508 974.993 73.7508 Q966.77 73.7508 961.585 67.1883 Q956.44 60.6258 956.44 49.9314 Q956.44 39.2371 961.585 32.6746 Q966.77 26.1121 974.993 26.1121 Q980.016 26.1121 983.581 28.0971 Q987.186 30.0415 989.536 34.0924 M964.137 49.9314 Q964.137 58.1548 967.499 62.8538 Q970.902 67.5124 976.816 67.5124 Q982.73 67.5124 986.133 62.8538 Q989.536 58.1548 989.536 49.9314 Q989.536 41.7081 986.133 37.0496 Q982.73 32.3505 976.816 32.3505 Q970.902 32.3505 967.499 37.0496 Q964.137 41.7081 964.137 49.9314 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1011.57 54.671 L1011.57 27.2059 L1019.03 27.2059 L1019.03 54.3874 Q1019.03 60.8284 1021.54 64.0691 Q1024.05 67.2693 1029.07 67.2693 Q1035.11 67.2693 1038.59 63.421 Q1042.12 59.5726 1042.12 52.9291 L1042.12 27.2059 L1049.57 27.2059 L1049.57 72.576 L1042.12 72.576 L1042.12 65.6084 Q1039.4 69.7404 1035.8 71.7658 Q1032.23 73.7508 1027.49 73.7508 Q1019.67 73.7508 1015.62 68.8897 Q1011.57 64.0286 1011.57 54.671 M1030.33 26.1121 L1030.33 26.1121 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1097.57 28.9478 L1097.57 35.9153 Q1094.41 34.1734 1091.21 33.3227 Q1088.05 32.4315 1084.81 32.4315 Q1077.56 32.4315 1073.55 37.0496 Q1069.54 41.6271 1069.54 49.9314 Q1069.54 58.2358 1073.55 62.8538 Q1077.56 67.4314 1084.81 67.4314 Q1088.05 67.4314 1091.21 66.5807 Q1094.41 65.6895 1097.57 63.9476 L1097.57 70.8341 Q1094.45 72.2924 1091.09 73.0216 Q1087.77 73.7508 1084 73.7508 Q1073.75 73.7508 1067.72 67.3098 Q1061.68 60.8689 1061.68 49.9314 Q1061.68 38.832 1067.76 32.472 Q1073.88 26.1121 1084.49 26.1121 Q1087.93 26.1121 1091.21 26.8413 Q1094.49 27.5299 1097.57 28.9478 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1117.91 14.324 L1117.91 27.2059 L1133.26 27.2059 L1133.26 32.9987 L1117.91 32.9987 L1117.91 57.6282 Q1117.91 63.1779 1119.41 64.7578 Q1120.95 66.3376 1125.61 66.3376 L1133.26 66.3376 L1133.26 72.576 L1125.61 72.576 Q1116.98 72.576 1113.7 69.3758 Q1110.41 66.1351 1110.41 57.6282 L1110.41 32.9987 L1104.95 32.9987 L1104.95 27.2059 L1110.41 27.2059 L1110.41 14.324 L1117.91 14.324 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1143.07 27.2059 L1150.52 27.2059 L1150.52 72.576 L1143.07 72.576 L1143.07 27.2059 M1143.07 9.54393 L1150.52 9.54393 L1150.52 18.9825 L1143.07 18.9825 L1143.07 9.54393 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1160.77 27.2059 L1168.67 27.2059 L1182.84 65.2844 L1197.02 27.2059 L1204.92 27.2059 L1187.91 72.576 L1177.78 72.576 L1160.77 27.2059 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1254.02 48.0275 L1254.02 51.6733 L1219.75 51.6733 Q1220.23 59.3701 1224.37 63.421 Q1228.54 67.4314 1235.95 67.4314 Q1240.25 67.4314 1244.26 66.3781 Q1248.31 65.3249 1252.28 63.2184 L1252.28 70.267 Q1248.27 71.9684 1244.05 72.8596 Q1239.84 73.7508 1235.51 73.7508 Q1224.65 73.7508 1218.29 67.4314 Q1211.97 61.1119 1211.97 50.3365 Q1211.97 39.1965 1217.97 32.6746 Q1224 26.1121 1234.21 26.1121 Q1243.37 26.1121 1248.67 32.0264 Q1254.02 37.9003 1254.02 48.0275 M1246.57 45.84 Q1246.48 39.7232 1243.12 36.0774 Q1239.8 32.4315 1234.29 32.4315 Q1228.05 32.4315 1224.29 35.9558 Q1220.56 39.4801 1219.99 45.8805 L1246.57 45.84 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip332)" d="M254.392 366.785 L254.392 1081.75 L458.101 1081.75 L458.101 366.785 L254.392 366.785 L254.392 366.785  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="254.392,366.785 254.392,1081.75 458.101,1081.75 458.101,366.785 254.392,366.785 "></polyline>
<path clip-path="url(#clip332)" d="M509.028 138.164 L509.028 1081.75 L712.736 1081.75 L712.736 138.164 L509.028 138.164 L509.028 138.164  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="509.028,138.164 509.028,1081.75 712.736,1081.75 712.736,138.164 509.028,138.164 "></polyline>
<path clip-path="url(#clip332)" d="M763.663 246.239 L763.663 1081.75 L967.371 1081.75 L967.371 246.239 L763.663 246.239 L763.663 246.239  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="763.663,246.239 763.663,1081.75 967.371,1081.75 967.371,246.239 763.663,246.239 "></polyline>
<path clip-path="url(#clip332)" d="M1018.3 125.694 L1018.3 1081.75 L1222.01 1081.75 L1222.01 125.694 L1018.3 125.694 L1018.3 125.694  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1018.3,125.694 1018.3,1081.75 1222.01,1081.75 1222.01,125.694 1018.3,125.694 "></polyline>
<path clip-path="url(#clip332)" d="M1272.93 375.099 L1272.93 1081.75 L1476.64 1081.75 L1476.64 375.099 L1272.93 375.099 L1272.93 375.099  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip332)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1272.93,375.099 1272.93,1081.75 1476.64,1081.75 1476.64,375.099 1272.93,375.099 "></polyline>
<circle clip-path="url(#clip332)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="356.247" cy="366.785" r="2"></circle>
<circle clip-path="url(#clip332)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="610.882" cy="138.164" r="2"></circle>
<circle clip-path="url(#clip332)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="865.517" cy="246.239" r="2"></circle>
<circle clip-path="url(#clip332)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="1120.15" cy="125.694" r="2"></circle>
<circle clip-path="url(#clip332)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="1374.79" cy="375.099" r="2"></circle>
<defs>
  <clippath id="clip333">
    <rect x="1779" y="97" width="1374" height="1014"></rect>
  </clippath>
</defs>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1956.83,1110.43 1956.83,97.0121 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="2211.46,1110.43 2211.46,97.0121 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="2466.1,1110.43 2466.1,97.0121 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="2720.73,1110.43 2720.73,97.0121 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="2975.37,1110.43 2975.37,97.0121 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1779.44,1110.43 3152.76,1110.43 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1956.83,1110.43 1956.83,1091.53 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2211.46,1110.43 2211.46,1091.53 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2466.1,1110.43 2466.1,1091.53 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2720.73,1110.43 2720.73,1091.53 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2975.37,1110.43 2975.37,1091.53 "></polyline>
<path clip-path="url(#clip330)" d="M1870.24 1141.26 L1870.24 1176.81 L1867.29 1176.81 L1867.29 1141.26 L1870.24 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1897.65 1144.5 L1897.65 1148.2 Q1895.88 1146.55 1893.87 1145.74 Q1891.87 1144.92 1889.61 1144.92 Q1885.17 1144.92 1882.81 1147.65 Q1880.45 1150.36 1880.45 1155.49 Q1880.45 1160.62 1882.81 1163.34 Q1885.17 1166.05 1889.61 1166.05 Q1891.87 1166.05 1893.87 1165.23 Q1895.88 1164.42 1897.65 1162.77 L1897.65 1166.43 Q1895.81 1167.68 1893.74 1168.31 Q1891.7 1168.93 1889.4 1168.93 Q1883.52 1168.93 1880.13 1165.34 Q1876.75 1161.73 1876.75 1155.49 Q1876.75 1149.24 1880.13 1145.65 Q1883.52 1142.04 1889.4 1142.04 Q1891.73 1142.04 1893.78 1142.66 Q1895.84 1143.27 1897.65 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1907.04 1141.26 L1907.04 1176.81 L1904.09 1176.81 L1904.09 1141.26 L1907.04 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1928.81 1157.54 Q1928.93 1158.83 1930.03 1160.91 Q1931.31 1163.32 1933.74 1164.68 Q1936.12 1166 1938.69 1166.01 L1950.79 1166.01 L1950.79 1168.78 L1938.69 1168.78 Q1935.36 1168.78 1932.27 1167.06 Q1929.2 1165.34 1927.55 1162.28 Q1925.9 1159.23 1925.9 1155.98 Q1925.9 1152.77 1927.55 1149.71 Q1929.2 1146.66 1932.27 1144.92 Q1935.36 1143.18 1938.69 1143.18 L1950.79 1143.18 L1950.79 1145.95 L1938.69 1145.95 Q1936.12 1145.96 1933.74 1147.3 Q1931.33 1148.67 1930.03 1151.07 Q1928.92 1153.15 1928.76 1154.76 L1950.79 1154.76 L1950.79 1157.54 L1928.81 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1968.19 1141.41 L1975.55 1141.41 L1975.55 1143.9 L1971.38 1143.9 L1971.38 1170.63 L1975.55 1170.63 L1975.55 1173.12 L1968.19 1173.12 L1968.19 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1990.31 1144.82 Q1987.6 1144.82 1986.23 1147.49 Q1984.87 1150.15 1984.87 1155.49 Q1984.87 1160.82 1986.23 1163.5 Q1987.6 1166.15 1990.31 1166.15 Q1993.03 1166.15 1994.39 1163.5 Q1995.76 1160.82 1995.76 1155.49 Q1995.76 1150.15 1994.39 1147.49 Q1993.03 1144.82 1990.31 1144.82 M1990.31 1142.04 Q1994.66 1142.04 1996.96 1145.49 Q1999.26 1148.93 1999.26 1155.49 Q1999.26 1162.04 1996.96 1165.49 Q1994.66 1168.93 1990.31 1168.93 Q1985.95 1168.93 1983.64 1165.49 Q1981.35 1162.04 1981.35 1155.49 Q1981.35 1148.93 1983.64 1145.49 Q1985.95 1142.04 1990.31 1142.04 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2005.79 1164.02 L2009.46 1164.02 L2009.46 1167 L2006.61 1172.56 L2004.37 1172.56 L2005.79 1167 L2005.79 1164.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2017.34 1165.48 L2023.07 1165.48 L2023.07 1145.7 L2016.83 1146.95 L2016.83 1143.76 L2023.03 1142.51 L2026.54 1142.51 L2026.54 1165.48 L2032.27 1165.48 L2032.27 1168.43 L2017.34 1168.43 L2017.34 1165.48 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2046.36 1141.41 L2046.36 1173.12 L2039 1173.12 L2039 1170.63 L2043.15 1170.63 L2043.15 1143.9 L2039 1143.9 L2039 1141.41 L2046.36 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2124.87 1141.26 L2124.87 1176.81 L2121.92 1176.81 L2121.92 1141.26 L2124.87 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2152.29 1144.5 L2152.29 1148.2 Q2150.51 1146.55 2148.5 1145.74 Q2146.5 1144.92 2144.25 1144.92 Q2139.8 1144.92 2137.44 1147.65 Q2135.08 1150.36 2135.08 1155.49 Q2135.08 1160.62 2137.44 1163.34 Q2139.8 1166.05 2144.25 1166.05 Q2146.5 1166.05 2148.5 1165.23 Q2150.51 1164.42 2152.29 1162.77 L2152.29 1166.43 Q2150.45 1167.68 2148.38 1168.31 Q2146.33 1168.93 2144.04 1168.93 Q2138.15 1168.93 2134.77 1165.34 Q2131.38 1161.73 2131.38 1155.49 Q2131.38 1149.24 2134.77 1145.65 Q2138.15 1142.04 2144.04 1142.04 Q2146.37 1142.04 2148.41 1142.66 Q2150.48 1143.27 2152.29 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2161.68 1141.26 L2161.68 1176.81 L2158.73 1176.81 L2158.73 1141.26 L2161.68 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2183.45 1157.54 Q2183.57 1158.83 2184.66 1160.91 Q2185.95 1163.32 2188.38 1164.68 Q2190.76 1166 2193.33 1166.01 L2205.43 1166.01 L2205.43 1168.78 L2193.33 1168.78 Q2189.99 1168.78 2186.9 1167.06 Q2183.83 1165.34 2182.18 1162.28 Q2180.53 1159.23 2180.53 1155.98 Q2180.53 1152.77 2182.18 1149.71 Q2183.83 1146.66 2186.9 1144.92 Q2189.99 1143.18 2193.33 1143.18 L2205.43 1143.18 L2205.43 1145.95 L2193.33 1145.95 Q2190.76 1145.96 2188.38 1147.3 Q2185.97 1148.67 2184.66 1151.07 Q2183.55 1153.15 2183.4 1154.76 L2205.43 1154.76 L2205.43 1157.54 L2183.45 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2222.82 1141.41 L2230.18 1141.41 L2230.18 1143.9 L2226.02 1143.9 L2226.02 1170.63 L2230.18 1170.63 L2230.18 1173.12 L2222.82 1173.12 L2222.82 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2240.46 1165.48 L2252.7 1165.48 L2252.7 1168.43 L2236.24 1168.43 L2236.24 1165.48 Q2238.24 1163.41 2241.68 1159.94 Q2245.13 1156.45 2246.02 1155.44 Q2247.7 1153.55 2248.36 1152.25 Q2249.04 1150.93 2249.04 1149.66 Q2249.04 1147.59 2247.58 1146.29 Q2246.14 1144.99 2243.81 1144.99 Q2242.16 1144.99 2240.32 1145.56 Q2238.5 1146.14 2236.42 1147.3 L2236.42 1143.76 Q2238.54 1142.91 2240.38 1142.47 Q2242.22 1142.04 2243.74 1142.04 Q2247.77 1142.04 2250.17 1144.05 Q2252.56 1146.07 2252.56 1149.43 Q2252.56 1151.03 2251.96 1152.47 Q2251.36 1153.9 2249.79 1155.84 Q2249.35 1156.34 2247.02 1158.76 Q2244.7 1161.15 2240.46 1165.48 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2260.43 1164.02 L2264.09 1164.02 L2264.09 1167 L2261.24 1172.56 L2259 1172.56 L2260.43 1167 L2260.43 1164.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2281.99 1154.45 Q2284.51 1154.99 2285.91 1156.69 Q2287.34 1158.39 2287.34 1160.89 Q2287.34 1164.73 2284.7 1166.83 Q2282.06 1168.93 2277.2 1168.93 Q2275.57 1168.93 2273.83 1168.6 Q2272.11 1168.29 2270.27 1167.65 L2270.27 1164.26 Q2271.73 1165.11 2273.47 1165.55 Q2275.2 1165.98 2277.09 1165.98 Q2280.39 1165.98 2282.11 1164.68 Q2283.85 1163.38 2283.85 1160.89 Q2283.85 1158.6 2282.23 1157.32 Q2280.64 1156.01 2277.77 1156.01 L2274.75 1156.01 L2274.75 1153.13 L2277.91 1153.13 Q2280.5 1153.13 2281.87 1152.11 Q2283.24 1151.07 2283.24 1149.12 Q2283.24 1147.13 2281.82 1146.07 Q2280.41 1144.99 2277.77 1144.99 Q2276.33 1144.99 2274.68 1145.3 Q2273.03 1145.62 2271.05 1146.28 L2271.05 1143.15 Q2273.05 1142.59 2274.78 1142.32 Q2276.54 1142.04 2278.08 1142.04 Q2282.08 1142.04 2284.4 1143.86 Q2286.73 1145.67 2286.73 1148.76 Q2286.73 1150.91 2285.5 1152.4 Q2284.26 1153.88 2281.99 1154.45 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2301 1141.41 L2301 1173.12 L2293.64 1173.12 L2293.64 1170.63 L2297.79 1170.63 L2297.79 1143.9 L2293.64 1143.9 L2293.64 1141.41 L2301 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2379.51 1141.26 L2379.51 1176.81 L2376.56 1176.81 L2376.56 1141.26 L2379.51 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2406.92 1144.5 L2406.92 1148.2 Q2405.15 1146.55 2403.14 1145.74 Q2401.14 1144.92 2398.88 1144.92 Q2394.44 1144.92 2392.08 1147.65 Q2389.72 1150.36 2389.72 1155.49 Q2389.72 1160.62 2392.08 1163.34 Q2394.44 1166.05 2398.88 1166.05 Q2401.14 1166.05 2403.14 1165.23 Q2405.15 1164.42 2406.92 1162.77 L2406.92 1166.43 Q2405.08 1167.68 2403.01 1168.31 Q2400.97 1168.93 2398.67 1168.93 Q2392.79 1168.93 2389.4 1165.34 Q2386.02 1161.73 2386.02 1155.49 Q2386.02 1149.24 2389.4 1145.65 Q2392.79 1142.04 2398.67 1142.04 Q2401 1142.04 2403.05 1142.66 Q2405.12 1143.27 2406.92 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2416.31 1141.26 L2416.31 1176.81 L2413.36 1176.81 L2413.36 1141.26 L2416.31 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2438.08 1157.54 Q2438.21 1158.83 2439.3 1160.91 Q2440.58 1163.32 2443.01 1164.68 Q2445.39 1166 2447.96 1166.01 L2460.06 1166.01 L2460.06 1168.78 L2447.96 1168.78 Q2444.63 1168.78 2441.54 1167.06 Q2438.47 1165.34 2436.82 1162.28 Q2435.17 1159.23 2435.17 1155.98 Q2435.17 1152.77 2436.82 1149.71 Q2438.47 1146.66 2441.54 1144.92 Q2444.63 1143.18 2447.96 1143.18 L2460.06 1143.18 L2460.06 1145.95 L2447.96 1145.95 Q2445.39 1145.96 2443.01 1147.3 Q2440.6 1148.67 2439.3 1151.07 Q2438.19 1153.15 2438.03 1154.76 L2460.06 1154.76 L2460.06 1157.54 L2438.08 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2477.46 1141.41 L2484.82 1141.41 L2484.82 1143.9 L2480.65 1143.9 L2480.65 1170.63 L2484.82 1170.63 L2484.82 1173.12 L2477.46 1173.12 L2477.46 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2501.71 1145.56 L2492.86 1159.4 L2501.71 1159.4 L2501.71 1145.56 M2500.79 1142.51 L2505.2 1142.51 L2505.2 1159.4 L2508.9 1159.4 L2508.9 1162.32 L2505.2 1162.32 L2505.2 1168.43 L2501.71 1168.43 L2501.71 1162.32 L2490.01 1162.32 L2490.01 1158.93 L2500.79 1142.51 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2515.06 1164.02 L2518.73 1164.02 L2518.73 1167 L2515.88 1172.56 L2513.64 1172.56 L2515.06 1167 L2515.06 1164.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2526.03 1142.51 L2539.8 1142.51 L2539.8 1145.46 L2529.25 1145.46 L2529.25 1151.81 Q2530.01 1151.55 2530.77 1151.43 Q2531.54 1151.29 2532.3 1151.29 Q2536.64 1151.29 2539.18 1153.67 Q2541.71 1156.05 2541.71 1160.11 Q2541.71 1164.3 2539.11 1166.62 Q2536.5 1168.93 2531.76 1168.93 Q2530.13 1168.93 2528.43 1168.65 Q2526.75 1168.38 2524.94 1167.82 L2524.94 1164.3 Q2526.5 1165.15 2528.17 1165.56 Q2529.84 1165.98 2531.69 1165.98 Q2534.7 1165.98 2536.45 1164.4 Q2538.21 1162.82 2538.21 1160.11 Q2538.21 1157.4 2536.45 1155.82 Q2534.7 1154.24 2531.69 1154.24 Q2530.29 1154.24 2528.88 1154.56 Q2527.49 1154.87 2526.03 1155.53 L2526.03 1142.51 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2555.64 1141.41 L2555.64 1173.12 L2548.27 1173.12 L2548.27 1170.63 L2552.42 1170.63 L2552.42 1143.9 L2548.27 1143.9 L2548.27 1141.41 L2555.64 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2634.14 1141.26 L2634.14 1176.81 L2631.19 1176.81 L2631.19 1141.26 L2634.14 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2661.56 1144.5 L2661.56 1148.2 Q2659.79 1146.55 2657.77 1145.74 Q2655.78 1144.92 2653.52 1144.92 Q2649.07 1144.92 2646.71 1147.65 Q2644.35 1150.36 2644.35 1155.49 Q2644.35 1160.62 2646.71 1163.34 Q2649.07 1166.05 2653.52 1166.05 Q2655.78 1166.05 2657.77 1165.23 Q2659.79 1164.42 2661.56 1162.77 L2661.56 1166.43 Q2659.72 1167.68 2657.65 1168.31 Q2655.6 1168.93 2653.31 1168.93 Q2647.42 1168.93 2644.04 1165.34 Q2640.65 1161.73 2640.65 1155.49 Q2640.65 1149.24 2644.04 1145.65 Q2647.42 1142.04 2653.31 1142.04 Q2655.64 1142.04 2657.68 1142.66 Q2659.75 1143.27 2661.56 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2670.95 1141.26 L2670.95 1176.81 L2668 1176.81 L2668 1141.26 L2670.95 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2692.72 1157.54 Q2692.84 1158.83 2693.93 1160.91 Q2695.22 1163.32 2697.65 1164.68 Q2700.03 1166 2702.6 1166.01 L2714.7 1166.01 L2714.7 1168.78 L2702.6 1168.78 Q2699.26 1168.78 2696.17 1167.06 Q2693.1 1165.34 2691.45 1162.28 Q2689.8 1159.23 2689.8 1155.98 Q2689.8 1152.77 2691.45 1149.71 Q2693.1 1146.66 2696.17 1144.92 Q2699.26 1143.18 2702.6 1143.18 L2714.7 1143.18 L2714.7 1145.95 L2702.6 1145.95 Q2700.03 1145.96 2697.65 1147.3 Q2695.24 1148.67 2693.93 1151.07 Q2692.82 1153.15 2692.67 1154.76 L2714.7 1154.76 L2714.7 1157.54 L2692.72 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2732.09 1141.41 L2739.46 1141.41 L2739.46 1143.9 L2735.29 1143.9 L2735.29 1170.63 L2739.46 1170.63 L2739.46 1173.12 L2732.09 1173.12 L2732.09 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2754.65 1154.07 Q2752.29 1154.07 2750.9 1155.68 Q2749.52 1157.3 2749.52 1160.11 Q2749.52 1162.91 2750.9 1164.54 Q2752.29 1166.15 2754.65 1166.15 Q2757.01 1166.15 2758.38 1164.54 Q2759.77 1162.91 2759.77 1160.11 Q2759.77 1157.3 2758.38 1155.68 Q2757.01 1154.07 2754.65 1154.07 M2761.61 1143.08 L2761.61 1146.28 Q2760.29 1145.65 2758.93 1145.32 Q2757.6 1144.99 2756.28 1144.99 Q2752.81 1144.99 2750.97 1147.33 Q2749.14 1149.68 2748.88 1154.42 Q2749.91 1152.91 2751.45 1152.11 Q2753 1151.29 2754.85 1151.29 Q2758.76 1151.29 2761.02 1153.67 Q2763.29 1156.03 2763.29 1160.11 Q2763.29 1164.1 2760.93 1166.52 Q2758.57 1168.93 2754.65 1168.93 Q2750.15 1168.93 2747.77 1165.49 Q2745.39 1162.04 2745.39 1155.49 Q2745.39 1149.35 2748.31 1145.7 Q2751.23 1142.04 2756.14 1142.04 Q2757.46 1142.04 2758.8 1142.3 Q2760.15 1142.56 2761.61 1143.08 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2769.7 1164.02 L2773.36 1164.02 L2773.36 1167 L2770.51 1172.56 L2768.27 1172.56 L2769.7 1167 L2769.7 1164.02 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2779.75 1142.51 L2796.42 1142.51 L2796.42 1144 L2787.01 1168.43 L2783.34 1168.43 L2792.2 1145.46 L2779.75 1145.46 L2779.75 1142.51 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2810.27 1141.41 L2810.27 1173.12 L2802.91 1173.12 L2802.91 1170.63 L2807.06 1170.63 L2807.06 1143.9 L2802.91 1143.9 L2802.91 1141.41 L2810.27 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2905.74 1141.26 L2905.74 1176.81 L2902.79 1176.81 L2902.79 1141.26 L2905.74 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2933.15 1144.5 L2933.15 1148.2 Q2931.38 1146.55 2929.37 1145.74 Q2927.37 1144.92 2925.12 1144.92 Q2920.67 1144.92 2918.31 1147.65 Q2915.95 1150.36 2915.95 1155.49 Q2915.95 1160.62 2918.31 1163.34 Q2920.67 1166.05 2925.12 1166.05 Q2927.37 1166.05 2929.37 1165.23 Q2931.38 1164.42 2933.15 1162.77 L2933.15 1166.43 Q2931.31 1167.68 2929.25 1168.31 Q2927.2 1168.93 2924.91 1168.93 Q2919.02 1168.93 2915.64 1165.34 Q2912.25 1161.73 2912.25 1155.49 Q2912.25 1149.24 2915.64 1145.65 Q2919.02 1142.04 2924.91 1142.04 Q2927.23 1142.04 2929.28 1142.66 Q2931.35 1143.27 2933.15 1144.5 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2942.55 1141.26 L2942.55 1176.81 L2939.59 1176.81 L2939.59 1141.26 L2942.55 1141.26 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2964.32 1157.54 Q2964.44 1158.83 2965.53 1160.91 Q2966.82 1163.32 2969.25 1164.68 Q2971.63 1166 2974.19 1166.01 L2986.3 1166.01 L2986.3 1168.78 L2974.19 1168.78 Q2970.86 1168.78 2967.77 1167.06 Q2964.7 1165.34 2963.05 1162.28 Q2961.4 1159.23 2961.4 1155.98 Q2961.4 1152.77 2963.05 1149.71 Q2964.7 1146.66 2967.77 1144.92 Q2970.86 1143.18 2974.19 1143.18 L2986.3 1143.18 L2986.3 1145.95 L2974.19 1145.95 Q2971.63 1145.96 2969.25 1147.3 Q2966.83 1148.67 2965.53 1151.07 Q2964.42 1153.15 2964.26 1154.76 L2986.3 1154.76 L2986.3 1157.54 L2964.32 1157.54 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M3003.69 1141.41 L3011.05 1141.41 L3011.05 1143.9 L3006.89 1143.9 L3006.89 1170.63 L3011.05 1170.63 L3011.05 1173.12 L3003.69 1173.12 L3003.69 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M3025.81 1156.12 Q3023.31 1156.12 3021.87 1157.46 Q3020.44 1158.79 3020.44 1161.14 Q3020.44 1163.48 3021.87 1164.82 Q3023.31 1166.15 3025.81 1166.15 Q3028.31 1166.15 3029.75 1164.82 Q3031.19 1163.46 3031.19 1161.14 Q3031.19 1158.79 3029.75 1157.46 Q3028.33 1156.12 3025.81 1156.12 M3022.3 1154.63 Q3020.05 1154.07 3018.78 1152.53 Q3017.53 1150.98 3017.53 1148.76 Q3017.53 1145.65 3019.73 1143.84 Q3021.96 1142.04 3025.81 1142.04 Q3029.68 1142.04 3031.89 1143.84 Q3034.09 1145.65 3034.09 1148.76 Q3034.09 1150.98 3032.82 1152.53 Q3031.57 1154.07 3029.33 1154.63 Q3031.87 1155.22 3033.27 1156.93 Q3034.7 1158.65 3034.7 1161.14 Q3034.7 1164.9 3032.39 1166.92 Q3030.1 1168.93 3025.81 1168.93 Q3021.52 1168.93 3019.21 1166.92 Q3016.92 1164.9 3016.92 1161.14 Q3016.92 1158.65 3018.34 1156.93 Q3019.77 1155.22 3022.3 1154.63 M3021.02 1149.09 Q3021.02 1151.1 3022.27 1152.23 Q3023.53 1153.36 3025.81 1153.36 Q3028.07 1153.36 3029.33 1152.23 Q3030.62 1151.1 3030.62 1149.09 Q3030.62 1147.07 3029.33 1145.95 Q3028.07 1144.82 3025.81 1144.82 Q3023.53 1144.82 3022.27 1145.95 Q3021.02 1147.07 3021.02 1149.09 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M3047.94 1141.41 L3047.94 1173.12 L3040.58 1173.12 L3040.58 1170.63 L3044.73 1170.63 L3044.73 1143.9 L3040.58 1143.9 L3040.58 1141.41 L3047.94 1141.41 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1779.44,1081.75 3152.76,1081.75 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1779.44,937.545 3152.76,937.545 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1779.44,793.344 3152.76,793.344 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1779.44,649.143 3152.76,649.143 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1779.44,504.942 3152.76,504.942 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1779.44,360.741 3152.76,360.741 "></polyline>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="1779.44,216.54 3152.76,216.54 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1779.44,1110.43 1779.44,97.0121 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1779.44,1081.75 1798.33,1081.75 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1779.44,937.545 1798.33,937.545 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1779.44,793.344 1798.33,793.344 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1779.44,649.143 1798.33,649.143 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1779.44,504.942 1798.33,504.942 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1779.44,360.741 1798.33,360.741 "></polyline>
<polyline clip-path="url(#clip330)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1779.44,216.54 1798.33,216.54 "></polyline>
<path clip-path="url(#clip330)" d="M1719.49 1067.54 Q1715.88 1067.54 1714.05 1071.11 Q1712.25 1074.65 1712.25 1081.78 Q1712.25 1088.89 1714.05 1092.45 Q1715.88 1095.99 1719.49 1095.99 Q1723.13 1095.99 1724.93 1092.45 Q1726.76 1088.89 1726.76 1081.78 Q1726.76 1074.65 1724.93 1071.11 Q1723.13 1067.54 1719.49 1067.54 M1719.49 1063.84 Q1725.3 1063.84 1728.36 1068.45 Q1731.44 1073.03 1731.44 1081.78 Q1731.44 1090.51 1728.36 1095.11 Q1725.3 1099.7 1719.49 1099.7 Q1713.68 1099.7 1710.6 1095.11 Q1707.55 1090.51 1707.55 1081.78 Q1707.55 1073.03 1710.6 1068.45 Q1713.68 1063.84 1719.49 1063.84 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1649.98 950.89 L1657.62 950.89 L1657.62 924.525 L1649.31 926.191 L1649.31 921.932 L1657.57 920.265 L1662.25 920.265 L1662.25 950.89 L1669.89 950.89 L1669.89 954.825 L1649.98 954.825 L1649.98 950.89 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1689.33 923.344 Q1685.72 923.344 1683.89 926.909 Q1682.08 930.45 1682.08 937.58 Q1682.08 944.686 1683.89 948.251 Q1685.72 951.793 1689.33 951.793 Q1692.96 951.793 1694.77 948.251 Q1696.6 944.686 1696.6 937.58 Q1696.6 930.45 1694.77 926.909 Q1692.96 923.344 1689.33 923.344 M1689.33 919.64 Q1695.14 919.64 1698.2 924.247 Q1701.27 928.83 1701.27 937.58 Q1701.27 946.307 1698.2 950.913 Q1695.14 955.497 1689.33 955.497 Q1683.52 955.497 1680.44 950.913 Q1677.39 946.307 1677.39 937.58 Q1677.39 928.83 1680.44 924.247 Q1683.52 919.64 1689.33 919.64 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1719.49 923.344 Q1715.88 923.344 1714.05 926.909 Q1712.25 930.45 1712.25 937.58 Q1712.25 944.686 1714.05 948.251 Q1715.88 951.793 1719.49 951.793 Q1723.13 951.793 1724.93 948.251 Q1726.76 944.686 1726.76 937.58 Q1726.76 930.45 1724.93 926.909 Q1723.13 923.344 1719.49 923.344 M1719.49 919.64 Q1725.3 919.64 1728.36 924.247 Q1731.44 928.83 1731.44 937.58 Q1731.44 946.307 1728.36 950.913 Q1725.3 955.497 1719.49 955.497 Q1713.68 955.497 1710.6 950.913 Q1707.55 946.307 1707.55 937.58 Q1707.55 928.83 1710.6 924.247 Q1713.68 919.64 1719.49 919.64 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1653.2 806.689 L1669.52 806.689 L1669.52 810.624 L1647.57 810.624 L1647.57 806.689 Q1650.23 803.935 1654.82 799.305 Q1659.42 794.652 1660.6 793.31 Q1662.85 790.786 1663.73 789.05 Q1664.63 787.291 1664.63 785.601 Q1664.63 782.847 1662.69 781.111 Q1660.77 779.374 1657.66 779.374 Q1655.46 779.374 1653.01 780.138 Q1650.58 780.902 1647.8 782.453 L1647.8 777.731 Q1650.63 776.597 1653.08 776.018 Q1655.53 775.439 1657.57 775.439 Q1662.94 775.439 1666.14 778.124 Q1669.33 780.81 1669.33 785.3 Q1669.33 787.43 1668.52 789.351 Q1667.73 791.249 1665.63 793.842 Q1665.05 794.513 1661.95 797.731 Q1658.84 800.925 1653.2 806.689 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1689.33 779.143 Q1685.72 779.143 1683.89 782.708 Q1682.08 786.249 1682.08 793.379 Q1682.08 800.485 1683.89 804.05 Q1685.72 807.592 1689.33 807.592 Q1692.96 807.592 1694.77 804.05 Q1696.6 800.485 1696.6 793.379 Q1696.6 786.249 1694.77 782.708 Q1692.96 779.143 1689.33 779.143 M1689.33 775.439 Q1695.14 775.439 1698.2 780.046 Q1701.27 784.629 1701.27 793.379 Q1701.27 802.106 1698.2 806.712 Q1695.14 811.296 1689.33 811.296 Q1683.52 811.296 1680.44 806.712 Q1677.39 802.106 1677.39 793.379 Q1677.39 784.629 1680.44 780.046 Q1683.52 775.439 1689.33 775.439 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1719.49 779.143 Q1715.88 779.143 1714.05 782.708 Q1712.25 786.249 1712.25 793.379 Q1712.25 800.485 1714.05 804.05 Q1715.88 807.592 1719.49 807.592 Q1723.13 807.592 1724.93 804.05 Q1726.76 800.485 1726.76 793.379 Q1726.76 786.249 1724.93 782.708 Q1723.13 779.143 1719.49 779.143 M1719.49 775.439 Q1725.3 775.439 1728.36 780.046 Q1731.44 784.629 1731.44 793.379 Q1731.44 802.106 1728.36 806.712 Q1725.3 811.296 1719.49 811.296 Q1713.68 811.296 1710.6 806.712 Q1707.55 802.106 1707.55 793.379 Q1707.55 784.629 1710.6 780.046 Q1713.68 775.439 1719.49 775.439 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1663.33 647.789 Q1666.69 648.507 1668.57 650.775 Q1670.46 653.044 1670.46 656.377 Q1670.46 661.493 1666.95 664.294 Q1663.43 667.095 1656.95 667.095 Q1654.77 667.095 1652.46 666.655 Q1650.16 666.238 1647.71 665.382 L1647.71 660.868 Q1649.65 662.002 1651.97 662.581 Q1654.28 663.159 1656.81 663.159 Q1661.21 663.159 1663.5 661.423 Q1665.81 659.687 1665.81 656.377 Q1665.81 653.322 1663.66 651.609 Q1661.53 649.872 1657.71 649.872 L1653.68 649.872 L1653.68 646.03 L1657.89 646.03 Q1661.34 646.03 1663.17 644.664 Q1665 643.275 1665 640.683 Q1665 638.021 1663.1 636.609 Q1661.23 635.173 1657.71 635.173 Q1655.79 635.173 1653.59 635.59 Q1651.39 636.007 1648.75 636.886 L1648.75 632.72 Q1651.41 631.979 1653.73 631.609 Q1656.07 631.238 1658.13 631.238 Q1663.45 631.238 1666.55 633.669 Q1669.65 636.076 1669.65 640.197 Q1669.65 643.067 1668.01 645.058 Q1666.37 647.025 1663.33 647.789 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1689.33 634.942 Q1685.72 634.942 1683.89 638.507 Q1682.08 642.048 1682.08 649.178 Q1682.08 656.284 1683.89 659.849 Q1685.72 663.391 1689.33 663.391 Q1692.96 663.391 1694.77 659.849 Q1696.6 656.284 1696.6 649.178 Q1696.6 642.048 1694.77 638.507 Q1692.96 634.942 1689.33 634.942 M1689.33 631.238 Q1695.14 631.238 1698.2 635.845 Q1701.27 640.428 1701.27 649.178 Q1701.27 657.905 1698.2 662.511 Q1695.14 667.095 1689.33 667.095 Q1683.52 667.095 1680.44 662.511 Q1677.39 657.905 1677.39 649.178 Q1677.39 640.428 1680.44 635.845 Q1683.52 631.238 1689.33 631.238 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1719.49 634.942 Q1715.88 634.942 1714.05 638.507 Q1712.25 642.048 1712.25 649.178 Q1712.25 656.284 1714.05 659.849 Q1715.88 663.391 1719.49 663.391 Q1723.13 663.391 1724.93 659.849 Q1726.76 656.284 1726.76 649.178 Q1726.76 642.048 1724.93 638.507 Q1723.13 634.942 1719.49 634.942 M1719.49 631.238 Q1725.3 631.238 1728.36 635.845 Q1731.44 640.428 1731.44 649.178 Q1731.44 657.905 1728.36 662.511 Q1725.3 667.095 1719.49 667.095 Q1713.68 667.095 1710.6 662.511 Q1707.55 657.905 1707.55 649.178 Q1707.55 640.428 1710.6 635.845 Q1713.68 631.238 1719.49 631.238 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1662.02 491.736 L1650.21 510.185 L1662.02 510.185 L1662.02 491.736 M1660.79 487.662 L1666.67 487.662 L1666.67 510.185 L1671.6 510.185 L1671.6 514.074 L1666.67 514.074 L1666.67 522.222 L1662.02 522.222 L1662.02 514.074 L1646.41 514.074 L1646.41 509.56 L1660.79 487.662 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1689.33 490.741 Q1685.72 490.741 1683.89 494.306 Q1682.08 497.847 1682.08 504.977 Q1682.08 512.083 1683.89 515.648 Q1685.72 519.19 1689.33 519.19 Q1692.96 519.19 1694.77 515.648 Q1696.6 512.083 1696.6 504.977 Q1696.6 497.847 1694.77 494.306 Q1692.96 490.741 1689.33 490.741 M1689.33 487.037 Q1695.14 487.037 1698.2 491.644 Q1701.27 496.227 1701.27 504.977 Q1701.27 513.704 1698.2 518.31 Q1695.14 522.894 1689.33 522.894 Q1683.52 522.894 1680.44 518.31 Q1677.39 513.704 1677.39 504.977 Q1677.39 496.227 1680.44 491.644 Q1683.52 487.037 1689.33 487.037 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1719.49 490.741 Q1715.88 490.741 1714.05 494.306 Q1712.25 497.847 1712.25 504.977 Q1712.25 512.083 1714.05 515.648 Q1715.88 519.19 1719.49 519.19 Q1723.13 519.19 1724.93 515.648 Q1726.76 512.083 1726.76 504.977 Q1726.76 497.847 1724.93 494.306 Q1723.13 490.741 1719.49 490.741 M1719.49 487.037 Q1725.3 487.037 1728.36 491.644 Q1731.44 496.227 1731.44 504.977 Q1731.44 513.704 1728.36 518.31 Q1725.3 522.894 1719.49 522.894 Q1713.68 522.894 1710.6 518.31 Q1707.55 513.704 1707.55 504.977 Q1707.55 496.227 1710.6 491.644 Q1713.68 487.037 1719.49 487.037 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1649.21 343.461 L1667.57 343.461 L1667.57 347.396 L1653.5 347.396 L1653.5 355.869 Q1654.52 355.521 1655.53 355.359 Q1656.55 355.174 1657.57 355.174 Q1663.36 355.174 1666.74 358.346 Q1670.12 361.517 1670.12 366.933 Q1670.12 372.512 1666.64 375.614 Q1663.17 378.693 1656.85 378.693 Q1654.68 378.693 1652.41 378.322 Q1650.16 377.952 1647.76 377.211 L1647.76 372.512 Q1649.84 373.646 1652.06 374.202 Q1654.28 374.757 1656.76 374.757 Q1660.77 374.757 1663.1 372.651 Q1665.44 370.545 1665.44 366.933 Q1665.44 363.322 1663.1 361.216 Q1660.77 359.109 1656.76 359.109 Q1654.89 359.109 1653.01 359.526 Q1651.16 359.943 1649.21 360.822 L1649.21 343.461 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1689.33 346.54 Q1685.72 346.54 1683.89 350.105 Q1682.08 353.646 1682.08 360.776 Q1682.08 367.882 1683.89 371.447 Q1685.72 374.989 1689.33 374.989 Q1692.96 374.989 1694.77 371.447 Q1696.6 367.882 1696.6 360.776 Q1696.6 353.646 1694.77 350.105 Q1692.96 346.54 1689.33 346.54 M1689.33 342.836 Q1695.14 342.836 1698.2 347.443 Q1701.27 352.026 1701.27 360.776 Q1701.27 369.503 1698.2 374.109 Q1695.14 378.693 1689.33 378.693 Q1683.52 378.693 1680.44 374.109 Q1677.39 369.503 1677.39 360.776 Q1677.39 352.026 1680.44 347.443 Q1683.52 342.836 1689.33 342.836 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1719.49 346.54 Q1715.88 346.54 1714.05 350.105 Q1712.25 353.646 1712.25 360.776 Q1712.25 367.882 1714.05 371.447 Q1715.88 374.989 1719.49 374.989 Q1723.13 374.989 1724.93 371.447 Q1726.76 367.882 1726.76 360.776 Q1726.76 353.646 1724.93 350.105 Q1723.13 346.54 1719.49 346.54 M1719.49 342.836 Q1725.3 342.836 1728.36 347.443 Q1731.44 352.026 1731.44 360.776 Q1731.44 369.503 1728.36 374.109 Q1725.3 378.693 1719.49 378.693 Q1713.68 378.693 1710.6 374.109 Q1707.55 369.503 1707.55 360.776 Q1707.55 352.026 1710.6 347.443 Q1713.68 342.836 1719.49 342.836 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1659.75 214.677 Q1656.6 214.677 1654.75 216.83 Q1652.92 218.982 1652.92 222.732 Q1652.92 226.459 1654.75 228.635 Q1656.6 230.788 1659.75 230.788 Q1662.89 230.788 1664.72 228.635 Q1666.58 226.459 1666.58 222.732 Q1666.58 218.982 1664.72 216.83 Q1662.89 214.677 1659.75 214.677 M1669.03 200.024 L1669.03 204.283 Q1667.27 203.45 1665.46 203.01 Q1663.68 202.57 1661.92 202.57 Q1657.29 202.57 1654.84 205.695 Q1652.41 208.82 1652.06 215.14 Q1653.43 213.126 1655.49 212.061 Q1657.55 210.973 1660.02 210.973 Q1665.23 210.973 1668.24 214.145 Q1671.27 217.293 1671.27 222.732 Q1671.27 228.056 1668.13 231.274 Q1664.98 234.492 1659.75 234.492 Q1653.75 234.492 1650.58 229.908 Q1647.41 225.302 1647.41 216.575 Q1647.41 208.381 1651.3 203.52 Q1655.19 198.635 1661.74 198.635 Q1663.5 198.635 1665.28 198.983 Q1667.08 199.33 1669.03 200.024 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1689.33 202.339 Q1685.72 202.339 1683.89 205.904 Q1682.08 209.445 1682.08 216.575 Q1682.08 223.681 1683.89 227.246 Q1685.72 230.788 1689.33 230.788 Q1692.96 230.788 1694.77 227.246 Q1696.6 223.681 1696.6 216.575 Q1696.6 209.445 1694.77 205.904 Q1692.96 202.339 1689.33 202.339 M1689.33 198.635 Q1695.14 198.635 1698.2 203.242 Q1701.27 207.825 1701.27 216.575 Q1701.27 225.302 1698.2 229.908 Q1695.14 234.492 1689.33 234.492 Q1683.52 234.492 1680.44 229.908 Q1677.39 225.302 1677.39 216.575 Q1677.39 207.825 1680.44 203.242 Q1683.52 198.635 1689.33 198.635 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M1719.49 202.339 Q1715.88 202.339 1714.05 205.904 Q1712.25 209.445 1712.25 216.575 Q1712.25 223.681 1714.05 227.246 Q1715.88 230.788 1719.49 230.788 Q1723.13 230.788 1724.93 227.246 Q1726.76 223.681 1726.76 216.575 Q1726.76 209.445 1724.93 205.904 Q1723.13 202.339 1719.49 202.339 M1719.49 198.635 Q1725.3 198.635 1728.36 203.242 Q1731.44 207.825 1731.44 216.575 Q1731.44 225.302 1728.36 229.908 Q1725.3 234.492 1719.49 234.492 Q1713.68 234.492 1710.6 229.908 Q1707.55 225.302 1707.55 216.575 Q1707.55 207.825 1710.6 203.242 Q1713.68 198.635 1719.49 198.635 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2154.03 28.5427 L2154.03 35.5912 Q2150.87 33.9709 2147.47 33.1607 Q2144.07 32.3505 2140.42 32.3505 Q2134.87 32.3505 2132.08 34.0519 Q2129.32 35.7533 2129.32 39.156 Q2129.32 41.7486 2131.31 43.2475 Q2133.29 44.7058 2139.29 46.0426 L2141.84 46.6097 Q2149.78 48.3111 2153.1 51.4303 Q2156.47 54.509 2156.47 60.0587 Q2156.47 66.3781 2151.44 70.0644 Q2146.46 73.7508 2137.71 73.7508 Q2134.06 73.7508 2130.09 73.0216 Q2126.16 72.3329 2121.79 70.9151 L2121.79 63.2184 Q2125.92 65.3654 2129.93 66.4591 Q2133.94 67.5124 2137.87 67.5124 Q2143.14 67.5124 2145.97 65.73 Q2148.81 63.9071 2148.81 60.6258 Q2148.81 57.5877 2146.74 55.9673 Q2144.72 54.3469 2137.79 52.8481 L2135.2 52.2405 Q2128.27 50.7821 2125.19 47.7845 Q2122.11 44.7463 2122.11 39.4801 Q2122.11 33.0797 2126.65 29.5959 Q2131.19 26.1121 2139.53 26.1121 Q2143.66 26.1121 2147.31 26.7198 Q2150.96 27.3274 2154.03 28.5427 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2168.33 27.2059 L2175.79 27.2059 L2175.79 72.576 L2168.33 72.576 L2168.33 27.2059 M2168.33 9.54393 L2175.79 9.54393 L2175.79 18.9825 L2168.33 18.9825 L2168.33 9.54393 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2226.71 35.9153 Q2229.5 30.8922 2233.39 28.5022 Q2237.28 26.1121 2242.55 26.1121 Q2249.64 26.1121 2253.48 31.0947 Q2257.33 36.0368 2257.33 45.1919 L2257.33 72.576 L2249.84 72.576 L2249.84 45.4349 Q2249.84 38.913 2247.53 35.7533 Q2245.22 32.5936 2240.48 32.5936 Q2234.69 32.5936 2231.33 36.4419 Q2227.96 40.2903 2227.96 46.9338 L2227.96 72.576 L2220.47 72.576 L2220.47 45.4349 Q2220.47 38.8725 2218.16 35.7533 Q2215.85 32.5936 2211.03 32.5936 Q2205.32 32.5936 2201.96 36.4824 Q2198.59 40.3308 2198.59 46.9338 L2198.59 72.576 L2191.1 72.576 L2191.1 27.2059 L2198.59 27.2059 L2198.59 34.2544 Q2201.15 30.082 2204.71 28.0971 Q2208.28 26.1121 2213.18 26.1121 Q2218.12 26.1121 2221.56 28.6237 Q2225.05 31.1352 2226.71 35.9153 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2279.41 65.7705 L2279.41 89.8329 L2271.92 89.8329 L2271.92 27.2059 L2279.41 27.2059 L2279.41 34.0924 Q2281.76 30.0415 2285.32 28.0971 Q2288.93 26.1121 2293.91 26.1121 Q2302.18 26.1121 2307.32 32.6746 Q2312.51 39.2371 2312.51 49.9314 Q2312.51 60.6258 2307.32 67.1883 Q2302.18 73.7508 2293.91 73.7508 Q2288.93 73.7508 2285.32 71.8063 Q2281.76 69.8214 2279.41 65.7705 M2304.77 49.9314 Q2304.77 41.7081 2301.37 37.0496 Q2298 32.3505 2292.09 32.3505 Q2286.18 32.3505 2282.77 37.0496 Q2279.41 41.7081 2279.41 49.9314 Q2279.41 58.1548 2282.77 62.8538 Q2286.18 67.5124 2292.09 67.5124 Q2298 67.5124 2301.37 62.8538 Q2304.77 58.1548 2304.77 49.9314 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2324.86 9.54393 L2332.31 9.54393 L2332.31 72.576 L2324.86 72.576 L2324.86 9.54393 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2386.72 48.0275 L2386.72 51.6733 L2352.45 51.6733 Q2352.93 59.3701 2357.07 63.421 Q2361.24 67.4314 2368.65 67.4314 Q2372.95 67.4314 2376.96 66.3781 Q2381.01 65.3249 2384.98 63.2184 L2384.98 70.267 Q2380.97 71.9684 2376.75 72.8596 Q2372.54 73.7508 2368.21 73.7508 Q2357.35 73.7508 2350.99 67.4314 Q2344.67 61.1119 2344.67 50.3365 Q2344.67 39.1965 2350.67 32.6746 Q2356.7 26.1121 2366.91 26.1121 Q2376.06 26.1121 2381.37 32.0264 Q2386.72 37.9003 2386.72 48.0275 M2379.26 45.84 Q2379.18 39.7232 2375.82 36.0774 Q2372.5 32.4315 2366.99 32.4315 Q2360.75 32.4315 2356.98 35.9558 Q2353.26 39.4801 2352.69 45.8805 L2379.26 45.84 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2433.43 86.3491 L2433.43 92.1419 L2390.32 92.1419 L2390.32 86.3491 L2433.43 86.3491 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2440.43 27.2059 L2447.89 27.2059 L2447.89 72.576 L2440.43 72.576 L2440.43 27.2059 M2440.43 9.54393 L2447.89 9.54393 L2447.89 18.9825 L2440.43 18.9825 L2440.43 9.54393 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2501.2 45.1919 L2501.2 72.576 L2493.74 72.576 L2493.74 45.4349 Q2493.74 38.994 2491.23 35.7938 Q2488.72 32.5936 2483.7 32.5936 Q2477.66 32.5936 2474.18 36.4419 Q2470.69 40.2903 2470.69 46.9338 L2470.69 72.576 L2463.2 72.576 L2463.2 27.2059 L2470.69 27.2059 L2470.69 34.2544 Q2473.37 30.163 2476.97 28.1376 Q2480.62 26.1121 2485.36 26.1121 Q2493.18 26.1121 2497.19 30.9732 Q2501.2 35.7938 2501.2 45.1919 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2545.92 34.0924 L2545.92 9.54393 L2553.37 9.54393 L2553.37 72.576 L2545.92 72.576 L2545.92 65.7705 Q2543.57 69.8214 2539.96 71.8063 Q2536.4 73.7508 2531.38 73.7508 Q2523.15 73.7508 2517.97 67.1883 Q2512.82 60.6258 2512.82 49.9314 Q2512.82 39.2371 2517.97 32.6746 Q2523.15 26.1121 2531.38 26.1121 Q2536.4 26.1121 2539.96 28.0971 Q2543.57 30.0415 2545.92 34.0924 M2520.52 49.9314 Q2520.52 58.1548 2523.88 62.8538 Q2527.28 67.5124 2533.2 67.5124 Q2539.11 67.5124 2542.52 62.8538 Q2545.92 58.1548 2545.92 49.9314 Q2545.92 41.7081 2542.52 37.0496 Q2539.11 32.3505 2533.2 32.3505 Q2527.28 32.3505 2523.88 37.0496 Q2520.52 41.7081 2520.52 49.9314 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2567.96 54.671 L2567.96 27.2059 L2575.41 27.2059 L2575.41 54.3874 Q2575.41 60.8284 2577.92 64.0691 Q2580.43 67.2693 2585.46 67.2693 Q2591.49 67.2693 2594.98 63.421 Q2598.5 59.5726 2598.5 52.9291 L2598.5 27.2059 L2605.95 27.2059 L2605.95 72.576 L2598.5 72.576 L2598.5 65.6084 Q2595.79 69.7404 2592.18 71.7658 Q2588.62 73.7508 2583.88 73.7508 Q2576.06 73.7508 2572.01 68.8897 Q2567.96 64.0286 2567.96 54.671 M2586.71 26.1121 L2586.71 26.1121 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2653.96 28.9478 L2653.96 35.9153 Q2650.8 34.1734 2647.6 33.3227 Q2644.44 32.4315 2641.2 32.4315 Q2633.95 32.4315 2629.93 37.0496 Q2625.92 41.6271 2625.92 49.9314 Q2625.92 58.2358 2629.93 62.8538 Q2633.95 67.4314 2641.2 67.4314 Q2644.44 67.4314 2647.6 66.5807 Q2650.8 65.6895 2653.96 63.9476 L2653.96 70.8341 Q2650.84 72.2924 2647.48 73.0216 Q2644.15 73.7508 2640.39 73.7508 Q2630.14 73.7508 2624.1 67.3098 Q2618.07 60.8689 2618.07 49.9314 Q2618.07 38.832 2624.14 32.472 Q2630.26 26.1121 2640.87 26.1121 Q2644.32 26.1121 2647.6 26.8413 Q2650.88 27.5299 2653.96 28.9478 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2674.29 14.324 L2674.29 27.2059 L2689.65 27.2059 L2689.65 32.9987 L2674.29 32.9987 L2674.29 57.6282 Q2674.29 63.1779 2675.79 64.7578 Q2677.33 66.3376 2681.99 66.3376 L2689.65 66.3376 L2689.65 72.576 L2681.99 72.576 Q2673.36 72.576 2670.08 69.3758 Q2666.8 66.1351 2666.8 57.6282 L2666.8 32.9987 L2661.33 32.9987 L2661.33 27.2059 L2666.8 27.2059 L2666.8 14.324 L2674.29 14.324 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2699.45 27.2059 L2706.9 27.2059 L2706.9 72.576 L2699.45 72.576 L2699.45 27.2059 M2699.45 9.54393 L2706.9 9.54393 L2706.9 18.9825 L2699.45 18.9825 L2699.45 9.54393 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2717.15 27.2059 L2725.05 27.2059 L2739.23 65.2844 L2753.41 27.2059 L2761.31 27.2059 L2744.29 72.576 L2734.16 72.576 L2717.15 27.2059 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip330)" d="M2810.4 48.0275 L2810.4 51.6733 L2776.13 51.6733 Q2776.62 59.3701 2780.75 63.421 Q2784.92 67.4314 2792.34 67.4314 Q2796.63 67.4314 2800.64 66.3781 Q2804.69 65.3249 2808.66 63.2184 L2808.66 70.267 Q2804.65 71.9684 2800.44 72.8596 Q2796.22 73.7508 2791.89 73.7508 Q2781.03 73.7508 2774.67 67.4314 Q2768.35 61.1119 2768.35 50.3365 Q2768.35 39.1965 2774.35 32.6746 Q2780.39 26.1121 2790.59 26.1121 Q2799.75 26.1121 2805.06 32.0264 Q2810.4 37.9003 2810.4 48.0275 M2802.95 45.84 Q2802.87 39.7232 2799.51 36.0774 Q2796.18 32.4315 2790.67 32.4315 Q2784.44 32.4315 2780.67 35.9558 Q2776.94 39.4801 2776.38 45.8805 L2802.95 45.84 Z" fill="#000000" fill-rule="nonzero" fill-opacity="1"></path><path clip-path="url(#clip333)" d="M1854.97 125.694 L1854.97 1081.75 L2058.68 1081.75 L2058.68 125.694 L1854.97 125.694 L1854.97 125.694  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="1854.97,125.694 1854.97,1081.75 2058.68,1081.75 2058.68,125.694 1854.97,125.694 "></polyline>
<path clip-path="url(#clip333)" d="M2109.61 703.94 L2109.61 1081.75 L2313.31 1081.75 L2313.31 703.94 L2109.61 703.94 L2109.61 703.94  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2109.61,703.94 2109.61,1081.75 2313.31,1081.75 2313.31,703.94 2109.61,703.94 "></polyline>
<path clip-path="url(#clip333)" d="M2364.24 989.458 L2364.24 1081.75 L2567.95 1081.75 L2567.95 989.458 L2364.24 989.458 L2364.24 989.458  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2364.24,989.458 2364.24,1081.75 2567.95,1081.75 2567.95,989.458 2364.24,989.458 "></polyline>
<path clip-path="url(#clip333)" d="M2618.88 1067.33 L2618.88 1081.75 L2822.59 1081.75 L2822.59 1067.33 L2618.88 1067.33 L2618.88 1067.33  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2618.88,1067.33 2618.88,1081.75 2822.59,1081.75 2822.59,1067.33 2618.88,1067.33 "></polyline>
<path clip-path="url(#clip333)" d="M2873.51 1080.3 L2873.51 1081.75 L3077.22 1081.75 L3077.22 1080.3 L2873.51 1080.3 L2873.51 1080.3  Z" fill="#009af9" fill-rule="evenodd" fill-opacity="1"></path>
<polyline clip-path="url(#clip333)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="2873.51,1080.3 2873.51,1081.75 3077.22,1081.75 3077.22,1080.3 2873.51,1080.3 "></polyline>
<circle clip-path="url(#clip333)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="1956.83" cy="125.694" r="2"></circle>
<circle clip-path="url(#clip333)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="2211.46" cy="703.94" r="2"></circle>
<circle clip-path="url(#clip333)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="2466.1" cy="989.458" r="2"></circle>
<circle clip-path="url(#clip333)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="2720.73" cy="1067.33" r="2"></circle>
<circle clip-path="url(#clip333)" style="fill:#009af9; stroke:none; fill-opacity:0" cx="2975.37" cy="1080.3" r="2"></circle>
</svg>
<figcaption class="figure-caption">Figure&nbsp;3: Distribution of set sizes for both approaches.</figcaption>
</figure>
</div>
</div>
</section>
<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">üîÅ Recap</h2>
<p>In this short guide, we have seen how easy it is to conformalize a deep learning image classifier in Julia using <code>ConformalPrediction.jl</code>. Almost any deep neural network trained in <code>Flux.jl</code> is compatible with <code>MLJ.jl</code> and can therefore be conformalized in just a few lines of code. This makes it remarkably easy to move uncertainty heuristics to rigorous predictive uncertainty estimates. We have also seen a sneak peek at the performance evaluation of conformal predictors. Stay tuned for more!</p>
</section>
<section id="references" class="level2">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">üéì References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-angelopoulos2021gentle" class="csl-entry">
Angelopoulos, Anastasios N., and Stephen Bates. 2021. <span>‚ÄúA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.‚Äù</span> <a href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>.
</div>
<div id="ref-angelopoulos2022uncertainty" class="csl-entry">
Angelopoulos, Anastasios, Stephen Bates, Jitendra Malik, and Michael I. Jordan. 2022. <span>‚ÄúUncertainty <span>Sets</span> for <span>Image Classifiers</span> Using <span>Conformal Prediction</span>.‚Äù</span> <span>arXiv</span>. <a href="https://arxiv.org/abs/2009.14193">https://arxiv.org/abs/2009.14193</a>.
</div>
<div id="ref-goodfellow2014explaining" class="csl-entry">
Goodfellow, Ian J, Jonathon Shlens, and Christian Szegedy. 2014. <span>‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù</span> <a href="https://arxiv.org/abs/1412.6572">https://arxiv.org/abs/1412.6572</a>.
</div>
<div id="ref-lecun1998mnist" class="csl-entry">
LeCun, Yann. 1998. <span>‚ÄúThe <span>MNIST</span> Database of Handwritten Digits.‚Äù</span>
</div>
</div></section><aside id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>For a full tutorial on how to build an MNIST image classifier relying solely on <code>Flux.jl</code>, check out this <a href="https://fluxml.ai/Flux.jl/stable/tutorials/2021-01-26-mlp/">tutorial</a>.‚Ü©Ô∏é</p></li>
</ol>
</aside><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {How to {Conformalize} a {Deep} {Image} {Classifier}},
  date = {2022-12-05},
  url = {https://www.paltmeyer.com/blog//blog/posts/conformal-image-classifier},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2022. <span>‚ÄúHow to Conformalize a Deep Image
Classifier.‚Äù</span> December 5, 2022. <a href="https://www.paltmeyer.com/blog//blog/posts/conformal-image-classifier">https://www.paltmeyer.com/blog//blog/posts/conformal-image-classifier</a>.
</div></div></section></div> ]]></description>
  <category>conformal prediction</category>
  <category>uncertainty</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/index.html</guid>
  <pubDate>Mon, 05 Dec 2022 05:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/conformal-image-classifier/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>A year of using Quarto with Julia</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/www/images/julia_quarto.gif" class="figure-img">
<figcaption class="figure-caption">
A year of using Quarto with Julia.
</figcaption>
</figure>
</div>
<p>Earlier this year in July, I gave a short Experience Talk at <a href="https://pretalx.com/juliacon-2022/speaker/8DGYCX/">JuliaCon</a>. In a related blog <a href="../../../blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html">post</a> I explained how the introduction of Quarto made my transition from R to Julia painless: I would be able to start learning Julia without having to give up on all the benefits associated with R Markdown.</p>
<p>In November, 2022, I am presenting on this topic again at the <a href="https://www.linkedin.com/feed/update/urn:li:activity:6995656928957718528?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A6995656928957718528%29">2nd JuliaLang Eindhoven meetup</a>. In addition to the <a href="../../../content/talks/posts/2022-julia-eindhoven/index.html">slides</a>, I thought I‚Äôd share a small companion blog post that highlights some useful tips and tricks for anyone interested in using Quarto with Julia.</p>
<section id="general-things" class="level2">
<h2 class="anchored" data-anchor-id="general-things">General things</h2>
<p>We will start in this section with a few general recommendations.</p>
<section id="setup" class="level3">
<h3 class="anchored" data-anchor-id="setup">Setup</h3>
<p>I continue to recommend using VSCode for any work with Quarto and Julia. The Quarto <a href="https://quarto.org/docs/computations/julia.html#vs-code">docs</a> explain how to get started by installing the necessary Quarto and IJulia extensions. Since most Julia users will regularly want to update their Julia version, I would additionally recommend to add <code>IJulia.jl</code> to your <code>~/.julia/config/startup.jl</code> file:<sup>1</sup></p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Setup OhMyREPL, Revise and Term</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Pkg</span></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">let</span></span>
<span id="cb1-4">    pkgs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Revise"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OhMyREPL"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Term"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"IJulia"</span>]</span>
<span id="cb1-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> pkg <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> pkgs</span>
<span id="cb1-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Base</span>.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">find_package</span>(pkg) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">===</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">nothing</span></span>
<span id="cb1-7">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Pkg</span>.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">add</span>(pkg)</span>
<span id="cb1-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb1-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb1-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
<p>Additionally, you only need to remember that ‚Ä¶</p>
<blockquote class="blockquote">
<p>‚Ä¶ if you install a new Julia binary [‚Ä¶], you must update the IJulia installation [‚Ä¶] by running <code>Pkg.build("IJulia")</code></p>
<p>‚Äî Source: <a href="https://julialang.github.io/IJulia.jl/stable/manual/installation/#Updating-Julia-and-IJulia">IJulia docs</a></p>
</blockquote>
<p>I guess this step can also be automated in <code>~/.julia/config/startup.jl</code>, but haven‚Äôt tried that yet.</p>
</section>
<section id="using-.ipynb-vs-.qmd" class="level3">
<h3 class="anchored" data-anchor-id="using-.ipynb-vs-.qmd">Using <code>.ipynb</code> vs <code>.qmd</code></h3>
<p>I also continue to recommend working with Quarto notebooks as opposed to Jupyter notebooks (files ending in <code>.qmd</code> and <code>.ipynb</code>, respectively). This is partially just based on preference (from R Markdown I‚Äôm used to working with <code>.Rmd</code> files), but there is also a good reason to consider using <code>.qmd</code>, even if you‚Äôre used to working with Jupyter: the code chunks in your Quarto notebook automatically link to the Julia REPL in VSCode. In other words, you can run code chunks in your notebook and then access any variable that you may have created in the REPL. I find this quite useful, cause it allows me to quickly test code. Perhaps there‚Äôs a good way to do this with Jupyter notebooks as well, but when I last used them I would always have to insert new code cells to test stuff.</p>
<p>Either way switching between Jupyter and Quarto notebooks is straight-forward: <code>quarto convert notebook.qmd</code> will convert any Quarto notebook into a Jupyter notebook and vice versa. One potential benefit of Jupyter notebooks is their connection to Google Colab: it is possible to store Jupyter notebooks on Github and make them available on Colab, allowing users to quickly interact with your code without the need to clone anything. If this is important to you, you can still work with <code>.qmd</code> documents and simply specify <code>keep-ipynb: true</code> in the YAML header.</p>
</section>
<section id="dynamic-content" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-content">Dynamic Content</h3>
<blockquote class="blockquote">
<p>The world and the data that describes it is not static üìà. Why should scientific outputs be?</p>
</blockquote>
<p>One of the things I have always really loved about R Markdown was the ability to use inline code: the Knitr engine allows you to call and render any object <code>x</code> that you have created in preceding R chunks like this: <code>r x</code>. This is very powerful, because it enables us to bridge the gap between computations and output. In other words, it allows us to easily produce reproducible and dynamic content.</p>
<p>Until recently I had not been aware that this is also possible for Julia. Consider the following example. The code below depends on remote data that is continuously updated:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">MarketData</span></span>
<span id="cb2-2">snp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">yahoo</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"^GSPC"</span>)</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Dates</span></span>
<span id="cb2-5">last_trade_day <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">timestamp</span>(snp[<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span>])[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-6">p_close <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">values</span>(snp[<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span>,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>Close])[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb2-7">last_trade_day_formatted <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Dates</span>.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span>(last_trade_day, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"U d, yyyy"</span>)</span></code></pre></div>
</div>
<p>It loads the most recent publicly available data on equity prices from Yahoo finance. In an ideal world, we‚Äôd like any updates to these inputs to be reflected in our output. That way you can just re-render the Quarto notebook to get an updated report. To render Julia code inline, we use <code>Markdown.jl</code> like so:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Markdown</span></span>
<span id="cb3-2">Markdown.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">parse</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb3-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">When the S&amp;P 500 last traded, on </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(last_trade_day_formatted)<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">, it closed at </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(p_close)<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">. </span></span>
<span id="cb3-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<p>When the S&amp;P 500 last traded, on February 23, 2023, it closed at 4012.320068.</p>
</div>
</div>
<p>In practice, one would of course set <code>#| echo: false</code> in this case. Whatever content you publish, this approach will keep it up-to-date. This practice of simply re-rendering the source notebook also ensures that any other output remains up-to-date (e.g. Figure&nbsp;1)</p>
<div class="cell" data-execution_count="3">
<div class="cell-output cell-output-display" data-execution_count="4">
<div id="fig-snp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/tips-and-tricks-for-using-quarto-with-julia/index_files/figure-html/fig-snp-output-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Price history of the S&amp;P 500.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="code-execution" class="level3">
<h3 class="anchored" data-anchor-id="code-execution">Code Execution</h3>
<p>Related to the previous point, I typically define the following execution options in my <code>_quarto.yml</code> or <code>_metadata.yml</code>. The <code>freeze: auto</code> option ensures that documents are only rerendered if the source changes. In cases where code should always be re-executed you whould want to set <code>freeze: false</code>, instead. I set <code>output: false</code> because typically I have a lot of code chunks that don‚Äôt generate any output that is of immediate interest to readers.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode yml code-with-copy"><code class="sourceCode yaml"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">execute</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb4-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">freeze</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> auto</span></span>
<span id="cb4-3"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eval</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb4-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">echo</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb4-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">output</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">false</span></span></code></pre></div>
</section>
<section id="reproducibility" class="level3">
<h3 class="anchored" data-anchor-id="reproducibility">Reproducibility</h3>
<p>To ensure that your content can be repoduced easily, it may additionally be helpful to explicitly specify the Julia version you used (<code>jupyter: julia-1.8</code>) and set up a global or local Julia environments. Inserting the following at the beginning of your Quarto notebook</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Pkg; Pkg</span>.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">activate</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"&lt;path&gt;"</span>)</span></code></pre></div>
<p>ensures that the desired environemnt that lives in <code>&lt;path&gt;</code> is actually activated and used.</p>
</section>
</section>
<section id="package-documentation" class="level2">
<h2 class="anchored" data-anchor-id="package-documentation">Package Documentation</h2>
<p>I have also continued to use Quarto in combination with <code>Documenter.jl</code> to document my Julia packages. This essentially boils down to writing up documentation using interactive <code>.qmd</code> notebooks and then rendering those to <code>.md</code> files as inputs for <code>Documenter.jl</code>. There are a few good reasons for this approach, especially if you‚Äôre used to working with Quarto anyway:</p>
<ol type="1">
<li>Re-rendering any docs with <code>eval: true</code> provides an additional layer of quality assurance: if any of the code chunks throws an error, you know that your documentation is outdated (perhaps due to an API change). It also offers a straight-forward way to test package functions that produce non-testable (e.g.&nbsp;stochastic) output. In such cases, the use of <code>jldoctest</code> is not always straight-forward (see <a href="https://github.com/JuliaDocs/Documenter.jl/issues/452">here</a>).</li>
<li>You get some stuff for free, e.g.&nbsp;citation management. Unfortunately, as far as I‚Äôm aware there is still no support for cross-referencing.</li>
<li>You can use Quarto execution options like <code>execute-dir: project</code> and <code>resources: www/</code> to globally specify the working directory and a directory for external resources like images.</li>
</ol>
<p>There are also a few peculiarities to be aware of. To avoid any issues with <code>Documenter.jl</code>, I‚Äôve found it useful to ensure that the rendered <code>.md</code> files do not contain any raw HTML and to preserve text wrapping:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode yml code-with-copy"><code class="sourceCode yaml"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span></span>
<span id="cb6-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">commonmark</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb6-3"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">variant</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> -raw_html</span></span>
<span id="cb6-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">wrap</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> preserve</span></span></code></pre></div>
<p>When working with <code>.qmd</code> files you also need to use a slightly different syntax for <a href="https://documenter.juliadocs.org/stable/showcase/#Admonitions">admonitions</a>. The following syntax inside the <code>.qmd</code></p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode md code-with-copy"><code class="sourceCode markdown"><span id="cb7-1">| !!! note \"An optional title\"</span>
<span id="cb7-2">|     Here is something that you should pay attention to.   </span></code></pre></div>
<p>will generate the desired output inside the rendered <code>.md</code>:<sup>2</sup></p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode md code-with-copy"><code class="sourceCode markdown"><span id="cb8-1">!!! note "An optional title"</span>
<span id="cb8-2">    Here is something that you should pay attention to.   </span></code></pre></div>
<p>Any of my package repos ‚Äî <a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl"><code>CounterfactualExplanations.jl</code></a>, <a href="https://github.com/juliatrustworthyai/LaplaceRedux.jl"><code>LaplaceRedux.jl</code></a>, <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> ‚Äî should provide additional colour on this topic.</p>
</section>
<section id="quarto-for-academic-journal-articles" class="level2">
<h2 class="anchored" data-anchor-id="quarto-for-academic-journal-articles">Quarto for Academic Journal Articles</h2>
<p>Quarto supports <img src="https://latex.codecogs.com/png.latex?%5CLaTeX"> templates/classes, which has helped me with paper submissions in the past (e.g.&nbsp;my pending JuliaCon Proceedings submissions). I‚Äôve found that <a href="https://pkgs.rstudio.com/rticles/articles/rticles.html"><code>rticles</code></a> still has an edge here, but the <a href="https://quarto.org/docs/extensions/listing-journals.html">list</a> of out-of-the-box templates for journal articles is growing. Should I find some time in the future, I will try to add a template for JuliaCon Proceedings. The beauty of this is that it should enable publishers to not only use traditional forms of publication (PDF), but also include more dynamic formats with ease (think <a href="https://distill.pub/">distill</a>, but more than that.)</p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping up</h2>
<p>This short post has provided a bit of an update on using Quarto with Julia. From my own experience so far, things have been getting easier and better (thanks to the amazing work of Quarto dev team). I‚Äôm exicted to see things improve even further and still think that Quarto is a revolutionary new tool for scientific publishing. Let‚Äôs hope publishers eventually recognise this value üëÄ.</p>


</section>


<div id="quarto-appendix" class="default"><aside id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Unrelated to Quarto, but this <a href="https://discourse.julialang.org/t/what-is-in-your-startup-jl/18228/21">thread</a> on discourse is full of other useful ideas for your <code>startup.jl</code>.‚Ü©Ô∏é</p></li>
<li id="fn2"><p>See related <a href="https://github.com/quarto-dev/quarto-cli/discussions/2947">discussion</a>.‚Ü©Ô∏é</p></li>
</ol>
</aside><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {A Year of Using {Quarto} with {Julia}},
  date = {2022-11-21},
  url = {https://www.paltmeyer.com/blog//blog/posts/tips-and-tricks-for-using-quarto-with-julia},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2022. <span>‚ÄúA Year of Using Quarto with
Julia.‚Äù</span> November 21, 2022. <a href="https://www.paltmeyer.com/blog//blog/posts/tips-and-tricks-for-using-quarto-with-julia">https://www.paltmeyer.com/blog//blog/posts/tips-and-tricks-for-using-quarto-with-julia</a>.
</div></div></section></div> ]]></description>
  <category>Quarto</category>
  <category>Julia</category>
  <category>open-source</category>
  <category>reproducibility</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html</guid>
  <pubDate>Mon, 21 Nov 2022 05:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/www/images/julia_quarto.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Conformal Prediction in Julia üü£üî¥üü¢</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Prediction sets for two different samples <br> and changing coverage rates. <br> As coverage grows, so does the size of the <br> prediction sets.
</figcaption>
</figure>
</div>
<p>A first crucial step towards building trustworthy AI systems is to be transparent about predictive uncertainty. Model parameters are random variables and their values are estimated from noisy data. That inherent stochasticity feeds through to model predictions and should to be addressed, at the very least in order to avoid overconfidence in models.</p>
<p>Beyond that obvious concern, it turns out that quantifying model uncertainty actually opens up a myriad of possibilities to improve up- and down-stream modeling tasks like active learning and robustness. In Bayesian Active Learning, for example, uncertainty estimates are used to guide the search for new input samples, which can make ground-truthing tasks more efficient <span class="citation" data-cites="houlsby2011bayesian">(Houlsby et al. 2011)</span>. With respect to model performance in downstream tasks, uncertainty quantification can be used to improve model calibration and robustness <span class="citation" data-cites="lakshminarayanan2016simple">(Lakshminarayanan, Pritzel, and Blundell 2016)</span>.</p>
<p>In previous posts we have looked at how uncertainty can be quantified in the Bayesian context (see <a href="https://www.paltmeyer.com/blog/posts/bayesian-logit/">here</a> and <a href="https://www.paltmeyer.com/blog/posts/effortsless-bayesian-dl/">here</a>). Since in Bayesian modeling we are generally concerned with estimating posterior distributions, we get uncertainty estimates almost as a byproduct. This is great for all intends and purposes, but it hinges on assumptions about prior distributions. Personally, I have no quarrel with the idea of making prior distributional assumptions. On the contrary, I think the Bayesian framework formalizes the idea of integrating prior information in models and therefore provides a powerful toolkit for conducting science. Still, in some cases this requirement may be seen as too restrictive or we may simply lack prior information.</p>
<p>Enter: Conformal Prediction (CP) ‚Äî a scalable frequentist approach to uncertainty quantification and coverage control. In this post we will go through the basic concepts underlying CP. A number of hands-on usage examples in Julia should hopefully help to convey some intuition and ideally attract people interested in contributing to a new and exciting open-source development.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üèÉ‚Äç‚ôÄÔ∏è TL;DR
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Conformal Prediction is an interesting frequentist approach to uncertainty quantification that can even be combined with Bayes (Section&nbsp;1).</li>
<li>It is scalable and model-agnostic and therefore well applicable to machine learning (Section&nbsp;1).</li>
<li><a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> implements CP in pure Julia and can be used with any supervised model available from <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> (Section&nbsp;2).</li>
<li>Implementing CP directly on top of an existing, powerful machine learning toolkit demonstrates the potential usefulness of this framework to the ML community (Section&nbsp;2).</li>
<li>Standard conformal classifiers produce set-valued predictions: for ambiguous samples these sets are typically large (for high coverage) or empty (for low coverage) (Section&nbsp;2.1).</li>
</ol>
</div>
</div>
<section id="sec-background" class="level2">
<h2 class="anchored" data-anchor-id="sec-background">üìñ Background</h2>
<p>Conformal Prediction promises to be an easy-to-understand, distribution-free and model-agnostic way to generate statistically rigorous uncertainty estimates. That‚Äôs quite a mouthful, so let‚Äôs break it down: firstly, as I will hopefully manage to illustrate in this post, the underlying concepts truly are fairly straight-forward to understand; secondly, CP indeed relies on only minimal distributional assumptions; thirdly, common procedures to generate conformal predictions really do apply almost universally to all supervised models, therefore making the framework very intriguing to the ML community; and, finally, CP does in fact come with a frequentist coverage guarantee that ensures that conformal prediction sets contain the true value with a user-chosen probability. For a formal proof of this <em>marginal coverage</em> property and a detailed introduction to the topic, I recommend <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In what follows we will loosely treat the tutorial by <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span> and the general framework it sets as a reference. You are not expected to have read the paper, but I also won‚Äôt reiterate any details here.</p>
</div>
</div>
<p>CP can be used to generate prediction intervals for regression models and prediction sets for classification models (more on this later). There is also some recent work on conformal predictive distributions and probabilistic predictions. Interestingly, it can even be used to complement Bayesian methods. <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span>, for example, point out that prior information should be incorporated into prediction sets and demonstrate how Bayesian predictive distributions can be conformalized in order to comply with the frequentist notion of coverage. Relatedly, <span class="citation" data-cites="hoff2021bayesoptimal">Hoff (2021)</span> proposes a Bayes-optimal prediction procedure. And finally, <span class="citation" data-cites="stanton2022bayesian">Stanton, Maddox, and Wilson (2022)</span> very recently proposed a way to introduce conformal prediction in Bayesian Optimization. I find this type of work that combines different schools of thought very promising, but I‚Äôm drifting off a little ‚Ä¶ So, without further ado, let us look at some code.</p>
</section>
<section id="sec-julia" class="level2">
<h2 class="anchored" data-anchor-id="sec-julia">üì¶ Conformal Prediction in Julia</h2>
<p>In this section of this first short post on CP we will look at how conformal prediction can be implemented in Julia. In particular, we will look at an approach that is compatible with any of the many supervised machine learning models available in <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a>: a beautiful, comprehensive machine learning framework funded by the <a href="https://www.turing.ac.uk/">Alan Turing Institute</a> and the <a href="https://www.mbie.govt.nz/science-and-technology/science-and-innovation/funding-information-and-opportunities/investment-funds/strategic-science-investment-fund/ssif-funded-programmes/university-of-auckland/">New Zealand Strategic Science Investment Fund</a> <span class="citation" data-cites="blaom2020mlj">Blaom et al. (2020)</span>. We will go through some basic usage examples employing a new Julia package that I have been working on: <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>ConformalPrediction.jl</code> is a package for uncertainty quantification through conformal prediction for machine learning models trained in <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a>. At the time of writing it is still in its early stages of development, but already implements a range of different approaches to CP. Contributions are very much welcome:</p>
<ul>
<li><a href="https://www.paltmeyer.com/ConformalPrediction.jl/stable/">Documentation</a></li>
<li><a href="https://www.paltmeyer.com/ConformalPrediction.jl/stable/#Contribute">Contributor‚Äôs Guide</a></li>
</ul>
</div>
</div>
<section id="sec-scp" class="level3">
<h3 class="anchored" data-anchor-id="sec-scp">Split Conformal Classification</h3>
<p>We consider a simple binary classification problem. Let <img src="https://latex.codecogs.com/png.latex?(X_i,%20Y_i),%20%5C%20i=1,...,n"> denote our feature-label pairs and let <img src="https://latex.codecogs.com/png.latex?%5Cmu:%20%5Cmathcal%7BX%7D%20%5Cmapsto%20%5Cmathcal%7BY%7D"> denote the mapping from features to labels. For illustration purposes we will use the moons dataset üåô. Using <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> we first generate the data and split into into a training and test set:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">MLJ</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Random</span></span>
<span id="cb1-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Random</span>.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seed!</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">123</span>)</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Data:</span></span>
<span id="cb1-6">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">make_moons</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>; noise<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.15</span>)</span>
<span id="cb1-7">train, test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">partition</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eachindex</span>(y), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">true</span>)</span></code></pre></div>
</div>
<p>Here we will use a specific case of CP called <em>split conformal prediction</em> which can then be summarized as follows:<sup>1</sup></p>
<ol type="1">
<li>Partition the training into a proper training set and a separate calibration set: <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D_n=%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Btrain%7D%7D%20%5Ccup%20%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Bcali%7D%7D">.</li>
<li>Train the machine learning model on the proper training set: <img src="https://latex.codecogs.com/png.latex?%5Chat%5Cmu_%7Bi%20%5Cin%20%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Btrain%7D%7D%7D(X_i,Y_i)">.</li>
<li>Compute nonconformity scores, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BS%7D">, using the calibration data <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Bcali%7D%7D"> and the fitted model <img src="https://latex.codecogs.com/png.latex?%5Chat%5Cmu_%7Bi%20%5Cin%20%5Cmathcal%7BD%7D%5E%7B%5Ctext%7Btrain%7D%7D%7D">.</li>
<li>For a user-specified desired coverage ratio <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)"> compute the corresponding quantile, <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bq%7D">, of the empirical distribution of nonconformity scores, <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BS%7D">.</li>
<li>For the given quantile and test sample <img src="https://latex.codecogs.com/png.latex?X_%7B%5Ctext%7Btest%7D%7D">, form the corresponding conformal prediction set:</li>
</ol>
<p><span id="eq-set"><img src="https://latex.codecogs.com/png.latex?%0AC(X_%7B%5Ctext%7Btest%7D%7D)=%5C%7By:s(X_%7B%5Ctext%7Btest%7D%7D,y)%20%5Cle%20%5Chat%7Bq%7D%5C%7D%0A%5Ctag%7B1%7D"></span></p>
<p>This is the default procedure used for classification and regression in <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a>.</p>
<p>You may want to take a look at the source code for the classification case <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl/blob/67712e870dc3a438bf0846d376fa48480612f042/src/ConformalModels/inductive_classification.jl#L1">here</a>. As a <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl/blob/67712e870dc3a438bf0846d376fa48480612f042/src/ConformalModels/inductive_classification.jl#L3">first</a> important step, we begin by defining a concrete type <code>SimpleInductiveClassifier</code> that wraps a supervised model from <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> and reserves additional fields for a few hyperparameters. As a <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl/blob/67712e870dc3a438bf0846d376fa48480612f042/src/ConformalModels/inductive_classification.jl#L26">second</a> step, we define the training procedure, which includes the data-splitting and calibration step. Finally, as a <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl/blob/67712e870dc3a438bf0846d376fa48480612f042/src/ConformalModels/inductive_classification.jl#L56">third</a> step we implement the procedure in Equation&nbsp;1 to compute the conformal prediction set.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Development Status
</div>
</div>
<div class="callout-body-container callout-body">
<p>The permalinks above take you to the version of the package that was up-to-date at the time of writing. Since the package is in its early stages of development, the code base and API can be expected to change.</p>
</div>
</div>
<p>Now let‚Äôs take this to our üåô data. To illustrate the package functionality we will demonstrate the envisioned workflow. We first define our atomic machine learning model following standard <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> conventions. Using <a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> we then wrap our atomic model in a conformal model using the standard API call <code>conformal_model(model::Supervised; kwargs...)</code>. To train and predict from our conformal model we can then rely on the conventional <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> procedure again. In particular, we wrap our conformal model in data (turning it into a machine) and then fit it on the training set. Finally, we use our machine to predict the label for a new test sample <code>Xtest</code>:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Model:</span></span>
<span id="cb2-2">KNNClassifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@load</span> KNNClassifier pkg<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>NearestNeighborModels</span>
<span id="cb2-3">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">KNNClassifier</span>(;K<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>) </span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Training:</span></span>
<span id="cb2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">ConformalPrediction</span></span>
<span id="cb2-7">conf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.9</span>)</span>
<span id="cb2-8">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(conf_model, X, y)</span>
<span id="cb2-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train)</span>
<span id="cb2-10"></span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Conformal Prediction:</span></span>
<span id="cb2-12">Xtest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">selectrows</span>(X, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">first</span>(test))</span>
<span id="cb2-13">ytest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y[<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">first</span>(test)]</span>
<span id="cb2-14"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(mach, Xtest)[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>import NearestNeighborModels</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> ‚úî</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div class="ansi-escaped-output">
<pre>           <span class="ansi-bright-white-fg ansi-bold">UnivariateFinite{Multiclass{2}}</span>      
     <span class="ansi-bright-black-fg">‚îå                                        ‚îê</span> 
   0 <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.94 <span class="ansi-bright-black-fg"> </span> 
     <span class="ansi-bright-black-fg">‚îî                                        ‚îò</span> </pre>
</div>
</div>
</div>
<p>The final predictions are set-valued. While the softmax output remains unchanged for the <code>SimpleInductiveClassifier</code>, the size of the prediction set depends on the chosen coverage rate, <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)">.</p>
<div class="cell" data-execution_count="4">
<div class="cell-output cell-output-display" data-execution_count="5">
<p>When specifying a coverage rate very close to one, the prediction set will typically include many (in some cases all) of the possible labels. Below, for example, both classes are included in the prediction set when setting the coverage rate equal to <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)">=1.0. This is intuitive, since high coverage quite literally requires that the true label is covered by the prediction set with high probability.</p>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1">conf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>coverage)</span>
<span id="cb5-2">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(conf_model, X, y)</span>
<span id="cb5-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train)</span>
<span id="cb5-4"></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Conformal Prediction:</span></span>
<span id="cb5-6">Xtest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (x1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],x2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb5-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(mach, Xtest)[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div class="ansi-escaped-output">
<pre>           <span class="ansi-bright-white-fg ansi-bold">UnivariateFinite{Multiclass{2}}</span>      
     <span class="ansi-bright-black-fg">‚îå                                        ‚îê</span> 
   0 <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.5 <span class="ansi-bright-black-fg"> </span> 
   1 <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.5 <span class="ansi-bright-black-fg"> </span> 
     <span class="ansi-bright-black-fg">‚îî                                        ‚îò</span> </pre>
</div>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="cell-output cell-output-display" data-execution_count="7">
<p>Conversely, for low coverage rates, prediction sets can also be empty. For a choice of <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)">=0.1, for example, the prediction set for our test sample is empty. This is a bit difficult to think about intuitively and I have not yet come across a satisfactory, intuitive interpretation.<sup>2</sup> When the prediction set is empty, the <code>predict</code> call currently returns <code>missing</code>:</p>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1">conf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>coverage)</span>
<span id="cb6-2">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(conf_model, X, y)</span>
<span id="cb6-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train)</span>
<span id="cb6-4"></span>
<span id="cb6-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Conformal Prediction:</span></span>
<span id="cb6-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(mach, Xtest)[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>missing</code></pre>
</div>
</div>
<p>Figure&nbsp;1 should provide some more intuition as to what exactly is happening here. It illustrates the effect of the chosen coverage rate on the predicted softmax output and the set size in the two-dimensional feature space. Contours are overlayed with the moon data points (including test data). The two samples highlighted in red, <img src="https://latex.codecogs.com/png.latex?X_1"> and <img src="https://latex.codecogs.com/png.latex?X_2">, have been manually added for illustration purposes. Let‚Äôs look at these one by one.</p>
<p>Firstly, note that <img src="https://latex.codecogs.com/png.latex?X_1"> (red cross) falls into a region of the domain that is characterized by high predictive uncertainty. It sits right at the bottom-right corner of our class-zero moon üåú (orange), a region that is almost entirely enveloped by our class-one moon üåõ (green). For low coverage rates the prediction set for <img src="https://latex.codecogs.com/png.latex?X_1"> is empty: on the left-hand side this is indicated by the missing contour for the softmax probability; on the right-hand side we can observe that the corresponding set size is indeed zero. For high coverage rates the prediction set includes both <img src="https://latex.codecogs.com/png.latex?y=0"> and <img src="https://latex.codecogs.com/png.latex?y=1">, indicative of the fact that the conformal classifier is uncertain about the true label.</p>
<p>With respect to <img src="https://latex.codecogs.com/png.latex?X_2">, we observe that while also sitting on the fringe of our class-zero moon, this sample populates a region that is not fully enveloped by data points from the opposite class. In this region, the underlying atomic classifier can be expected to be more certain about its predictions, but still not highly confident. How is this reflected by our corresponding conformal prediction sets?</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">Xtest_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (x1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>],x2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>])</span>
<span id="cb8-2">cov_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">.9</span></span>
<span id="cb8-3">conf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cov_)</span>
<span id="cb8-4">mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(conf_model, X, y)</span>
<span id="cb8-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train)</span>
<span id="cb8-6">pÃÇ_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pdf</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(mach, Xtest_2)[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
</details>
</div>
<div class="cell" data-execution_count="10">
<div class="cell-output cell-output-display" data-execution_count="11">
<p>Well, for low coverage rates (roughly <img src="https://latex.codecogs.com/png.latex?%3C0.9">) the conformal prediction set does not include <img src="https://latex.codecogs.com/png.latex?y=0">: the set size is zero (right panel). Only for higher coverage rates do we have <img src="https://latex.codecogs.com/png.latex?C(X_2)=%5C%7B0%5C%7D">: the coverage rate is high enough to include <img src="https://latex.codecogs.com/png.latex?y=0">, but the corresponding softmax probability is still fairly low. For example, for <img src="https://latex.codecogs.com/png.latex?(1-%5Calpha)=0.9"> we have <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bp%7D(y=0%7CX_2)=0.72."></p>
</div>
</div>
<p>These two examples illustrate an interesting point: for regions characterised by high predictive uncertainty, conformal prediction sets are typically empty (for low coverage) or large (for high coverage). While set-valued predictions may be something to get used to, this notion is overall intuitive.</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Setup</span></span>
<span id="cb9-2">coverages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">range</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>,length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb9-3">n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb9-4">x1_range <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">range</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">extrema</span>(X.x1)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>,length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n)</span>
<span id="cb9-5">x2_range <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">range</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">extrema</span>(X.x2)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>,length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n)</span>
<span id="cb9-6"></span>
<span id="cb9-7">anim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">@animate</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> coverage <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> coverages</span>
<span id="cb9-8">    conf_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">conformal_model</span>(model; coverage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>coverage)</span>
<span id="cb9-9">    mach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">machine</span>(conf_model, X, y)</span>
<span id="cb9-10">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(mach, rows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train)</span>
<span id="cb9-11">    p1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">contourf_cp</span>(mach, x1_range, x2_range; <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>proba, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Softmax"</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">nothing</span>)</span>
<span id="cb9-12">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scatter!</span>(p1, X.x1, X.x2, group<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y, ms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, msw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span>)</span>
<span id="cb9-13">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scatter!</span>(p1, Xtest.x1, Xtest.x2, ms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>red, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"X‚ÇÅ"</span>, shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>cross, msw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)</span>
<span id="cb9-14">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scatter!</span>(p1, Xtest_2.x1, Xtest_2.x2, ms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>red, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"X‚ÇÇ"</span>, shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>diamond, msw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)</span>
<span id="cb9-15">    p2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">contourf_cp</span>(mach, x1_range, x2_range; <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>set_size, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Set size"</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">nothing</span>)</span>
<span id="cb9-16">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scatter!</span>(p2, X.x1, X.x2, group<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y, ms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, msw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span>)</span>
<span id="cb9-17">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scatter!</span>(p2, Xtest.x1, Xtest.x2, ms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>red, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"X‚ÇÅ"</span>, shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>cross, msw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)</span>
<span id="cb9-18">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scatter!</span>(p2, Xtest_2.x1, Xtest_2.x2, ms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>red, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"X‚ÇÇ"</span>, shape<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>diamond, msw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)</span>
<span id="cb9-19">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(p1, p2, plot_title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(1-Œ±)=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(coverage,digits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">800</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>))</span>
<span id="cb9-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb9-21"></span>
<span id="cb9-22"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">gif</span>(anim, fps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span></code></pre></div>
</details>
<div id="fig-anim" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/data:image/gif;base64,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" class="figure-img">
<figcaption class="figure-caption">Figure&nbsp;1: The effect of the coverage rate on the conformal prediction set. Softmax probabilities are shown on the left. The size of the prediction set is shown on the right.</figcaption>
</figure>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">üèÅ Conclusion</h2>
<p>This has really been a whistle-stop tour of Conformal Prediction: an active area of research that probably deserves much more attention. Hopefully, though, this post has helped to provide some color and, if anything, made you more curious about the topic. Let‚Äôs recap the TL;DR from above:</p>
<ol type="1">
<li>Conformal Prediction is an interesting frequentist approach to uncertainty quantification that can even be combined with Bayes (Section&nbsp;1).</li>
<li>It is scalable and model-agnostic and therefore well applicable to machine learning (Section&nbsp;1).</li>
<li><a href="https://github.com/juliatrustworthyai/ConformalPrediction.jl"><code>ConformalPrediction.jl</code></a> implements CP in pure Julia and can be used with any supervised model available from <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.18/"><code>MLJ.jl</code></a> (Section&nbsp;2).</li>
<li>Implementing CP directly on top of an existing, powerful machine learning toolkit demonstrates the potential usefulness of this framework to the ML community (Section&nbsp;2).</li>
<li>Standard conformal classifiers produce set-valued predictions: for ambiguous samples these sets are typically large (for high coverage) or empty (for low coverage) (Section&nbsp;2.1).</li>
</ol>
<p>Below I will leave you with some further resources.</p>
</section>
<section id="further-resources" class="level2">
<h2 class="anchored" data-anchor-id="further-resources">üìö Further Resources</h2>
<p>Chances are that you have already come across the Awesome Conformal Prediction <a href="https://github.com/valeman/awesome-conformal-prediction">repo</a>: <span class="citation" data-cites="manokhin2022awesome">Manokhin (n.d.)</span> provides a comprehensive, up-to-date overview of resources related to the conformal prediction. Among the listed articles you will also find <span class="citation" data-cites="angelopoulos2021gentle">Angelopoulos and Bates (2021)</span>, which inspired much of this post. The repo also points to open-source implementations in other popular programming languages including Python and R.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-angelopoulos2021gentle" class="csl-entry">
Angelopoulos, Anastasios N., and Stephen Bates. 2021. <span>‚ÄúA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.‚Äù</span> <a href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>.
</div>
<div id="ref-blaom2020mlj" class="csl-entry">
Blaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. <span>‚Äú<span>MLJ</span>: <span>A Julia</span> Package for Composable Machine Learning.‚Äù</span> <em>Journal of Open Source Software</em> 5 (55): 2704. <a href="https://doi.org/10.21105/joss.02704">https://doi.org/10.21105/joss.02704</a>.
</div>
<div id="ref-hoff2021bayesoptimal" class="csl-entry">
Hoff, Peter. 2021. <span>‚ÄúBayes-Optimal Prediction with Frequentist Coverage Control.‚Äù</span> <a href="https://arxiv.org/abs/2105.14045">https://arxiv.org/abs/2105.14045</a>.
</div>
<div id="ref-houlsby2011bayesian" class="csl-entry">
Houlsby, Neil, Ferenc Husz√°r, Zoubin Ghahramani, and M√°t√© Lengyel. 2011. <span>‚ÄúBayesian Active Learning for Classification and Preference Learning.‚Äù</span> <a href="https://arxiv.org/abs/1112.5745">https://arxiv.org/abs/1112.5745</a>.
</div>
<div id="ref-lakshminarayanan2016simple" class="csl-entry">
Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2016. <span>‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù</span> <a href="https://arxiv.org/abs/1612.01474">https://arxiv.org/abs/1612.01474</a>.
</div>
<div id="ref-manokhin2022awesome" class="csl-entry">
Manokhin, Valery. n.d. <span>‚ÄúAwesome Conformal Prediction.‚Äù</span>
</div>
<div id="ref-stanton2022bayesian" class="csl-entry">
Stanton, Samuel, Wesley Maddox, and Andrew Gordon Wilson. 2022. <span>‚ÄúBayesian <span>Optimization</span> with <span>Conformal Coverage Guarantees</span>.‚Äù</span> <a href="https://arxiv.org/abs/2210.12496">https://arxiv.org/abs/2210.12496</a>.
</div>
</div></section><aside id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In other places split conformal prediction is sometimes referred to as <em>inductive</em> conformal prediction.‚Ü©Ô∏é</p></li>
<li id="fn2"><p>Any thoughts/comments welcome!‚Ü©Ô∏é</p></li>
</ol>
</aside><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {Conformal {Prediction} in {Julia} üü£üî¥üü¢},
  date = {2022-10-25},
  url = {https://www.paltmeyer.com/blog//blog/posts/conformal-prediction},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2022. <span>‚ÄúConformal Prediction in Julia
üü£üî¥üü¢.‚Äù</span> October 25, 2022. <a href="https://www.paltmeyer.com/blog//blog/posts/conformal-prediction">https://www.paltmeyer.com/blog//blog/posts/conformal-prediction</a>.
</div></div></section></div> ]]></description>
  <category>conformal prediction</category>
  <category>uncertainty</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/index.html</guid>
  <pubDate>Tue, 25 Oct 2022 04:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/conformal-prediction/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>A new tool for explainable AI</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Turning a 9 (nine) into a 4 (four).
</figcaption>
</figure>
</div>
<!-- Intro -->
<p>Counterfactual explanations, which I introduced in one of my previous posts<sup>1</sup>, offer a simple and intuitive way to explain black-box models without opening them. Still, as of today there exists only one open-source library that provides a unifying approach to generate and benchmark counterfactual explanations for models built and trained in Python <span class="citation" data-cites="pawelczyk2021carla">(Pawelczyk et al. 2021)</span>. This is great, but of limited use to users of other programming languages ü•≤.</p>
<p>Enter <a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/stable/"><code>CounterfactualExplanations.jl</code></a>: a Julia package that can be used to explain machine learning algorithms developed and trained in Julia, Python and R. Counterfactual explanations fall into the broader category of explainable artificial intelligence (XAI).</p>
<p>Explainable AI typically involves models that are not inherently interpretable but require additional tools to be explainable to humans. Examples of the latter include ensembles, support vector machines and deep neural networks. This is not to be confused with interpretable AI, which involves models that are inherently interpretable and transparent such as general additive models (GAM), decision trees and rule-based models.</p>
<p>Some would argue that we best avoid explaining black-box models altogether <span class="citation" data-cites="rudin2019stop">(Rudin 2019)</span> and instead focus solely on interpretable AI. While I agree that initial efforts should always be geared towards interpretable models, stopping there would entail missed opportunities and anyway is probably not very realistic in times of <a href="https://openai.com/blog/dall-e/">DALL<img src="https://latex.codecogs.com/png.latex?%5Ccdot">E</a> and Co.</p>
<blockquote class="blockquote">
<p>Even though [‚Ä¶] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the ‚Äúblack box.‚Äù</p>
<p>‚Äî <span class="citation" data-cites="wachter2017counterfactual">Wachter, Mittelstadt, and Russell (2017)</span></p>
</blockquote>
<!-- Nut paragraph -->
<p>This post introduces the main functionality of the new Julia package. Following a motivating example using a model trained in Julia, we will see how easy the package can be adapted to work with models trained in Python and R. Since the motivation for this post is also to hopefully attract contributors, the final section outlines some of the exciting developments we have planned.</p>
<section id="counterfactuals-for-image-data" class="level2">
<h2 class="anchored" data-anchor-id="counterfactuals-for-image-data">Counterfactuals for image data üñº</h2>
<p>To introduce counterfactual explanations I used a simple binary classification problem in my previous <a href="https://towardsdatascience.com/individual-recourse-for-black-box-models-5e9ed1e4b4cc">post</a>. It involved a linear classifier and a linearly separable, synthetic data set with just two features. This time we are going to step it up a notch: we will generate counterfactual explanations MNIST data. The MNIST dataset contains 60,000 training samples of handwritten digits in the form of 28x28 pixel grey-scale images <span class="citation" data-cites="lecun1998mnist">(LeCun 1998)</span>. Each image is associated with a label indicating the digit (0-9) that the image represents.</p>
<p>The <a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/stable/"><code>CounterfactualExplanations.jl</code></a> package ships with two black-box models that were trained to predict labels for this data: firstly, a simple multi-layer perceptron (MLP) and, secondly, a corresponding deep ensemble. Originally proposed by <span class="citation" data-cites="lakshminarayanan2016simple">Lakshminarayanan, Pritzel, and Blundell (2016)</span>, deep ensembles are really just ensembles of deep neural networks. They are still among the most popular approaches to Bayesian deep learning.<sup>2</sup></p>
<section id="black-box-models" class="level3">
<h3 class="anchored" data-anchor-id="black-box-models">Black-box models</h3>
<p>The code below loads relevant packages along with the MNIST data and pre-trained models.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load package, models and data:</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">CounterfactualExplanations</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Flux</span></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">CounterfactualExplanations.Data</span>: mnist_data, mnist_model, mnist_ensemble</span>
<span id="cb1-4">data, X, ys <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mnist_data</span>()</span>
<span id="cb1-5">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mnist_model</span>()</span>
<span id="cb1-6">ensemble <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mnist_ensemble</span>()</span>
<span id="cb1-7">counterfactual_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">CounterfactualData</span>(X,ys;domain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span></code></pre></div>
</div>
<p>While the package can currently handle a few simple classification models natively, it is designed to be easily extensible through users and contributors. Extending the package to deal with custom models typically involves only two simple steps:</p>
<ol type="1">
<li><strong>Subtyping</strong>: the custom model needs to be declared as a subtype of the package-internal type <code>AbstractFittedModel</code>.</li>
<li><strong>Multiple dispatch</strong>: the package-internal functions <code>logits</code> and <code>probs</code> need to be extended through custom methods for the new model type.</li>
</ol>
<p>The following code implements these two steps first for the MLP and then for the deep ensemble.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">CounterfactualExplanations.Models</span></span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">CounterfactualExplanations.Models</span>: logits, probs</span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MLP:</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 1)</span></span>
<span id="cb2-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">struct</span> NeuralNetwork <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;:</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;"> Models.AbstractFittedModel</span></span>
<span id="cb2-6">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Any</span></span>
<span id="cb2-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 2)</span></span>
<span id="cb2-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">logits</span>(M<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">NeuralNetwork</span>, X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractArray</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> M.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">model</span>(X)</span>
<span id="cb2-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">probs</span>(M<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">NeuralNetwork</span>, X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractArray</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">softmax</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">logits</span>(M, X))</span>
<span id="cb2-11">M <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">NeuralNetwork</span>(model)</span>
<span id="cb2-12"></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Deep ensemble:</span></span>
<span id="cb2-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Flux</span>: stack</span>
<span id="cb2-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 1)</span></span>
<span id="cb2-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">struct</span> FittedEnsemble <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;:</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;"> Models.AbstractFittedModel</span></span>
<span id="cb2-17">    ensemble<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractArray</span></span>
<span id="cb2-18"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb2-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 2)</span></span>
<span id="cb2-20"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Statistics</span></span>
<span id="cb2-21"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">logits</span>(M<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">FittedEnsemble</span>, X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractArray</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stack</span>([<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">m</span>(X) for m <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> M.ensemble],<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>),dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb2-22"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">probs</span>(M<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">FittedEnsemble</span>, X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractArray</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stack</span>([<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">softmax</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">m</span>(X)) for m <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> M.ensemble],<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>),dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb2-23">M_ensemble <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">FittedEnsemble</span>(ensemble)</span></code></pre></div>
</div>
</section>
<section id="counterfactual-generators" class="level3">
<h3 class="anchored" data-anchor-id="counterfactual-generators">Counterfactual generators</h3>
<p>Next, we need to specify the counterfactual generators we want to use. The package currently ships with two default generators that both need gradient access: firstly, the generic generator introduced by <span class="citation" data-cites="wachter2017counterfactual">Wachter, Mittelstadt, and Russell (2017)</span> and, secondly, a greedy generator introduced by <span class="citation" data-cites="schut2021generating">Schut et al. (2021)</span>.</p>
<p>The greedy generator is designed to be used with models that incorporate uncertainty in their predictions such as the deep ensemble introduced above. It works for probabilistic (Bayesian) models, because they only produce high-confidence predictions in regions of the feature domain that are populated by training samples. As long as the model is expressive enough and well-specified, counterfactuals in these regions will always be realistic and unambiguous since by construction they should look very similar to training samples. Other popular approaches to counterfactual explanations like REVISE <span class="citation" data-cites="joshi2019realistic">(Joshi et al. 2019)</span> and CLUE <span class="citation" data-cites="antoran2020getting">(Antor√°n et al. 2020)</span> also play with this simple idea.</p>
<p>The following code instantiates the two generators for the problem at hand.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1">generic <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">GenericGenerator</span>(;loss<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>logitcrossentropy)</span>
<span id="cb3-2">greedy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">GreedyGenerator</span>(;loss<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>logitcrossentropy)</span></code></pre></div>
</div>
</section>
<section id="explanations" class="level3">
<h3 class="anchored" data-anchor-id="explanations">Explanations</h3>
<p>Once the model and counterfactual generator are specified, running counterfactual search is very easy using the package. For a given factual (<code>x</code>), target class (<code>target</code>) and data set (<code>counterfactual_data</code>), simply running</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">generate_counterfactual</span>(x, target, counterfactual_data, M, generic)</span></code></pre></div>
</div>
<p>will generate the results, in this case using the generic generator (<code>generic</code>) for the MLP (<code>M</code>). Since we have specified two different black-box models and two different counterfactual generators, we have four combinations of a model and a generator in total. For each of these combinations I have used the <code>generate_counterfactual</code> function to produce the results in Figure&nbsp;1.</p>
<p>In every case the desired label switch is in fact achieved, but arguably from a human perspective only the counterfactuals for the deep ensemble look like a four. The generic generator produces mild perturbations in regions that seem irrelevant from a human perspective, but nonetheless yields a counterfactual that can pass as a four. The greedy approach clearly targets pixels at the top of the handwritten nine and yields the best result overall. For the non-Bayesian MLP, both the generic and the greedy approach generate counterfactuals that look much like adversarial examples: they perturb pixels in seemingly random regions on the image.</p>
<div id="fig-mnist-9to4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/www/mnist_9_to_4.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Counterfactual explanations for MNIST: turning a nine (9) into a four (4).</figcaption>
</figure>
</div>
</section>
</section>
<section id="language-interoperability" class="level2">
<h2 class="anchored" data-anchor-id="language-interoperability">Language interoperability üë•</h2>
<p>The Julia language offers unique support for programming language interoperability. For example, calling R or Python is made remarkably easy through <code>RCall.jl</code> and <code>PyCall.jl</code>, respectively. This functionality can be leveraged to use <code>CounterfactualExplanations.jl</code> to generate explanations for models that were developed in other programming languages. At this time there is no native support for foreign programming languages, but the following example involving a <code>torch</code> neural network trained in <code>R</code> demonstrates how versatile the package is.<sup>3</sup></p>
<section id="explaining-a-torch-model" class="level3">
<h3 class="anchored" data-anchor-id="explaining-a-torch-model">Explaining a <code>torch</code> model</h3>
<p>We will consider a simple MLP trained for a binary classification task. As before we first need to adapt this custom model for use with our package. The code below the two necessary steps - sub-typing and method extension. Logits are returned by the <code>torch</code> model and copied from the R environment into the Julia scope. Probabilities are then computed inside the Julia scope by passing the logits through the sigmoid function.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Flux</span></span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">CounterfactualExplanations</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">CounterfactualExplanations.Models</span></span>
<span id="cb5-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">CounterfactualExplanations.Models</span>: logits, probs <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># import functions in order to extend</span></span>
<span id="cb5-4"></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 1)</span></span>
<span id="cb5-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">struct</span> TorchNetwork <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;:</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;"> Models.AbstractFittedModel</span></span>
<span id="cb5-7">    nn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Any</span></span>
<span id="cb5-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb5-9"></span>
<span id="cb5-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Step 2)</span></span>
<span id="cb5-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">logits</span>(M<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">TorchNetwork</span>, X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractArray</span>)</span>
<span id="cb5-12">  nn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> M.nn</span>
<span id="cb5-13">  y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rcopy</span>(R<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"as_array(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>nn<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">(torch_tensor(t(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>X<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">))))"</span>)</span>
<span id="cb5-14">  y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">isa</span>(y, <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractArray</span>) ? y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> [y]</span>
<span id="cb5-15">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb5-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb5-17"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">probs</span>(M<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">TorchNetwork</span>, X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractArray</span>)</span>
<span id="cb5-18">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">œÉ</span>.(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">logits</span>(M, X))</span>
<span id="cb5-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb5-20">M <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">TorchNetwork</span>(R<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>)</span></code></pre></div>
</div>
<p>Compared to models trained in Julia, we need to do a little more work at this point. Since our counterfactual generators need gradient access, we essentially need to allow our package to communicate with the R <code>torch</code> library. While this may sound daunting, it turns out to be quite manageable: all we have to do is respecify the function that computes the gradient with respect to the counterfactual loss function so that it can deal with the <code>TorchNetwork</code> type we defined above. That is all the adjustment needed to use <code>CounterfactualExplanations.jl</code> for our custom R model. Figure&nbsp;2 shows a counterfactual path for a randomly chosen sample with respect to the MLP trained in R.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Experimental functionality
</div>
</div>
<div class="callout-body-container callout-body">
<p>You may have stumbled across the term <em>respecify</em> above: does it really seem like a good idea to just replace an existing function from our package? Surely not! There are certainly better ways to go about this, which we will consider when adding native support for Python and R models in future package releases. Which brings us to our final section ‚Ä¶</p>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">CounterfactualExplanations.Generators</span>: ‚àÇ‚Ñì</span>
<span id="cb6-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">LinearAlgebra</span></span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Countefactual loss:</span></span>
<span id="cb6-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">‚àÇ‚Ñì</span>(</span>
<span id="cb6-6">    generator<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">AbstractGradientBasedGenerator</span>, </span>
<span id="cb6-7">    counterfactual_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">CounterfactualState</span>) </span>
<span id="cb6-8">  M <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> counterfactual_state.M</span>
<span id="cb6-9">  nn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> M.nn</span>
<span id="cb6-10">  x‚Ä≤ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> counterfactual_state.x‚Ä≤</span>
<span id="cb6-11">  t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> counterfactual_state.target_encoded</span>
<span id="cb6-12">  R<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb6-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  x &lt;- torch_tensor(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>x<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">‚Ä≤, requires_grad=TRUE)</span></span>
<span id="cb6-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  output &lt;- </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>nn<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">(x)</span></span>
<span id="cb6-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  loss_fun &lt;- nnf_binary_cross_entropy_with_logits</span></span>
<span id="cb6-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  obj_loss &lt;- loss_fun(output,</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>t<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">)</span></span>
<span id="cb6-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  obj_loss</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>backward<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">()</span></span>
<span id="cb6-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  """</span></span>
<span id="cb6-19">  grad <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rcopy</span>(R<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"as_array(x</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>grad<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span>)</span>
<span id="cb6-20">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> grad</span>
<span id="cb6-21"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
</div>
<div id="fig-torch" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/www/interop_r.gif" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Counterfactual path using the generic counterfactual generator for a model trained in R.</figcaption>
</figure>
</div>
<!-- kicker -->
</section>
</section>
<section id="we-need-you" class="level2">
<h2 class="anchored" data-anchor-id="we-need-you">We need you! ü´µ</h2>
<p>The ambition for <code>CounterfactualExplanations.jl</code> is to provide a go-to place for counterfactual explanations to the Julia community and beyond. This is a grand ambition, especially for a package that has so far been built by a single developer who has little prior experience with Julia. We would therefore very much like to invite community contributions. If you have an interest in trustworthy AI, the open-source community and Julia, please do get involved! This package is still in its early stages of development, so any kind of contribution is welcome: advice on the core package architecture, pull requests, issues, discussions and even just comments below would be much appreciated.</p>
<p>To give you a flavor of what type of future developments we envision, here is a non-exhaustive list:</p>
<ol type="1">
<li>Native support for additional counterfactual generators and predictive models including those built and trained in Python or R.</li>
<li>Additional datasets for testing, evaluation and benchmarking.</li>
<li>Improved preprocessing including native support for categorical features.</li>
<li>Support for regression models.</li>
</ol>
<p>Finally, if you like this project but don‚Äôt have much time, then simply sharing this article or starring the <a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl">repo</a> on GitHub would also go a long way.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading üìö</h2>
<p>If you‚Äôre interested in learning more about this development, feel free to check out the following resources:</p>
<ul>
<li>Package docs: <a href="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/stable">[stable]</a>, <a href="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/dev">[dev]</a>.</li>
<li><a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/stable/contributing/">Contributor‚Äôs guide</a>.</li>
<li><a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl">GitHub repo</a>.</li>
</ul>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-antoran2020getting" class="csl-entry">
Antor√°n, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and Jos√© Miguel Hern√°ndez-Lobato. 2020. <span>‚ÄúGetting a Clue: <span>A</span> Method for Explaining Uncertainty Estimates.‚Äù</span> <a href="https://arxiv.org/abs/2006.06848">https://arxiv.org/abs/2006.06848</a>.
</div>
<div id="ref-joshi2019realistic" class="csl-entry">
Joshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. <span>‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù</span> <a href="https://arxiv.org/abs/1907.09615">https://arxiv.org/abs/1907.09615</a>.
</div>
<div id="ref-lakshminarayanan2016simple" class="csl-entry">
Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2016. <span>‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù</span> <a href="https://arxiv.org/abs/1612.01474">https://arxiv.org/abs/1612.01474</a>.
</div>
<div id="ref-lecun1998mnist" class="csl-entry">
LeCun, Yann. 1998. <span>‚ÄúThe <span>MNIST</span> Database of Handwritten Digits.‚Äù</span>
</div>
<div id="ref-pawelczyk2021carla" class="csl-entry">
Pawelczyk, Martin, Sascha Bielawski, Johannes van den Heuvel, Tobias Richter, and Gjergji Kasneci. 2021. <span>‚ÄúCarla: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms.‚Äù</span> <a href="https://arxiv.org/abs/2108.00783">https://arxiv.org/abs/2108.00783</a>.
</div>
<div id="ref-rudin2019stop" class="csl-entry">
Rudin, Cynthia. 2019. <span>‚ÄúStop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.‚Äù</span> <em>Nature Machine Intelligence</em> 1 (5): 206‚Äì15.
</div>
<div id="ref-schut2021generating" class="csl-entry">
Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. <span>‚ÄúGenerating <span>Interpretable Counterfactual Explanations By Implicit Minimisation</span> of <span>Epistemic</span> and <span>Aleatoric Uncertainties</span>.‚Äù</span> In <em>International <span>Conference</span> on <span>Artificial Intelligence</span> and <span>Statistics</span></em>, 1756‚Äì64. <span>PMLR</span>.
</div>
<div id="ref-wachter2017counterfactual" class="csl-entry">
Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. <span>‚ÄúCounterfactual Explanations Without Opening the Black Box: <span>Automated</span> Decisions and the <span>GDPR</span>.‚Äù</span> <em>Harv. JL &amp; Tech.</em> 31: 841.
</div>
</div></section><aside id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See: [<a href="https://towardsdatascience.com/individual-recourse-for-black-box-models-5e9ed1e4b4cc">TDS</a>], [<a href="https://www.paltmeyer.com/blog/posts/individual-recourse-for-black-box-models/">blog</a>]‚Ü©Ô∏é</p></li>
<li id="fn2"><p>For more information on Bayesian deep learning see my previous post: [<a href="https://towardsdatascience.com/go-deep-but-also-go-bayesian-ab25efa6f7b">TDS</a>], [<a href="https://www.paltmeyer.com/blog/posts/effortsless-bayesian-dl/">blog</a>].‚Ü©Ô∏é</p></li>
<li id="fn3"><p>The corresponding example involving <code>PyTorch</code> is analogous and therefore not included here. You may find it <a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/dev/tutorials/interop/">here</a>.‚Ü©Ô∏é</p></li>
</ol>
</aside><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {A New Tool for Explainable {AI}},
  date = {2022-04-20},
  url = {https://www.paltmeyer.com/blog//blog/posts/a-new-tool-for-explainable-ai},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2022. <span>‚ÄúA New Tool for Explainable AI.‚Äù</span>
April 20, 2022. <a href="https://www.paltmeyer.com/blog//blog/posts/a-new-tool-for-explainable-ai">https://www.paltmeyer.com/blog//blog/posts/a-new-tool-for-explainable-ai</a>.
</div></div></section></div> ]]></description>
  <category>counterfactuals</category>
  <category>explainable AI</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/index.html</guid>
  <pubDate>Wed, 20 Apr 2022 04:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/a-new-tool-for-explainable-ai/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Julia and Quarto: a match made in heaven? üå§</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/julia-and-quarto-a-match-made-in-heaven/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Julia and Quarto: a perfect match.
</figcaption>
</figure>
</div>
<p>Does your work involve research, coding, writing and publishing? If so, then chances are that you often find yourself bouncing back and forth between different open-source text editors, IDEs, programming languages and platforms depending on your current needs. Using a diverse set of tools is reasonable, because there typically is no single perfect approach that solves all our problems. For example, interactive notebooks like Jupyter are useful for working with code and communicating it to others, but they are probably not anyone‚Äôs first choice for producing a scientific article. Similarly, Beamer presentations can be useful for presenting science in a standardized fashion, but they are the very opposite of interactive and look incredibly boring.</p>
<p>As much as the great variety of free tools deserves being celebrated, all this bouncing back and forth can be really tiring. What if there was a single tool, an engine that can turn your work into all kinds of different outputs? I mean literally any output you can think of: Markdown, HTML, PDF, LateX, ePub, entire websites, presentations (yes, also Beamer if you have to), MS Word, OpenOffice, ‚Ä¶ the list goes on. All of that starting from the same place: a plain Markdown document blended with essentially any programming language of your choice and a YAML header defining your output. This tool now exists and it goes by the name <a href="https://quarto.org/">Quarto</a>.</p>
<p>In this short blog post I hope to convince you that Quarto is the only publishing engine you will ever need. What I am definitely not going to tell you is which IDE, text editor or programming language you should be using to actually produce your work. Quarto does not care about that. Quarto is here to make your life a bit easier (and by ‚Äòa bit‚Äô I mean a whole lot). Quarto is nothing less but a revolution for scientific publishing.</p>
<p>To put this all in some context (well, my context), I will now tell you a bit about what has led me to making such bold claims about yet another open-source tool.</p>
<blockquote class="blockquote">
<p>Hold up?! Wasn‚Äôt this supposed to be about Julia and Quarto?</p>
</blockquote>
<p>Yes! But it‚Äôs worth noting that a lot of the benefits that Quarto brings have been available to R users for many years, thanks to the amazing work of many great open-source contributors like <a href="https://twitter.com/xieyihui">@xieyihui</a>. Julia was the main reason for me to branch out of this comfortable R bubble as I describe below. That said, if you are a Julia user who really couldn‚Äôt care less about my previous experiences with R Markdown, this is a good time to skip straight ahead to Section&nbsp;2. By the way, if you haven‚Äôt clicked on that link, here‚Äôs a small showcase demonstrating how it was generated. It shows easy it is to have everything well organised and connected with Quarto.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Cross-referencing
</div>
</div>
<div class="callout-body-container callout-body">
<p>There is a standard recipe for generating cross-references in Quarto. The example below involves a section cross-reference.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1">If you are a Julia user that really couldn't care less about my previous experiences with R Markdown, this is a good time to skip straight ahead to @sec-match.</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">## Quarto and Julia - a perfect match {#sec-match}</span></span></code></pre></div>
<p>There is actually a comprehensive 8-step guide explaining how to achieve something similar in MS Word, but personally I wouldn‚Äôt go there. Anyway, take your pick:</p>
<ol type="a">
<li>üî¥ <a href="https://support.microsoft.com/en-us/office/create-a-cross-reference-300b208c-e45a-487a-880b-a02767d9774b">Go there</a>.</li>
<li>üü¢ Move on to Section&nbsp;1 #safespace.</li>
</ol>
</div>
</div>
<section id="sec-bubble" class="level2">
<h2 class="anchored" data-anchor-id="sec-bubble">A comfortable bubble üéà</h2>
<p>For many years I have used R Markdown for essentially anything work-related. As an undergraduate economics student facing the unfortunate reality that people still teach Stata, I was drawn to R. This was partially because R has a great open-source community and also partially because Stata. Once I realised that I would be able to use R Markdown to write up all of my future homework assignments and even my thesis, I never looked back. MS Word was now officially dead to me. Overleaf was nothing more than a last resort if everyone else in my team insisted on using it for a group project. Being able to write my undergraduate dissertation in R Markdown was a first truly triumphant moment. Soon after that I would also try myself at Shiny, produce outputs in HTML and build entire websites through <code>blogdown</code>. And all of that from within R Studio involving R and Markdown and really not much else. During my first professional job at the Bank of England I was reluctant to use anything other than R Markdown to produce all of my output. Luckily for me, the Bank was very much heading in that same direction at the time and my reluctance was not perceived as stubbornness, but actually welcome (at least I hoped so).</p>
<section id="cracks-in-the-bubble" class="level4">
<h4 class="anchored" data-anchor-id="cracks-in-the-bubble">Cracks in the bubble üß®</h4>
<p>Soon though, part of me felt a little boxed in. For any work that required me to look outside of the R bubble, I knew I might also have to give up a very, very comfortable work environment and my productivity would surely take a hit. During my master‚Äôs in Data Science, for example, the mantra was very much ‚ÄúPython + Jupyter or die‚Äù. Through <a href="https://rstudio.github.io/reticulate/"><code>reticulate</code></a> and R Studio‚Äôs growing support for Python I managed to get by without having to leave my bubble too often. But <code>reticulate</code> always felt a little clunky (sorry!) and some professors were reluctant to accept anything other than Jupyter notebooks. Even if others had not perceived it that way in the past, I certainly started to feel that I might just be a little too attached the beautiful bubble that R Studio had created around me.</p>
</section>
<section id="enter-julia" class="level4">
<h4 class="anchored" data-anchor-id="enter-julia">Enter: Julia üí£</h4>
<p>Then there was Julia: elegant, fast, pure, scientific and - oh my REPL! - those beautiful colors and unicode symbols. The stuff of dreams, really! Geeky dreams, but dreams nonetheless. I had once before given Julia a shot when working with high-frequency trade data for a course in market microstructure. This was the first time R really revealed its limitations to me and my bubble nearly burst, but thanks to <code>data.table</code> and <code>Rcpp</code> I managed to escape with only minor bruises. Still, Julia kept popping up, teasing me whenever I would work on some Frakenstein-style C++ code snippets that would hopefully resolve my R bottlenecks. I actually enjoyed mixing <strong>some</strong> C++ into my R code like I did <a href="https://github.com/pat-alt/reinforcement_learning">here</a>, but the process was just a little painful and slow. But wouldn‚Äôt learning <strong>all of</strong> Julia take even more time and patience? And what about my dependence on R Markdown?</p>
</section>
<section id="julia-bursts-my-bubble" class="level4">
<h4 class="anchored" data-anchor-id="julia-bursts-my-bubble">Julia bursts my bubble üí•</h4>
<p>As I started my PhD in September 2021, I eventually gave in. New beginnings - time to suck it up! If it meant that I‚Äôd have to use Jupyter notebooks with Julia, so be it! And so I was off to a somewhat bumpy start that would have me bouncing back and forth between trying to make Julia work in R Studio (meh), setting up Jupyter Lab (meeeh), just using the Julia REPL because ‚Äúthe REPL is all you need‚Äù (nope) and even struggling with Vim and Emacs. Then there was also <code>Pluto.jl</code>, of course, which admittedly looks amazing! But it also looks very much tailored to Julia and (I believe) the number of different output formats you can produce is still very limited. Eventually, I settled for VSCode in combination with Jupyter notebooks. As much as I dreaded the latter, Jupyter is popular, arguably versatile and supports both R and Julia. This setup worked well enough for me, but it still definitely fell short of the breeze that R Studio had always provided. One thing that really bugged me, for example, was the fact that the IJulia kernel was not accessible from the Julia REPL. Each notebook would have its own environment, which could only be accessed through the notebook. In R Studio the interaction between R Markdown and the console is seamless, as both have access to the same environment variables.</p>
</section>
<section id="enter-quarto" class="level4">
<h4 class="anchored" data-anchor-id="enter-quarto">Enter: Quarto ‚ù§Ô∏è‚Äçü©π</h4>
<p>Around the same time that I started using Julia, I read about Quarto for the first time. It looked ‚Ä¶ great! Like a timely little miracle really! But also ‚Ä¶ unfinished? Definitely experimental at the time. I loved the idea though and in a footnote somewhere on their website it said that the project was supported by R Studio which I took as a very good sign. So I decided to at least give it a quick try and built a small (tiny) <a href="https://www.paltmeyer.com/tai/">website</a> summarising some of the literature I had read for my PhD:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Just had my first go <a href="https://twitter.com/hashtag/quarto?src=hash&amp;ref_src=twsrc%5Etfw">#quarto</a> and I absolutely love the concept! Open-source and language agnostic - truly amazing work from <a href="https://twitter.com/rstudio?ref_src=twsrc%5Etfw">&amp;#64rstudio</a> <a href="https://t.co/veCg7ywQ8v">https://t.co/veCg7ywQ8v</a>
</p>
‚Äî Patrick Altmeyer (&amp;#64paltmey) <a href="https://twitter.com/paltmey/status/1454042807019180035?ref_src=twsrc%5Etfw">October 29, 2021</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This was a first very pleasant encounter with Quarto, arguable even smoother than building websites in <code>blogdown</code>. As for working with Julia though, I had made up my mind that VSCode was the way to go and at the time there was no Quarto extension (there is <a href="https://marketplace.visualstudio.com/items?itemName=quarto.quarto">now</a>). There was also little in terms of communication about the project by R Studio, probably because things were really still in the early development stages. I was hopeful that eventually Quarto would enable me to emulate the R Studio experience in VS Code, but for now things were not quite there yet.</p>
</section>
<section id="quarto-keeps-growing" class="level4">
<h4 class="anchored" data-anchor-id="quarto-keeps-growing">Quarto keeps growing ü§û</h4>
<p>Since I was now working with VSCode + Jupyter and since Quarto supports Jupyter as well as all of my old R Markdown work, my next little Quarto project involved turning my old <code>blogdown</code>-powered blog into a Quarto-powered <a href="https://www.paltmeyer.com/blog/">blog</a>. This was not strictly necessary, as I could always export my new Jupyter notebooks to HTML and let <code>blogdown</code> do the rest. But it did streamline things a little bit and the default Quarto blog theme - you are staring at it - is actually üî•. I also did not have to feel guilty towards <a href="https://twitter.com/xieyihui">@xieyihui</a> about leaving <code>blogdown</code>, because unsurprisingly he is on the Quarto team. As I was working on this little project I started noticing that the Quarto website was updated regularly and responses to issues I opened like this <a href="https://github.com/quarto-dev/quarto-cli/issues/293">one</a> were answered very swiftly. Clearly, things were moving and they were moving fast. More recently, the news about Quarto has been spreading and it‚Äôs left some folks as confused and amazed as I was, when I first heard about it:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
<a href="https://twitter.com/hashtag/RStats?src=hash&amp;ref_src=twsrc%5Etfw">#RStats</a> can someone explain to me what's the difference between {Quarto} and {RMarkdown}? I saw a tweet about Quarto and now I'm all confused ‚Ä¶ What gap is it supposed to fill?
</p>
‚Äî Erwin Lares (&amp;#64lasrubieras) <a href="https://twitter.com/lasrubieras/status/1509014670262390784?ref_src=twsrc%5Etfw">March 30, 2022</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This is why finally I‚Äôve decided I should write a brief post about how and why I use Quarto. Since I have been working mostly with Julia for the past couple of months, I‚Äôve chosen to focus on the interaction between Quarto and Julia. Coincidentally, yesterday was also the first time I saw a <a href="https://quarto.org/docs/computations/julia.html">guide</a> dedicated to Julia on the Quarto website, so evidently I am not the only one interested in that marriage. This also means that there really is not too much left for me to talk about now, since Quarto‚Äôs documentation is state-of-the-art. But a few bits and pieces I mention below might hopefully still be useful or at least some food for thought.</p>
</section>
</section>
<section id="sec-match" class="level2">
<h2 class="anchored" data-anchor-id="sec-match">Quarto and Julia: a perfect match üíôüíúüíö</h2>
<p>While what follows may be relevant to other programming languages, my main goal for this last section is to flag Quarto to the Julia community. In any case, #rstats folks have been using R and Python in R Markdown documents for a while now and won‚Äôt need much of an introduction to Quarto. As for Python aficionados, I can only recommend to give Quarto a shot (you will still be able to use Jupyter notebooks).</p>
<section id="working-with-vscode-quarto-and-julia" class="level4">
<h4 class="anchored" data-anchor-id="working-with-vscode-quarto-and-julia">Working with VSCode, Quarto and Julia</h4>
<p>The very article you are reading right now was composed in a Quarto document. These documents feel and look very much like standard Julia Markdown documents, but you can do a lot more with them. You can find the source code for this and other documents presented in this blog <a href="https://github.com/pat-alt/blog">here</a>.</p>
<p>To get you started, here is my current setup combining VSCode, Quarto and Julia:</p>
<ol type="1">
<li>VSCode extensions: in addition to the <a href="https://marketplace.visualstudio.com/items?itemName=julialang.language-julia">Julia extension</a> you will need the <a href="https://marketplace.visualstudio.com/items?itemName=quarto.quarto">Quarto extension</a>. In addition, the <a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-yaml">YAML extension</a> and some extension to preview Markdown docs would be helpful. I am not sure if <a href="https://marketplace.visualstudio.com/items?itemName=colinfang.markdown-julia">Markdown Julia</a> and <a href="https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter">Jupyter</a> are strictly necessary, but it won‚Äôt hurt.</li>
<li>I do most of my work in Quarto documents <code>.qmd</code>.</li>
<li>If you choose to also do that, make sure that the <code>.qmd</code> document has access to a <code>Pkg.jl</code> environment that has <code>IJulia</code> added.</li>
</ol>
<p>Julia code cells can be added anywhere along with your plain text Markdown. They look like this:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{julia}</span></span>
<span id="cb2-2">using Pkg</span>
<span id="cb2-3">Pkg.add(<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">"</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">CounterfactualExplanations</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb2-4"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<p>Contrary to Jupyter notebooks, executing this code cells will start a Julia REPL in VSCode. I find this very helpful, because it lets me fiddle with anything I have created inside the Quarto notebook without having to click into cells all the time. Quarto comes with great support for specifying <a href="https://quarto.org/docs/computations/julia.html">code executing options</a>. For example, for the code below I have specified <code>#| echo: true</code> in order for the code to be rendered. The code itself is the code I actually used to build the animation above (heavily borrowed from this <code>Javis.jl</code> <a href="https://juliaanimators.github.io/Javis.jl/stable/tutorials/tutorial_7/">tutorial</a>).</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#| echo: true</span></span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Javis</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Animations</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Colors</span></span>
<span id="cb3-3"></span>
<span id="cb3-4">size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">600</span></span>
<span id="cb3-5">radius_factor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.33</span></span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ground</span>(args<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>)</span>
<span id="cb3-8">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">background</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"transparent"</span>)</span>
<span id="cb3-9">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sethue</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"white"</span>)</span>
<span id="cb3-10"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-11"></span>
<span id="cb3-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rotate_anim</span>(idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Number</span>, total<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">Number</span>) </span>
<span id="cb3-13">    distance_circle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.875</span></span>
<span id="cb3-14">    steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">collect</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">range</span>(distance_circle,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>distance_circle,length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>total))</span>
<span id="cb3-15">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Animation</span>(</span>
<span id="cb3-16">        [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># must go from 0 to 1</span></span>
<span id="cb3-17">        [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, steps[idx]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>œÄ],</span>
<span id="cb3-18">        [<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sineio</span>()],</span>
<span id="cb3-19">    )</span>
<span id="cb3-20"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-21"></span>
<span id="cb3-22">translate_anim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Animation</span>(</span>
<span id="cb3-23">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># must go from 0 to 1</span></span>
<span id="cb3-24">    [O, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Point</span>(size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>radius_factor, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)],</span>
<span id="cb3-25">    [<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sineio</span>()],</span>
<span id="cb3-26">)</span>
<span id="cb3-27"></span>
<span id="cb3-28">translate_back_anim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Animation</span>(</span>
<span id="cb3-29">    [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># must go from 0 to 1</span></span>
<span id="cb3-30">    [O, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Point</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">-</span>(size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>radius_factor), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)],</span>
<span id="cb3-31">    [<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sineio</span>()],</span>
<span id="cb3-32">)</span>
<span id="cb3-33"></span>
<span id="cb3-34">julia_colours <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Dict</span>(</span>
<span id="cb3-35">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>blue <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#4063D8"</span>,</span>
<span id="cb3-36">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>green <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#389826"</span>,</span>
<span id="cb3-37">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>purple <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#9558b2"</span>,</span>
<span id="cb3-38">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>red <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#CB3C33"</span></span>
<span id="cb3-39">)</span>
<span id="cb3-40">colour_order <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>red, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>purple, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>green, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>blue]</span>
<span id="cb3-41">n_colours <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">length</span>(julia_colours)</span>
<span id="cb3-42"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">color_anim</span>(start_colour<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">String</span>, quarto_col<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">String</span>=<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"#4b95d0"</span>)</span>
<span id="cb3-43">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Animation</span>(</span>
<span id="cb3-44">        [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># must go from 0 to 1</span></span>
<span id="cb3-45">        [<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Lab</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">color</span>(start_colour)), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Lab</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">color</span>(quarto_col))],</span>
<span id="cb3-46">        [<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sineio</span>()],</span>
<span id="cb3-47">    )</span>
<span id="cb3-48"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-49"></span>
<span id="cb3-50">video <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Video</span>(size, size)</span>
<span id="cb3-51"></span>
<span id="cb3-52">frame_starts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span></span>
<span id="cb3-53">n_total <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span></span>
<span id="cb3-54">n_frames <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span></span>
<span id="cb3-55"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Background</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>n_total, ground)</span>
<span id="cb3-56"></span>
<span id="cb3-57"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Blob:</span></span>
<span id="cb3-58"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">element</span>(; radius <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-59">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">circle</span>(O, radius, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>fill) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The 4 is to make the circle not so small</span></span>
<span id="cb3-60"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-61"></span>
<span id="cb3-62"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Cross:</span></span>
<span id="cb3-63"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cross</span>(color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"black"</span>;orientation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>horizontal)</span>
<span id="cb3-64">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sethue</span>(color)</span>
<span id="cb3-65">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">setline</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb3-66">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> orientation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==:</span>horizontal</span>
<span id="cb3-67">        out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">line</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Point</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>size,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>),<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Point</span>(size,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>stroke)</span>
<span id="cb3-68">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span></span>
<span id="cb3-69">        out <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">line</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Point</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>size),<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Point</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,size), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>stroke)</span>
<span id="cb3-70">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-71">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> out</span>
<span id="cb3-72"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-73"></span>
<span id="cb3-74"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> (i, frame_start) <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">enumerate</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>)</span>
<span id="cb3-75"></span>
<span id="cb3-76">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Julia circles:</span></span>
<span id="cb3-77">    blob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Object</span>(frame_start<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>n_total, (args<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>;radius<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">element</span>(;radius<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>radius))</span>
<span id="cb3-78">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">act!</span>(blob, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Action</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Int</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">round</span>(n_frames<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">change</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>radius, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span>))) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># scale up</span></span>
<span id="cb3-79">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">act!</span>(blob, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Action</span>(n_frames<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>(n_frames<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">change</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>radius, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">75</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span>))) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># scale up further</span></span>
<span id="cb3-80">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">act!</span>(blob, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Action</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, translate_anim, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">translate</span>()))</span>
<span id="cb3-81">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">act!</span>(blob, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Action</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">31</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">120</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rotate_anim</span>(i, n_colours), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rotate_around</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Point</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">-</span>(size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>radius_factor), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>))))</span>
<span id="cb3-82">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">act!</span>(blob, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Action</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">121</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span>, translate_back_anim, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">translate</span>()))</span>
<span id="cb3-83">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">act!</span>(blob, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Action</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">150</span>, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">color_anim</span>(julia_colours[colour_order[i]]), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sethue</span>()))</span>
<span id="cb3-84"></span>
<span id="cb3-85">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Quarto cross:</span></span>
<span id="cb3-86">    cross_h <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Object</span>((n_frames<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>n_total, (args<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cross</span>(;orientation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>horizontal))</span>
<span id="cb3-87">    cross_v <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Object</span>((n_frames<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>n_total, (args<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cross</span>(;orientation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>vertical))</span>
<span id="cb3-88"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-89"></span>
<span id="cb3-90"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">render</span>(</span>
<span id="cb3-91">    video;</span>
<span id="cb3-92">    pathname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">joinpath</span>(www_path, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"intro.gif"</span>),</span>
<span id="cb3-93">)</span></code></pre></div>
</section>
<section id="working-with-documenter.jl-and-quarto" class="level4">
<h4 class="anchored" data-anchor-id="working-with-documenter.jl-and-quarto">Working with <code>Documenter.jl</code> and Quarto</h4>
<p>An interesting application of Quarto in the Julia ecosystem is package documentation. This is of course best done using <code>Documenter.jl</code> and fortunately the two play nicely with each other, since both share a common ground (Markdown). Their interaction is perhaps best demonstrated through this Julia library I recently developed: <a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl"><code>CounterfactualExplanatinos.jl</code></a>. On there you will find lot of Julia scripts <code>*.jl</code> under <code>src/</code> and <code>test/</code>, as well as many Markdown <code>.md</code> and Quarto documents <code>.qmd</code> under <code>docs</code>. I <em>wrote</em> the package documentation in the Quarto documents, <em>rendered</em> documents individually through <code>quarto render [doc].qmd</code> and then fed the resulting Markdown documents to <code>Documenter.jl</code> as always.</p>
<p>Below is my standard YAML header for those Quarto documents:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">format</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span></span>
<span id="cb4-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">commonmark</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb4-3"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">variant</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> -raw_html</span></span>
<span id="cb4-4"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">wrap</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> none</span></span>
<span id="cb4-5"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">self-contained</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb4-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">crossref</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb4-7"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fig-prefix</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Figure</span></span>
<span id="cb4-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tbl-prefix</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> Table</span></span>
<span id="cb4-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bibliography</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> https://raw.githubusercontent.com/pat-alt/bib/main/bib.bib</span></span>
<span id="cb4-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">output</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> asis</span></span>
<span id="cb4-11"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">execute</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span></span>
<span id="cb4-12"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">echo</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">true</span></span>
<span id="cb4-13"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">eval</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">false</span></span>
<span id="cb4-14"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">jupyter</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> julia-1.7</span></span></code></pre></div>
<p>You can see that it points to Bibtex file I host on another Github repository. This makes it very easy to generate citations and references for the rendered Markdown documents, that also show up in the docs (e.g.&nbsp;<a href="https://www.paltmeyer.com/CounterfactualExplanations.jl/stable/cats_dogs/">here</a>). Unfortunately, cross-referencing only partially works, because it relies on auto-generated HTML and <code>Documenter.jl</code> expects this to be passed in blocks. Choosing <code>variant: -raw_html</code> is only a workaround as I have discussed <a href="https://github.com/JuliaDocs/Documenter.jl/issues/1778">here</a>. Ideally, <code>Documenter.jl</code> would just accept HTML documents rendered from Quarto, but currently only Markdown documents are accepted by <code>make_docs</code>. Still, if anything this workaround is a nice gimmick that extends the default <code>Documenter.jl</code> functionality, without any hassle involved. Hopefully, this can be improved in the future.</p>
</section>
<section id="using-quarto-for-juliacon-proceedings" class="level4">
<h4 class="anchored" data-anchor-id="using-quarto-for-juliacon-proceedings">Using Quarto for JuliaCon Proceedings</h4>
<p>Another very good use-case for Quarto involves actual scientific publications in journals such as JuliaCon Proceedings. The existing submission process is tailored towards reproducibility and actually involves reviews directly on GitHub, which is fantastic. But currently only submissions in TeX format are accepted, which is not so great. Using Quarto would not only streamline this process further, but also open the JuliaCon Proceedings Journal up to publishing content in different output formats. Quarto docs could be used to still render the traditional PDF. But those same documents could also be used to create interactive versions in HTML. Arguably, the entire journal could probably be built through Quarto.</p>
</section>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping up üéó</h2>
<p>In this post I wanted to demonstrate that Quarto might just be the next revolution in scientific publishing. In particular, I hope I have managed to demonstrate its appeal to the Julia community, which I am proud to be part of now that I have managed to branch out of my old R bubble. Please let me hear your thoughts and comments below!</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {Julia and {Quarto:} A Match Made in Heaven? üå§},
  date = {2022-04-07},
  url = {https://www.paltmeyer.com/blog//blog/posts/julia-and-quarto-a-match-made-in-heaven},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2022. <span>‚ÄúJulia and Quarto: A Match Made in
Heaven? üå§.‚Äù</span> April 7, 2022. <a href="https://www.paltmeyer.com/blog//blog/posts/julia-and-quarto-a-match-made-in-heaven">https://www.paltmeyer.com/blog//blog/posts/julia-and-quarto-a-match-made-in-heaven</a>.
</div></div></section></div> ]]></description>
  <category>scientific publishing</category>
  <category>Quarto</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html</guid>
  <pubDate>Thu, 07 Apr 2022 04:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/julia-and-quarto-a-match-made-in-heaven/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Go deep, but also ‚Ä¶ go Bayesian!</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
A Bayesian Neural Network gradually learns.
</figcaption>
</figure>
</div>
<p>Deep learning has dominated AI research in recent years<sup>1</sup> - but how much promise does it really hold? That is very much an ongoing and increasingly polarising debate that you can follow live on <a href="https://twitter.com/ilyasut/status/1491554478243258368">Twitter</a>. On one side you have optimists like Ilya Sutskever, chief scientist of OpenAI, who believes that large deep neural networks may already be slightly conscious - that‚Äôs ‚Äúmay‚Äù and ‚Äúslightly‚Äù and only if you just go deep enough? On the other side you have prominent skeptics like Judea Pearl who has long since argued that deep learning still boils down to curve fitting - purely associational and not even remotely intelligent <span class="citation" data-cites="pearl2018book">(Pearl and Mackenzie 2018)</span>.</p>
<section id="the-case-for-bayesian-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="the-case-for-bayesian-deep-learning">The case for Bayesian Deep Learning</h2>
<p>Whatever side of this entertaining twitter dispute you find yourself on, the reality is that deep-learning systems have already been deployed at large scale both in academia and industry. More pressing debates therefore revolve around the trustworthiness of these existing systems. How robust are they and in what way exactly do they arrive at decisions that affect each and every one of us? Robustifying deep neural networks generally involves some form of adversarial training, which is costly, can hurt generalization <span class="citation" data-cites="raghunathan2019adversarial">(Raghunathan et al. 2019)</span> and does ultimately not guarantee stability <span class="citation" data-cites="bastounis2021mathematics">(Bastounis, Hansen, and Vlaƒçiƒá 2021)</span>. With respect to interpretability, surrogate explainers like LIME and SHAP are among the most popular tools, but they too have been shown to lack robustness <span class="citation" data-cites="slack2020fooling">(Slack et al. 2020)</span>.</p>
<p>Exactly why are deep neural networks unstable and in-transparent? Let <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D=%5C%7Bx,y%5C%7D_%7Bn=1%7D%5EN"> denote our feature-label pairs and let <img src="https://latex.codecogs.com/png.latex?f(x;%5Ctheta)=y"> denote some deep neural network specified by its parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta">. Then the first thing to note is that the number of free parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is typically huge (if you ask Mr Sutskever it really probably cannot be huge enough!). That alone makes it very hard to monitor and interpret the inner workings of deep-learning algorithms. Perhaps more importantly though, the number of parameters <em>relative</em> to the size of <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> is generally huge:</p>
<blockquote class="blockquote">
<p>[‚Ä¶] deep neural networks are typically very underspecified by the available data, and [‚Ä¶] parameters [therefore] correspond to a diverse variety of compelling explanations for the data. <span class="citation" data-cites="wilson2020case">(Wilson 2020)</span></p>
</blockquote>
<p>In other words, training a single deep neural network may (and usually does) lead to one random parameter specification that fits the underlying data very well. But in all likelihood there are many other specifications that also fit the data very well. This is both a strength and vulnerability of deep learning: it is a strength because it typically allows us to find one such ‚Äúcompelling explanation‚Äù for the data with ease through stochastic optimization; it is a vulnerability because one has to wonder:</p>
<blockquote class="blockquote">
<p>How compelling is an explanation really if it competes with many other equally compelling, but potentially very different explanations?</p>
</blockquote>
<p>A scenario like this very much calls for treating predictions from deep learning models probabilistically [<span class="citation" data-cites="wilson2020case">Wilson (2020)</span>]<sup>2</sup><sup>3</sup>.</p>
<p>Formally, we are interested in estimating the posterior predictive distribution as the following Bayesian model average (BMA):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(y%7Cx,%5Cmathcal%7BD%7D)%20=%20%5Cint%20p(y%7Cx,%5Ctheta)p(%5Ctheta%7C%5Cmathcal%7BD%7D)d%5Ctheta%0A"></p>
<p>The integral implies that we essentially need many predictions from many different specifications of <img src="https://latex.codecogs.com/png.latex?%5Ctheta">. Unfortunately, this means more work for us or rather our computers. Fortunately though, researchers have proposed many ingenious ways to approximate the equation above in recent years: <span class="citation" data-cites="gal2016dropout">Gal and Ghahramani (2016)</span> propose using dropout at test time while <span class="citation" data-cites="lakshminarayanan2016simple">Lakshminarayanan, Pritzel, and Blundell (2016)</span> show that averaging over an ensemble of just five models seems to do the trick. Still, despite their simplicity and usefulness these approaches involve additional computational costs compared to training just a single network. As we shall see now though, another promising approach has recently entered the limelight: <strong>Laplace approximation</strong> (LA).</p>
<p>If you have read my <a href="https://towardsdatascience.com/bayesian-logistic-regression-53df017ba90f">previous post</a> on Bayesian Logistic Regression, then the term Laplace should already sound familiar to you. As a matter of fact, we will see that all concepts covered in that previous post can be naturally extended to deep learning. While some of these concepts will be revisited below, I strongly recommend you check out the previous post before reading on here. Without further ado let us now see how LA can be used for truly effortless deep learning.</p>
</section>
<section id="laplace-approximation" class="level2">
<h2 class="anchored" data-anchor-id="laplace-approximation">Laplace Approximation</h2>
<p>While LA was first proposed in the 18th century, it has so far not attracted serious attention from the deep learning community largely because it involves a possibly large Hessian computation. <span class="citation" data-cites="daxberger2021laplace">Daxberger et al. (2021)</span> are on a mission to change the perception that LA has no use in DL: in their <a href="https://arxiv.org/pdf/2106.14806.pdf">NeurIPS 2021 paper</a> they demonstrate empirically that LA can be used to produce Bayesian model averages that are at least at par with existing approaches in terms of uncertainty quantification and out-of-distribution detection and significantly cheaper to compute. They show that recent advancements in autodifferentation can be leveraged to produce fast and accurate approximations of the Hessian and even provide a fully-fledged <a href="https://aleximmer.github.io/Laplace/">Python library</a> that can be used with any pretrained Torch model. For this post, I have built a much less comprehensive, pure-play equivalent of their package in Julia - <a href="https://www.paltmeyer.com/LaplaceRedux.jl/dev/">LaplaceRedux.jl</a> can be used with deep learning models built in <a href="https://fluxml.ai/">Flux.jl</a>, which is Julia‚Äôs main DL library. As in the previous post on Bayesian logistic regression I will rely on Julia code snippits instead of equations to convey the underlying maths. If you‚Äôre curious about the maths, the <a href="https://arxiv.org/pdf/2106.14806.pdf">NeurIPS 2021 paper</a> provides all the detail you need.</p>
<section id="from-bayesian-logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="from-bayesian-logistic-regression">From Bayesian Logistic Regression ‚Ä¶</h3>
<p>Let‚Äôs recap: in the case of logistic regression we had a assumed a zero-mean Gaussian prior <img src="https://latex.codecogs.com/png.latex?p(%5Cmathbf%7Bw%7D)%20%5Csim%20%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7B0%7D,%20%5Csigma_0%5E2%20%5Cmathbf%7BI%7D%20%5Cright)=%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7B0%7D,%20%5Cmathbf%7BH%7D_0%5E%7B-1%7D%20%5Cright)"> for the weights that are used to compute logits <img src="https://latex.codecogs.com/png.latex?%5Cmu_n=%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_n">, which in turn are fed to a sigmoid function to produce probabilities <img src="https://latex.codecogs.com/png.latex?p(y_n=1)=%5Csigma(%5Cmu_n)">. We saw that under this assumption solving the logistic regression problem corresponds to minimizing the following differentiable loss function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cell(%5Cmathbf%7Bw%7D)=%20-%20%5Csum_%7Bn%7D%5EN%20%5By_n%20%5Clog%20%5Cmu_n%20+%20(1-y_n)%5Clog%20(1-%5Cmu_n)%5D%20+%20%5C%5C%20%5Cfrac%7B1%7D%7B2%7D%20(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%5ET%5Cmathbf%7BH%7D_0(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%0A"></p>
<p>As our first step towards Bayesian deep learning, we observe the following: the loss function above corresponds to the objective faced by a single-layer artificial neural network with sigmoid activation and weight decay<sup>4</sup>. In other words, regularized logistic regression is equivalent to a very simple neural network architecture and hence it is not surprising that underlying concepts can in theory be applied in much the same way.</p>
<p>So let‚Äôs quickly recap the next core concept: LA relies on the fact that the second-order Taylor expansion of our loss function <img src="https://latex.codecogs.com/png.latex?%5Cell"> evaluated at the <strong>maximum a posteriori</strong> (MAP) estimate <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5Chat%7Bw%7D%7D=%5Carg%5Cmax_%7B%5Cmathbf%7Bw%7D%7D%20p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> amounts to a multi-variate Gaussian distribution. In particular, that Gaussian is centered around the MAP estimate with covariance equal to the inverse Hessian evaluated at the mode <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5CSigma%7D=(%5Cmathbf%7BH%7D(%5Cmathbf%7B%5Chat%7Bw%7D%7D))%5E%7B-1%7D"> <span class="citation" data-cites="murphy2022probabilistic">(Murphy 2022)</span>.</p>
<p>That is basically all there is to the story: if we have a good estimate of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BH%7D(%5Cmathbf%7B%5Chat%7Bw%7D%7D)"> we have an analytical expression for an (approximate) posterior over parameters. So let‚Äôs go ahead and start by run Bayesian Logistic regression using <a href="https://fluxml.ai/">Flux.jl</a>. We begin by loading some required packages including <a href="https://www.paltmeyer.com/LaplaceRedux.jl/dev/">LaplaceRedux.jl</a>. It ships with a helper function <code>toy_data_linear</code> that creates a toy data set composed of linearly separable samples evenly balanced across the two classes.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Import libraries.</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Flux</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Plots</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Random</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">PlotThemes</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Statistics</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">LaplaceRedux</span></span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>wong)</span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of points to generate.</span></span>
<span id="cb1-5">xs, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toy_data_linear</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb1-6">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">hcat</span>(xs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>); <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># bring into tabular format</span></span>
<span id="cb1-7">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">zip</span>(xs,y);</span></code></pre></div>
</div>
<p>Then we proceed to prepare the single-layer neural network with weight decay. The term <img src="https://latex.codecogs.com/png.latex?%5Clambda"> determines the strength of the <img src="https://latex.codecogs.com/png.latex?%5Cell2"> penalty: we regularize parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> more heavily for higher values. Equivalently, we can say that from the Bayesian perspective it governs the strength of the prior <img src="https://latex.codecogs.com/png.latex?p(%5Ctheta)%20%5Csim%20%5Cmathcal%7BN%7D%20%5Cleft(%20%5Ctheta%20%7C%20%5Cmathbf%7B0%7D,%20%5Csigma_0%5E2%20%5Cmathbf%7BI%7D%20%5Cright)=%20%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7B0%7D,%20%5Clambda_0%5E%7B-2%7D%20%5Cmathbf%7BI%7D%20%5Cright)">: a higher value of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> indicates a higher conviction about our prior belief that <img src="https://latex.codecogs.com/png.latex?%5Ctheta=%5Cmathbf%7B0%7D">, which is of course equivalent to regularizing more heavily. The exact choice of <img src="https://latex.codecogs.com/png.latex?%5Clambda=0.5"> for this toy example is somewhat arbitrary (it made for good visualizations below). Note that I have used <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> to denote our neural parameters to distinguish the case from Bayesian logistic regression, but we are in fact still solving the same problem.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb2-1">nn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Chain</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Dense</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb2-2">Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span></span>
<span id="cb2-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqnorm</span>(x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(abs2, x)</span>
<span id="cb2-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">weight_regularization</span>(Œª<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Œª) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> Œª<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(sqnorm, Flux.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">params</span>(nn))</span>
<span id="cb2-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">loss</span>(x, y) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Flux.Losses.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">logitbinarycrossentropy</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nn</span>(x), y) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">weight_regularization</span>();</span></code></pre></div>
</div>
<p>Before we apply Laplace approximation we train our model:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">using</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Flux.Optimise</span>: update!, ADAM</span>
<span id="cb3-2">opt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ADAM</span>()</span>
<span id="cb3-3">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>epochs</span>
<span id="cb3-6">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> data</span>
<span id="cb3-7">    gs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">gradient</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">params</span>(nn)) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">do</span></span>
<span id="cb3-8">      l <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">loss</span>(d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>)</span>
<span id="cb3-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-10">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">update!</span>(opt, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">params</span>(nn), gs)</span>
<span id="cb3-11">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb3-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
</div>
<p>Up until this point we have just followed the standard recipe for training a regularized artificial neural network in <a href="https://fluxml.ai/">Flux.jl</a> for a simple binary classification task. To compute the Laplace approximation using <a href="https://www.paltmeyer.com/LaplaceRedux.jl/dev/">LaplaceRedux.jl</a> we need just two more lines of code:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb4-1">la <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">laplace</span>(nn, Œª<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Œª)</span>
<span id="cb4-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(la, data);</span></code></pre></div>
</div>
<p>Under the hood the Hessian is approximated through the <strong>empirical Fisher</strong>, which can be computed using only the gradients of our loss function <img src="https://latex.codecogs.com/png.latex?%5Cnabla_%7B%5Ctheta%7D%5Cell(f(%5Cmathbf%7Bx%7D_n;%5Ctheta,y_n))"> where <img src="https://latex.codecogs.com/png.latex?%5C%7B%5Cmathbf%7Bx%7D_n,y_n%5C%7D"> are training data (see <a href="https://arxiv.org/pdf/2106.14806.pdf">NeurIPS 2021 paper</a> for details). Finally, <a href="https://www.paltmeyer.com/LaplaceRedux.jl/dev/">LaplaceRedux.jl</a> ships with a function <code>predict(ùë≥::LaplaceRedux, X::AbstractArray; link_approx=:probit)</code> that computes the posterior predictive using a probit approximation, much like we saw in the previous post. That function is used under the hood of the <code>plot_contour</code> function below to create the right panel of Figure&nbsp;1. It visualizes the posterior predictive distribution in the 2D feature space. For comparison I have added the corresponding plugin estimate as well. Note how for the Laplace approximation the predicted probabilities fan out indicating that confidence decreases in regions scarce of data.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb5-1">p_plugin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Plugin"</span>,<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>plugin);</span>
<span id="cb5-2">p_laplace <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Laplace"</span>)</span>
<span id="cb5-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the posterior distribution with a contour plot.</span></span>
<span id="cb5-4">plt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(p_plugin, p_laplace, layout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>))</span>
<span id="cb5-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">savefig</span>(plt, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"www/posterior_predictive_logit.png"</span>);</span></code></pre></div>
</div>
<div id="fig-logit" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/posterior_predictive_logit.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Posterior predictive distribution of Logistic regression in the 2D feature space using plugin estimator (left) and Laplace approximation (right).</figcaption>
</figure>
</div>
</section>
<section id="to-bayesian-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="to-bayesian-neural-networks">‚Ä¶ to Bayesian Neural Networks</h3>
<p>Now let‚Äôs step it up a notch: we will repeat the exercise from above, but this time for data that is not linearly separable using a simple MLP instead of the single-layer neural network we used above. The code below is almost the same as above, so I will not go through the various steps again.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Number of points to generate:</span></span>
<span id="cb6-2">xs, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toy_data_non_linear</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>)</span>
<span id="cb6-3">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">hcat</span>(xs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>); <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># bring into tabular format</span></span>
<span id="cb6-4">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">zip</span>(xs,y)</span>
<span id="cb6-5"></span>
<span id="cb6-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Build MLP:</span></span>
<span id="cb6-7">n_hidden <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb6-8">D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">size</span>(X)[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb6-9">nn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Chain</span>(</span>
<span id="cb6-10">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Dense</span>(D, n_hidden, œÉ),</span>
<span id="cb6-11">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Dense</span>(n_hidden, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb6-12">)  </span>
<span id="cb6-13">Œª <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span></span>
<span id="cb6-14"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sqnorm</span>(x) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(abs2, x)</span>
<span id="cb6-15"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">weight_regularization</span>(Œª<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Œª) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> Œª<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(sqnorm, Flux.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">params</span>(nn))</span>
<span id="cb6-16"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">loss</span>(x, y) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Flux.Losses.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">logitbinarycrossentropy</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nn</span>(x), y) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">weight_regularization</span>()</span>
<span id="cb6-17"></span>
<span id="cb6-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Training:</span></span>
<span id="cb6-19">epochs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span></span>
<span id="cb6-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> epoch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>epochs</span>
<span id="cb6-21">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> d <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> data</span>
<span id="cb6-22">    gs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">gradient</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">params</span>(nn)) <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">do</span></span>
<span id="cb6-23">      l <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">loss</span>(d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">...</span>)</span>
<span id="cb6-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb6-25">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">update!</span>(opt, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">params</span>(nn), gs)</span>
<span id="cb6-26">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span>
<span id="cb6-27"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">end</span></span></code></pre></div>
</div>
<p>Fitting the Laplace approximation is also analogous, but note that this we have added an argument: <code>subset_of_weights=:last_layer</code>. This specifies that we only want to use the parameters of the last layer of our MLP. While we could have used all of them (<code>subset_of_weights=:all</code>), <span class="citation" data-cites="daxberger2021laplace">Daxberger et al. (2021)</span> find that the last-layer Laplace approximation produces satisfying results, while be computationally cheaper. Figure&nbsp;2 demonstrates that once again the Laplace approximation yields a posterior predictive distribution that is more conservative than the over-confident plugin estimate.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1">la <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">laplace</span>(nn, Œª<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Œª, subset_of_weights<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>last_layer)</span>
<span id="cb7-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">fit!</span>(la, data);</span>
<span id="cb7-3">p_plugin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Plugin"</span>,<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>plugin)</span>
<span id="cb7-4">p_laplace <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Laplace"</span>)</span>
<span id="cb7-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the posterior distribution with a contour plot.</span></span>
<span id="cb7-6">plt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(p_plugin, p_laplace, layout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>))</span>
<span id="cb7-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">savefig</span>(plt, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"www/posterior_predictive_mlp.png"</span>);</span></code></pre></div>
</div>
<div id="fig-mlp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/posterior_predictive_mlp.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Posterior predictive distribution of MLP in the 2D feature space using plugin estimator (left) and Laplace approximation (right).</figcaption>
</figure>
</div>
<p>To see why this is a desirable outcome consider the zoomed out version of Figure&nbsp;2 below: the plugin estimator classifies with full confidence in regions completely scarce of any data. Arguably Laplace approximation produces a much more reasonable picture, even though it too could likely be improved by fine-tuning our choice of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> and the neural network architecture.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb8-1">zoom<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb8-2">p_plugin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Plugin"</span>,<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=:</span>plugin,zoom<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>zoom);</span>
<span id="cb8-3">p_laplace <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot_contour</span>(X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">'</span>,y,la;title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Laplace"</span>,zoom<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>zoom);</span>
<span id="cb8-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Plot the posterior distribution with a contour plot.</span></span>
<span id="cb8-5">plt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(p_plugin, p_laplace, layout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>));</span>
<span id="cb8-6"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">savefig</span>(plt, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"www/posterior_predictive_mlp_zoom.png"</span>);</span></code></pre></div>
</div>
<div id="fig-mlp-zoom" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/posterior_predictive_mlp_zoom.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Posterior predictive distribution of MLP in the 2D feature space using plugin estimator (left) and Laplace approximation (right). Zoomed out.</figcaption>
</figure>
</div>
</section>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping up</h2>
<p>Recent state-of-the-art research on neural information processing suggests that Bayesian deep learning can be effortless: Laplace approximation for deep neural networks appears to work very well and it does so at minimal computational cost <span class="citation" data-cites="daxberger2021laplace">(Daxberger et al. 2021)</span>. This is great news, because the case for turning Bayesian is strong: society increasingly relies on complex automated decision-making systems that need to be trustworthy. More and more of these systems involve deep learning which in and of itself is not trustworthy. We have seen that typically there exist various viable parameterizations of deep neural networks each with their own distinct and compelling explanation for the data at hand. When faced with many viable options, don‚Äôt put all of your eggs in one basket. In other words, go Bayesian!</p>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<p>To get started with Bayesian deep learning I have found many useful and free resources online, some of which are listed below:</p>
<ul>
<li><a href="https://turing.ml/dev/tutorials/03-bayesian-neural-network/"><code>Turing.jl</code> tutorial</a> on Bayesian deep learning in Julia.</li>
<li>Various RStudio AI blog posts including <a href="https://blogs.rstudio.com/ai/posts/2018-11-12-uncertainty_estimates_dropout/">this one</a> and <a href="https://blogs.rstudio.com/ai/posts/2019-06-05-uncertainty-estimates-tfprobability/">this one</a>.</li>
<li><a href="https://medium.com/tensorflow/regression-with-probabilistic-layers-in-tensorflow-probability-e46ff5d37baf">TensorFlow blog post</a> on regression with probabilistic layers.</li>
<li>Kevin Murphy‚Äôs <a href="https://probml.github.io/pml-book/book1.html">draft text book</a>, now also available as print.</li>
</ul>
</section>
<section id="references" class="level2">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bastounis2021mathematics" class="csl-entry">
Bastounis, Alexander, Anders C Hansen, and Verner Vlaƒçiƒá. 2021. <span>‚ÄúThe Mathematics of Adversarial Attacks in <span>AI</span>‚Äì<span>Why</span> Deep Learning Is Unstable Despite the Existence of Stable Neural Networks.‚Äù</span> <a href="https://arxiv.org/abs/2109.06098">https://arxiv.org/abs/2109.06098</a>.
</div>
<div id="ref-daxberger2021laplace" class="csl-entry">
Daxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. <span>‚ÄúLaplace <span>Redux-Effortless Bayesian Deep Learning</span>.‚Äù</span> <em>Advances in Neural Information Processing Systems</em> 34.
</div>
<div id="ref-gal2016dropout" class="csl-entry">
Gal, Yarin, and Zoubin Ghahramani. 2016. <span>‚ÄúDropout as a Bayesian Approximation: <span>Representing</span> Model Uncertainty in Deep Learning.‚Äù</span> In <em>International Conference on Machine Learning</em>, 1050‚Äì59. <span>PMLR</span>.
</div>
<div id="ref-lakshminarayanan2016simple" class="csl-entry">
Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2016. <span>‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù</span> <a href="https://arxiv.org/abs/1612.01474">https://arxiv.org/abs/1612.01474</a>.
</div>
<div id="ref-murphy2022probabilistic" class="csl-entry">
Murphy, Kevin P. 2022. <em>Probabilistic <span>Machine Learning</span>: <span>An</span> Introduction</em>. <span>MIT Press</span>.
</div>
<div id="ref-pearl2018book" class="csl-entry">
Pearl, Judea, and Dana Mackenzie. 2018. <em>The Book of Why: The New Science of Cause and Effect</em>. <span>Basic books</span>.
</div>
<div id="ref-raghunathan2019adversarial" class="csl-entry">
Raghunathan, Aditi, Sang Michael Xie, Fanny Yang, John C Duchi, and Percy Liang. 2019. <span>‚ÄúAdversarial Training Can Hurt Generalization.‚Äù</span> <a href="https://arxiv.org/abs/1906.06032">https://arxiv.org/abs/1906.06032</a>.
</div>
<div id="ref-slack2020fooling" class="csl-entry">
Slack, Dylan, Sophie Hilgard, Emily Jia, Sameer Singh, and Himabindu Lakkaraju. 2020. <span>‚ÄúFooling Lime and Shap: <span>Adversarial</span> Attacks on Post Hoc Explanation Methods.‚Äù</span> In <em>Proceedings of the <span>AAAI</span>/<span>ACM Conference</span> on <span>AI</span>, <span>Ethics</span>, and <span>Society</span></em>, 180‚Äì86.
</div>
<div id="ref-wilson2020case" class="csl-entry">
Wilson, Andrew Gordon. 2020. <span>‚ÄúThe Case for <span>Bayesian</span> Deep Learning.‚Äù</span> <a href="https://arxiv.org/abs/2001.10995">https://arxiv.org/abs/2001.10995</a>.
</div>
</div></section><aside id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See for example <a href="https://www.technologyreview.com/2019/01/25/1436/we-analyzed-16625-papers-to-figure-out-where-ai-is-headed-next/">this article</a> in the MIT Technology Review‚Ü©Ô∏é</p></li>
<li id="fn2"><p>In fact, not treating probabilistic deep learning models as such is sheer madness because remember that the underlying parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> are random variables. Frequentists and Bayesians alike will tell you that relying on a single point estimate of random variables is just nuts!‚Ü©Ô∏é</p></li>
<li id="fn3"><p>Proponents of Causal AI like Judea Pearl would argue that the Bayesian treatment still does not go far enough: in their view model explanations can only be truly compelling if they are causally found.‚Ü©Ô∏é</p></li>
<li id="fn4"><p>See this <a href="https://stats.stackexchange.com/a/500973/288736">answer</a> on Stack Exchange for a detailed discussion.‚Ü©Ô∏é</p></li>
</ol>
</aside><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {Go Deep, but Also ... Go {Bayesian!}},
  date = {2022-02-18},
  url = {https://www.paltmeyer.com/blog//blog/posts/effortsless-bayesian-dl},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2022. <span>‚ÄúGo Deep, but Also ... Go
Bayesian!‚Äù</span> February 18, 2022. <a href="https://www.paltmeyer.com/blog//blog/posts/effortsless-bayesian-dl">https://www.paltmeyer.com/blog//blog/posts/effortsless-bayesian-dl</a>.
</div></div></section></div> ]]></description>
  <category>bayes</category>
  <category>deep learning</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/index.html</guid>
  <pubDate>Fri, 18 Feb 2022 05:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/effortsless-bayesian-dl/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Bayesian Logistic Regression</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/index.html</link>
  <description><![CDATA[ 



<section id="uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="uncertainty">Uncertainty</h2>
<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/www/intro.gif" class="figure-img">
<figcaption class="figure-caption">
Simulation of changing parameter distribution.
</figcaption>
</figure>
</div>
<p>If you‚Äôve ever searched for evaluation metrics to assess model accuracy, chances are that you found many different options to choose from (too many?). Accuracy is in some sense the holy grail of prediction so it‚Äôs not at all surprising that the machine learning community spends a lot time thinking about it. In a world where more and more high-stake decisions are being automated, model accuracy is in fact a very valid concern.</p>
<p>But does this recipe for model evaluation seem like a sound and complete approach to automated decision-making? Haven‚Äôt we forgot anything? Some would argue that we need to pay more attention to <strong>model uncertainty</strong>. No matter how many times you have cross-validated your model, the loss metric that it is being optimized against as well as its parameters and predictions remain inherently random variables. Focusing merely on prediction accuracy and ignoring uncertainty altogether can install a false level of confidence in automated decision-making systems. Any <strong>trustworthy</strong> approach to learning from data should therefore at the very least be transparent about its own uncertainty.</p>
<p>How can we estimate uncertainty around model parameters and predictions? <strong>Frequentist</strong> methods for uncertainty quantification generally involve either closed-form solutions based on asymptotic theory or bootstrapping (see for example <a href="https://web.stanford.edu/class/archive/stats/stats200/stats200.1172/Lecture26.pdf">here</a> for the case of logistic regression). In Bayesian statistics and machine learning we are instead concerned with modelling the <strong>posterior distribution</strong> over model parameters. This approach to uncertainty quantification is known as <strong>Bayesian Inference</strong> because we treat model parameters in a Bayesian way: we make assumptions about their distribution based on <strong>prior</strong> knowledge or beliefs and update these beliefs in light of new evidence. The frequentist approach avoids the need for being explicit about prior beliefs, which in the past has sometimes been considered as <em>un</em>scientific. However, frequentist methods come with their own assumptions and pitfalls (see for example <span class="citation" data-cites="murphy2012machine">Murphy (2012)</span>) for a discussion). Without diving further into this argument, let us now see how <strong>Bayesian Logistic Regression</strong> can be implemented from the bottom up.</p>
</section>
<section id="the-ground-truth" class="level2">
<h2 class="anchored" data-anchor-id="the-ground-truth">The ground truth</h2>
<p>In this post we will work with a synthetic toy data set <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> composed of <img src="https://latex.codecogs.com/png.latex?N"> binary labels <img src="https://latex.codecogs.com/png.latex?y_n%5Cin%5C%7B0,1%5C%7D"> and corresponding feature vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_n%5Cin%20%5Cmathbb%7BR%7D%5ED">. Working with synthetic data has the benefit that we have control over the <strong>ground truth</strong> that generates our data. In particular, we will assume that the binary labels <img src="https://latex.codecogs.com/png.latex?y_n"> are generated by a logistic regression model</p>
<p><span id="eq-logreg"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(y_n%7C%5Cmathbf%7Bx%7D_n;%5Cmathbf%7Bw%7D)&amp;%5Csim%5Ctext%7BBer%7D(y_n%7C%5Csigma(%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_n))%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B1%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Csigma(a)=1/(1+e%5E%7B-a%7D)"> is the <strong>sigmoid</strong> or <strong>logit</strong> function <span class="citation" data-cites="murphy2022probabilistic">(Murphy 2022)</span>.<sup>1</sup> Features are generated from a mixed Gaussian model.</p>
<p>To add a little bit of life to our example we will assume that the binary labels classify samples into cats and dogs, based on their height and tail length. Figure&nbsp;1 shows the synthetic data in the two-dimensional feature domain. Following an introduction to Bayesian Logistic Regression in the next section we will use the synthetic data <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> to estimate our model.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-ground" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/index_files/figure-html/fig-ground-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Ground truth labels.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="the-maths" class="level2">
<h2 class="anchored" data-anchor-id="the-maths">The maths</h2>
<p>Estimation usually boils down to finding the vector of parameters <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bw%7D%7D"> that maximizes the likelihood of observing <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> under the assumed model. That estimate can then be used to compute predictions for some new unlabelled data set <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D=%5C%7Bx_m:m=1,...,M%5C%7D">.</p>
<section id="problem-setup" class="level3">
<h3 class="anchored" data-anchor-id="problem-setup">Problem setup</h3>
<p>The starting point for Bayesian Logistic Regression is <strong>Bayes‚Äô Theorem</strong>:</p>
<p><span id="eq-posterior"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)&amp;%5Cpropto%20p(%5Cmathcal%7BD%7D%7C%5Cmathbf%7Bw%7D)p(%5Cmathbf%7Bw%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B2%7D"></span></p>
<p>Formally, this says that the posterior distribution of parameters <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> is proportional to the product of the likelihood of observing <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> given <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> and the prior density of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D">. Applied to our context this can intuitively be understood as follows: our posterior beliefs around <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> are formed by both our prior beliefs and the evidence we observe. Yet another way to look at this is that maximising Equation&nbsp;2 with respect to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> corresponds to maximum likelihood estimation regularized by prior beliefs (we will come back to this).</p>
<p>Under the assumption that individual label-feature pairs are <strong>independently</strong> and <strong>identically</strong> distributed, their joint likelihood is simply the product over their individual densities. The prior beliefs around <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> are at our discretion. In practice they may be derived from previous experiments. Here we will use a zero-mean spherical Gaussian prior for reasons explained further below. To sum this up we have</p>
<p><span id="eq-prior"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(%5Cmathcal%7BD%7D%7C%5Cmathbf%7Bw%7D)&amp;%20%5Csim%20%5Cprod_%7Bn=1%7D%5EN%20p(y_n%7C%5Cmathbf%7Bx%7D_n;%5Cmathbf%7Bw%7D)%5C%5C%0A&amp;&amp;%20p(%5Cmathbf%7Bw%7D)&amp;%20%5Csim%20%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7Bw%7D_0,%20%5CSigma_0%20%5Cright)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B3%7D"></span></p>
<p>with <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_0=%5Cmathbf%7B0%7D"> and <img src="https://latex.codecogs.com/png.latex?%5CSigma_0=%5Csigma%5E2%5Cmathbf%7BI%7D">. Plugging this into Bayes‚Äô rule we finally have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)&amp;%5Cpropto%5Cprod_%7Bn=1%7D%5EN%20%5Ctext%7BBer%7D(y_n%7C%5Csigma(%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_n))%5Cmathcal%7BN%7D%20%5Cleft(%20%5Cmathbf%7Bw%7D%20%7C%20%5Cmathbf%7Bw%7D_0,%20%5CSigma_0%20%5Cright)%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>Unlike with linear regression there are no closed-form analytical solutions to estimating or maximising this posterior, but fortunately accurate approximations do exist <span class="citation" data-cites="murphy2022probabilistic">(Murphy 2022)</span>. One of the simplest approaches called <strong>Laplace Approximation</strong> is straight-forward to implement and computationally very efficient. It relies on the observation that under the assumption of a Gaussian prior, the posterior of logistic regression is also approximately Gaussian: in particular, this Gaussian distribution is centered around the <strong>maximum a posteriori</strong> (MAP) estimate <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bw%7D%7D=%5Carg%5Cmax_%7B%5Cmathbf%7Bw%7D%7D%20p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> with a covariance matrix equal to the inverse Hessian evaluated at the mode <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5CSigma%7D=(%5Cmathbf%7BH%7D(%5Chat%7B%5Cmathbf%7Bw%7D%7D))%5E%7B-1%7D">. With that in mind, finding <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bw%7D%7D"> seems like a natural next step.</p>
</section>
<section id="solving-the-problem" class="level3">
<h3 class="anchored" data-anchor-id="solving-the-problem">Solving the problem</h3>
<p>In practice we do not maximize the posterior <img src="https://latex.codecogs.com/png.latex?p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> directly. Instead we minimize the negative log likelihood, which is an equivalent optimization problem and easier to implement. In Equation&nbsp;4 below I have denoted the negative log likelihood as <img src="https://latex.codecogs.com/png.latex?%5Cell(%5Cmathbf%7Bw%7D)"> indicating that this is the <strong>loss function</strong> we aim to minimize. The following two lines in Equation&nbsp;4 show the gradient and Hessian - so the first- and second-order derivatives of <img src="https://latex.codecogs.com/png.latex?%5Cell"> with respect to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> - where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BH%7D_0=%5CSigma_0%5E%7B-1%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmu_n=%5Csigma(%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_n)">. To understand how exactly the gradient and Hessian are derived see for example chapter 10 in <span class="citation" data-cites="murphy2022probabilistic">Murphy (2022)</span>.<sup>2</sup>.</p>
<p><span id="eq-likeli"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cell(%5Cmathbf%7Bw%7D)&amp;=-%20%5Csum_%7Bn=1%7D%5E%7BN%7D%20%5By_n%20%5Clog%20%5Cmu_n%20+%20(1-y_n)%5Clog%20(1-%5Cmu_n)%5D%20+%20%5Cfrac%7B1%7D%7B2%7D%20(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%5ET%5Cmathbf%7BH%7D_0(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%20%5C%5C%0A&amp;&amp;%20%5Cnabla_%7B%5Cmathbf%7Bw%7D%7D%5Cell(%5Cmathbf%7Bw%7D)&amp;=%20%5Csum_%7Bn=1%7D%5E%7BN%7D%20(%5Cmu_n-y_n)%20%5Cmathbf%7Bx%7D_n%20+%20%5Cmathbf%7BH%7D_0(%5Cmathbf%7Bw%7D-%5Cmathbf%7Bw%7D_0)%20%5C%5C%0A&amp;&amp;%20%5Cnabla%5E2_%7B%5Cmathbf%7Bw%7D%7D%5Cell(%5Cmathbf%7Bw%7D)&amp;=%20%5Csum_%7Bn=1%7D%5E%7BN%7D%20(%5Cmu_n-y_n)%20%5Cleft(%20%5Cmu_n(1-%5Cmu_n)%20%5Cmathbf%7Bx%7D_n%20%5Cmathbf%7Bx%7D_n%5ET%20%5Cright)%20+%20%5Cmathbf%7BH%7D_0%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B4%7D"></span></p>
<div class="sidenote">
<p><strong>SIDENOTE</strong> üí°</p>
<p>Note how earlier I mentioned that maximising the posterior likelihood can be seen as regularized maximum likelihood estimation. We can now make that connection explicit: in Equation&nbsp;4 let us assume that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_0=%5Cmathbf%7B0%7D">. Then since <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BH%7D_0=%5Clambda%5Cmathbf%7BI%7D"> with <img src="https://latex.codecogs.com/png.latex?1/%5Csigma%5E2"> the second term in the first line is simply <img src="https://latex.codecogs.com/png.latex?%5Clambda%20%5Cfrac%7B1%7D%7B2%7D%20%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bw%7D=%5Clambda%20%5Cfrac%7B1%7D%7B2%7D%20%7C%7C%5Cmathbf%7Bw%7D%7C%7C_2%5E2">. This is equivalent to running logistic regression with an <img src="https://latex.codecogs.com/png.latex?%5Cell_2">-penalty <span class="citation" data-cites="bishop2006pattern">(Bishop 2006)</span>.</p>
</div>
<p><br></p>
<p>Since minimizing the loss function in Equation&nbsp;4 is a convex optimization problem we have many efficient algorithms to choose from in order to solve this problem. With the Hessian at hand it seems natural to use a second-order method, because incorporating information about the curvature of the loss function generally leads to faster convergence. Here we will implement <strong>Newton‚Äôs method</strong> in line with the presentation in chapter 8 of <span class="citation" data-cites="murphy2022probabilistic">Murphy (2022)</span>.</p>
</section>
<section id="posterior-predictive" class="level3">
<h3 class="anchored" data-anchor-id="posterior-predictive">Posterior predictive</h3>
<p>Suppose now that we have trained the Bayesian Logistic Regression model as our binary classifier <img src="https://latex.codecogs.com/png.latex?g_N(%5Cmathbf%7Bx%7D)"> using our training data <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D">. A new unlabelled sample <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%7Bx%7D_%7BN+1%7D,?)"> arrives. As with any binary classifier we can predict the missing label by simply plugging the new sample into our classifier <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_%7BN+1%7D=g_N(%5Cmathbf%7Bx%7D_%7BN+1%7D)=%5Csigma(%5Chat%7B%5Cmathbf%7Bw%7D%7D%5ET%5Cmathbf%7Bx%7D_%7BN+1%7D)">, where <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bw%7D%7D"> is the MAP estimate as before. If at training phase we have found <img src="https://latex.codecogs.com/png.latex?g_N(%5Cmathbf%7Bx%7D)"> to achieve good accuracy, we may expect <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%7Bx%7D_%7BN+1%7D,%5Chat%7By%7D_%7BN+1%7D)"> to be a reasonably good approximation of the true and unobserved pair <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%7Bx%7D_%7BN+1%7D,y_%7BN+1%7D)">. But since we are still dealing with an expected value of a random variable, we would generally like to have an idea of how noisy this prediction is.</p>
<p>Formally, we are interested in the <strong>posterior predictive</strong> distribution:</p>
<p><span id="eq-posterior-pred"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Cmathcal%7BD%7D)&amp;=%20%5Cint%20%5Csigma(%5Cmathbf%7Bw%7D%5ET%20%5Cmathbf%7Bx%7D)p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)d%5Cmathbf%7Bw%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B5%7D"></span></p>
<div class="sidenote">
<p><strong>SIDENOTE</strong> üí°</p>
<p>The approach that ignores uncertainty altogether corresponds to what is referred to as <strong>plugin</strong> approximation of the posterior predictive. Formally, it imposes <img src="https://latex.codecogs.com/png.latex?p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Cmathcal%7BD%7D)%5Capprox%20p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Chat%7B%5Cmathbf%7Bw%7D%7D)">.</p>
</div>
<p><br></p>
<p>With the posterior distribution over model parameters <img src="https://latex.codecogs.com/png.latex?p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> at hand we have the necessary ingredients to estimate the posterior predictive distribution <img src="https://latex.codecogs.com/png.latex?p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Cmathcal%7BD%7D)">.</p>
<p>An obvious, but computationally expensive way to estimate it is through Monte Carlo: draw <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D_s"> from <img src="https://latex.codecogs.com/png.latex?p(%5Cmathbf%7Bw%7D%7C%5Cmathcal%7BD%7D)"> for <img src="https://latex.codecogs.com/png.latex?s=1:S"> and compute fitted values <img src="https://latex.codecogs.com/png.latex?%5Csigma(%5Cmathbf%7Bw_s%7D%5ET%5Cmathbf%7Bx%7D)"> each. Then the posterior predictive distribution corresponds to the average over all fitted values, <img src="https://latex.codecogs.com/png.latex?p(y=1%7C%5Cmathbf%7Bx%7D,%20%5Cmathcal%7BD%7D)=1/S%20%5Csum_%7Bs=1%7D%5E%7BS%7D%5Csigma(%5Cmathbf%7Bw_s%7D%5ET%5Cmathbf%7Bx%7D)">. By the law of large numbers the Monte Carlo estimate is an accurate estimate of the true posterior predictive for large enough <img src="https://latex.codecogs.com/png.latex?S">. Of course, ‚Äúlarge enough‚Äù is somewhat loosely defined here and depending on the problem can mean ‚Äúvery large‚Äù. Consequently, the computational costs involved essentially know no upper bound.</p>
<p>Fortunately, it turns out that we can trade off a little bit of accuracy in return for a convenient analytical solution. In particular, we have that <img src="https://latex.codecogs.com/png.latex?%5Csigma(a)%20%5Capprox%20%5CPhi(%5Clambda%20a)"> where <img src="https://latex.codecogs.com/png.latex?%5CPhi(.)"> is the standard Gaussian cdf and <img src="https://latex.codecogs.com/png.latex?%5Clambda=%5Cpi/8"> ensures that the two functions have the same slope at the origin (Figure&nbsp;2). Without dwelling further on the details we can use this finding to approximate the integral in Equation&nbsp;5 as a sigmoid function. This is called <strong>probit approximation</strong> and implemented below.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-probit" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/index_files/figure-html/fig-probit-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Demonstration of the probit approximation.</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="the-code" class="level2">
<h2 class="anchored" data-anchor-id="the-code">The code</h2>
<p>We now have all the necessary ingredients to code Bayesian Logistic Regression up from scratch. While in practice we would usually want to rely on existing packages that have been properly tested, I often find it very educative and rewarding to program algorithms from the bottom up. You will see that Julia‚Äôs syntax so closely resembles the mathematical formulas we have seen above, that going from maths to code is incredibly easy. Seeing those formulas and algorithms then actually doing their magic is quite fun! The code chunk below, for example, shows the implementation of the loss function and its derivatives from Equation&nbsp;4 above. Take a moment to go through the code line-by-line and try to understand how it relates back to the equations in Equation&nbsp;4. Isn‚Äôt it amazing how closely the code resembles the actual equations?</p>
<script src="https://gist.github.com/pat-alt/cc53a11470e4fb736f24bb6de2393f54.js"></script>
<p>Aside from the optimization routine this is essentially all there is to coding up Bayesian Logistic Regression from scratch in Julia Language. If you are curious to see the full source code in detail you can check out this <a href="https://colab.research.google.com/github/pat-alt/pat-alt.github.io/blob/main/content/post/2021-11-15-bayesian-logistic-regression/julia_implementation.ipynb">interactive notebook</a>. Now let us finally turn back to our synthetic data and see how Bayesian Logistic Regression can help us understand the uncertainty around our model predictions.</p>
<div class="disclaimer">
<p><strong>DISCLAIMER</strong> ‚ùóÔ∏è</p>
<p>I should mention that this is the first time I program in Julia, so for any Julia pros out there: please bear with me! Happy to hear your suggestions/comments.</p>
</div>
<p><br></p>
</section>
<section id="the-estimates" class="level2">
<h2 class="anchored" data-anchor-id="the-estimates">The estimates</h2>
<p>Figure&nbsp;3 below shows the resulting posterior distribution for <img src="https://latex.codecogs.com/png.latex?w_2"> and <img src="https://latex.codecogs.com/png.latex?w_3"> at varying degrees of prior uncertainty <img src="https://latex.codecogs.com/png.latex?%5Csigma">. The constant <img src="https://latex.codecogs.com/png.latex?w_1"> is held constant at the mode (<img src="https://latex.codecogs.com/png.latex?%5Chat%7Bw%7D_1">). The red dot indicates the MLE. Note how for the choice of <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Crightarrow%200"> the posterior is equal to the prior. This is intuitive since we have imposed that we have no uncertainty around our prior beliefs and hence no amount of new evidence can move us in any direction. Conversely, for <img src="https://latex.codecogs.com/png.latex?%5Csigma%20%5Crightarrow%20%5Cinfty"> the posterior distribution is centered around the unconstrained MLE: prior knowledge is very uncertain and hence the posterior is dominated by the likelihood of the data.</p>
<div id="fig-posterior" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/www/images/posterior.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Posterior distribution for <img src="https://latex.codecogs.com/png.latex?w_2"> and <img src="https://latex.codecogs.com/png.latex?w_3"> at varying degrees of prior uncertainty <img src="https://latex.codecogs.com/png.latex?%5Csigma">.</figcaption>
</figure>
</div>
<p>What about the posterior predictive? The story is similar: since for <img src="https://latex.codecogs.com/png.latex?%5Csigma%5Crightarrow%200"> the posterior is completely dominated by the zero-mean prior we have <img src="https://latex.codecogs.com/png.latex?p(y=1%7C%5Cmathbf%7Bx%7D,%5Chat%7B%5Cmathbf%7Bw%7D%7D)=0.5"> everywhere (top left panel in Figure&nbsp;4. As we gradually increase uncertainty around our prior the predictive posterior depends more and more on the data <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D">: uncertainty around predicted labels is high only in regions that are not populated by samples <img src="https://latex.codecogs.com/png.latex?(y_n,%20%5Cmathbf%7Bx%7D_n)">. Not surprisingly, this effect is strongest for the MLE (<img src="https://latex.codecogs.com/png.latex?%5Csigma%5Crightarrow%20%5Cinfty">) where we see some evidence of overfitting.</p>
<div id="fig-predictive" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/www/images/predictive.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Predictive posterior distribution at varying degrees of prior uncertainty <img src="https://latex.codecogs.com/png.latex?%5Csigma">.</figcaption>
</figure>
</div>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping up</h2>
<p>In this post we have seen how Bayesian Logistic Regression can be implemented from scratch in Julia language. The estimated posterior distribution over model parameters can be used to quantify uncertainty around coefficients and model predictions. I have argued that it is important to be transparent about model uncertainty to avoid being overly confident in estimates.</p>
<p>There are many more benefits associated with Bayesian (probabilistic) machine learning. Understanding where in the input domain our model exerts high uncertainty can for example be instrumental in labelling data: see for example <span class="citation" data-cites="gal2017deep">Gal, Islam, and Ghahramani (2017)</span> and follow-up works for an interesting application to <strong>active learning</strong> for image data. Similarly, there is a recent work that uses estimates of the posterior predictive in the context of <strong>algorithmic recourse</strong> <span class="citation" data-cites="schut2021generating">(Schut et al. 2021)</span>. For a brief introduction to algorithmic recourse see one of my <a href="../../../blog/posts/individual-recourse-for-black-box-models/index.html">previous posts</a>.</p>
<p>As a great reference for further reading about probabilistic machine learning I can highly recommend <span class="citation" data-cites="murphy2022probabilistic">Murphy (2022)</span>. An electronic version of the book is currently freely available as a draft. Finally, remember that if you want to try yourself at the code, you can check out this <a href="https://colab.research.google.com/github/pat-alt/pat-alt.github.io/blob/43e18fe5e8cc625ffe1e4270da49f253dac8523a/content/post/2021-10-27-bayesian-logistic-regression/julia_implementation.ipynb">interactive notebook</a>.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bishop2006pattern" class="csl-entry">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. <span>springer</span>.
</div>
<div id="ref-gal2017deep" class="csl-entry">
Gal, Yarin, Riashat Islam, and Zoubin Ghahramani. 2017. <span>‚ÄúDeep Bayesian Active Learning with Image Data.‚Äù</span> In <em>International <span>Conference</span> on <span>Machine Learning</span></em>, 1183‚Äì92. <span>PMLR</span>.
</div>
<div id="ref-murphy2012machine" class="csl-entry">
Murphy, Kevin P. 2012. <em>Machine Learning: <span>A</span> Probabilistic Perspective</em>. <span>MIT press</span>.
</div>
<div id="ref-murphy2022probabilistic" class="csl-entry">
‚Äî‚Äî‚Äî. 2022. <em>Probabilistic <span>Machine Learning</span>: <span>An</span> Introduction</em>. <span>MIT Press</span>.
</div>
<div id="ref-schut2021generating" class="csl-entry">
Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. <span>‚ÄúGenerating <span>Interpretable Counterfactual Explanations By Implicit Minimisation</span> of <span>Epistemic</span> and <span>Aleatoric Uncertainties</span>.‚Äù</span> In <em>International <span>Conference</span> on <span>Artificial Intelligence</span> and <span>Statistics</span></em>, 1756‚Äì64. <span>PMLR</span>.
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><aside id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>We let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D=(10,%200.75,%20-2.5)%5ET"> define the true coefficients.‚Ü©Ô∏é</p></li>
<li id="fn2"><p>Note that the author works with the negative log likelihood scaled by the sample size‚Ü©Ô∏é</p></li>
</ol>
</aside><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick},
  title = {Bayesian {Logistic} {Regression}},
  date = {2021-11-15},
  url = {https://www.paltmeyer.com/blog//blog/posts/bayesian-logit},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2021. <span>‚ÄúBayesian Logistic Regression.‚Äù</span>
November 15, 2021. <a href="https://www.paltmeyer.com/blog//blog/posts/bayesian-logit">https://www.paltmeyer.com/blog//blog/posts/bayesian-logit</a>.
</div></div></section></div> ]]></description>
  <category>bayes</category>
  <category>logistic regression</category>
  <category>Julia</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/index.html</guid>
  <pubDate>Mon, 15 Nov 2021 05:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/bayesian-logit/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>Individual recourse for Black Box Models</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/intro.gif" class="figure-img">
</figure>
</div>
<blockquote class="blockquote">
<p>‚ÄúYou cannot appeal to [algorithms]. They do not listen. Nor do they bend.‚Äù</p>
<p>‚Äî Cathy O‚ÄôNeil</p>
</blockquote>
<p>In her popular book <a href="https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction">Weapons of Math Destruction</a> Cathy O‚ÄôNeil presents the example of public school teacher Sarah Wysocki, who lost her job after a teacher evaluation algorithm had rendered her redundant <span class="citation" data-cites="oneil2016weapons">(O‚ÄôNeil 2016)</span>. Sarah was highly popular among her peers, supervisors and students.</p>
<p>This post looks at a novel algorithmic solution to the problem that individuals like Sarah, who are faced with an undesirable outcome, should be provided with means to revise that outcome. The literature commonly refers to this as <em>individual recourse</em>. One of the first approaches towards individual recourse was proposed by <span class="citation" data-cites="ustun2019actionable">Ustun, Spangher, and Liu (2019)</span>. In a recent follow-up paper, <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span> propose a methodology coined <code>REVISE</code>, which extends the earlier approach in at least three key ways:</p>
<ol type="1">
<li><code>REVISE</code> provides a framework that avoids suggesting an unrealistic set of changes by imposing a threshold likelihood on the revised attributes.</li>
<li>It is applicable to a broader class of models including Black Box classifiers and structural causal models.</li>
<li>It can be used to detect poorly defined proxies and biases.</li>
</ol>
<p>For a detailed discussion of these points you may check out this <a href="paper_presentation.pdf">slide deck</a> or consult the paper directly (freely available on <a href="https://deepai.org/publication/towards-realistic-individual-recourse-and-actionable-explanations-in-black-box-decision-making-systems">DeepAI</a>). Here, we will abstract from some of these complications and instead look at an application of a slightly simplified version of <code>REVISE</code>. This should help us to first build a good intuition. Readers interested in the technicalities and code may find all of this in the annex below.</p>
<section id="from-to" class="level2">
<h2 class="anchored" data-anchor-id="from-to">From üê± to üê∂</h2>
<p>We will explain <code>REVISE</code> through a short tale of cats and dogs. The protagonist of this tale is Kitty üê±, a young cat that identifies as a dog. Unfortunately, Kitty is not very tall and her tail, though short for a cat, is longer than that of the average dog (Figure&nbsp;1).</p>
<div id="fig-density" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/density.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Empirical distributions of simulated data set describing cats and dogs. Vertical stalks represent Kitty‚Äôs attribute values.</figcaption>
</figure>
</div>
<p>Much to her dismay, Kitty has been recognized as a cat by a linear classifier <img src="https://latex.codecogs.com/png.latex?g_n(X)"> that we trained through stochastic gradient descent using the data on animals‚Äô height and tail length. Once again interested readers may find technical details and code in the annex below. Figure&nbsp;2 shows the resulting linear separation in the attribute space with the decision boundary in solid black and Kitty‚Äôs location indicated by a red circle. Can we provide individual recourse to Kitty?</p>
<div id="fig-class" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/class.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Linear separation of cats and dogs in the 2-dimensional attribute space with the decision boundary of the fitted classifier in solid black. Kitty‚Äôs location is indicated by a red circle.</figcaption>
</figure>
</div>
<p>Let‚Äôs see if and how we can apply <code>REVISE</code> to Kitty‚Äôs problem. The following summary should give you some flavour of how the algorithm works:</p>
<ol type="1">
<li>Initialize <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i'%5E%7B(0)%7D">, that is the attributes that will be revised recursively. Kitty‚Äôs original attributes seem like a reasonable place to start.</li>
<li>Through gradient descent recursively revise <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i'%5E%7B(t)%7D"> until <img src="https://latex.codecogs.com/png.latex?g_n(%5Cmathbf%7Bx%7D_i'%5E%7B(T)%7D)=">üê∂. At this point <img src="https://latex.codecogs.com/png.latex?T"> the descent terminates since for these revised attributes the classifier labels Kitty as a dog.</li>
<li>Return <img src="https://latex.codecogs.com/png.latex?%5Cdelta_i=%5Cmathbf%7Bx%7D_i'%5E%7B(T)%7D-%5Cmathbf%7Bx%7D_i">, that is the individual recourse for Kitty.</li>
</ol>
<p>Figure&nbsp;3 illustrates what happens when this approach is applied to Kitty‚Äôs problem. The different panels show the results for different values of a regularization parameter <img src="https://latex.codecogs.com/png.latex?%5Clambda"> that governs the trade-off between achieving the desired label switch and keeping the distance between the original (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i">) and revised (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i'">) attributes small. In all but one case, <code>REVISE</code> converges: a decrease in tail length along with an increase in height eventually allows Kitty to cross the decision boundary. In other words, we have successfully turned Kitty into a dog - at least in the eyes of the linear classifier!</p>
<p>We also observe that as we increase <img src="https://latex.codecogs.com/png.latex?%5Clambda"> for a fixed learning rate, <code>REVISE</code> takes longer to converge. This should come as no surprise, since higher values of <img src="https://latex.codecogs.com/png.latex?%5Clambda"> lead to greater regularization with respect to the penalty we place on the distance that Kitty has to travel. When we penalize too much (<img src="https://latex.codecogs.com/png.latex?%5Clambda=10">), Kitty never reaches the decision boundary, because she is reluctant to change her characteristics beyond a certain point. While not visible to the naked eye, in this particular example <img src="https://latex.codecogs.com/png.latex?%5Clambda=0.001"> corresponds to the best choice among the candidate values.</p>
<div id="fig-revise" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/revise.gif" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: The simplified <code>REVISE</code> algorithm in action: how Kitty crosses the decision boundary by changing her attributes. Regularization with respect to the distance penalty increases from top left to bottom right.</figcaption>
</figure>
</div>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>While hopefully Kitty‚Äôs journey has provided you with some useful intuition, the story is of course very silly. Even if your cat ever seems to signal that she wants to be a dog, helping her cross that decision boundary will be tricky. Some attributes are simply immutable or very difficult to change, which <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span> do not fail to account for in their framework. Their proposed methodology offers a simple and ingenious approach towards providing individual recourse. Instead of concerning ourselves with Black Box interpretability, why not simply provide remedy in case things go wrong?</p>
<p>To some extent that idea has its merit. As this post has hopefully shown, <code>REVISE</code> is straight-forward to understand and readily applicable. It could be a very useful tool to provide individual recourse in many real-world applications. As the implementation of our simplified version of <code>REVISE</code> demonstrates, researchers should also find it relatively easy to develop the methodology further and tailor it to specific use cases. The simpler version here, for example, may be useful in settings where the dimensionality is relatively small and one can reasonably model the distribution of attributes without the need for generative models.</p>
<p>Still, you may be wondering: if the original classifier is based on poorly defined rules and proxies, then what good does <code>REVISE</code> really do? Going back to the example of high-school teacher Sarah Wysocki, one of the key attributes determining teachers‚Äô evaluations was their students‚Äô performance. Realizing this, some teachers took the shortest route to success by artificially inflating their students‚Äô test scores. That same course of action may well have been suggested by <code>REVISE</code>. As <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span> demonstrate, this very property of <code>REVISE</code> may actually proof useful in detecting weaknesses of decision making systems before setting them loose (key contribution 3).</p>
<p>Nonetheless, the example above also demonstrates that approaches like <code>REVISE</code>, useful as they may be, tend to provide solutions for very particular problems. In reality data-driven decision making systems are often subject to many different problems and hence research on trustworthy AI will need to tackle the issue from various angles. A few places to start include the question of dealing with data that is inherently biased, improving ad-hoc and post-hoc model interpretability and continuing efforts around causality-inspired AI.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-joshi2019realistic" class="csl-entry">
Joshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. <span>‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù</span> <a href="https://arxiv.org/abs/1907.09615">https://arxiv.org/abs/1907.09615</a>.
</div>
<div id="ref-oneil2016weapons" class="csl-entry">
O‚ÄôNeil, Cathy. 2016. <em>Weapons of Math Destruction: <span>How</span> Big Data Increases Inequality and Threatens Democracy</em>. <span>Crown</span>.
</div>
<div id="ref-ustun2019actionable" class="csl-entry">
Ustun, Berk, Alexander Spangher, and Yang Liu. 2019. <span>‚ÄúActionable Recourse in Linear Classification.‚Äù</span> In <em>Proceedings of the <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 10‚Äì19.
</div>
</div>
</section>
<section id="annex" class="level2">
<h2 class="anchored" data-anchor-id="annex">Annex</h2>
<p>In my blog posts I aim to implement interesting ideas from scratch even if that sometimes means that things need to undergo some sort of simplification. The benefit of this approach is that the experience is educationally rewarding - both for myself and hopefully also for readers. The first two sections of this annex show how <code>REVISE</code> and linear classification can be implemented in R. The final section just shows how the synthetic data was generated. To also inspect the code that generates the visualizations and everything else, you can find the source code of this file on <a href="https://github.com/pat-alt/patalt/blob/master/content/post/2021-04-26-individual-recourse-for-black-box-models/index.Rmd">GitHub</a>.</p>
<section id="linear-classifier" class="level3">
<h3 class="anchored" data-anchor-id="linear-classifier">Linear classifier</h3>
<p>Linear classification is implemented through stochastic gradient descent (SGD) with Hinge loss</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cell(-%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_i%20y_i)&amp;=(1-%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_i%20y_i)_+%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> is a coefficient vector, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i"> is the attribute vector of individual <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?y_i"> is the individual‚Äôs outcome. Since we apply SGD in order to minimize the loss function <img src="https://latex.codecogs.com/png.latex?%5Cell"> by varying <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D">, we need an expression for its gradient with respect to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D">, which is given by:</p>
<p><span id="eq-hinge"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cnabla_%7B%5Cmathbf%7BW%7D%7D%20%5Cleft(%20%5Cell(-%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_i%20y_i)%20%5Cright)%20&amp;=%20%5Cbegin%7Bcases%7D%20-%5Cmathbf%7Bx%7D_i%20y_i%20&amp;%20%5Ctext%7Bif%7D%20%5C%20%5C%20%5C%20%5Cmathbf%7Bw%7D%5ET%5Cmathbf%7Bx%7D_i%20y_i%20%5Cle%201%5C%5C%200%20&amp;%20%5Ctext%7Botherwise%7D%20%5Cend%7Bcases%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B1%7D"></span></p>
<p>The code below uses this analytical solution to perform SGD over <img src="https://latex.codecogs.com/png.latex?T"> iterations or as long as updates yield feasible parameter values. As the final vector of coefficients the function returns <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5Cbar%7Bw%7D%7D=%20%5Cfrac%7B1%7D%7BT%7D%20%5Csum_%7Bt=1%7D%5E%7BT%7D%20%5Cmathbf%7Bw%7D_t">. Denoting the optimal coefficient vector as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%5E*">, it can be shown that under certain conditions <img src="https://latex.codecogs.com/png.latex?%5Cell(%5Cmathbf%7B%5Cbar%7Bw%7D%7D)%5Crightarrow%5Cell(%5Cmathbf%7Bw%7D%5E*)"> as <img src="https://latex.codecogs.com/png.latex?T%5Crightarrow%5Cinfty">.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' Stochastic gradient descent</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param X Feature matrix.</span></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param y Vector containing training labels.</span></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param eta Learning rate.</span></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param n_iter Maximum number of iterations.</span></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param w_init Initial parameter values.</span></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param save_steps Boolean checking if coefficients should be saved at each step.</span></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'</span></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @return</span></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @export</span></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'</span></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @author Patrick Altmeyer</span></span>
<span id="cb1-14">linear_classifier <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(X,y,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">eta=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n_iter=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">w_init=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">save_steps=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>) {</span>
<span id="cb1-15">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialization: ----</span></span>
<span id="cb1-16">  n <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">nrow</span>(X) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># number of observations</span></span>
<span id="cb1-17">  d <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ncol</span>(X) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># number of dimensions</span></span>
<span id="cb1-18">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">is.null</span>(w_init)) {</span>
<span id="cb1-19">    w <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rep</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,d)) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># initialize coefficients as zero...</span></span>
<span id="cb1-20">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> {</span>
<span id="cb1-21">    w <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(w_init) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ...unless initial values have been provided.</span></span>
<span id="cb1-22">  }</span>
<span id="cb1-23">  w_avg <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>n_iter <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> w <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># initialize average coefficients</span></span>
<span id="cb1-24">  iter <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># iteration count</span></span>
<span id="cb1-25">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (save_steps) {</span>
<span id="cb1-26">    steps <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.table</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">w=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(w), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">d=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>d) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># if desired, save coefficient at each step</span></span>
<span id="cb1-27">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> {</span>
<span id="cb1-28">    steps <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span></span>
<span id="cb1-29">  }</span>
<span id="cb1-30">  feasible_w <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># to check if coefficients are finite, non-nan, ...</span></span>
<span id="cb1-31">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Surrogate loss:</span></span>
<span id="cb1-32">  l <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(X,y,w) {</span>
<span id="cb1-33">    x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> (<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">crossprod</span>(X,w) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> y</span>
<span id="cb1-34">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pmax</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> x) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hinge loss</span></span>
<span id="cb1-35">  }</span>
<span id="cb1-36">  grad <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(X,y,w) {</span>
<span id="cb1-37">    X <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ifelse</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">crossprod</span>(X,w) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> y<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>y,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Gradient of Hinge loss</span></span>
<span id="cb1-38">  }</span>
<span id="cb1-39">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Stochastic gradient descent: ----</span></span>
<span id="cb1-40">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">while</span> (feasible_w <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> iter<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>n_iter) {</span>
<span id="cb1-41">    t <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sample</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>n,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># random draw</span></span>
<span id="cb1-42">    X_t <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(X[t,])</span>
<span id="cb1-43">    y_t <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(y[t])</span>
<span id="cb1-44">    v_t <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">grad</span>(X_t,y_t,w) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># compute estimate of gradient</span></span>
<span id="cb1-45">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update:</span></span>
<span id="cb1-46">    w <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> w <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> eta <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> v_t <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># update coefficient vector</span></span>
<span id="cb1-47">    feasible_w <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">all</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sapply</span>(w, <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(i) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">is.na</span>(i) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">is.finite</span>(i))) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># check if feasible</span></span>
<span id="cb1-48">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (feasible_w) {</span>
<span id="cb1-49">      w_avg <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> w_avg <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>n_iter <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> w <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># update average</span></span>
<span id="cb1-50">    }</span>
<span id="cb1-51">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (save_steps) {</span>
<span id="cb1-52">      steps <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rbind</span>(steps, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.table</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter=</span>iter, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">w=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(w), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">d=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>d))</span>
<span id="cb1-53">    }</span>
<span id="cb1-54">    iter <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> iter <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># increase counter</span></span>
<span id="cb1-55">  }</span>
<span id="cb1-56">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Output: ----</span></span>
<span id="cb1-57">  output <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(</span>
<span id="cb1-58">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">X =</span> X,</span>
<span id="cb1-59">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(y),</span>
<span id="cb1-60">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">coefficients =</span> w_avg,</span>
<span id="cb1-61">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">eta =</span> eta,</span>
<span id="cb1-62">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n_iter =</span> n_iter,</span>
<span id="cb1-63">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">steps =</span> steps</span>
<span id="cb1-64">  )</span>
<span id="cb1-65">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">class</span>(output) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classifier"</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># assign S3 class</span></span>
<span id="cb1-66">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">return</span>(output)</span>
<span id="cb1-67">}</span>
<span id="cb1-68"></span>
<span id="cb1-69"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Methods: ----</span></span>
<span id="cb1-70">print.classifier <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(classifier) {</span>
<span id="cb1-71">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Coefficients:"</span>)</span>
<span id="cb1-72">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>(classifier<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>coefficients)</span>
<span id="cb1-73">}</span>
<span id="cb1-74">print <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(classifier) {</span>
<span id="cb1-75">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">UseMethod</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"print"</span>)</span>
<span id="cb1-76">}</span>
<span id="cb1-77"></span>
<span id="cb1-78">predict.classifier <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(classifier, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">newdata=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">discrete=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>) {</span>
<span id="cb1-79">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">is.null</span>(newdata)) {</span>
<span id="cb1-80">    fitted <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> newdata <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> classifier<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>coefficients <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># out-of-sampple prediction</span></span>
<span id="cb1-81">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> {</span>
<span id="cb1-82">    fitted <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> classifier<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>X <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> classifier<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>coefficients <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># in-sample fit</span></span>
<span id="cb1-83">  }</span>
<span id="cb1-84">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (discrete) {</span>
<span id="cb1-85">    fitted <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sign</span>(fitted) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># map to {-1,1}</span></span>
<span id="cb1-86">  }</span>
<span id="cb1-87">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">return</span>(fitted)</span>
<span id="cb1-88">}</span>
<span id="cb1-89">predict <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(classifier, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">newdata=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">discrete=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>) {</span>
<span id="cb1-90">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">UseMethod</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"predict"</span>)</span>
<span id="cb1-91">}</span></code></pre></div>
</div>
</section>
<section id="revise-simplified" class="level3">
<h3 class="anchored" data-anchor-id="revise-simplified"><code>REVISE</code> (simplified)</h3>
<p>As flagged above, we are looking at a slightly simplified version of the algorithm presented in <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span>. In particular, the approach here does not incorporate the threshold on the likelihood nor does it account for immutable attributes.</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?y%5Cin%5C%7B-1,1%5C%7D"> be a binary outcome variable, <img src="https://latex.codecogs.com/png.latex?X%5Cin%5Cmathbb%7BR%7D%5Ed"> a feature matrix containing individuals‚Äô attributes and <img src="https://latex.codecogs.com/png.latex?g_n(X)"> a corresponding data-dependent classifier. Suppose <img src="https://latex.codecogs.com/png.latex?y_i=-1"> (the negative outcome) for some individual characterized by attributes <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i">. Then we want to find <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i'"> closest to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i"> such that the classifier assigns the positive outcome <img src="https://latex.codecogs.com/png.latex?g(%5Cmathbf%7Bx%7D_i%5E%7B'%7D)=1">. In order to do so, we use gradient descent with Hinge loss <img src="https://latex.codecogs.com/png.latex?%5Cell"> to minimize the following function</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cmin_%7B%5Cmathbf%7Bx%7D_i%5E%7B'%7D%7D&amp;%20%5C%20%5Cell(g_n(%5Cmathbf%7Bx%7D_i%5E%7B'%7D),1)%20+%20%5Clambda%20d(%5Cmathbf%7Bx%7D_i%5E%7B'%7D,%5Cmathbf%7Bx%7D_i)%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?d=%7C%7C%5Cmathbf%7Bx%7D_i%5E%7B'%7D-%5Cmathbf%7Bx%7D_i%7C%7C"> denotes the Euclidean distance. Note that this time we take the coefficient vector defining <img src="https://latex.codecogs.com/png.latex?g_n"> as given and instead vary the attributes. In particular, we will perform gradient descent steps as follows</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%7B%5Cmathbf%7Bx%7D_i%5E%7B'%7D%7D%5Et&amp;%5Cleftarrow%20%7B%5Cmathbf%7Bx%7D_i%5E%7B'%7D%7D%5E%7Bt-1%7D%20+%20%5Ceta%20%5Cnabla_%7B%7B%5Cmathbf%7Bx%7D_i%5E%7B'%7D%7D%7D%20%5Cleft(%20%5Cell(g_n(%5Cmathbf%7Bx%7D_i%5E%7B'%7D),1)%20+%20%5Clambda%20d(%5Cmathbf%7Bx%7D_i%5E%7B'%7D,%5Cmathbf%7Bx%7D_i)%20%20%5Cright)%20%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Ceta"> is the learning rate. The descent step is almost equivalent to the one described in <span class="citation" data-cites="joshi2019realistic">Joshi et al. (2019)</span>, but here we greatly simplify things by optimizing directly in the attribute space instead of a latent space. The gradient of the loss function looks very similar to Equation&nbsp;1. With respect to the Euclidean distance partial derivatives are of the following form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%20%5Cfrac%7B%5Cpartial%20%7C%7C%5Cmathbf%7Bx%7D_i%5E%7B'%7D-%5Cmathbf%7Bx%7D_i%7C%7C%7D%7B%5Cpartial%20%7Bx_i'%7D%5E%7B(d)%7D%7D%20%20&amp;=%20%5Cfrac%7B%7Bx_i'%7D%5E%7B(d)%7D-%7Bx_i%7D%5E%7B(d)%7D%7D%7B%7C%7C%5Cmathbf%7Bx%7D_i%5E%7B'%7D-%5Cmathbf%7Bx%7D_i%7C%7C%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<p>The code that implements this optimization follows below.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' REVISE algoritm - a simplified version</span></span>
<span id="cb2-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param classifier The fitted classifier.</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param x_star Attributes of individual seeking individual recourse.</span></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param eta Learning rate.</span></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param lambda Regularization parameter.</span></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param n_iter Maximum number of operations.</span></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @param save_steps Boolean indicating if intermediate steps should be saved.</span></span>
<span id="cb2-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'</span></span>
<span id="cb2-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @return</span></span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @export</span></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#'</span></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#' @author Patrick Altmeyer</span></span>
<span id="cb2-14">revise.classifier <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(classifier,x_star,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">eta=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">lambda=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n_iter=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">save_steps=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>) {</span>
<span id="cb2-15">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialization: ----</span></span>
<span id="cb2-16">  d <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">length</span>(x_star) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># number of dimensions</span></span>
<span id="cb2-17">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">is.null</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">names</span>(x_star))) {</span>
<span id="cb2-18">    d_names <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">names</span>(x_star) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># names of attributes, if provided</span></span>
<span id="cb2-19">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> {</span>
<span id="cb2-20">    d_names <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sprintf</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"X%i"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>d)</span>
<span id="cb2-21">  }</span>
<span id="cb2-22">  w <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> classifier<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>coefficients <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># coefficient vector</span></span>
<span id="cb2-23">  x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> x_star <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># initialization of revised attributes</span></span>
<span id="cb2-24">  distance <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># initial distance from starting point</span></span>
<span id="cb2-25">  converged <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(classifier, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">newdata =</span> x)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># positive outcome?</span></span>
<span id="cb2-26">  iter <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># counter</span></span>
<span id="cb2-27">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (save_steps) {</span>
<span id="cb2-28">    steps <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.table</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span>x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">d=</span>d_names) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># save intermediate steps, if desired</span></span>
<span id="cb2-29">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> {</span>
<span id="cb2-30">    steps <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span></span>
<span id="cb2-31">  }</span>
<span id="cb2-32">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Gradients:</span></span>
<span id="cb2-33">  grad <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(x,y,w) {</span>
<span id="cb2-34">    w <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ifelse</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">crossprod</span>(x,w) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> y<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>y,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># gradient of Hinge loss with respect to X</span></span>
<span id="cb2-35">  }</span>
<span id="cb2-36">  grad_dist <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(x,x_star) {</span>
<span id="cb2-37">    d <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">length</span>(x_star)</span>
<span id="cb2-38">    distance <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dist</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cbind</span>(x_star,x),<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow=</span>d,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> T))</span>
<span id="cb2-39">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>((x<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>x_star) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> distance) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># gradient of Euclidean distance with respect to X</span></span>
<span id="cb2-40">  }</span>
<span id="cb2-41">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Gradient descent: ----</span></span>
<span id="cb2-42">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">while</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span>converged <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> iter<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>n_iter) {</span>
<span id="cb2-43">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (distance<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) {</span>
<span id="cb2-44">      x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(x <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> eta <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> (<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">grad</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(x),<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,w) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> lambda <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">grad_dist</span>(x,x_star))) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># gradient descent step</span></span>
<span id="cb2-45">    } <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> {</span>
<span id="cb2-46">      x <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(x <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> eta <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">grad</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(x),<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,w)) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># gradient with respect to distance not defined at zero</span></span>
<span id="cb2-47">    }</span>
<span id="cb2-48">    converged <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(classifier, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">newdata =</span> x)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># positive outcome?</span></span>
<span id="cb2-49">    iter <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> iter <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># update counter</span></span>
<span id="cb2-50">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (save_steps) {</span>
<span id="cb2-51">      steps <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rbind</span>(steps, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data.table</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">iter=</span>iter, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x=</span>x, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">d=</span>d_names))</span>
<span id="cb2-52">    }</span>
<span id="cb2-53">    distance <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dist</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cbind</span>(x_star,x),<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow=</span>d,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">byrow =</span> T)) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># update distance</span></span>
<span id="cb2-54">  }</span>
<span id="cb2-55">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Output: ----</span></span>
<span id="cb2-56">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> (converged) {</span>
<span id="cb2-57">    revise <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> x <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> x_star</span>
<span id="cb2-58">  } <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> {</span>
<span id="cb2-59">    revise <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NA</span></span>
<span id="cb2-60">  }</span>
<span id="cb2-61">  output <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(</span>
<span id="cb2-62">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x_star =</span> x_star,</span>
<span id="cb2-63">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">revise =</span> revise,</span>
<span id="cb2-64">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">classifier =</span> classifier,</span>
<span id="cb2-65">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">steps =</span> steps,</span>
<span id="cb2-66">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">lambda =</span> lambda,</span>
<span id="cb2-67">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">distance =</span> distance,</span>
<span id="cb2-68">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">mean_distance =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mean</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">abs</span>(revise))</span>
<span id="cb2-69">  )</span>
<span id="cb2-70">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">return</span>(output)</span>
<span id="cb2-71">}</span>
<span id="cb2-72"></span>
<span id="cb2-73">revise <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(classifier,x_star,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">eta=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">lambda=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n_iter=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">save_steps=</span><span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>) {</span>
<span id="cb2-74">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">UseMethod</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"revise"</span>)</span>
<span id="cb2-75">}</span></code></pre></div>
</div>
</section>
<section id="simulated-data" class="level3">
<h3 class="anchored" data-anchor-id="simulated-data">Simulated data</h3>
<p>The synthetic data describing cats and dogs was generated as follows:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1">sim_data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">function</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">n=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,averages,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">noise=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>) {</span>
<span id="cb3-2">  d <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ncol</span>(averages)</span>
<span id="cb3-3">  y <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rbinom</span>(n,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># generate binary outcome: 1=dog, -1=cat</span></span>
<span id="cb3-4">  X <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">as.matrix</span>(averages[(y<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># generate attributes conditional on y</span></span>
<span id="cb3-5">  dogs <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> y<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># boolean index for dogs</span></span>
<span id="cb3-6">  cats <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> y<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># boolean index for cats</span></span>
<span id="cb3-7">  X[cats,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> X[cats,] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb3-8">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rnorm</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(cats)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>d),<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(cats)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">diag</span>(noise<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>averages[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add noise for y=1 (cats)</span></span>
<span id="cb3-9">  X[dogs,] <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> X[dogs,] <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb3-10">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">matrix</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rnorm</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(dogs)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>d),<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow=</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">sum</span>(dogs)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%*%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">diag</span>(noise<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>averages[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,]) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># add noise for y=1 (dogs)</span></span>
<span id="cb3-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">return</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">X=</span>X,<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y=</span>y))</span>
<span id="cb3-12">}</span></code></pre></div>
</div>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick},
  title = {Individual Recourse for {Black} {Box} {Models}},
  date = {2021-04-27},
  url = {https://www.paltmeyer.com/blog//blog/posts/individual-recourse-for-black-box-models},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2021. <span>‚ÄúIndividual Recourse for Black Box
Models.‚Äù</span> April 27, 2021. <a href="https://www.paltmeyer.com/blog//blog/posts/individual-recourse-for-black-box-models">https://www.paltmeyer.com/blog//blog/posts/individual-recourse-for-black-box-models</a>.
</div></div></section></div> ]]></description>
  <category>counterfactuals</category>
  <category>algorithmic recourse</category>
  <category>deep learning</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/index.html</guid>
  <pubDate>Tue, 27 Apr 2021 04:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/individual-recourse-for-black-box-models/www/intro.gif" medium="image" type="image/gif"/>
</item>
<item>
  <title>A peek inside the ‚ÄòBlack Box‚Äô - interpreting neural networks</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html</link>
  <description><![CDATA[ 



<div class="intro-gif">
<figure class="figure">
<img src="https://www.paltmeyer.com/blog/blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/www/intro.jpeg" class="figure-img">
</figure>
</div>
<p>Propelled by advancements in modern computer technology, deep learning has re-emerged as perhaps the most promising artificial intelligence (AI) technology of the last two decades. By treating problems as a nested, hierarchy of hidden layers deep artificial neural networks achieve the power and flexibility necessary for AI systems to navigate complex real-world environments. Unfortunately, their very nature has earned them a reputation as <em>Black Box</em> algorithms and their lack of interpretability remains a major impediment to their more wide-spread application.</p>
<p>In science, research questions usually demand not just answers but also explanations and variable selection is often as important as prediction <span class="citation" data-cites="ish-horowicz2019interpreting">(Ish-Horowicz et al. 2019)</span>. Economists, for example, recognise the undeniable potential of deep learning, but are rightly hesitant to employ novel tools that are not fully transparent and ultimately cannot be trusted. Similarly, real-world applications of AI have come under increasing scrutiny with regulators imposing that individuals influenced by algorithms should have the right to obtain explanations <span class="citation" data-cites="fan2020interpretability">(Fan, Xiong, and Wang 2020)</span>. In high-risk decision-making fields such as AI systems that drive autonomous vehicles the need for explanations is self-evident <span class="citation" data-cites="ish-horowicz2019interpreting">(Ish-Horowicz et al. 2019)</span>.</p>
<p>In light of these challenges it is not surprising that research on explainable AI has recently gained considerable momentum <span class="citation" data-cites="arrieta2020explainable">(Arrieta et al. 2020)</span>. While in this short essay we will focus on deep learning in particular, it should be noted that this growing body of literature is concerned with a broader realm of machine learning models. The rest of this note is structured as follows: the first section provides a brief overview of recent advancements towards interpreting deep neural networks largely drawing on <span class="citation" data-cites="fan2020interpretability">Fan, Xiong, and Wang (2020)</span>; the second section considers a novel entropy-based approach towards interpretability proposed by <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span>; finally, in the last section we will see how this approach can be applied to deep neural networks as proposed in <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span>.</p>
<section id="interpretable-dl" class="level1">
<h1>Interpretable DL - a whistle-stop tour</h1>
<p>Before delving further into <em>how</em> the intrinsics of deep neural networks can be disentangled we should first clarify <em>what</em> interpretability in the context of algorithms actually means. <span class="citation" data-cites="fan2020interpretability">Fan, Xiong, and Wang (2020)</span> describes model interpretability simply as the extent to which humans can ‚Äúunderstand and reason‚Äù the model. This may concern an understanding of both the <em>ad-hoc</em> workings of the algorithm as well as the <em>post-hoc</em> interpretability of its output. In the context of linear regression, for example, <em>ad-hoc</em> workings of the model are often described through the intuitive idea of linearly projecting the outcome variable <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7By%7D"> onto the column space of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">. <em>Post-hoc</em> interpretations usually center around variable importance ‚Äì the main focus of the following sections. Various recent advancements tackle interpretability of DNNs from different angles depending on whether the focus is on <em>ad-hoc</em> or <em>post-hoc</em> interpretability. <span class="citation" data-cites="fan2020interpretability">Fan, Xiong, and Wang (2020)</span> further asses that model interpretability hinges on three main aspects of <em>simulatability</em>, <em>decomposability</em> and <em>algorithmic transparency</em>, but for the purpose of this short note the <em>ad-hoc</em> vs.&nbsp;<em>post-hoc</em> taxonomy provides a simpler more natural framework. <sup>1</sup></p>
<p>Understanding the <em>ad-hoc</em> intrinsic mechanisms of a DNN is inherently difficult. While generally transparency may be preserved in the presence of nonlinearity (e.g.&nbsp;decision trees), multiple hidden layers of networks (each of them) involving nonlinear operations are usually out of the realm of human comprehension <span class="citation" data-cites="fan2020interpretability">(Fan, Xiong, and Wang 2020)</span>. Training also generally involves optimization of non-convex functions that involve an increasing number of saddle points as the dimensionality increases <span class="citation" data-cites="fan2020interpretability">(Fan, Xiong, and Wang 2020)</span>. Methods to circumvent this problematic usually boil down to decreasing the overall complexity, either by regularizing the model or through proxy methods. Regularization ‚Äì while traditionally done to avoid overfitting ‚Äì has been found to be useful to create more interpretable representations. Monotonicity constraints, for example, impose that as the value of a specified covariate increases model predictions either monotonically decrease or increase. Proxy methods construct simpler representations of a learned DNN, such as a rule-based decision tree. This essentially involves repeatedly querying the trained network while varying the inputs and then deriving decision rules based on the model output.</p>
<p>Post-hoc interpretability usually revolves around the understanding of feature importance. A greedy approach to this issue involves simply removing features one by one and checking how model predictions change. A more sophisticated approach along these lines is <em>Shapley</em> value, which draws on cooperative game theory. The Shapley value assigns varying payouts to players depending on their contribution to overall payout. In the context of neural networks input covariate <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_p"> represents a player while overall payout is represented by the difference between average and individual outcome predictions.<sup>2</sup> Exact computations of Shapley values are prohibitive as the dimensionality increases, though approximate methods have recently been developed <span class="citation" data-cites="fan2020interpretability">(Fan, Xiong, and Wang 2020)</span>.</p>
<p>The remainder of this note focuses on a novel approach to feature extraction that measures entropy shifts in a learned probabilistic neural network in response to model inputs <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX_1%7D,...,%5Cmathbf%7BX%7D_P">. We will first introduce this methodology in the context of Gaussian Process regression in the following section before finally turning to its application to Bayesian neural networks.</p>
</section>
<section id="rate" class="level1">
<h1>An entropy-based approach to variable importance</h1>
<p><span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> motivate their methodology for interpreting neural networks through Gaussian Process regression. Consider the following Bayesian regression model with Gaussian priors:</p>
<p><span id="eq-bayes"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20f(%5Cmathbf%7BX%7D%7C%5Cmathbf%7Bw%7D)&amp;=%5Cphi(%5Cmathbf%7BX%7D)%5ET%5Cmathbf%7Bw%7D%20+%20%5Cvarepsilon,%20&amp;&amp;%5Cvarepsilon%20%5Csim%20%5Cmathcal%7BN%7D(0,%5Cmathbf%7BI%7D)%20%5C%5C%0A&amp;&amp;%20%5Cmathbf%7Bw%7D&amp;%20%5Csim%20%5Cmathcal%7BN%7D(0,%7B1%5Cover%7B%5Clambda%7D%7D%20%5Cmathbf%7BI%7D)%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B1%7D"></span></p>
<p>This naturally gives rise to a particular example of a Gaussian Process (GP). In particular, since <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)=%5CPhi(%5Cmathbf%7BX%7D)%5ET%5Cmathbf%7Bw%7D"> is just a linear combination fo Gaussian random variables it follows a Gaussian Process itself</p>
<p><span id="eq-khbs"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)=%5CPhi(%5Cmathbf%7BX%7D)%5ET%5Cmathbf%7Bw%7D&amp;%20%5Csim%20%5Cmathcal%7BN%7D(%5Cmathbf%7B0%7D,%20%5Cmathbf%7BK%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B2%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BK%7D"> is the Kernel (or Gram) matrix and <img src="https://latex.codecogs.com/png.latex?K_%7Bi,j%7D=k(%5Cmathbf%7BX_i,%5Cmathbf%7BX%7D_j%7D)=%7B1%5Cover%7B%5Clambda%7D%7D%5Cphi(%5Cmathbf%7BX_i%7D)%5ET%5Cphi(%5Cmathbf%7BX_m%7D)"> is the kernel function <span class="citation" data-cites="bishop2006pattern">(Bishop 2006)</span>. In other words, the prior distribution over <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D"> induces a probability distribution over random functions <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)">. Similarly, the GP can be understood as a prior distribution over a an infinite-dimensional reproducible kernel Hilbert space (RKHS) <span class="citation" data-cites="crawford2019variable">(Crawford et al. 2019)</span>, which in a finite-dimensional setting becomes multivariate Gaussian.</p>
<p>In a standard linear regression model coefficients characterize the projection of the outcome variable <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7By%7D"> onto the column space of the regressors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">. In particular, with ordinary least square we define:</p>
<p><span id="eq-ols"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cbeta&amp;=(%5Cmathbf%7BX%7D%5ET%5Cmathbf%7BX%7D)%5E%7B-1%7D%5Cmathbf%7BX%7D%5ET%5Cmathbf%7By%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B3%7D"></span></p>
<p>The primary focus here is to learn the mapping from input to output. The key differentiating feature between this approach and the non-parametric model in Equation&nbsp;1 is the fact that in case of the latter we are interested in learning not only the mapping from inputs to outputs, but also the representation (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)">) of the inputs (see for example <span class="citation" data-cites="goodfellow2016deep">(Goodfellow, Bengio, and Courville 2016)</span>). To be even more specific, treating the feature representation itself as random as in Equation&nbsp;1 allows us to learn non-linear relationships between the covariates <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">, since they are implicitly captured by the RKHS <span class="citation" data-cites="crawford2019variable">(Crawford et al. 2019)</span>. Neural networks share this architecture and hence it is worth dwelling on it a bit further: the fact that the learned model inherently incorporates variable interactions leads to the observation that an individual feature is rarely important on its own with respect to the mapping from <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D"> to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7By%7D"> <span class="citation" data-cites="ish-horowicz2019interpreting">(Ish-Horowicz et al. 2019)</span>. Hence, in order to gain an understanding of individual variable importance, one should aim to understand what role feature <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j"> plays <em>within</em> the learned model, thereby taking into account its interactions with other covariates. Formally, <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> and define the <em>effect size analogue</em> as the equivalent of the familiar regression coefficient in the non-parametric setting</p>
<p><span id="eq-effect-size"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Ctilde%5Cbeta&amp;=%5Cmathbf%7BX%7D%5E+%5CPhi%5ET%5Cmathbf%7Bw%7D=%5Cmathbf%7BX%7D%5E+%5Cmathbf%7Bu%7D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B4%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D%5E+=%5Clim_%7B%5Calpha%7D%20(%5Cmathbf%7BX%7D%5ET%5Cmathbf%7BX%7D+%5Calpha%20%5Cmathbf%7BI%7D)%5E%7B-1%7D%5Cmathbf%7BX%7D%5ET"> denotes the Moore-Penrose pseudo-inverse (see for example <span class="citation" data-cites="goodfellow2016deep">Goodfellow, Bengio, and Courville (2016)</span>). Intuitively the effect size analogue can be thought of as the resulting coefficients from regressing the fitted values <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7Bu%7D%7D"> from the learned probabilistic model on the covariates <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">. It can be interpreted in the same way as linear regression coefficients, in the sense that <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta_j"> describes the marginal change in <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> given a unit increase in <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j"> holding all else constant. Note here the subtle, but crucial difference between Equation&nbsp;3 ‚Äì a projection from the outcome variable onto the column space of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D"> ‚Äì and Equation&nbsp;4 ‚Äì a projection from the learned model to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D">. In other words, looking at <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta"> can be thought of peeking directly into the <em>Block Box</em>. Unfortunately, as <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> point out, working with Equation&nbsp;4 is usually not straight-forward. From a practitioner‚Äôs point of view, it may also not be obvious how to interpret a coefficient that describes marginal effects of input variables on a learned model. A more useful indicator in this context would provide a measure of how much individual variables contribute to the overall variation in the learned model. For this purpose <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> propose to work with a distributional centrality measure based on <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta">, which we shall turn to next.</p>
<p>The proposed methodology in <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> and <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> depends on the availability of a posterior distribution over <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta"> in that it measures its entropic shifts in response to the introduction of covariates. The intuition is straight-forward: within the context of the learned probabilistic model is covariate <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j"> informative or not? More formally this boils down to determining if the posterior distribution of <img src="https://latex.codecogs.com/png.latex?p(%5Ctilde%5Cbeta_%7B-j%7D)"> is dependent on the effect of <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta_j">. This can be quantified through the Kullback-Leibler divergence (KLD) between <img src="https://latex.codecogs.com/png.latex?p(%5Ctilde%5Cbeta_%7B-j%7D)"> and the conditional posterior <img src="https://latex.codecogs.com/png.latex?p(%5Ctilde%5Cbeta_%7B-j%7D%7C%5Ctilde%5Cbeta_j)">:</p>
<p><span id="eq-kld"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Ctext%7BKLD%7D_j&amp;=%5Ctext%7BKL%7D%5Cleft(p(%5Ctilde%5Cbeta_%7B-j%7D)%20%7C%7C%20p(%5Ctilde%5Cbeta_%7B-j%7D%7C%5Ctilde%5Cbeta_j)%5Cright)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B5%7D"></span></p>
<p>Covariates that contribute significant information to the model will have <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BKLD%7D%3E0">, while for insignificant covariates <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BKLD%7D%5Capprox0">. The measure of induced entropy change gives rise to a ranking of the covariates in terms of their relative importance in the model. The RATE criterion of variable <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j"> is then simply defined as</p>
<p><span id="eq-rate"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Cgamma_j&amp;=%5Cfrac%7B%5Ctext%7BKLD%7D_j%7D%7B%5Csum_%7Bp=1%7D%5E%7BP%7D%5Ctext%7BKLD%7D_p%7D%5Cin%5B0,1%5D%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B6%7D"></span></p>
<p>which in light of its bounds can naturally be interpreted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_j">`s percentage contribution to the learned model. It is worth noting that <img src="https://latex.codecogs.com/png.latex?p(%5Ctilde%5Cbeta_%7B-j%7D%7C%5Ctilde%5Cbeta_j)"> of course depends on the value of the conditioning variable. A natural choice is <img src="https://latex.codecogs.com/png.latex?%5Ctilde%5Cbeta_j=0"> which usually corresponds to the null hypothesis.</p>
</section>
<section id="interpreting-bnns" class="level1">
<h1>Application to Bayesian neural networks</h1>
<p>In order to use the RATE criterion in the context of deep learning we need to work in the Bayesian setting. Contrary to standard artificial neural networks which work under the assumption that weights have some true latent value, Bayesian neural networks place a prior distribution over network parameters and hence treat weights as random variables <span class="citation" data-cites="goan2020bayesian">(Goan and Fookes 2020)</span>. Not only does it perhaps seem more natural to treat unobserved weights as random, but the Bayesian setting also naturally gives rise to reason about uncertainty in predictions, which can ultimately help us develop more trustworthy models <span class="citation" data-cites="goan2020bayesian">(Goan and Fookes 2020)</span>. A drawback of BNNs is that exact computation of posteriors is computationally challenging and often intractable (a non-trivial issue that we will turn back to in a moment).</p>
<p>When the prior placed over parameters is Gaussian, the output of the BNN approaches a Gaussian Process as the width of the network grows, in line with the discussion in the previous section. This is exactly the assumption that <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> work with. They propose an architecture for a multi-layer perceptron (MLP) composed of (1) an input layer collecting covariates <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D_1,...,%5Cmathbf%7BX%7D_p">, (2) a single deterministic, hidden layer and (3) an outer layer producing predictions from a probabilistic model <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)">. Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D"> be a <img src="https://latex.codecogs.com/png.latex?(N%20%5Ctimes%20P)"> matrix of covariates. Then formally, we have</p>
<p><span id="eq-bnn"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Baligned%7D%0A&amp;&amp;%20%5Chat%7B%5Cmathbf%7By%7D%7D&amp;=%5Csigma(%5Cmathbf%7Bu%7D)%20%5C%5C%0A&amp;&amp;%20%5Cmathbf%7Bu%7D(%5Cmathbf%7BZ%7D)&amp;=%5Cmathbf%7BZ%7D(%5Cmathbf%7BX%7D)%5Cmathbf%7Bw%7D%5E%7B(L+1)%7D,%20&amp;&amp;%20%5Cmathbf%7Bw%7D%5E%7B(L+1)%7D%20%5Csim%20%5Cmathcal%7BN%7D(%5Cmathbf%7Bm%7D,%20%5Cmathbf%7BV%7D)%20%5C%5C%0A&amp;&amp;%20%5Cmathbf%7BZ%7D(%5Cmathbf%7BX%7D)&amp;=f(%5Cmathbf%7BX%7D%5Cmathbf%7Bw%7D%5E%7B(L)%7D)%20%5C%5C%0A%5Cend%7Baligned%7D%0A%5Cend%7Bequation%7D%0A%5Ctag%7B7%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Csigma(.)"> is a link function and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D(%5Cmathbf%7BX%7D)"> represents the probabilistic model learned in the outer layer with weights <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%5E%7B(L+1)%7D"> assumed to be Gaussian random variables.<sup>3</sup> Finally, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BZ%7D(%5Cmathbf%7BX%7D)"> denotes the inner (or more generally penultimate) layer, an <img src="https://latex.codecogs.com/png.latex?(N%20%5Ctimes%20P)"> matrix of neural activations through <img src="https://latex.codecogs.com/png.latex?f:(%5Cmathbf%7BX%7D%5Cmathbf%7Bw%7D%5E%7B(L)%7D)%5Cmapsto%20%5Cmathbf%7BZ%7D">. <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> work with a simple single-layer MLP, but it should be evident that this be extended to arbitrary depth and complexity, while still maintaining the high-level structure imposed by Equation&nbsp;7. This flexibility allows RATE to be applied to a wide range of Bayesian network architectures, since all that is really required is the posterior distribution over weights <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%5E%7B(L+1)%7D">, which arises from the probabilistic outer layer. The fact that only the outer layer needs to be probabilistic has the additional benefit of mitigating the computational burden that comes with Bayesian inference, which was mentioned earlier.</p>
<p>Having established this basic, flexible set-up the <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> go on to derive closed-form expressions for RATE in this setting. The details are omitted here since the logic is largely analogous to what we learned above, but can be found in <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span>.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>The RATE criterion originally proposed by <span class="citation" data-cites="crawford2019variable">Crawford et al. (2019)</span> and shown to be applicable to Bayesian neural networks in <span class="citation" data-cites="ish-horowicz2019interpreting">Ish-Horowicz et al. (2019)</span> offers an intuitive way to measure variable importance in the context of deep learning. By defining variable importance as the contribution inputs make to a probabilistic model, it implicitly incorporates the interactions between covariates and nonlinearities that the model has learned. In other words, it allows researchers to peek directly into the <em>Black Box</em>. This opens up interesting avenues for future research, as the approach can be readily applied in academic disciplines and real-world applications that rely heavily on explainability of outcomes.</p>
<div style="page-break-after: always;"></div>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-arrieta2020explainable" class="csl-entry">
Arrieta, Alejandro Barredo, Natalia Diaz-Rodriguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garcia, et al. 2020. <span>‚ÄúExplainable <span>Artificial Intelligence</span> (<span>XAI</span>): <span>Concepts</span>, Taxonomies, Opportunities and Challenges Toward Responsible <span>AI</span>.‚Äù</span> <em>Information Fusion</em> 58: 82‚Äì115.
</div>
<div id="ref-bishop2006pattern" class="csl-entry">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. <span>springer</span>.
</div>
<div id="ref-crawford2019variable" class="csl-entry">
Crawford, Lorin, Seth R Flaxman, Daniel E Runcie, and Mike West. 2019. <span>‚ÄúVariable Prioritization in Nonlinear Black Box Methods: <span>A</span> Genetic Association Case Study.‚Äù</span> <em>The Annals of Applied Statistics</em> 13 (2): 958.
</div>
<div id="ref-fan2020interpretability" class="csl-entry">
Fan, Fenglei, Jinjun Xiong, and Ge Wang. 2020. <span>‚ÄúOn Interpretability of Artificial Neural Networks.‚Äù</span> <a href="https://arxiv.org/abs/2001.02522">https://arxiv.org/abs/2001.02522</a>.
</div>
<div id="ref-goan2020bayesian" class="csl-entry">
Goan, Ethan, and Clinton Fookes. 2020. <span>‚ÄúBayesian <span>Neural Networks</span>: <span>An Introduction</span> and <span>Survey</span>.‚Äù</span> In <em>Case <span>Studies</span> in <span>Applied Bayesian Data Science</span></em>, 45‚Äì87. <span>Springer</span>.
</div>
<div id="ref-goodfellow2016deep" class="csl-entry">
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep <span>Learning</span></em>. <span>MIT Press</span>.
</div>
<div id="ref-ish-horowicz2019interpreting" class="csl-entry">
Ish-Horowicz, Jonathan, Dana Udwin, Seth Flaxman, Sarah Filippi, and Lorin Crawford. 2019. <span>‚ÄúInterpreting Deep Neural Networks Through Variable Importance.‚Äù</span> <a href="https://arxiv.org/abs/1901.09839">https://arxiv.org/abs/1901.09839</a>.
</div>
</div>
<div style="page-break-after: always;"></div>


</section>


<div id="quarto-appendix" class="default"><aside id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Simulatability describes the overall, high-level understandability of the mechanisms underlying the model ‚Äì put simply, the less complex the model, the higher its simulatability. Decomposability concerns the extent to which the model can be taken apart into smaller pieces ‚Äì neural networks by there very nature are compositions of multiple layers. Finally, algorithmic transparency refers to the extent to which the training of the algorithm is well-understood and to some extent observable ‚Äì since DNNs generally deal with optimization of non-convex functions and often lack unique solution they are inherently intransparent.‚Ü©Ô∏é</p></li>
<li id="fn2"><p>For more detail see for example <a href="https://christophm.github.io/interpretable-ml-book/shapley.html">here</a>.‚Ü©Ô∏é</p></li>
<li id="fn3"><p>For simplicity I have omitted the deterministic bias term.‚Ü©Ô∏é</p></li>
</ol>
</aside><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick},
  title = {A Peek Inside the ‚Äú{Black} {Box}‚Äù - Interpreting Neural
    Networks},
  date = {2021-02-07},
  url = {https://www.paltmeyer.com/blog//blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2021. <span>‚ÄúA Peek Inside the <span>‚ÄòBlack
Box‚Äô</span> - Interpreting Neural Networks.‚Äù</span> February 7, 2021. <a href="https://www.paltmeyer.com/blog//blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks">https://www.paltmeyer.com/blog//blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks</a>.
</div></div></section></div> ]]></description>
  <category>deep learning</category>
  <category>explainable AI</category>
  <category>bayes</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html</guid>
  <pubDate>Sun, 07 Feb 2021 05:00:00 GMT</pubDate>
  <media:content url="https://www.paltmeyer.com/blog/blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/www/intro.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>How I‚Äôm building this website in R</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/how-i-m-building-this-website-in-r/index.html</link>
  <description><![CDATA[ 



<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Update on Feb 20, 2022</strong></p>
<p>The post below was written when I still used <code>blogdown</code> in combination with Hugo to build this blog. I have recently migrated the blog (along pretty much everything else I do) to <a href="https://quarto.org/">quarto</a>.</p>
<blockquote class="blockquote">
<p>Quarto¬Æ is an open-source scientific and technical publishing system built on Pandoc.</p>
</blockquote>
<p>Based on my first few experiences I would go further and say that quarto is <em>the only</em> open-source scientific and technical publishing system you‚Äôll ever need. The project is supported by RStudio and (unsurprisingly) Yihui Xie is one of the contributors. Go check it out!</p>
</div>
</div>
<section id="getting-started" class="level2">
<h2 class="anchored" data-anchor-id="getting-started">Getting started</h2>
<p>It turns out building a static website in R is remarkably easy, as long as you know your way around R Markdown. Knowledge of HTML and CSS helps, but is not strictly necessary and can be acquired along the way. My package of choice for this website is <code>blogdown</code> by <a href="https://yihui.org/">Yihui Xie</a> who has had a major impact on the R community through his many package contributions (<code>knitr</code>, <code>bookdown</code>, <code>pagedown</code>, ‚Ä¶) and certainly made my life a lot easier on many occasions.</p>
<p>To get started just follow the instructions on <code>blogdown</code>‚Äôs <a href="https://github.com/rstudio/blogdown">GitHub repository</a> or keep reading here for a high-level overview. Setting up a basic website in R requires exactly two steps:</p>
<ol type="1">
<li><p>Set up a local directory for the website. Let‚Äôs suppose you create it here <code>~/Documents/myAwesomeWebsite</code>.</p></li>
<li><p>In R, navigate to the directory and simply run <code>blogdown::newsite()</code>.</p></li>
</ol>
<p>This will set up a basic template which you can develop. Changing the theme and playing with the basic structure of the website is relatively straight-forward. Personally I have so far managed to work things out based on a working knowledge of HTML and CSS that I‚Äôve developed in the past through my work with R Shiny.</p>
</section>
<section id="deploying-your-website" class="level2">
<h2 class="anchored" data-anchor-id="deploying-your-website">Deploying your website</h2>
<p>There are various ways to deploy your website, i.e.&nbsp;make it accessible to the public. This website is deployed through GitHub pages. Detailed instructions on how to do this can be found <a href="https://bookdown.org/yihui/blogdown/github-pages.html">here</a>. Since I already had an existing local clone of my <code>pat-alt.github.io</code> repo, I just dropped it in the source directory of the website:</p>
<pre><code>source/
‚îÇ
‚îú‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ content/
‚îú‚îÄ‚îÄ themes/
‚îî‚îÄ‚îÄ ...

patalt.github.io/
‚îÇ
‚îú‚îÄ‚îÄ .git/
‚îú‚îÄ‚îÄ .nojekyll
‚îú‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ about/
‚îî‚îÄ‚îÄ ...</code></pre>
<p>After adding <code>publishDir: pat-alt.github.io</code> to my <code>config.yaml</code> and then running <code>blogdown::hugo_build()</code> the website was built inside the clone. All that was left to do was to commit changes from the local clone to the <code>pat-alt.github.io</code> remote repo. A few moments later the website was already up and running.</p>
</section>
<section id="why-all-the-trouble" class="level2">
<h2 class="anchored" data-anchor-id="why-all-the-trouble">Why all the trouble?</h2>
<p>There are certainly easier ways to build a website. But if like me you do pretty much all your work in R Markdown and want to share some of it, then you will love <code>blogdown</code>. The beauty of it is that once the basic infrastructure is set up, adding content is as simple as running the following wrapper function</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1">blogdown<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">new_post</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Your new post"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">ext =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".Rmd"</span>)</span></code></pre></div>
</div>
<p>where the first argument is just the title of your post and the <code>ext</code> argument can be used to specify that you want to create an R Markdown document that can include code chucks. The wrapper function will automatically set up a directory for your post under <code>/post/</code>. R Studio will redirect you to the relevant <code>.Rmd</code> file that you can then fill with content. By default that folder will look roughly like this:</p>
<pre><code>‚îú‚îÄ‚îÄ index.Rmd
‚îú‚îÄ‚îÄ index.html
‚îî‚îÄ‚îÄ index_files
    ‚îî‚îÄ‚îÄ header-attrs
        ‚îî‚îÄ‚îÄ header-attrs.js</code></pre>
</section>
<section id="a-simple-coding-example" class="level2">
<h2 class="anchored" data-anchor-id="a-simple-coding-example">A simple coding example</h2>
<p>As you can probably tell from the code chunks above this post was created just in the way I described. So I thought I might as well go ahead with a simple coding example to add some flavour. Suppose you have built some function that you think is worth sharing with the world or simply learned something new and interesting. As a case in point, I recently had a look at the <code>Rcpp</code> package and wrote a small program in C++ to be used in R. Since R Markdown supports <code>Rcpp</code> code chunks (along with Python, bash, SQL, ‚Ä¶) it is straight-forward to show-case that code on this website.</p>
<p>The program can be used to simulate data from a categorical distribution. This distribution describes the possible results of a random variable that can take on one of <img src="https://latex.codecogs.com/png.latex?K"> possible categories with different probabilities. In base R we could use <code>rmultinom(n=1000,1,p=c(0.5,0.1,0.4))</code> to simulate draws from one such distribution with three different categories. Alternatively, we could write the program in C++ as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb4-1"><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">#include </span><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">&lt;Rcpp.h&gt;</span></span>
<span id="cb4-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">using</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">namespace</span> Rcpp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// [[Rcpp::export]]</span></span>
<span id="cb4-5">NumericMatrix simCategorical<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">int</span> n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> NumericVector p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb4-6">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">int</span> k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">();</span></span>
<span id="cb4-7">  NumericMatrix mat<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">);</span></span>
<span id="cb4-8">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Normalise prob if necessary:</span></span>
<span id="cb4-9">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>sum<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)!=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb4-10">    p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>sum<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">);</span></span>
<span id="cb4-11">  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb4-12">  NumericVector emp_cdf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cumsum<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">);</span></span>
<span id="cb4-13">  NumericVector u <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Rcpp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span>runif<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">);</span></span>
<span id="cb4-14">  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Matrix for 1-hot-encoding:</span></span>
<span id="cb4-15">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">int</span> j <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> j <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> j<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">++)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb4-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Perform binary search:</span></span>
<span id="cb4-17">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">int</span> l <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb4-18">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">int</span> r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb4-19">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">double</span> target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> u<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span>j<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">];</span></span>
<span id="cb4-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">while</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>l <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb4-21">      <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">int</span> m <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> floor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">((</span>l<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">);</span></span>
<span id="cb4-22">      <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>emp_cdf<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span>m<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> target<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb4-23">        r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb4-24">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb4-25">        l <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb4-26">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb4-27">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb4-28">    mat<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span>r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span>j<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb4-29">  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb4-30">  <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> mat<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb4-31"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
<p>In terms of performance it turns out that the simple C++ program actually does somewhat better than the base R alternative:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(microbenchmark)</span>
<span id="cb5-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb5-3">n <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb5-4">p <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>)</span>
<span id="cb5-5">mb <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">microbenchmark</span>(</span>
<span id="cb5-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rmultinom"</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> {<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rmultinom</span>(n, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, p)},</span>
<span id="cb5-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Rcpp"</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">=</span> {<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">simCategorical</span>(n, p)}</span>
<span id="cb5-8">)</span>
<span id="cb5-9"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">autoplot</span>(mb)</span></code></pre></div>
</div>
</section>
<section id="embedding-existing-work" class="level2">
<h2 class="anchored" data-anchor-id="embedding-existing-work">Embedding existing work</h2>
<p>If you have some existing work that you would like to share you can just use it to overwrite the <code>index.Rmd</code> file. <code>blogdown</code> supports any kind of R Markdown documents so you can use all of your favourite markdown packages (<code>bookdown</code>, <code>pagedown</code>, ‚Ä¶). Just make sure to specify HTML output in the YAML header.</p>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<p>For more information about <code>blogdown</code> see <a href="https://bookdown.org/yihui/blogdown/">here</a>. To inspect the code that builds this website check out my <a href="https://github.com/pat-alt/patalt">GitHub repository</a>.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick},
  title = {How {I‚Äôm} Building This Website in {R}},
  date = {2021-02-02},
  url = {https://www.paltmeyer.com/blog//blog/posts/how-i-m-building-this-website-in-r},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick. 2021. <span>‚ÄúHow I‚Äôm Building This Website in
R.‚Äù</span> February 2, 2021. <a href="https://www.paltmeyer.com/blog//blog/posts/how-i-m-building-this-website-in-r">https://www.paltmeyer.com/blog//blog/posts/how-i-m-building-this-website-in-r</a>.
</div></div></section></div> ]]></description>
  <category>blogdown</category>
  <category>rmarkdown</category>
  <category>C++</category>
  <guid>https://www.paltmeyer.com/blog/blog/posts/how-i-m-building-this-website-in-r/index.html</guid>
  <pubDate>Tue, 02 Feb 2021 05:00:00 GMT</pubDate>
</item>
<item>
  <title>Welcome</title>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <dc:creator>Patrick Altmeyer</dc:creator>
  <link>https://www.paltmeyer.com/blog/blog/posts/welcome/index.html</link>
  <description><![CDATA[ 



<p>Welcome to my blog!</p>
<p>Having worked with R Markdown and some of <a href="https://yihui.org/">Yihui Xie</a>‚Äôs amazing packages for years, I have only now come across his <a href="https://bookdown.org/yihui/blogdown/">blogdown</a> package. For a while I have been thinking about a good way to share some of my work and actually started collecting snippets in a <a href="https://pat-alt.github.io/fromScratch/">Gitbook</a> through <a href="https://bookdown.org/yihui/bookdown/">bookdown</a> quite some time ago. While the book is a work-in-progress that I aim to finish eventually, I will use this website to regularly share content related to my work, research and other things.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Update on Feb 20, 2022</strong></p>
<p>I have recently migrated this blog and pretty much everything else I do to <a href="https://quarto.org/">quarto</a>.</p>
<blockquote class="blockquote">
<p>Quarto¬Æ is an open-source scientific and technical publishing system built on Pandoc.</p>
</blockquote>
<p>Based on my first few experiences I would go further and say that quarto is <em>the only</em> open-source scientific and technical publishing system you‚Äôll ever need. The project is supported by RStudio and (unsurprisingly) Yihui Xie is one of the contributors. Go check it out!</p>
</div>
</div>



<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2021,
  author = {Altmeyer, Patrick and Altmeyer, Patrick},
  title = {Welcome},
  date = {2021-02-01},
  url = {https://www.paltmeyer.com/blog//blog/posts/welcome},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2021" class="csl-entry quarto-appendix-citeas">
Altmeyer, Patrick, and Patrick Altmeyer. 2021. <span>‚ÄúWelcome.‚Äù</span>
February 1, 2021. <a href="https://www.paltmeyer.com/blog//blog/posts/welcome">https://www.paltmeyer.com/blog//blog/posts/welcome</a>.
</div></div></section></div> ]]></description>
  <guid>https://www.paltmeyer.com/blog/blog/posts/welcome/index.html</guid>
  <pubDate>Mon, 01 Feb 2021 05:00:00 GMT</pubDate>
</item>
</channel>
</rss>
