<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Patrick Altmeyer">
<meta name="dcterms.date" content="2022-04-20">
<meta name="description" content="This post introduces a new Julia package for generating counterfactual explanations. The package can be used to explain machine learning algorithms developed and trained in Julia as well as other popular programming languages like Python and R.">

<title>patalt - A new tool for explainable AI</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../..//www/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BEEZ30787D"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-BEEZ30787D', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="patalt - A new tool for explainable AI">
<meta property="og:description" content="This post introduces a new Julia package for generating counterfactual explanations. The package can be used to explain machine learning algorithms developed and trained in Julia as well as other popular programming languages like Python and R.">
<meta property="og:image" content="https://www.patalt.org/blog/posts/a-new-tool-for-explainable-ai/www/intro.gif">
<meta property="og:site_name" content="patalt">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../www/icon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">patalt</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/publications/index.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/talks/index.html"> 
<span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="../../../blog/index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pat-alt"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://julialang.social/@patalt" rel="me"> <i class="bi bi-mastodon" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#counterfactuals-for-image-data" id="toc-counterfactuals-for-image-data" class="nav-link active" data-scroll-target="#counterfactuals-for-image-data">Counterfactuals for image data 🖼</a>
  <ul class="collapse">
  <li><a href="#black-box-models" id="toc-black-box-models" class="nav-link" data-scroll-target="#black-box-models">Black-box models</a></li>
  <li><a href="#counterfactual-generators" id="toc-counterfactual-generators" class="nav-link" data-scroll-target="#counterfactual-generators">Counterfactual generators</a></li>
  <li><a href="#explanations" id="toc-explanations" class="nav-link" data-scroll-target="#explanations">Explanations</a></li>
  </ul></li>
  <li><a href="#language-interoperability" id="toc-language-interoperability" class="nav-link" data-scroll-target="#language-interoperability">Language interoperability 👥</a>
  <ul class="collapse">
  <li><a href="#explaining-a-torch-model" id="toc-explaining-a-torch-model" class="nav-link" data-scroll-target="#explaining-a-torch-model">Explaining a <code>torch</code> model</a></li>
  </ul></li>
  <li><a href="#we-need-you" id="toc-we-need-you" class="nav-link" data-scroll-target="#we-need-you">We need you! 🫵</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading">Further reading 📚</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/pat-alt/pat-alt.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">A new tool for explainable AI</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Counterfactual Explanations in Julia — Part I</p>
  <div class="quarto-categories">
    <div class="quarto-category">counterfactuals</div>
    <div class="quarto-category">explainable AI</div>
    <div class="quarto-category">Julia</div>
  </div>
  </div>

<div>
  <div class="description">
    <p>This post introduces a new Julia package for generating counterfactual explanations. The package can be used to explain machine learning algorithms developed and trained in Julia as well as other popular programming languages like Python and R.</p>
  </div>
</div>

<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://www.paltmeyer.com/">Patrick Altmeyer</a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://www.tudelft.nl/en/">
            Delft University of Technology
            </a>
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 20, 2022</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="intro-gif">
<figure class="figure">
<img src="www/intro.gif" class="figure-img">
<figcaption>
Turning a 9 (nine) into a 4 (four).
</figcaption>
</figure>
</div>
<!-- Intro -->
<p>Counterfactual explanations, which I introduced in one of my previous posts<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, offer a simple and intuitive way to explain black-box models without opening them. Still, as of today there exists only one open-source library that provides a unifying approach to generate and benchmark counterfactual explanations for models built and trained in Python <span class="citation" data-cites="pawelczyk2021carla">(<a href="#ref-pawelczyk2021carla" role="doc-biblioref">Pawelczyk et al. 2021</a>)</span>. This is great, but of limited use to users of other programming languages 🥲.</p>
<p>Enter <a href="https://www.patalt.org/CounterfactualExplanations.jl/stable/"><code>CounterfactualExplanations.jl</code></a>: a Julia package that can be used to explain machine learning algorithms developed and trained in Julia, Python and R. Counterfactual explanations fall into the broader category of explainable artificial intelligence (XAI).</p>
<p>Explainable AI typically involves models that are not inherently interpretable but require additional tools to be explainable to humans. Examples of the latter include ensembles, support vector machines and deep neural networks. This is not to be confused with interpretable AI, which involves models that are inherently interpretable and transparent such as general additive models (GAM), decision trees and rule-based models.</p>
<p>Some would argue that we best avoid explaining black-box models altogether <span class="citation" data-cites="rudin2019stop">(<a href="#ref-rudin2019stop" role="doc-biblioref">Rudin 2019</a>)</span> and instead focus solely on interpretable AI. While I agree that initial efforts should always be geared towards interpretable models, stopping there would entail missed opportunities and anyway is probably not very realistic in times of <a href="https://openai.com/blog/dall-e/">DALL<span class="math inline">\(\cdot\)</span>E</a> and Co.</p>
<blockquote class="blockquote">
<p>Even though […] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the “black box.”</p>
<p>— <span class="citation" data-cites="wachter2017counterfactual">Wachter, Mittelstadt, and Russell (<a href="#ref-wachter2017counterfactual" role="doc-biblioref">2017</a>)</span></p>
</blockquote>
<!-- Nut paragraph -->
<p>This post introduces the main functionality of the new Julia package. Following a motivating example using a model trained in Julia, we will see how easy the package can be adapted to work with models trained in Python and R. Since the motivation for this post is also to hopefully attract contributors, the final section outlines some of the exciting developments we have planned.</p>
<section id="counterfactuals-for-image-data" class="level2">
<h2 class="anchored" data-anchor-id="counterfactuals-for-image-data">Counterfactuals for image data 🖼</h2>
<p>To introduce counterfactual explanations I used a simple binary classification problem in my previous <a href="https://towardsdatascience.com/individual-recourse-for-black-box-models-5e9ed1e4b4cc">post</a>. It involved a linear classifier and a linearly separable, synthetic data set with just two features. This time we are going to step it up a notch: we will generate counterfactual explanations MNIST data. The MNIST dataset contains 60,000 training samples of handwritten digits in the form of 28x28 pixel grey-scale images <span class="citation" data-cites="lecun1998mnist">(<a href="#ref-lecun1998mnist" role="doc-biblioref">LeCun 1998</a>)</span>. Each image is associated with a label indicating the digit (0-9) that the image represents.</p>
<p>The <a href="https://www.patalt.org/CounterfactualExplanations.jl/stable/"><code>CounterfactualExplanations.jl</code></a> package ships with two black-box models that were trained to predict labels for this data: firstly, a simple multi-layer perceptron (MLP) and, secondly, a corresponding deep ensemble. Originally proposed by <span class="citation" data-cites="lakshminarayanan2016simple">Lakshminarayanan, Pritzel, and Blundell (<a href="#ref-lakshminarayanan2016simple" role="doc-biblioref">2017</a>)</span>, deep ensembles are really just ensembles of deep neural networks. They are still among the most popular approaches to Bayesian deep learning.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<section id="black-box-models" class="level3">
<h3 class="anchored" data-anchor-id="black-box-models">Black-box models</h3>
<p>The code below loads relevant packages along with the MNIST data and pre-trained models.</p>
<div id="54d7db74" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Load package, models and data:</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">using</span> <span class="bu">CounterfactualExplanations</span>, <span class="bu">Flux</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">using</span> <span class="bu">CounterfactualExplanations.Data</span>: mnist_data, mnist_model, mnist_ensemble</span>
<span id="cb1-4"><a href="#cb1-4"></a>data, X, ys <span class="op">=</span> <span class="fu">mnist_data</span>()</span>
<span id="cb1-5"><a href="#cb1-5"></a>model <span class="op">=</span> <span class="fu">mnist_model</span>()</span>
<span id="cb1-6"><a href="#cb1-6"></a>ensemble <span class="op">=</span> <span class="fu">mnist_ensemble</span>()</span>
<span id="cb1-7"><a href="#cb1-7"></a>counterfactual_data <span class="op">=</span> <span class="fu">CounterfactualData</span>(X,ys;domain<span class="op">=</span>(<span class="fl">0</span>,<span class="fl">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>While the package can currently handle a few simple classification models natively, it is designed to be easily extensible through users and contributors. Extending the package to deal with custom models typically involves only two simple steps:</p>
<ol type="1">
<li><strong>Subtyping</strong>: the custom model needs to be declared as a subtype of the package-internal type <code>AbstractFittedModel</code>.</li>
<li><strong>Multiple dispatch</strong>: the package-internal functions <code>logits</code> and <code>probs</code> need to be extended through custom methods for the new model type.</li>
</ol>
<p>The following code implements these two steps first for the MLP and then for the deep ensemble.</p>
<div id="33917159" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb2-1"><a href="#cb2-1"></a><span class="im">using</span> <span class="bu">CounterfactualExplanations.Models</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="im">import</span> <span class="bu">CounterfactualExplanations.Models</span>: logits, probs</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co"># MLP:</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co"># Step 1)</span></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="kw">struct</span> NeuralNetwork <span class="op">&lt;:</span><span class="dt"> Models.AbstractFittedModel</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>    model<span class="op">::</span><span class="dt">Any</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="kw">end</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="co"># Step 2)</span></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="fu">logits</span>(M<span class="op">::</span><span class="dt">NeuralNetwork</span>, X<span class="op">::</span><span class="dt">AbstractArray</span>) <span class="op">=</span> M.<span class="fu">model</span>(X)</span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="fu">probs</span>(M<span class="op">::</span><span class="dt">NeuralNetwork</span>, X<span class="op">::</span><span class="dt">AbstractArray</span>)<span class="op">=</span> <span class="fu">softmax</span>(<span class="fu">logits</span>(M, X))</span>
<span id="cb2-11"><a href="#cb2-11"></a>M <span class="op">=</span> <span class="fu">NeuralNetwork</span>(model)</span>
<span id="cb2-12"><a href="#cb2-12"></a></span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="co"># Deep ensemble:</span></span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="im">using</span> <span class="bu">Flux</span>: stack</span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="co"># Step 1)</span></span>
<span id="cb2-16"><a href="#cb2-16"></a><span class="kw">struct</span> FittedEnsemble <span class="op">&lt;:</span><span class="dt"> Models.AbstractFittedModel</span></span>
<span id="cb2-17"><a href="#cb2-17"></a>    ensemble<span class="op">::</span><span class="dt">AbstractArray</span></span>
<span id="cb2-18"><a href="#cb2-18"></a><span class="kw">end</span></span>
<span id="cb2-19"><a href="#cb2-19"></a><span class="co"># Step 2)</span></span>
<span id="cb2-20"><a href="#cb2-20"></a><span class="im">using</span> <span class="bu">Statistics</span></span>
<span id="cb2-21"><a href="#cb2-21"></a><span class="fu">logits</span>(M<span class="op">::</span><span class="dt">FittedEnsemble</span>, X<span class="op">::</span><span class="dt">AbstractArray</span>) <span class="op">=</span> <span class="fu">mean</span>(<span class="fu">stack</span>([<span class="fu">m</span>(X) for m <span class="kw">in</span> M.ensemble],<span class="fl">3</span>),dims<span class="op">=</span><span class="fl">3</span>)</span>
<span id="cb2-22"><a href="#cb2-22"></a><span class="fu">probs</span>(M<span class="op">::</span><span class="dt">FittedEnsemble</span>, X<span class="op">::</span><span class="dt">AbstractArray</span>) <span class="op">=</span> <span class="fu">mean</span>(<span class="fu">stack</span>([<span class="fu">softmax</span>(<span class="fu">m</span>(X)) for m <span class="kw">in</span> M.ensemble],<span class="fl">3</span>),dims<span class="op">=</span><span class="fl">3</span>)</span>
<span id="cb2-23"><a href="#cb2-23"></a>M_ensemble <span class="op">=</span> <span class="fu">FittedEnsemble</span>(ensemble)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="counterfactual-generators" class="level3">
<h3 class="anchored" data-anchor-id="counterfactual-generators">Counterfactual generators</h3>
<p>Next, we need to specify the counterfactual generators we want to use. The package currently ships with two default generators that both need gradient access: firstly, the generic generator introduced by <span class="citation" data-cites="wachter2017counterfactual">Wachter, Mittelstadt, and Russell (<a href="#ref-wachter2017counterfactual" role="doc-biblioref">2017</a>)</span> and, secondly, a greedy generator introduced by <span class="citation" data-cites="schut2021generating">Schut et al. (<a href="#ref-schut2021generating" role="doc-biblioref">2021</a>)</span>.</p>
<p>The greedy generator is designed to be used with models that incorporate uncertainty in their predictions such as the deep ensemble introduced above. It works for probabilistic (Bayesian) models, because they only produce high-confidence predictions in regions of the feature domain that are populated by training samples. As long as the model is expressive enough and well-specified, counterfactuals in these regions will always be realistic and unambiguous since by construction they should look very similar to training samples. Other popular approaches to counterfactual explanations like REVISE <span class="citation" data-cites="joshi2019realistic">(<a href="#ref-joshi2019realistic" role="doc-biblioref">Joshi et al. 2019</a>)</span> and CLUE <span class="citation" data-cites="antoran2020getting">(<a href="#ref-antoran2020getting" role="doc-biblioref">Antorán et al. 2020</a>)</span> also play with this simple idea.</p>
<p>The following code instantiates the two generators for the problem at hand.</p>
<div id="321ebc82" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><a href="#cb3-1"></a>generic <span class="op">=</span> <span class="fu">GenericGenerator</span>(;loss<span class="op">=:</span>logitcrossentropy)</span>
<span id="cb3-2"><a href="#cb3-2"></a>greedy <span class="op">=</span> <span class="fu">GreedyGenerator</span>(;loss<span class="op">=:</span>logitcrossentropy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="explanations" class="level3">
<h3 class="anchored" data-anchor-id="explanations">Explanations</h3>
<p>Once the model and counterfactual generator are specified, running counterfactual search is very easy using the package. For a given factual (<code>x</code>), target class (<code>target</code>) and data set (<code>counterfactual_data</code>), simply running</p>
<div id="0eece317" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb4-1"><a href="#cb4-1"></a><span class="fu">generate_counterfactual</span>(x, target, counterfactual_data, M, generic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>will generate the results, in this case using the generic generator (<code>generic</code>) for the MLP (<code>M</code>). Since we have specified two different black-box models and two different counterfactual generators, we have four combinations of a model and a generator in total. For each of these combinations I have used the <code>generate_counterfactual</code> function to produce the results in <a href="#fig-mnist-9to4" class="quarto-xref">Figure&nbsp;1</a>.</p>
<p>In every case the desired label switch is in fact achieved, but arguably from a human perspective only the counterfactuals for the deep ensemble look like a four. The generic generator produces mild perturbations in regions that seem irrelevant from a human perspective, but nonetheless yields a counterfactual that can pass as a four. The greedy approach clearly targets pixels at the top of the handwritten nine and yields the best result overall. For the non-Bayesian MLP, both the generic and the greedy approach generate counterfactuals that look much like adversarial examples: they perturb pixels in seemingly random regions on the image.</p>
<div id="fig-mnist-9to4" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mnist-9to4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="www/mnist_9_to_4.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mnist-9to4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Counterfactual explanations for MNIST: turning a nine (9) into a four (4).
</figcaption>
</figure>
</div>
</section>
</section>
<section id="language-interoperability" class="level2">
<h2 class="anchored" data-anchor-id="language-interoperability">Language interoperability 👥</h2>
<p>The Julia language offers unique support for programming language interoperability. For example, calling R or Python is made remarkably easy through <code>RCall.jl</code> and <code>PyCall.jl</code>, respectively. This functionality can be leveraged to use <code>CounterfactualExplanations.jl</code> to generate explanations for models that were developed in other programming languages. At this time there is no native support for foreign programming languages, but the following example involving a <code>torch</code> neural network trained in <code>R</code> demonstrates how versatile the package is.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<section id="explaining-a-torch-model" class="level3">
<h3 class="anchored" data-anchor-id="explaining-a-torch-model">Explaining a <code>torch</code> model</h3>
<p>We will consider a simple MLP trained for a binary classification task. As before we first need to adapt this custom model for use with our package. The code below the two necessary steps - sub-typing and method extension. Logits are returned by the <code>torch</code> model and copied from the R environment into the Julia scope. Probabilities are then computed inside the Julia scope by passing the logits through the sigmoid function.</p>
<div id="63ca46af" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">using</span> <span class="bu">Flux</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="im">using</span> <span class="bu">CounterfactualExplanations</span>, <span class="bu">CounterfactualExplanations.Models</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="im">import</span> <span class="bu">CounterfactualExplanations.Models</span>: logits, probs <span class="co"># import functions in order to extend</span></span>
<span id="cb5-4"><a href="#cb5-4"></a></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="co"># Step 1)</span></span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="kw">struct</span> TorchNetwork <span class="op">&lt;:</span><span class="dt"> Models.AbstractFittedModel</span></span>
<span id="cb5-7"><a href="#cb5-7"></a>    nn<span class="op">::</span><span class="dt">Any</span></span>
<span id="cb5-8"><a href="#cb5-8"></a><span class="kw">end</span></span>
<span id="cb5-9"><a href="#cb5-9"></a></span>
<span id="cb5-10"><a href="#cb5-10"></a><span class="co"># Step 2)</span></span>
<span id="cb5-11"><a href="#cb5-11"></a><span class="kw">function</span> <span class="fu">logits</span>(M<span class="op">::</span><span class="dt">TorchNetwork</span>, X<span class="op">::</span><span class="dt">AbstractArray</span>)</span>
<span id="cb5-12"><a href="#cb5-12"></a>  nn <span class="op">=</span> M.nn</span>
<span id="cb5-13"><a href="#cb5-13"></a>  y <span class="op">=</span> <span class="fu">rcopy</span>(R<span class="st">"as_array(</span><span class="sc">$</span>nn<span class="st">(torch_tensor(t(</span><span class="sc">$</span>X<span class="st">))))"</span>)</span>
<span id="cb5-14"><a href="#cb5-14"></a>  y <span class="op">=</span> <span class="fu">isa</span>(y, <span class="dt">AbstractArray</span>) ? y <span class="op">:</span> [y]</span>
<span id="cb5-15"><a href="#cb5-15"></a>  <span class="cf">return</span> y<span class="op">'</span></span>
<span id="cb5-16"><a href="#cb5-16"></a><span class="kw">end</span></span>
<span id="cb5-17"><a href="#cb5-17"></a><span class="kw">function</span> <span class="fu">probs</span>(M<span class="op">::</span><span class="dt">TorchNetwork</span>, X<span class="op">::</span><span class="dt">AbstractArray</span>)</span>
<span id="cb5-18"><a href="#cb5-18"></a>  <span class="cf">return</span> <span class="fu">σ</span>.(<span class="fu">logits</span>(M, X))</span>
<span id="cb5-19"><a href="#cb5-19"></a><span class="kw">end</span></span>
<span id="cb5-20"><a href="#cb5-20"></a>M <span class="op">=</span> <span class="fu">TorchNetwork</span>(R<span class="st">"model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Compared to models trained in Julia, we need to do a little more work at this point. Since our counterfactual generators need gradient access, we essentially need to allow our package to communicate with the R <code>torch</code> library. While this may sound daunting, it turns out to be quite manageable: all we have to do is respecify the function that computes the gradient with respect to the counterfactual loss function so that it can deal with the <code>TorchNetwork</code> type we defined above. That is all the adjustment needed to use <code>CounterfactualExplanations.jl</code> for our custom R model. <a href="#fig-torch" class="quarto-xref">Figure&nbsp;2</a> shows a counterfactual path for a randomly chosen sample with respect to the MLP trained in R.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Experimental functionality
</div>
</div>
<div class="callout-body-container callout-body">
<p>You may have stumbled across the term <em>respecify</em> above: does it really seem like a good idea to just replace an existing function from our package? Surely not! There are certainly better ways to go about this, which we will consider when adding native support for Python and R models in future package releases. Which brings us to our final section …</p>
</div>
</div>
<div id="06af8432" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><a href="#cb6-1"></a><span class="im">import</span> <span class="bu">CounterfactualExplanations.Generators</span>: ∂ℓ</span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="im">using</span> <span class="bu">LinearAlgebra</span></span>
<span id="cb6-3"><a href="#cb6-3"></a></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="co"># Countefactual loss:</span></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="kw">function</span> <span class="fu">∂ℓ</span>(</span>
<span id="cb6-6"><a href="#cb6-6"></a>    generator<span class="op">::</span><span class="dt">AbstractGradientBasedGenerator</span>, </span>
<span id="cb6-7"><a href="#cb6-7"></a>    counterfactual_state<span class="op">::</span><span class="dt">CounterfactualState</span>) </span>
<span id="cb6-8"><a href="#cb6-8"></a>  M <span class="op">=</span> counterfactual_state.M</span>
<span id="cb6-9"><a href="#cb6-9"></a>  nn <span class="op">=</span> M.nn</span>
<span id="cb6-10"><a href="#cb6-10"></a>  x′ <span class="op">=</span> counterfactual_state.x′</span>
<span id="cb6-11"><a href="#cb6-11"></a>  t <span class="op">=</span> counterfactual_state.target_encoded</span>
<span id="cb6-12"><a href="#cb6-12"></a>  R<span class="st">"""</span></span>
<span id="cb6-13"><a href="#cb6-13"></a><span class="st">  x &lt;- torch_tensor(</span><span class="sc">$</span>x<span class="st">′, requires_grad=TRUE)</span></span>
<span id="cb6-14"><a href="#cb6-14"></a><span class="st">  output &lt;- </span><span class="sc">$</span>nn<span class="st">(x)</span></span>
<span id="cb6-15"><a href="#cb6-15"></a><span class="st">  loss_fun &lt;- nnf_binary_cross_entropy_with_logits</span></span>
<span id="cb6-16"><a href="#cb6-16"></a><span class="st">  obj_loss &lt;- loss_fun(output,</span><span class="sc">$</span>t<span class="st">)</span></span>
<span id="cb6-17"><a href="#cb6-17"></a><span class="st">  obj_loss</span><span class="sc">$</span>backward<span class="st">()</span></span>
<span id="cb6-18"><a href="#cb6-18"></a><span class="st">  """</span></span>
<span id="cb6-19"><a href="#cb6-19"></a>  grad <span class="op">=</span> <span class="fu">rcopy</span>(R<span class="st">"as_array(x</span><span class="sc">$</span>grad<span class="st">)"</span>)</span>
<span id="cb6-20"><a href="#cb6-20"></a>  <span class="cf">return</span> grad</span>
<span id="cb6-21"><a href="#cb6-21"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="fig-torch" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-torch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="www/interop_r.gif" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-torch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Counterfactual path using the generic counterfactual generator for a model trained in R.
</figcaption>
</figure>
</div>
<!-- kicker -->
</section>
</section>
<section id="we-need-you" class="level2">
<h2 class="anchored" data-anchor-id="we-need-you">We need you! 🫵</h2>
<p>The ambition for <code>CounterfactualExplanations.jl</code> is to provide a go-to place for counterfactual explanations to the Julia community and beyond. This is a grand ambition, especially for a package that has so far been built by a single developer who has little prior experience with Julia. We would therefore very much like to invite community contributions. If you have an interest in trustworthy AI, the open-source community and Julia, please do get involved! This package is still in its early stages of development, so any kind of contribution is welcome: advice on the core package architecture, pull requests, issues, discussions and even just comments below would be much appreciated.</p>
<p>To give you a flavor of what type of future developments we envision, here is a non-exhaustive list:</p>
<ol type="1">
<li>Native support for additional counterfactual generators and predictive models including those built and trained in Python or R.</li>
<li>Additional datasets for testing, evaluation and benchmarking.</li>
<li>Improved preprocessing including native support for categorical features.</li>
<li>Support for regression models.</li>
</ol>
<p>Finally, if you like this project but don’t have much time, then simply sharing this article or starring the <a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl">repo</a> on GitHub would also go a long way.</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading 📚</h2>
<p>If you’re interested in learning more about this development, feel free to check out the following resources:</p>
<ul>
<li>Package docs: <a href="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/stable">[stable]</a>, <a href="https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/dev">[dev]</a>.</li>
<li><a href="https://www.patalt.org/CounterfactualExplanations.jl/stable/contributing/">Contributor’s guide</a>.</li>
<li><a href="https://github.com/juliatrustworthyai/CounterfactualExplanations.jl">GitHub repo</a>.</li>
</ul>


<!-- -->


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-antoran2020getting" class="csl-entry" role="listitem">
Antorán, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and José Miguel Hernández-Lobato. 2020. <span>“Getting a Clue: <span>A</span> Method for Explaining Uncertainty Estimates.”</span> <a href="https://arxiv.org/abs/2006.06848">https://arxiv.org/abs/2006.06848</a>.
</div>
<div id="ref-joshi2019realistic" class="csl-entry" role="listitem">
Joshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. <span>“Towards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.”</span> <a href="https://arxiv.org/abs/1907.09615">https://arxiv.org/abs/1907.09615</a>.
</div>
<div id="ref-lakshminarayanan2016simple" class="csl-entry" role="listitem">
Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2017. <span>“Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.”</span> <em>Advances in Neural Information Processing Systems</em> 30.
</div>
<div id="ref-lecun1998mnist" class="csl-entry" role="listitem">
LeCun, Yann. 1998. <span>“The MNIST Database of Handwritten Digits.”</span> http://yann.lecun.com/exdb/mnist/.
</div>
<div id="ref-pawelczyk2021carla" class="csl-entry" role="listitem">
Pawelczyk, Martin, Sascha Bielawski, Johannes van den Heuvel, Tobias Richter, and Gjergji Kasneci. 2021. <span>“CARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms.”</span> <a href="https://arxiv.org/abs/2108.00783">https://arxiv.org/abs/2108.00783</a>.
</div>
<div id="ref-rudin2019stop" class="csl-entry" role="listitem">
Rudin, Cynthia. 2019. <span>“Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.”</span> <em>Nature Machine Intelligence</em> 1 (5): 206–15. <a href="https://doi.org/10.1038/s42256-019-0048-x">https://doi.org/10.1038/s42256-019-0048-x</a>.
</div>
<div id="ref-schut2021generating" class="csl-entry" role="listitem">
Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. <span>“Generating <span>Interpretable Counterfactual Explanations By Implicit Minimisation</span> of <span>Epistemic</span> and <span>Aleatoric Uncertainties</span>.”</span> In <em>International <span>Conference</span> on <span>Artificial Intelligence</span> and <span>Statistics</span></em>, 1756–64. <span>PMLR</span>.
</div>
<div id="ref-wachter2017counterfactual" class="csl-entry" role="listitem">
Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. <span>“Counterfactual Explanations Without Opening the Black Box: <span>Automated</span> Decisions and the <span>GDPR</span>.”</span> <em>Harv. JL &amp; Tech.</em> 31: 841. <a href="https://doi.org/10.2139/ssrn.3063289">https://doi.org/10.2139/ssrn.3063289</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>See: [<a href="https://towardsdatascience.com/individual-recourse-for-black-box-models-5e9ed1e4b4cc">TDS</a>], [<a href="https://www.patalt.org/blog/posts/individual-recourse-for-black-box-models/">blog</a>]<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>For more information on Bayesian deep learning see my previous post: [<a href="https://towardsdatascience.com/go-deep-but-also-go-bayesian-ab25efa6f7b">TDS</a>], [<a href="https://www.patalt.org/blog/posts/effortsless-bayesian-dl/">blog</a>].<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The corresponding example involving <code>PyTorch</code> is analogous and therefore not included here. You may find it <a href="https://www.patalt.org/CounterfactualExplanations.jl/dev/tutorials/interop/">here</a>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2022,
  author = {Altmeyer, Patrick},
  title = {A New Tool for Explainable {AI}},
  date = {2022-04-20},
  url = {https://www.patalt.org//blog/posts/a-new-tool-for-explainable-ai},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2022" class="csl-entry quarto-appendix-citeas" role="listitem">
Altmeyer, Patrick. 2022. <span>“A New Tool for Explainable AI.”</span>
April 20, 2022. <a href="https://www.patalt.org//blog/posts/a-new-tool-for-explainable-ai">https://www.patalt.org//blog/posts/a-new-tool-for-explainable-ai</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="pat-alt/pat-alt.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb7" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb7-1"><a href="#cb7-1"></a><span class="co">---</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="an">title:</span><span class="co"> "A new tool for explainable AI"</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="an">subtitle:</span><span class="co"> "Counterfactual Explanations in Julia --- Part I"</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="an">date:</span><span class="co"> '2022-04-20'</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="an">description:</span><span class="co"> |</span></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="co">    This post introduces a new Julia package for generating counterfactual explanations. The package can be used to explain machine learning algorithms developed and trained in Julia as well as other popular programming languages like Python and R.</span></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="an">categories:</span></span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="co">  - counterfactuals</span></span>
<span id="cb7-9"><a href="#cb7-9"></a><span class="co">  - explainable AI</span></span>
<span id="cb7-10"><a href="#cb7-10"></a><span class="co">  - Julia</span></span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="an">image:</span><span class="co"> www/intro.gif</span></span>
<span id="cb7-12"><a href="#cb7-12"></a><span class="an">execute:</span></span>
<span id="cb7-13"><a href="#cb7-13"></a><span class="co">  eval: false</span></span>
<span id="cb7-14"><a href="#cb7-14"></a><span class="co">  echo: true</span></span>
<span id="cb7-15"><a href="#cb7-15"></a><span class="an">draft:</span><span class="co"> false</span></span>
<span id="cb7-16"><a href="#cb7-16"></a><span class="co">---</span></span>
<span id="cb7-17"><a href="#cb7-17"></a></span>
<span id="cb7-20"><a href="#cb7-20"></a><span class="in">```{julia}</span></span>
<span id="cb7-21"><a href="#cb7-21"></a><span class="in">#| echo: false</span></span>
<span id="cb7-22"><a href="#cb7-22"></a><span class="in">www_path = "posts/a-new-tool-for-explainable-ai/www"</span></span>
<span id="cb7-23"><a href="#cb7-23"></a><span class="in">```</span></span>
<span id="cb7-24"><a href="#cb7-24"></a></span>
<span id="cb7-25"><a href="#cb7-25"></a>&lt;div class="intro-gif"&gt;</span>
<span id="cb7-26"><a href="#cb7-26"></a>  &lt;figure&gt;</span>
<span id="cb7-27"><a href="#cb7-27"></a>    &lt;img src="www/intro.gif"&gt;</span>
<span id="cb7-28"><a href="#cb7-28"></a>    &lt;figcaption&gt;Turning a 9 (nine) into a 4 (four).&lt;/figcaption&gt;</span>
<span id="cb7-29"><a href="#cb7-29"></a>  &lt;/figure&gt;</span>
<span id="cb7-30"><a href="#cb7-30"></a>&lt;/div&gt;</span>
<span id="cb7-31"><a href="#cb7-31"></a></span>
<span id="cb7-32"><a href="#cb7-32"></a><span class="co">&lt;!-- Intro --&gt;</span></span>
<span id="cb7-33"><a href="#cb7-33"></a></span>
<span id="cb7-34"><a href="#cb7-34"></a>Counterfactual explanations, which I introduced in one of my previous posts^<span class="co">[</span><span class="ot">See: [[TDS](https://towardsdatascience.com/individual-recourse-for-black-box-models-5e9ed1e4b4cc)</span><span class="co">]</span>, [<span class="co">[</span><span class="ot">blog</span><span class="co">](https://www.patalt.org/blog/posts/individual-recourse-for-black-box-models/)</span>]], offer a simple and intuitive way to explain black-box models without opening them. Still, as of today there exists only one open-source library that provides a unifying approach to generate and benchmark counterfactual explanations for models built and trained in Python <span class="co">[</span><span class="ot">@pawelczyk2021carla</span><span class="co">]</span>. This is great, but of limited use to users of other programming languages 🥲. </span>
<span id="cb7-35"><a href="#cb7-35"></a></span>
<span id="cb7-36"><a href="#cb7-36"></a>Enter <span class="co">[</span><span class="ot">`CounterfactualExplanations.jl`</span><span class="co">](https://www.patalt.org/CounterfactualExplanations.jl/stable/)</span>: a Julia package that can be used to explain machine learning algorithms developed and trained in Julia, Python and R. Counterfactual explanations fall into the broader category of explainable artificial intelligence (XAI). </span>
<span id="cb7-37"><a href="#cb7-37"></a></span>
<span id="cb7-38"><a href="#cb7-38"></a>Explainable AI typically involves models that are not inherently interpretable but require additional tools to be explainable to humans. Examples of the latter include ensembles, support vector machines and deep neural networks. This is not to be confused with interpretable AI, which involves models that are inherently interpretable and transparent such as general additive models (GAM), decision trees and rule-based models. </span>
<span id="cb7-39"><a href="#cb7-39"></a></span>
<span id="cb7-40"><a href="#cb7-40"></a>Some would argue that we best avoid explaining black-box models altogether <span class="co">[</span><span class="ot">@rudin2019stop</span><span class="co">]</span> and instead focus solely on interpretable AI. While I agree that initial efforts should always be geared towards interpretable models, stopping there would entail missed opportunities and anyway is probably not very realistic in times of <span class="co">[</span><span class="ot">DALL$\cdot$E</span><span class="co">](https://openai.com/blog/dall-e/)</span> and Co.</span>
<span id="cb7-41"><a href="#cb7-41"></a></span>
<span id="cb7-42"><a href="#cb7-42"></a><span class="at">&gt; Even though </span><span class="co">[</span><span class="ot">...</span><span class="co">]</span><span class="at"> interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the “black box.”</span></span>
<span id="cb7-43"><a href="#cb7-43"></a><span class="at">&gt;</span></span>
<span id="cb7-44"><a href="#cb7-44"></a><span class="at">&gt; --- @wachter2017counterfactual</span></span>
<span id="cb7-45"><a href="#cb7-45"></a></span>
<span id="cb7-46"><a href="#cb7-46"></a><span class="co">&lt;!-- Nut paragraph --&gt;</span></span>
<span id="cb7-47"><a href="#cb7-47"></a></span>
<span id="cb7-48"><a href="#cb7-48"></a>This post introduces the main functionality of the new Julia package. Following a motivating example using a model trained in Julia, we will see how easy the package can be adapted to work with models trained in Python and R. Since the motivation for this post is also to hopefully attract contributors, the final section outlines some of the exciting developments we have planned. </span>
<span id="cb7-49"><a href="#cb7-49"></a></span>
<span id="cb7-50"><a href="#cb7-50"></a><span class="fu">## Counterfactuals for image data 🖼</span></span>
<span id="cb7-51"><a href="#cb7-51"></a></span>
<span id="cb7-52"><a href="#cb7-52"></a>To introduce counterfactual explanations I used a simple binary classification problem in my previous <span class="co">[</span><span class="ot">post</span><span class="co">](https://towardsdatascience.com/individual-recourse-for-black-box-models-5e9ed1e4b4cc)</span>. It involved a linear classifier and a linearly separable, synthetic data set with just two features. This time we are going to step it up a notch: we will generate counterfactual explanations MNIST data. The MNIST dataset contains 60,000 training samples of handwritten digits in the form of 28x28 pixel grey-scale images <span class="co">[</span><span class="ot">@lecun1998mnist</span><span class="co">]</span>. Each image is associated with a label indicating the digit (0-9) that the image represents. </span>
<span id="cb7-53"><a href="#cb7-53"></a></span>
<span id="cb7-54"><a href="#cb7-54"></a>The <span class="co">[</span><span class="ot">`CounterfactualExplanations.jl`</span><span class="co">](https://www.patalt.org/CounterfactualExplanations.jl/stable/)</span> package ships with two black-box models that were trained to predict labels for this data: firstly, a simple multi-layer perceptron (MLP) and, secondly, a corresponding deep ensemble. Originally proposed by @lakshminarayanan2016simple, deep ensembles are really just ensembles of deep neural networks. They are still among the most popular approaches to Bayesian deep learning.^<span class="co">[</span><span class="ot">For more information on Bayesian deep learning see my previous post: [[TDS](https://towardsdatascience.com/go-deep-but-also-go-bayesian-ab25efa6f7b)</span><span class="co">]</span>, [<span class="co">[</span><span class="ot">blog</span><span class="co">](https://www.patalt.org/blog/posts/effortsless-bayesian-dl/)</span>].] </span>
<span id="cb7-55"><a href="#cb7-55"></a></span>
<span id="cb7-56"><a href="#cb7-56"></a><span class="fu">### Black-box models</span></span>
<span id="cb7-57"><a href="#cb7-57"></a></span>
<span id="cb7-58"><a href="#cb7-58"></a>The code below loads relevant packages along with the MNIST data and pre-trained models. </span>
<span id="cb7-59"><a href="#cb7-59"></a></span>
<span id="cb7-62"><a href="#cb7-62"></a><span class="in">```{julia}</span></span>
<span id="cb7-63"><a href="#cb7-63"></a><span class="in"># Load package, models and data:</span></span>
<span id="cb7-64"><a href="#cb7-64"></a><span class="in">using CounterfactualExplanations, Flux</span></span>
<span id="cb7-65"><a href="#cb7-65"></a><span class="in">using CounterfactualExplanations.Data: mnist_data, mnist_model, mnist_ensemble</span></span>
<span id="cb7-66"><a href="#cb7-66"></a><span class="in">data, X, ys = mnist_data()</span></span>
<span id="cb7-67"><a href="#cb7-67"></a><span class="in">model = mnist_model()</span></span>
<span id="cb7-68"><a href="#cb7-68"></a><span class="in">ensemble = mnist_ensemble()</span></span>
<span id="cb7-69"><a href="#cb7-69"></a><span class="in">counterfactual_data = CounterfactualData(X,ys;domain=(0,1))</span></span>
<span id="cb7-70"><a href="#cb7-70"></a><span class="in">```</span></span>
<span id="cb7-71"><a href="#cb7-71"></a></span>
<span id="cb7-72"><a href="#cb7-72"></a>While the package can currently handle a few simple classification models natively, it is designed to be easily extensible through users and contributors. Extending the package to deal with custom models typically involves only two simple steps:</span>
<span id="cb7-73"><a href="#cb7-73"></a></span>
<span id="cb7-74"><a href="#cb7-74"></a><span class="ss">1. </span>**Subtyping**: the custom model needs to be declared as a subtype of the package-internal type <span class="in">`AbstractFittedModel`</span>.</span>
<span id="cb7-75"><a href="#cb7-75"></a><span class="ss">2. </span>**Multiple dispatch**: the package-internal functions <span class="in">`logits`</span> and <span class="in">`probs`</span> need to be extended through custom methods for the new model type.</span>
<span id="cb7-76"><a href="#cb7-76"></a></span>
<span id="cb7-77"><a href="#cb7-77"></a>The following code implements these two steps first for the MLP and then for the deep ensemble.</span>
<span id="cb7-78"><a href="#cb7-78"></a></span>
<span id="cb7-81"><a href="#cb7-81"></a><span class="in">```{julia}</span></span>
<span id="cb7-82"><a href="#cb7-82"></a><span class="in">using CounterfactualExplanations.Models</span></span>
<span id="cb7-83"><a href="#cb7-83"></a><span class="in">import CounterfactualExplanations.Models: logits, probs</span></span>
<span id="cb7-84"><a href="#cb7-84"></a><span class="in"># MLP:</span></span>
<span id="cb7-85"><a href="#cb7-85"></a><span class="in"># Step 1)</span></span>
<span id="cb7-86"><a href="#cb7-86"></a><span class="in">struct NeuralNetwork &lt;: Models.AbstractFittedModel</span></span>
<span id="cb7-87"><a href="#cb7-87"></a><span class="in">    model::Any</span></span>
<span id="cb7-88"><a href="#cb7-88"></a><span class="in">end</span></span>
<span id="cb7-89"><a href="#cb7-89"></a><span class="in"># Step 2)</span></span>
<span id="cb7-90"><a href="#cb7-90"></a><span class="in">logits(M::NeuralNetwork, X::AbstractArray) = M.model(X)</span></span>
<span id="cb7-91"><a href="#cb7-91"></a><span class="in">probs(M::NeuralNetwork, X::AbstractArray)= softmax(logits(M, X))</span></span>
<span id="cb7-92"><a href="#cb7-92"></a><span class="in">M = NeuralNetwork(model)</span></span>
<span id="cb7-93"><a href="#cb7-93"></a></span>
<span id="cb7-94"><a href="#cb7-94"></a><span class="in"># Deep ensemble:</span></span>
<span id="cb7-95"><a href="#cb7-95"></a><span class="in">using Flux: stack</span></span>
<span id="cb7-96"><a href="#cb7-96"></a><span class="in"># Step 1)</span></span>
<span id="cb7-97"><a href="#cb7-97"></a><span class="in">struct FittedEnsemble &lt;: Models.AbstractFittedModel</span></span>
<span id="cb7-98"><a href="#cb7-98"></a><span class="in">    ensemble::AbstractArray</span></span>
<span id="cb7-99"><a href="#cb7-99"></a><span class="in">end</span></span>
<span id="cb7-100"><a href="#cb7-100"></a><span class="in"># Step 2)</span></span>
<span id="cb7-101"><a href="#cb7-101"></a><span class="in">using Statistics</span></span>
<span id="cb7-102"><a href="#cb7-102"></a><span class="in">logits(M::FittedEnsemble, X::AbstractArray) = mean(stack([m(X) for m in M.ensemble],3),dims=3)</span></span>
<span id="cb7-103"><a href="#cb7-103"></a><span class="in">probs(M::FittedEnsemble, X::AbstractArray) = mean(stack([softmax(m(X)) for m in M.ensemble],3),dims=3)</span></span>
<span id="cb7-104"><a href="#cb7-104"></a><span class="in">M_ensemble = FittedEnsemble(ensemble)</span></span>
<span id="cb7-105"><a href="#cb7-105"></a><span class="in">```</span></span>
<span id="cb7-106"><a href="#cb7-106"></a></span>
<span id="cb7-107"><a href="#cb7-107"></a><span class="fu">### Counterfactual generators</span></span>
<span id="cb7-108"><a href="#cb7-108"></a></span>
<span id="cb7-109"><a href="#cb7-109"></a>Next, we need to specify the counterfactual generators we want to use. The package currently ships with two default generators that both need gradient access: firstly, the generic generator introduced by @wachter2017counterfactual and, secondly, a greedy generator introduced by @schut2021generating. </span>
<span id="cb7-110"><a href="#cb7-110"></a></span>
<span id="cb7-111"><a href="#cb7-111"></a>The greedy generator is designed to be used with models that incorporate uncertainty in their predictions such as the deep ensemble introduced above. It works for probabilistic (Bayesian) models, because they only produce high-confidence predictions in regions of the feature domain that are populated by training samples. As long as the model is expressive enough and well-specified, counterfactuals in these regions will always be realistic and unambiguous since by construction they should look very similar to training samples. Other popular approaches to counterfactual explanations like REVISE <span class="co">[</span><span class="ot">@joshi2019realistic</span><span class="co">]</span> and CLUE <span class="co">[</span><span class="ot">@antoran2020getting</span><span class="co">]</span> also play with this simple idea. </span>
<span id="cb7-112"><a href="#cb7-112"></a></span>
<span id="cb7-113"><a href="#cb7-113"></a>The following code instantiates the two generators for the problem at hand. </span>
<span id="cb7-114"><a href="#cb7-114"></a></span>
<span id="cb7-117"><a href="#cb7-117"></a><span class="in">```{julia}</span></span>
<span id="cb7-118"><a href="#cb7-118"></a><span class="in">generic = GenericGenerator(;loss=:logitcrossentropy)</span></span>
<span id="cb7-119"><a href="#cb7-119"></a><span class="in">greedy = GreedyGenerator(;loss=:logitcrossentropy)</span></span>
<span id="cb7-120"><a href="#cb7-120"></a><span class="in">```</span></span>
<span id="cb7-121"><a href="#cb7-121"></a></span>
<span id="cb7-122"><a href="#cb7-122"></a><span class="fu">### Explanations</span></span>
<span id="cb7-123"><a href="#cb7-123"></a></span>
<span id="cb7-126"><a href="#cb7-126"></a><span class="in">```{julia}</span></span>
<span id="cb7-127"><a href="#cb7-127"></a><span class="in">#| echo: false</span></span>
<span id="cb7-128"><a href="#cb7-128"></a><span class="in"># Randomly selected factual:</span></span>
<span id="cb7-129"><a href="#cb7-129"></a><span class="in">using Random</span></span>
<span id="cb7-130"><a href="#cb7-130"></a><span class="in">Random.seed!(1234)</span></span>
<span id="cb7-131"><a href="#cb7-131"></a><span class="in">x = Flux.unsqueeze(select_factual(counterfactual_data, rand(1:size(X)[2])),2)</span></span>
<span id="cb7-132"><a href="#cb7-132"></a><span class="in">target = 5</span></span>
<span id="cb7-133"><a href="#cb7-133"></a><span class="in">γ = 0.80</span></span>
<span id="cb7-134"><a href="#cb7-134"></a><span class="in">```</span></span>
<span id="cb7-135"><a href="#cb7-135"></a></span>
<span id="cb7-136"><a href="#cb7-136"></a>Once the model and counterfactual generator are specified, running counterfactual search is very easy using the package. For a given factual (<span class="in">`x`</span>), target class (<span class="in">`target`</span>) and data set (<span class="in">`counterfactual_data`</span>), simply running </span>
<span id="cb7-137"><a href="#cb7-137"></a></span>
<span id="cb7-140"><a href="#cb7-140"></a><span class="in">```{julia}</span></span>
<span id="cb7-141"><a href="#cb7-141"></a><span class="in">#| code-fold: false</span></span>
<span id="cb7-142"><a href="#cb7-142"></a><span class="in">generate_counterfactual(x, target, counterfactual_data, M, generic)</span></span>
<span id="cb7-143"><a href="#cb7-143"></a><span class="in">```</span> </span>
<span id="cb7-144"><a href="#cb7-144"></a></span>
<span id="cb7-145"><a href="#cb7-145"></a>will generate the results, in this case using the generic generator (<span class="in">`generic`</span>) for the MLP (<span class="in">`M`</span>). Since we have specified two different black-box models and two different counterfactual generators, we have four combinations of a model and a generator in total. For each of these combinations I have used the <span class="in">`generate_counterfactual`</span> function to produce the results in @fig-mnist-9to4. </span>
<span id="cb7-146"><a href="#cb7-146"></a></span>
<span id="cb7-147"><a href="#cb7-147"></a>In every case the desired label switch is in fact achieved, but arguably from a human perspective only the counterfactuals for the deep ensemble look like a four. The generic generator produces mild perturbations in regions that seem irrelevant from a human perspective, but nonetheless yields a counterfactual that can pass as a four. The greedy approach clearly targets pixels at the top of the handwritten nine and yields the best result overall. For the non-Bayesian MLP, both the generic and the greedy approach generate counterfactuals that look much like adversarial examples: they perturb pixels in seemingly random regions on the image.</span>
<span id="cb7-148"><a href="#cb7-148"></a></span>
<span id="cb7-151"><a href="#cb7-151"></a><span class="in">```{julia}</span></span>
<span id="cb7-152"><a href="#cb7-152"></a><span class="in">#| echo: false</span></span>
<span id="cb7-153"><a href="#cb7-153"></a><span class="in">generators = Dict(</span></span>
<span id="cb7-154"><a href="#cb7-154"></a><span class="in">    "Wachter" =&gt; generic,</span></span>
<span id="cb7-155"><a href="#cb7-155"></a><span class="in">    "Greedy" =&gt; greedy</span></span>
<span id="cb7-156"><a href="#cb7-156"></a><span class="in">)</span></span>
<span id="cb7-157"><a href="#cb7-157"></a><span class="in">models = Dict("MLP" =&gt; M, "Ensemble" =&gt; M_ensemble)</span></span>
<span id="cb7-158"><a href="#cb7-158"></a></span>
<span id="cb7-159"><a href="#cb7-159"></a><span class="in"># Plotting utilities:</span></span>
<span id="cb7-160"><a href="#cb7-160"></a><span class="in">using Images</span></span>
<span id="cb7-161"><a href="#cb7-161"></a><span class="in">using MLDatasets.MNIST: convert2image</span></span>
<span id="cb7-162"><a href="#cb7-162"></a></span>
<span id="cb7-163"><a href="#cb7-163"></a><span class="in">input_dim = size(X)[1]</span></span>
<span id="cb7-164"><a href="#cb7-164"></a></span>
<span id="cb7-165"><a href="#cb7-165"></a><span class="in">using Flux: onecold</span></span>
<span id="cb7-166"><a href="#cb7-166"></a></span>
<span id="cb7-167"><a href="#cb7-167"></a><span class="in"># Specific image:</span></span>
<span id="cb7-168"><a href="#cb7-168"></a><span class="in">function from_digit_to_digit(from::AbstractArray, to::Number, generator, model; γ=γ, x=X, y=ys, seed=1234, T=1000)</span></span>
<span id="cb7-169"><a href="#cb7-169"></a><span class="in">    </span></span>
<span id="cb7-170"><a href="#cb7-170"></a><span class="in">    x = from</span></span>
<span id="cb7-171"><a href="#cb7-171"></a><span class="in">    target = to + 1</span></span>
<span id="cb7-172"><a href="#cb7-172"></a><span class="in">    counterfactuals = Dict()</span></span>
<span id="cb7-173"><a href="#cb7-173"></a></span>
<span id="cb7-174"><a href="#cb7-174"></a><span class="in">    for (k_gen,v_gen) ∈ generators</span></span>
<span id="cb7-175"><a href="#cb7-175"></a><span class="in">        for (k_mod,v_mod) ∈ models </span></span>
<span id="cb7-176"><a href="#cb7-176"></a><span class="in">            k = k_mod * " - " * k_gen</span></span>
<span id="cb7-177"><a href="#cb7-177"></a><span class="in">            counterfactuals[k] = generate_counterfactual(x, target, counterfactual_data, v_mod, v_gen; T=T, γ=γ)</span></span>
<span id="cb7-178"><a href="#cb7-178"></a><span class="in">        end</span></span>
<span id="cb7-179"><a href="#cb7-179"></a><span class="in">    end</span></span>
<span id="cb7-180"><a href="#cb7-180"></a></span>
<span id="cb7-181"><a href="#cb7-181"></a><span class="in">    return counterfactuals</span></span>
<span id="cb7-182"><a href="#cb7-182"></a></span>
<span id="cb7-183"><a href="#cb7-183"></a><span class="in">end</span></span>
<span id="cb7-184"><a href="#cb7-184"></a></span>
<span id="cb7-185"><a href="#cb7-185"></a><span class="in"># Specific digit:</span></span>
<span id="cb7-186"><a href="#cb7-186"></a><span class="in">function from_digit_to_digit(from::Number, to::Number, generator::Dict, model::Dict; γ=γ, x=X, y=ys, seed=1234, T=1000)</span></span>
<span id="cb7-187"><a href="#cb7-187"></a></span>
<span id="cb7-188"><a href="#cb7-188"></a><span class="in">    Random.seed!(seed)</span></span>
<span id="cb7-189"><a href="#cb7-189"></a></span>
<span id="cb7-190"><a href="#cb7-190"></a><span class="in">    candidates = findall(onecold(y,0:9).==from)</span></span>
<span id="cb7-191"><a href="#cb7-191"></a><span class="in">    x = Flux.unsqueeze(x[:,rand(candidates)],2)</span></span>
<span id="cb7-192"><a href="#cb7-192"></a><span class="in">    target = to + 1</span></span>
<span id="cb7-193"><a href="#cb7-193"></a><span class="in">    counterfactuals = Dict()</span></span>
<span id="cb7-194"><a href="#cb7-194"></a></span>
<span id="cb7-195"><a href="#cb7-195"></a><span class="in">    for (k_gen,v_gen) ∈ generators</span></span>
<span id="cb7-196"><a href="#cb7-196"></a><span class="in">        for (k_mod,v_mod) ∈ models </span></span>
<span id="cb7-197"><a href="#cb7-197"></a><span class="in">            k = k_mod * " - " * k_gen</span></span>
<span id="cb7-198"><a href="#cb7-198"></a><span class="in">            counterfactuals[k] = generate_counterfactual(x, target, counterfactual_data, v_mod, v_gen; T=T, γ=γ)</span></span>
<span id="cb7-199"><a href="#cb7-199"></a><span class="in">        end</span></span>
<span id="cb7-200"><a href="#cb7-200"></a><span class="in">    end</span></span>
<span id="cb7-201"><a href="#cb7-201"></a></span>
<span id="cb7-202"><a href="#cb7-202"></a><span class="in">    return counterfactuals</span></span>
<span id="cb7-203"><a href="#cb7-203"></a><span class="in">end</span></span>
<span id="cb7-204"><a href="#cb7-204"></a><span class="in">```</span></span>
<span id="cb7-205"><a href="#cb7-205"></a></span>
<span id="cb7-208"><a href="#cb7-208"></a><span class="in">```{julia}</span></span>
<span id="cb7-209"><a href="#cb7-209"></a><span class="in">#| echo: false</span></span>
<span id="cb7-210"><a href="#cb7-210"></a><span class="in">using Plots</span></span>
<span id="cb7-211"><a href="#cb7-211"></a><span class="in">to = 4</span></span>
<span id="cb7-212"><a href="#cb7-212"></a><span class="in">counterfactuals = from_digit_to_digit(x,to,generators,models)</span></span>
<span id="cb7-213"><a href="#cb7-213"></a><span class="in">plts =  first(values(counterfactuals)).x |&gt; x -&gt; plot(convert2image(reshape(x,Int(√(input_dim)),Int(√(input_dim)))),title="Original")</span></span>
<span id="cb7-214"><a href="#cb7-214"></a><span class="in">plts = vcat(plts, [plot(convert2image(reshape(v.x′,Int(√(input_dim)),Int(√(input_dim)))),title=k) for (k,v) in counterfactuals])</span></span>
<span id="cb7-215"><a href="#cb7-215"></a><span class="in">plt = plot(plts...,layout=(1,length(plts)),axis=nothing, size=(1200,300))</span></span>
<span id="cb7-216"><a href="#cb7-216"></a><span class="in">savefig(plt, joinpath(www_path, "mnist_9_to_4.png"))</span></span>
<span id="cb7-217"><a href="#cb7-217"></a><span class="in">```</span></span>
<span id="cb7-218"><a href="#cb7-218"></a></span>
<span id="cb7-219"><a href="#cb7-219"></a><span class="al">![Counterfactual explanations for MNIST: turning a nine (9) into a four (4).](www/mnist_9_to_4.png)</span>{#fig-mnist-9to4}</span>
<span id="cb7-220"><a href="#cb7-220"></a></span>
<span id="cb7-223"><a href="#cb7-223"></a><span class="in">```{julia}</span></span>
<span id="cb7-224"><a href="#cb7-224"></a><span class="in">#| echo: false</span></span>
<span id="cb7-225"><a href="#cb7-225"></a><span class="in">X = counterfactuals["Ensemble - Greedy"].search[:path]</span></span>
<span id="cb7-226"><a href="#cb7-226"></a><span class="in">anim = @animate for t in 1:length(X)</span></span>
<span id="cb7-227"><a href="#cb7-227"></a><span class="in">    plot(convert2image(reshape(X[t],Int(√(input_dim)),Int(√(input_dim)))),axis=nothing,size=(300,300))</span></span>
<span id="cb7-228"><a href="#cb7-228"></a><span class="in">end every 10</span></span>
<span id="cb7-229"><a href="#cb7-229"></a><span class="in">gif(anim, joinpath(www_path, "intro.gif"))</span></span>
<span id="cb7-230"><a href="#cb7-230"></a><span class="in">```</span></span>
<span id="cb7-231"><a href="#cb7-231"></a></span>
<span id="cb7-232"><a href="#cb7-232"></a><span class="fu">## Language interoperability 👥</span></span>
<span id="cb7-233"><a href="#cb7-233"></a></span>
<span id="cb7-234"><a href="#cb7-234"></a>The Julia language offers unique support for programming language interoperability. For example, calling R or Python is made remarkably easy through <span class="in">`RCall.jl`</span> and <span class="in">`PyCall.jl`</span>, respectively. This functionality can be leveraged to use <span class="in">`CounterfactualExplanations.jl`</span> to generate explanations for models that were developed in other programming languages. At this time there is no native support for foreign programming languages, but the following example involving a <span class="in">`torch`</span> neural network trained in <span class="in">`R`</span> demonstrates how versatile the package is.^<span class="co">[</span><span class="ot">The corresponding example involving `PyTorch` is analogous and therefore not included here. You may find it [here](https://www.patalt.org/CounterfactualExplanations.jl/dev/tutorials/interop/).</span><span class="co">]</span></span>
<span id="cb7-235"><a href="#cb7-235"></a></span>
<span id="cb7-236"><a href="#cb7-236"></a><span class="fu">### Explaining a `torch` model </span></span>
<span id="cb7-237"><a href="#cb7-237"></a></span>
<span id="cb7-240"><a href="#cb7-240"></a><span class="in">```{julia}</span></span>
<span id="cb7-241"><a href="#cb7-241"></a><span class="in">#| echo: false</span></span>
<span id="cb7-242"><a href="#cb7-242"></a><span class="in">using Random</span></span>
<span id="cb7-243"><a href="#cb7-243"></a><span class="in"># Some random data:</span></span>
<span id="cb7-244"><a href="#cb7-244"></a><span class="in">Random.seed!(1234)</span></span>
<span id="cb7-245"><a href="#cb7-245"></a><span class="in">N = 100</span></span>
<span id="cb7-246"><a href="#cb7-246"></a><span class="in">using CounterfactualExplanations</span></span>
<span id="cb7-247"><a href="#cb7-247"></a><span class="in">using CounterfactualExplanations.Data</span></span>
<span id="cb7-248"><a href="#cb7-248"></a><span class="in">xs, ys = Data.toy_data_non_linear(N)</span></span>
<span id="cb7-249"><a href="#cb7-249"></a><span class="in">X = hcat(xs...)</span></span>
<span id="cb7-250"><a href="#cb7-250"></a><span class="in">counterfactual_data = CounterfactualData(X,ys')</span></span>
<span id="cb7-251"><a href="#cb7-251"></a><span class="in">```</span></span>
<span id="cb7-252"><a href="#cb7-252"></a></span>
<span id="cb7-255"><a href="#cb7-255"></a><span class="in">```{julia}</span></span>
<span id="cb7-256"><a href="#cb7-256"></a><span class="in">#| echo: false</span></span>
<span id="cb7-257"><a href="#cb7-257"></a><span class="in">using RCall</span></span>
<span id="cb7-258"><a href="#cb7-258"></a><span class="in">R"""</span></span>
<span id="cb7-259"><a href="#cb7-259"></a><span class="in"># Data</span></span>
<span id="cb7-260"><a href="#cb7-260"></a><span class="in">library(torch)</span></span>
<span id="cb7-261"><a href="#cb7-261"></a><span class="in">X &lt;- torch_tensor(t($X))</span></span>
<span id="cb7-262"><a href="#cb7-262"></a><span class="in">ys &lt;- torch_tensor($ys)</span></span>
<span id="cb7-263"><a href="#cb7-263"></a></span>
<span id="cb7-264"><a href="#cb7-264"></a><span class="in"># Model:</span></span>
<span id="cb7-265"><a href="#cb7-265"></a><span class="in">mlp &lt;- nn_module(</span></span>
<span id="cb7-266"><a href="#cb7-266"></a><span class="in">  initialize = function() {</span></span>
<span id="cb7-267"><a href="#cb7-267"></a><span class="in">    self$layer1 &lt;- nn_linear(2, 32)</span></span>
<span id="cb7-268"><a href="#cb7-268"></a><span class="in">    self$layer2 &lt;- nn_linear(32, 1)</span></span>
<span id="cb7-269"><a href="#cb7-269"></a><span class="in">  },</span></span>
<span id="cb7-270"><a href="#cb7-270"></a><span class="in">  forward = function(input) {</span></span>
<span id="cb7-271"><a href="#cb7-271"></a><span class="in">    input &lt;- self$layer1(input)</span></span>
<span id="cb7-272"><a href="#cb7-272"></a><span class="in">    input &lt;- nnf_sigmoid(input)</span></span>
<span id="cb7-273"><a href="#cb7-273"></a><span class="in">    input &lt;- self$layer2(input)</span></span>
<span id="cb7-274"><a href="#cb7-274"></a><span class="in">    input</span></span>
<span id="cb7-275"><a href="#cb7-275"></a><span class="in">  }</span></span>
<span id="cb7-276"><a href="#cb7-276"></a><span class="in">)</span></span>
<span id="cb7-277"><a href="#cb7-277"></a><span class="in">model &lt;- mlp()</span></span>
<span id="cb7-278"><a href="#cb7-278"></a><span class="in">optimizer &lt;- optim_adam(model$parameters, lr = 0.1)</span></span>
<span id="cb7-279"><a href="#cb7-279"></a><span class="in">loss_fun &lt;- nnf_binary_cross_entropy_with_logits</span></span>
<span id="cb7-280"><a href="#cb7-280"></a></span>
<span id="cb7-281"><a href="#cb7-281"></a><span class="in">for (epoch in 1:100) {</span></span>
<span id="cb7-282"><a href="#cb7-282"></a></span>
<span id="cb7-283"><a href="#cb7-283"></a><span class="in">  model$train()</span></span>
<span id="cb7-284"><a href="#cb7-284"></a><span class="in">  train_losses &lt;- c()  </span></span>
<span id="cb7-285"><a href="#cb7-285"></a></span>
<span id="cb7-286"><a href="#cb7-286"></a><span class="in">  optimizer$zero_grad()</span></span>
<span id="cb7-287"><a href="#cb7-287"></a><span class="in">  output &lt;- model(X)</span></span>
<span id="cb7-288"><a href="#cb7-288"></a><span class="in">  loss &lt;- loss_fun(output[,1], ys)</span></span>
<span id="cb7-289"><a href="#cb7-289"></a><span class="in">  loss$backward()</span></span>
<span id="cb7-290"><a href="#cb7-290"></a><span class="in">  optimizer$step()</span></span>
<span id="cb7-291"><a href="#cb7-291"></a><span class="in">  train_losses &lt;- c(train_losses, loss$item())</span></span>
<span id="cb7-292"><a href="#cb7-292"></a><span class="in">  </span></span>
<span id="cb7-293"><a href="#cb7-293"></a><span class="in">  cat(sprintf("Loss at epoch %d: %3f\n", epoch, mean(train_losses)))</span></span>
<span id="cb7-294"><a href="#cb7-294"></a><span class="in">}</span></span>
<span id="cb7-295"><a href="#cb7-295"></a><span class="in">"""</span></span>
<span id="cb7-296"><a href="#cb7-296"></a><span class="in">```</span></span>
<span id="cb7-297"><a href="#cb7-297"></a></span>
<span id="cb7-298"><a href="#cb7-298"></a>We will consider a simple MLP trained for a binary classification task. As before we first need to adapt this custom model for use with our package. The code below the two necessary steps - sub-typing and method extension. Logits are returned by the <span class="in">`torch`</span> model and copied from the R environment into the Julia scope. Probabilities are then computed inside the Julia scope by passing the logits through the sigmoid function.</span>
<span id="cb7-299"><a href="#cb7-299"></a></span>
<span id="cb7-302"><a href="#cb7-302"></a><span class="in">```{julia}</span></span>
<span id="cb7-303"><a href="#cb7-303"></a><span class="in">using Flux</span></span>
<span id="cb7-304"><a href="#cb7-304"></a><span class="in">using CounterfactualExplanations, CounterfactualExplanations.Models</span></span>
<span id="cb7-305"><a href="#cb7-305"></a><span class="in">import CounterfactualExplanations.Models: logits, probs # import functions in order to extend</span></span>
<span id="cb7-306"><a href="#cb7-306"></a></span>
<span id="cb7-307"><a href="#cb7-307"></a><span class="in"># Step 1)</span></span>
<span id="cb7-308"><a href="#cb7-308"></a><span class="in">struct TorchNetwork &lt;: Models.AbstractFittedModel</span></span>
<span id="cb7-309"><a href="#cb7-309"></a><span class="in">    nn::Any</span></span>
<span id="cb7-310"><a href="#cb7-310"></a><span class="in">end</span></span>
<span id="cb7-311"><a href="#cb7-311"></a></span>
<span id="cb7-312"><a href="#cb7-312"></a><span class="in"># Step 2)</span></span>
<span id="cb7-313"><a href="#cb7-313"></a><span class="in">function logits(M::TorchNetwork, X::AbstractArray)</span></span>
<span id="cb7-314"><a href="#cb7-314"></a><span class="in">  nn = M.nn</span></span>
<span id="cb7-315"><a href="#cb7-315"></a><span class="in">  y = rcopy(R"as_array($nn(torch_tensor(t($X))))")</span></span>
<span id="cb7-316"><a href="#cb7-316"></a><span class="in">  y = isa(y, AbstractArray) ? y : [y]</span></span>
<span id="cb7-317"><a href="#cb7-317"></a><span class="in">  return y'</span></span>
<span id="cb7-318"><a href="#cb7-318"></a><span class="in">end</span></span>
<span id="cb7-319"><a href="#cb7-319"></a><span class="in">function probs(M::TorchNetwork, X::AbstractArray)</span></span>
<span id="cb7-320"><a href="#cb7-320"></a><span class="in">  return σ.(logits(M, X))</span></span>
<span id="cb7-321"><a href="#cb7-321"></a><span class="in">end</span></span>
<span id="cb7-322"><a href="#cb7-322"></a><span class="in">M = TorchNetwork(R"model")</span></span>
<span id="cb7-323"><a href="#cb7-323"></a><span class="in">```</span></span>
<span id="cb7-324"><a href="#cb7-324"></a></span>
<span id="cb7-325"><a href="#cb7-325"></a>Compared to models trained in Julia, we need to do a little more work at this point. Since our counterfactual generators need gradient access, we essentially need to allow our package to communicate with the R <span class="in">`torch`</span> library. While this may sound daunting, it turns out to be quite manageable: all we have to do is respecify the function that computes the gradient with respect to the counterfactual loss function so that it can deal with the <span class="in">`TorchNetwork`</span> type we defined above. That is all the adjustment needed to use <span class="in">`CounterfactualExplanations.jl`</span> for our custom R model. @fig-torch shows a counterfactual path for a randomly chosen sample with respect to the MLP trained in R.</span>
<span id="cb7-326"><a href="#cb7-326"></a></span>
<span id="cb7-327"><a href="#cb7-327"></a>:::{.callout-caution}</span>
<span id="cb7-328"><a href="#cb7-328"></a><span class="fu">## Experimental functionality</span></span>
<span id="cb7-329"><a href="#cb7-329"></a></span>
<span id="cb7-330"><a href="#cb7-330"></a>You may have stumbled across the term *respecify* above: does it really seem like a good idea to just replace an existing function from our package? Surely not! There are certainly better ways to go about this, which we will consider when adding native support for Python and R models in future package releases. Which brings us to our final section ...</span>
<span id="cb7-331"><a href="#cb7-331"></a>:::</span>
<span id="cb7-332"><a href="#cb7-332"></a></span>
<span id="cb7-335"><a href="#cb7-335"></a><span class="in">```{julia}</span></span>
<span id="cb7-336"><a href="#cb7-336"></a><span class="in">import CounterfactualExplanations.Generators: ∂ℓ</span></span>
<span id="cb7-337"><a href="#cb7-337"></a><span class="in">using LinearAlgebra</span></span>
<span id="cb7-338"><a href="#cb7-338"></a></span>
<span id="cb7-339"><a href="#cb7-339"></a><span class="in"># Countefactual loss:</span></span>
<span id="cb7-340"><a href="#cb7-340"></a><span class="in">function ∂ℓ(</span></span>
<span id="cb7-341"><a href="#cb7-341"></a><span class="in">    generator::AbstractGradientBasedGenerator, </span></span>
<span id="cb7-342"><a href="#cb7-342"></a><span class="in">    counterfactual_state::CounterfactualState) </span></span>
<span id="cb7-343"><a href="#cb7-343"></a><span class="in">  M = counterfactual_state.M</span></span>
<span id="cb7-344"><a href="#cb7-344"></a><span class="in">  nn = M.nn</span></span>
<span id="cb7-345"><a href="#cb7-345"></a><span class="in">  x′ = counterfactual_state.x′</span></span>
<span id="cb7-346"><a href="#cb7-346"></a><span class="in">  t = counterfactual_state.target_encoded</span></span>
<span id="cb7-347"><a href="#cb7-347"></a><span class="in">  R"""</span></span>
<span id="cb7-348"><a href="#cb7-348"></a><span class="in">  x &lt;- torch_tensor($x′, requires_grad=TRUE)</span></span>
<span id="cb7-349"><a href="#cb7-349"></a><span class="in">  output &lt;- $nn(x)</span></span>
<span id="cb7-350"><a href="#cb7-350"></a><span class="in">  loss_fun &lt;- nnf_binary_cross_entropy_with_logits</span></span>
<span id="cb7-351"><a href="#cb7-351"></a><span class="in">  obj_loss &lt;- loss_fun(output,$t)</span></span>
<span id="cb7-352"><a href="#cb7-352"></a><span class="in">  obj_loss$backward()</span></span>
<span id="cb7-353"><a href="#cb7-353"></a><span class="in">  """</span></span>
<span id="cb7-354"><a href="#cb7-354"></a><span class="in">  grad = rcopy(R"as_array(x$grad)")</span></span>
<span id="cb7-355"><a href="#cb7-355"></a><span class="in">  return grad</span></span>
<span id="cb7-356"><a href="#cb7-356"></a><span class="in">end</span></span>
<span id="cb7-357"><a href="#cb7-357"></a><span class="in">```</span></span>
<span id="cb7-358"><a href="#cb7-358"></a></span>
<span id="cb7-361"><a href="#cb7-361"></a><span class="in">```{julia}</span></span>
<span id="cb7-362"><a href="#cb7-362"></a><span class="in">#| echo: false</span></span>
<span id="cb7-363"><a href="#cb7-363"></a><span class="in"># Randomly selected factual:</span></span>
<span id="cb7-364"><a href="#cb7-364"></a><span class="in">Random.seed!(123)</span></span>
<span id="cb7-365"><a href="#cb7-365"></a><span class="in">x = select_factual(counterfactual_data, rand(1:length(xs))) </span></span>
<span id="cb7-366"><a href="#cb7-366"></a><span class="in">y = round(probs(M, x)[1])</span></span>
<span id="cb7-367"><a href="#cb7-367"></a><span class="in">target = ifelse(y==1.0,0.0,1.0) # opposite label as target</span></span>
<span id="cb7-368"><a href="#cb7-368"></a><span class="in"># Define generator:</span></span>
<span id="cb7-369"><a href="#cb7-369"></a><span class="in">generator = GenericGenerator()</span></span>
<span id="cb7-370"><a href="#cb7-370"></a><span class="in"># Generate recourse:</span></span>
<span id="cb7-371"><a href="#cb7-371"></a><span class="in">counterfactual = generate_counterfactual(x, target, counterfactual_data, M, generator)</span></span>
<span id="cb7-372"><a href="#cb7-372"></a><span class="in">```</span></span>
<span id="cb7-373"><a href="#cb7-373"></a></span>
<span id="cb7-376"><a href="#cb7-376"></a><span class="in">```{julia}</span></span>
<span id="cb7-377"><a href="#cb7-377"></a><span class="in">#| echo: false</span></span>
<span id="cb7-378"><a href="#cb7-378"></a><span class="in">using Plots</span></span>
<span id="cb7-379"><a href="#cb7-379"></a><span class="in">T = size(path(counterfactual))[1]</span></span>
<span id="cb7-380"><a href="#cb7-380"></a><span class="in">X_path = reduce(hcat,path(counterfactual))</span></span>
<span id="cb7-381"><a href="#cb7-381"></a><span class="in">plt = plot_contour(X',ys,M)</span></span>
<span id="cb7-382"><a href="#cb7-382"></a><span class="in">[scatter!(plt, [path(counterfactual)[t][1]], [path(counterfactual)[t][2]], ms=7.5, color=Int(y), label="") for t in 1:T]</span></span>
<span id="cb7-383"><a href="#cb7-383"></a><span class="in">savefig(plt, joinpath(www_path,"interop_r.png"))</span></span>
<span id="cb7-384"><a href="#cb7-384"></a><span class="in">```</span></span>
<span id="cb7-385"><a href="#cb7-385"></a></span>
<span id="cb7-386"><a href="#cb7-386"></a><span class="al">![Counterfactual path using the generic counterfactual generator for a model trained in R.](www/interop_r.gif)</span>{#fig-torch}</span>
<span id="cb7-387"><a href="#cb7-387"></a></span>
<span id="cb7-388"><a href="#cb7-388"></a><span class="co">&lt;!-- kicker --&gt;</span></span>
<span id="cb7-389"><a href="#cb7-389"></a></span>
<span id="cb7-390"><a href="#cb7-390"></a><span class="fu">## We need you! 🫵</span></span>
<span id="cb7-391"><a href="#cb7-391"></a></span>
<span id="cb7-392"><a href="#cb7-392"></a>The ambition for <span class="in">`CounterfactualExplanations.jl`</span> is to provide a go-to place for counterfactual explanations to the Julia community and beyond. This is a grand ambition, especially for a package that has so far been built by a single developer who has little prior experience with Julia. We would therefore very much like to invite community contributions. If you have an interest in trustworthy AI, the open-source community and Julia, please do get involved! This package is still in its early stages of development, so any kind of contribution is welcome: advice on the core package architecture, pull requests, issues, discussions and even just comments below would be much appreciated. </span>
<span id="cb7-393"><a href="#cb7-393"></a></span>
<span id="cb7-394"><a href="#cb7-394"></a>To give you a flavor of what type of future developments we envision, here is a non-exhaustive list:</span>
<span id="cb7-395"><a href="#cb7-395"></a></span>
<span id="cb7-396"><a href="#cb7-396"></a><span class="ss">1. </span>Native support for additional counterfactual generators and predictive models including those built and trained in Python or R.</span>
<span id="cb7-397"><a href="#cb7-397"></a><span class="ss">2. </span>Additional datasets for testing, evaluation and benchmarking.</span>
<span id="cb7-398"><a href="#cb7-398"></a><span class="ss">3. </span>Improved preprocessing including native support for categorical features.</span>
<span id="cb7-399"><a href="#cb7-399"></a><span class="ss">4. </span>Support for regression models.</span>
<span id="cb7-400"><a href="#cb7-400"></a></span>
<span id="cb7-401"><a href="#cb7-401"></a>Finally, if you like this project but don't have much time, then simply sharing this article or starring the <span class="co">[</span><span class="ot">repo</span><span class="co">](https://github.com/juliatrustworthyai/CounterfactualExplanations.jl)</span> on GitHub would also go a long way.</span>
<span id="cb7-402"><a href="#cb7-402"></a></span>
<span id="cb7-403"><a href="#cb7-403"></a><span class="fu">## Further reading 📚</span></span>
<span id="cb7-404"><a href="#cb7-404"></a></span>
<span id="cb7-405"><a href="#cb7-405"></a>If you're interested in learning more about this development, feel free to check out the following resources:</span>
<span id="cb7-406"><a href="#cb7-406"></a></span>
<span id="cb7-407"><a href="#cb7-407"></a><span class="ss">- </span>Package docs: [<span class="co">[</span><span class="ot">stable</span><span class="co">]</span>](https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/stable), [<span class="co">[</span><span class="ot">dev</span><span class="co">]</span>](https://juliatrustworthyai.github.io/CounterfactualExplanations.jl/dev).</span>
<span id="cb7-408"><a href="#cb7-408"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Contributor's guide</span><span class="co">](https://www.patalt.org/CounterfactualExplanations.jl/stable/contributing/)</span>.</span>
<span id="cb7-409"><a href="#cb7-409"></a><span class="ss">- </span><span class="co">[</span><span class="ot">GitHub repo</span><span class="co">](https://github.com/juliatrustworthyai/CounterfactualExplanations.jl)</span>.</span>
<span id="cb7-410"><a href="#cb7-410"></a></span>
<span id="cb7-411"><a href="#cb7-411"></a></span>
<span id="cb7-412"><a href="#cb7-412"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" class="img-fluid" alt="License: MIT"></a> <a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg" class="img-fluid" alt="CC BY 4.0"></a> © 2024, Patrick Altmeyer</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/pat-alt/pat-alt.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.patalt.org/">
      <i class="bi bi-house" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pat-alt">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://julialang.social/@patalt" rel="me">
      <i class="bi bi-mastodon" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://medium.com/@patrick.altmeyer">
      <i class="bi bi-medium" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>