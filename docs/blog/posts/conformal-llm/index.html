<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Patrick Altmeyer">
<meta name="dcterms.date" content="2023-07-05">
<meta name="description" content="For this year‚Äôs edition of the ING Analytics Experiment Week, we put ConformalPrediction.jl to work and built a chatbot that can be used for Conformal Intent Recognition.">

<title>patalt - Building a Conformal Chatbot in Julia</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
.display.math{display: block; text-align: center; margin: 0.5rem auto;}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../..//www/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BEEZ30787D"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-BEEZ30787D', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="../../../styles.css">
<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="patalt - Building a Conformal Chatbot in Julia">
<meta property="og:description" content="For this year‚Äôs edition of the ING Analytics Experiment Week, we put ConformalPrediction.jl to work and built a chatbot that can be used for Conformal Intent Recognition.">
<meta property="og:image" content="https://www.patalt.org/blog/posts/conformal-llm/www/intro.gif">
<meta property="og:site_name" content="patalt">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../www/icon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">patalt</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/publications/index.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/talks/index.html"> 
<span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="../../../blog/index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pat-alt"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://julialang.social/@patalt" rel="me"> <i class="bi bi-mastodon" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#huggingface-model" id="toc-huggingface-model" class="nav-link active" data-scroll-target="#huggingface-model">ü§ó HuggingFace Model</a></li>
  <li><a href="#mlj-interface" id="toc-mlj-interface" class="nav-link" data-scroll-target="#mlj-interface">üîÅ <code>MLJ</code> Interface</a></li>
  <li><a href="#conformal-chatbot" id="toc-conformal-chatbot" class="nav-link" data-scroll-target="#conformal-chatbot">ü§ñ Conformal Chatbot</a></li>
  <li><a href="#wrapping-up" id="toc-wrapping-up" class="nav-link" data-scroll-target="#wrapping-up">üåØ Wrapping Up</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">üéì References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/pat-alt/pat-alt.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Building a Conformal Chatbot in Julia</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">HuggingFace, Transformers, and Conformal Prediction - Part 1</p>
  <div class="quarto-categories">
    <div class="quarto-category">conformal prediction</div>
    <div class="quarto-category">transformers</div>
    <div class="quarto-category">llm</div>
    <div class="quarto-category">Julia</div>
  </div>
  </div>

<div>
  <div class="description">
    For this year‚Äôs edition of the ING Analytics Experiment Week, we put <code>ConformalPrediction.jl</code> to work and built a chatbot that can be used for Conformal Intent Recognition.
  </div>
</div>

<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://www.paltmeyer.com/">Patrick Altmeyer</a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://www.tudelft.nl/en/">
            Delft University of Technology
            </a>
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 5, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="intro-gif">
<figure class="figure">
<img src="www/intro.gif" style="width: 400px; height: 300px;" class="figure-img">
<figcaption>
Short demo of our conformal chatbot.
</figcaption>
</figure>
</div>
<p>Large Language Models are all the buzz right now. They are used for a variety of tasks, including text classification, question answering, and text generation. In this tutorial, we will show how to conformalize a transformer language model for text classification. We will use the <a href="https://arxiv.org/abs/2003.04807">Banking77</a> dataset <span class="citation" data-cites="casanueva2020efficient">(<a href="#ref-casanueva2020efficient" role="doc-biblioref">Casanueva et al. 2020</a>)</span>, which consists of 13,083 queries from 77 intents. On the model side, we will use the <a href="https://huggingface.co/mrm8488/distilroberta-finetuned-banking77">DistilRoBERTa</a> model, which is a distilled version of <a href="https://arxiv.org/abs/1907.11692">RoBERTa</a> <span class="citation" data-cites="liu2019roberta">(<a href="#ref-liu2019roberta" role="doc-biblioref">Liu et al. 2019</a>)</span> finetuned on the Banking77 dataset.</p>
<section id="huggingface-model" class="level2">
<h2 class="anchored" data-anchor-id="huggingface-model">ü§ó HuggingFace Model</h2>
<p>The model can be loaded from HF straight into our running Julia session using the <a href="https://github.com/chengchingwen/Transformers.jl/tree/master"><code>Transformers.jl</code></a> package. Below we load the tokenizer <code>tkr</code> and the model <code>mod</code>. The tokenizer is used to convert the text into a sequence of integers, which is then fed into the model. The model outputs a hidden state, which is then fed into a classifier to get the logits for each class. Finally, the logits are then passed through a softmax function to get the corresponding predicted probabilities. Below we run a few queries through the model to see how it performs.</p>
<div id="221ae383" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Load model from HF ü§ó:</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>tkr <span class="op">=</span> hgf<span class="st">"mrm8488/distilroberta-finetuned-banking77:tokenizer"</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>mod <span class="op">=</span> hgf<span class="st">"mrm8488/distilroberta-finetuned-banking77:ForSequenceClassification"</span></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co"># Test model:</span></span>
<span id="cb1-6"><a href="#cb1-6"></a>query <span class="op">=</span> [</span>
<span id="cb1-7"><a href="#cb1-7"></a>    <span class="st">"What is the base of the exchange rates?"</span>,</span>
<span id="cb1-8"><a href="#cb1-8"></a>    <span class="st">"Why is my card not working?"</span>,</span>
<span id="cb1-9"><a href="#cb1-9"></a>    <span class="st">"My Apple Pay is not working, what should I do?"</span>,</span>
<span id="cb1-10"><a href="#cb1-10"></a>]</span>
<span id="cb1-11"><a href="#cb1-11"></a>a <span class="op">=</span> <span class="fu">encode</span>(tkr, query)</span>
<span id="cb1-12"><a href="#cb1-12"></a>b <span class="op">=</span> mod.<span class="fu">model</span>(a)</span>
<span id="cb1-13"><a href="#cb1-13"></a>c <span class="op">=</span> mod.<span class="fu">cls</span>(b.hidden_state)</span>
<span id="cb1-14"><a href="#cb1-14"></a>d <span class="op">=</span> <span class="fu">softmax</span>(c.logit)</span>
<span id="cb1-15"><a href="#cb1-15"></a>[labels[i] for i <span class="kw">in</span> Flux.<span class="fu">onecold</span>(d)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>3-element Vector{String}:
 "exchange_rate"
 "card_not_working"
 "apple_pay_or_google_pay"</code></pre>
</div>
</div>
</section>
<section id="mlj-interface" class="level2">
<h2 class="anchored" data-anchor-id="mlj-interface">üîÅ <code>MLJ</code> Interface</h2>
<p>Since our package is interfaced to <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/"><code>MLJ.jl</code></a>, we need to define a wrapper model that conforms to the <code>MLJ</code> interface. In order to add the model for general use, we would probably go through <a href="https://github.com/FluxML/MLJFlux.jl"><code>MLJFlux.jl</code></a>, but for this tutorial, we will make our life easy and simply overload the <code>MLJBase.fit</code> and <code>MLJBase.predict</code> methods. Since the model from HF is already pre-trained and we are not interested in further fine-tuning, we will simply return the model object in the <code>MLJBase.fit</code> method. The <code>MLJBase.predict</code> method will then take the model object and the query and return the predicted probabilities. We also need to define the <code>MLJBase.target_scitype</code> and <code>MLJBase.predict_mode</code> methods. The former tells <code>MLJ</code> what the output type of the model is, and the latter can be used to retrieve the label with the highest predicted probability.</p>
<div id="b8daf1c0" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">struct</span> IntentClassifier <span class="op">&lt;:</span><span class="dt"> MLJBase.Probabilistic</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>    tkr<span class="op">::</span><span class="dt">TextEncoders.AbstractTransformerTextEncoder</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>    mod<span class="op">::</span><span class="dt">HuggingFace.HGFRobertaForSequenceClassification</span></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="kw">end</span></span>
<span id="cb3-5"><a href="#cb3-5"></a></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="kw">function</span> <span class="fu">IntentClassifier</span>(;</span>
<span id="cb3-7"><a href="#cb3-7"></a>    tokenizer<span class="op">::</span><span class="dt">TextEncoders.AbstractTransformerTextEncoder</span>, </span>
<span id="cb3-8"><a href="#cb3-8"></a>    model<span class="op">::</span><span class="dt">HuggingFace.HGFRobertaForSequenceClassification</span>,</span>
<span id="cb3-9"><a href="#cb3-9"></a>)</span>
<span id="cb3-10"><a href="#cb3-10"></a>    <span class="fu">IntentClassifier</span>(tkr, mod)</span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="kw">end</span></span>
<span id="cb3-12"><a href="#cb3-12"></a></span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="kw">function</span> <span class="fu">get_hidden_state</span>(clf<span class="op">::</span><span class="dt">IntentClassifier</span>, query<span class="op">::</span><span class="dt">Union{AbstractString, Vector{&lt;:AbstractString}}</span>)</span>
<span id="cb3-14"><a href="#cb3-14"></a>    token <span class="op">=</span> <span class="fu">encode</span>(clf.tkr, query)</span>
<span id="cb3-15"><a href="#cb3-15"></a>    hidden_state <span class="op">=</span> clf.mod.<span class="fu">model</span>(token).hidden_state</span>
<span id="cb3-16"><a href="#cb3-16"></a>    <span class="cf">return</span> hidden_state</span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="kw">end</span></span>
<span id="cb3-18"><a href="#cb3-18"></a></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="co"># This doesn't actually retrain the model, but it retrieves the classifier object</span></span>
<span id="cb3-20"><a href="#cb3-20"></a><span class="kw">function</span> MLJBase.<span class="fu">fit</span>(clf<span class="op">::</span><span class="dt">IntentClassifier</span>, verbosity, X, y)</span>
<span id="cb3-21"><a href="#cb3-21"></a>    cache<span class="op">=</span><span class="cn">nothing</span></span>
<span id="cb3-22"><a href="#cb3-22"></a>    report<span class="op">=</span><span class="cn">nothing</span></span>
<span id="cb3-23"><a href="#cb3-23"></a>    fitresult <span class="op">=</span> (clf <span class="op">=</span> clf.mod.cls, labels <span class="op">=</span> <span class="fu">levels</span>(y))</span>
<span id="cb3-24"><a href="#cb3-24"></a>    <span class="cf">return</span> fitresult, cache, report</span>
<span id="cb3-25"><a href="#cb3-25"></a><span class="kw">end</span></span>
<span id="cb3-26"><a href="#cb3-26"></a></span>
<span id="cb3-27"><a href="#cb3-27"></a><span class="kw">function</span> MLJBase.<span class="fu">predict</span>(clf<span class="op">::</span><span class="dt">IntentClassifier</span>, fitresult, Xnew)</span>
<span id="cb3-28"><a href="#cb3-28"></a>    output <span class="op">=</span> fitresult.<span class="fu">clf</span>(<span class="fu">get_hidden_state</span>(clf, Xnew))</span>
<span id="cb3-29"><a href="#cb3-29"></a>    pÃÇ <span class="op">=</span> <span class="fu">UnivariateFinite</span>(fitresult.labels,<span class="fu">softmax</span>(output.logit)<span class="ch">',pool=missing)</span></span>
<span id="cb3-30"><a href="#cb3-30"></a>    <span class="cf">return</span> pÃÇ</span>
<span id="cb3-31"><a href="#cb3-31"></a><span class="kw">end</span></span>
<span id="cb3-32"><a href="#cb3-32"></a></span>
<span id="cb3-33"><a href="#cb3-33"></a>MLJBase.<span class="fu">target_scitype</span>(clf<span class="op">::</span><span class="dt">IntentClassifier</span>) <span class="op">=</span> <span class="dt">AbstractVector</span>{<span class="op">&lt;:</span><span class="dt">Finite</span>}</span>
<span id="cb3-34"><a href="#cb3-34"></a></span>
<span id="cb3-35"><a href="#cb3-35"></a>MLJBase.<span class="fu">predict_mode</span>(clf<span class="op">::</span><span class="dt">IntentClassifier</span>, fitresult, Xnew) <span class="op">=</span> <span class="fu">mode</span>.(MLJBase.<span class="fu">predict</span>(clf, fitresult, Xnew))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>To test that everything is working as expected, we fit the model and generated predictions for a subset of the test data:</p>
<div id="70bb4266" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb4-1"><a href="#cb4-1"></a>clf <span class="op">=</span> <span class="fu">IntentClassifier</span>(tkr, mod)</span>
<span id="cb4-2"><a href="#cb4-2"></a>top_n <span class="op">=</span> <span class="fl">10</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>fitresult, _, _ <span class="op">=</span> MLJBase.<span class="fu">fit</span>(clf, <span class="fl">1</span>, <span class="cn">nothing</span>, y_test[<span class="fl">1</span><span class="op">:</span>top_n])</span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="pp">@time</span> yÃÇ <span class="op">=</span> MLJBase.<span class="fu">predict</span>(clf, fitresult, queries_test[<span class="fl">1</span><span class="op">:</span>top_n]);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  3.152725 seconds (8.34 M allocations: 614.050 MiB, 2.84% gc time, 72.43% compilation time)</code></pre>
</div>
</div>
</section>
<section id="conformal-chatbot" class="level2">
<h2 class="anchored" data-anchor-id="conformal-chatbot">ü§ñ Conformal Chatbot</h2>
<p>To turn the wrapped, pre-trained model into a conformal intent classifier, we can now rely on standard API calls. We first wrap our atomic model where we also specify the desired coverage rate and method. Since even simple forward passes are computationally expensive for our (small) LLM, we rely on Simple Inductive Conformal Classification.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb6-1"><a href="#cb6-1"></a>conf_model <span class="op">=</span> <span class="fu">conformal_model</span>(clf; coverage<span class="op">=</span><span class="fl">0.99</span>, method<span class="op">=:</span>simple_inductive, train_ratio<span class="op">=</span>train_ratio)</span>
<span id="cb6-2"><a href="#cb6-2"></a>mach <span class="op">=</span> <span class="fu">machine</span>(conf_model, queries, y)</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="pp">@time</span> <span class="fu">fit!</span>(mach)</span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="bu">Serialization</span>.<span class="fu">serialize</span>(<span class="st">"dev/private/simple_inductive.jls"</span>, mach)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finally, we use our conformal LLM to build a simple yet powerful chatbot that runs directly in the Julia REPL. Without dwelling on the details too much, the <code>conformal_chatbot</code> works as follows:</p>
<ol type="1">
<li>Prompt user to explain their intent.</li>
<li>Feed user input through conformal LLM and present the output to the user.</li>
<li>If the conformal prediction set includes more than one label, prompt the user to either refine their input or choose one of the options included in the set.</li>
</ol>
<div id="9ea277c4" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb7-1"><a href="#cb7-1"></a>mach <span class="op">=</span> <span class="bu">Serialization</span>.<span class="fu">deserialize</span>(<span class="st">"dev/private/simple_inductive.jls"</span>)</span>
<span id="cb7-2"><a href="#cb7-2"></a></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="kw">function</span> <span class="fu">prediction_set</span>(mach, query<span class="op">::</span><span class="dt">String</span>)</span>
<span id="cb7-4"><a href="#cb7-4"></a>    pÃÇ <span class="op">=</span> MLJBase.<span class="fu">predict</span>(mach, query)[<span class="fl">1</span>]</span>
<span id="cb7-5"><a href="#cb7-5"></a>    probs <span class="op">=</span> <span class="fu">pdf</span>.(pÃÇ, <span class="fu">collect</span>(<span class="fl">1</span><span class="op">:</span><span class="fl">77</span>))</span>
<span id="cb7-6"><a href="#cb7-6"></a>    in_set <span class="op">=</span> <span class="fu">findall</span>(probs <span class="op">.!=</span> <span class="fl">0</span>)</span>
<span id="cb7-7"><a href="#cb7-7"></a>    labels_in_set <span class="op">=</span> labels[in_set]</span>
<span id="cb7-8"><a href="#cb7-8"></a>    probs_in_set <span class="op">=</span> probs[in_set]</span>
<span id="cb7-9"><a href="#cb7-9"></a>    _order <span class="op">=</span> <span class="fu">sortperm</span>(<span class="op">-</span>probs_in_set)</span>
<span id="cb7-10"><a href="#cb7-10"></a>    plt <span class="op">=</span> UnicodePlots.<span class="fu">barplot</span>(labels_in_set[_order], probs_in_set[_order], title<span class="op">=</span><span class="st">"Possible Intents"</span>)</span>
<span id="cb7-11"><a href="#cb7-11"></a>    <span class="cf">return</span> labels_in_set, plt</span>
<span id="cb7-12"><a href="#cb7-12"></a><span class="kw">end</span></span>
<span id="cb7-13"><a href="#cb7-13"></a></span>
<span id="cb7-14"><a href="#cb7-14"></a><span class="kw">function</span> <span class="fu">conformal_chatbot</span>()</span>
<span id="cb7-15"><a href="#cb7-15"></a>    <span class="fu">println</span>(<span class="st">"üëã Hi, I'm a Julia, your conformal chatbot. I'm here to help you with your banking query. Ask me anything or type 'exit' to exit ...</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb7-16"><a href="#cb7-16"></a>    completed <span class="op">=</span> <span class="cn">false</span></span>
<span id="cb7-17"><a href="#cb7-17"></a>    queries <span class="op">=</span> <span class="st">""</span></span>
<span id="cb7-18"><a href="#cb7-18"></a>    <span class="cf">while</span> !completed</span>
<span id="cb7-19"><a href="#cb7-19"></a>        query <span class="op">=</span> <span class="fu">readline</span>()</span>
<span id="cb7-20"><a href="#cb7-20"></a>        queries <span class="op">=</span> queries <span class="op">*</span> <span class="st">","</span> <span class="op">*</span> query</span>
<span id="cb7-21"><a href="#cb7-21"></a>        labels, plt <span class="op">=</span> <span class="fu">prediction_set</span>(mach, queries)</span>
<span id="cb7-22"><a href="#cb7-22"></a>        <span class="cf">if</span> <span class="fu">length</span>(labels) <span class="op">&gt;</span> <span class="fl">1</span></span>
<span id="cb7-23"><a href="#cb7-23"></a>            <span class="fu">println</span>(<span class="st">"ü§î Hmmm ... I can think of several options here. If any of these applies, simply type the corresponding number (e.g. '1' for the first option). Otherwise, can you refine your question, please?</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb7-24"><a href="#cb7-24"></a>            <span class="fu">println</span>(plt)</span>
<span id="cb7-25"><a href="#cb7-25"></a>        <span class="cf">else</span></span>
<span id="cb7-26"><a href="#cb7-26"></a>            <span class="fu">println</span>(<span class="st">"ü•≥ I think you mean </span><span class="sc">$</span>(labels[<span class="fl">1</span>])<span class="st">. Correct?"</span>)</span>
<span id="cb7-27"><a href="#cb7-27"></a>        <span class="cf">end</span></span>
<span id="cb7-28"><a href="#cb7-28"></a></span>
<span id="cb7-29"><a href="#cb7-29"></a>        <span class="co"># Exit:</span></span>
<span id="cb7-30"><a href="#cb7-30"></a>        <span class="cf">if</span> query <span class="op">==</span> <span class="st">"exit"</span></span>
<span id="cb7-31"><a href="#cb7-31"></a>            <span class="fu">println</span>(<span class="st">"üëã Bye!"</span>)</span>
<span id="cb7-32"><a href="#cb7-32"></a>            <span class="cf">break</span></span>
<span id="cb7-33"><a href="#cb7-33"></a>        <span class="cf">end</span></span>
<span id="cb7-34"><a href="#cb7-34"></a>        <span class="cf">if</span> query <span class="op">‚àà</span> <span class="fu">string</span>.(<span class="fu">collect</span>(<span class="fl">1</span><span class="op">:</span><span class="fl">77</span>))</span>
<span id="cb7-35"><a href="#cb7-35"></a>            <span class="fu">println</span>(<span class="st">"üëç Great! You've chosen '</span><span class="sc">$</span>(labels[<span class="fu">parse</span>(<span class="dt">Int64</span>, query)])<span class="st">'. I'm glad I could help you. Have a nice day!"</span>)</span>
<span id="cb7-36"><a href="#cb7-36"></a>            completed <span class="op">=</span> <span class="cn">true</span></span>
<span id="cb7-37"><a href="#cb7-37"></a>        <span class="cf">end</span></span>
<span id="cb7-38"><a href="#cb7-38"></a>    <span class="cf">end</span></span>
<span id="cb7-39"><a href="#cb7-39"></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Below we show the output for two example queries. The first one is very ambiguous. As expected, the size of the prediction set is therefore large.</p>
<div id="b0d0e81d" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb8-1"><a href="#cb8-1"></a>ambiguous_query <span class="op">=</span> <span class="st">"transfer mondey?"</span></span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="fu">prediction_set</span>(mach, ambiguous_query)[<span class="fl">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="8">
<div class="ansi-escaped-output">
<pre>                                                        <span class="ansi-bright-white-fg ansi-bold">Possible Intents</span>              
                                           <span class="ansi-bright-black-fg">‚îå                                        ‚îê</span> 
                   beneficiary_not_allowed <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.150517 <span class="ansi-bright-black-fg"> </span> 
   balance_not_updated_after_bank_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.111409         <span class="ansi-bright-black-fg"> </span> 
                     transfer_into_account <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0939535           <span class="ansi-bright-black-fg"> </span> 
        transfer_not_received_by_recipient <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.091163             <span class="ansi-bright-black-fg"> </span> 
            top_up_by_bank_transfer_charge <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0893061            <span class="ansi-bright-black-fg"> </span> 
                           failed_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0888321            <span class="ansi-bright-black-fg"> </span> 
                           transfer_timing <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0641954                 <span class="ansi-bright-black-fg"> </span> 
                      transfer_fee_charged <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0361131                       <span class="ansi-bright-black-fg"> </span> 
                          pending_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0270795                         <span class="ansi-bright-black-fg"> </span> 
                           receiving_money <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.0252126                         <span class="ansi-bright-black-fg"> </span> 
                                           <span class="ansi-bright-black-fg">‚îî                                        ‚îò</span> </pre>
</div>
</div>
</div>
<p>The more refined version of the prompt yields a smaller prediction set: less ambiguous prompts result in lower predictive uncertainty.</p>
<div id="1ec659f4" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource julia number-lines code-with-copy"><code class="sourceCode julia"><span id="cb9-1"><a href="#cb9-1"></a>refined_query <span class="op">=</span> <span class="st">"I tried to transfer money to my friend, but it failed."</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="fu">prediction_set</span>(mach, refined_query)[<span class="fl">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="9">
<div class="ansi-escaped-output">
<pre>                                                        <span class="ansi-bright-white-fg ansi-bold">Possible Intents</span>              
                                           <span class="ansi-bright-black-fg">‚îå                                        ‚îê</span> 
                           failed_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.59042 <span class="ansi-bright-black-fg"> </span> 
                   beneficiary_not_allowed <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†</span> 0.139806                        <span class="ansi-bright-black-fg"> </span> 
        transfer_not_received_by_recipient <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†</span> 0.0449784                            <span class="ansi-bright-black-fg"> </span> 
   balance_not_updated_after_bank_transfer <span class="ansi-bright-black-fg">‚î§</span><span class="ansi-green-fg">‚ñ†‚ñ†</span> 0.037894                             <span class="ansi-bright-black-fg"> </span> 
                                           <span class="ansi-bright-black-fg">‚îî                                        ‚îò</span> </pre>
</div>
</div>
</div>
<p>Below we include a short demo video that shows the REPL-based chatbot in action.</p>
<p><img src="www/demo.gif" class="img-fluid"></p>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">üåØ Wrapping Up</h2>
<p>This work was done in collaboration with colleagues at ING as part of the ING Analytics 2023 Experiment Week. Our team demonstrated that Conformal Prediction provides a powerful and principled alternative to top-<em>K</em> intent classification. We won the first prize by popular vote.</p>
<p>There are a lot of things that can be improved. As far as LLMs are concerned, we have of course used a fairly small model here. In terms of Conformal Prediction, we have relied on simple inductive conformal classification. This is a good starting point, but there are more advanced methods available (and implemented in the package). Another thing we did not take into consideration here is that we have many outcome classes and may in practice be interested in achieving class-conditional coverage. Stay tuned for more!</p>
</section>
<section id="references" class="level2">



<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">üéì References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-casanueva2020efficient" class="csl-entry" role="listitem">
Casanueva, I√±igo, Tadas Temƒçinas, Daniela Gerz, Matthew Henderson, and Ivan Vuliƒá. 2020. <span>‚ÄúEfficient <span>Intent</span> <span>Detection</span> with <span>Dual</span> <span>Sentence</span> <span>Encoders</span>.‚Äù</span> In <em>Proceedings of the 2nd <span>Workshop</span> on <span>Natural</span> <span>Language</span> <span>Processing</span> for <span>Conversational</span> <span>AI</span></em>, 38‚Äì45. Online: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2020.nlp4convai-1.5">https://doi.org/10.18653/v1/2020.nlp4convai-1.5</a>.
</div>
<div id="ref-liu2019roberta" class="csl-entry" role="listitem">
Liu, Yinhan, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. <span>‚ÄúRoBERTa: A Robustly Optimized BERT Pretraining Approach.‚Äù</span> <a href="https://arxiv.org/abs/1907.11692">https://arxiv.org/abs/1907.11692</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2023,
  author = {Altmeyer, Patrick},
  title = {Building a {Conformal} {Chatbot} in {Julia}},
  date = {2023-07-05},
  url = {https://www.patalt.org//blog/posts/conformal-llm},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2023" class="csl-entry quarto-appendix-citeas" role="listitem">
Altmeyer, Patrick. 2023. <span>‚ÄúBuilding a Conformal Chatbot in
Julia.‚Äù</span> July 5, 2023. <a href="https://www.patalt.org//blog/posts/conformal-llm">https://www.patalt.org//blog/posts/conformal-llm</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="pat-alt/pat-alt.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb10" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb10-1"><a href="#cb10-1"></a><span class="co">---</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="an">title:</span><span class="co"> Building a Conformal Chatbot in Julia</span></span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="an">subtitle:</span><span class="co"> HuggingFace, Transformers, and Conformal Prediction - Part 1</span></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="an">date:</span><span class="co"> '2023-07-05'</span></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="an">categories:</span></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="co">  - conformal prediction</span></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="co">  - transformers</span></span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="co">  - llm</span></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="co">  - Julia</span></span>
<span id="cb10-10"><a href="#cb10-10"></a><span class="an">description:</span><span class="co"> &gt;-</span></span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="co">  For this year's edition of the ING Analytics Experiment Week, we put `ConformalPrediction.jl` to work and built a chatbot that can be used for Conformal Intent Recognition.</span></span>
<span id="cb10-12"><a href="#cb10-12"></a><span class="an">image:</span><span class="co"> www/intro.gif</span></span>
<span id="cb10-13"><a href="#cb10-13"></a><span class="an">jupyter:</span><span class="co"> julia-1.10</span></span>
<span id="cb10-14"><a href="#cb10-14"></a><span class="an">draft:</span><span class="co"> false</span></span>
<span id="cb10-15"><a href="#cb10-15"></a><span class="co">---</span></span>
<span id="cb10-16"><a href="#cb10-16"></a></span>
<span id="cb10-19"><a href="#cb10-19"></a><span class="in">```{julia}</span></span>
<span id="cb10-20"><a href="#cb10-20"></a><span class="in">#| echo: false</span></span>
<span id="cb10-21"><a href="#cb10-21"></a></span>
<span id="cb10-22"><a href="#cb10-22"></a><span class="in">BLOG_DIR = "blog/posts/conformal-llm"</span></span>
<span id="cb10-23"><a href="#cb10-23"></a><span class="in">using Pkg; Pkg.activate(BLOG_DIR)</span></span>
<span id="cb10-24"><a href="#cb10-24"></a></span>
<span id="cb10-25"><a href="#cb10-25"></a><span class="in">using ConformalPrediction</span></span>
<span id="cb10-26"><a href="#cb10-26"></a><span class="in">using CSV</span></span>
<span id="cb10-27"><a href="#cb10-27"></a><span class="in">using DataFrames</span></span>
<span id="cb10-28"><a href="#cb10-28"></a><span class="in">using Flux</span></span>
<span id="cb10-29"><a href="#cb10-29"></a><span class="in">using MLJBase</span></span>
<span id="cb10-30"><a href="#cb10-30"></a><span class="in">using Serialization</span></span>
<span id="cb10-31"><a href="#cb10-31"></a><span class="in">using Transformers</span></span>
<span id="cb10-32"><a href="#cb10-32"></a><span class="in">using Transformers.TextEncoders</span></span>
<span id="cb10-33"><a href="#cb10-33"></a><span class="in">using Transformers.HuggingFace</span></span>
<span id="cb10-34"><a href="#cb10-34"></a><span class="in">using UnicodePlots</span></span>
<span id="cb10-35"><a href="#cb10-35"></a><span class="in">```</span></span>
<span id="cb10-36"><a href="#cb10-36"></a></span>
<span id="cb10-37"><a href="#cb10-37"></a>&lt;div class="intro-gif"&gt;</span>
<span id="cb10-38"><a href="#cb10-38"></a>  &lt;figure&gt;</span>
<span id="cb10-39"><a href="#cb10-39"></a>    &lt;img src="www/intro.gif" style="width: 400px; height: 300px;"&gt;</span>
<span id="cb10-40"><a href="#cb10-40"></a>    &lt;figcaption&gt;Short demo of our conformal chatbot.&lt;/figcaption&gt;</span>
<span id="cb10-41"><a href="#cb10-41"></a>  &lt;/figure&gt;</span>
<span id="cb10-42"><a href="#cb10-42"></a>&lt;/div&gt;</span>
<span id="cb10-43"><a href="#cb10-43"></a></span>
<span id="cb10-44"><a href="#cb10-44"></a>Large Language Models are all the buzz right now. They are used for a variety of tasks, including text classification, question answering, and text generation. In this tutorial, we will show how to conformalize a transformer language model for text classification. We will use the <span class="co">[</span><span class="ot">Banking77</span><span class="co">](https://arxiv.org/abs/2003.04807)</span> dataset <span class="co">[</span><span class="ot">@casanueva2020efficient</span><span class="co">]</span>, which consists of 13,083 queries from 77 intents. On the model side, we will use the <span class="co">[</span><span class="ot">DistilRoBERTa</span><span class="co">](https://huggingface.co/mrm8488/distilroberta-finetuned-banking77)</span> model, which is a distilled version of <span class="co">[</span><span class="ot">RoBERTa</span><span class="co">](https://arxiv.org/abs/1907.11692)</span> <span class="co">[</span><span class="ot">@liu2019roberta</span><span class="co">]</span> finetuned on the Banking77 dataset.</span>
<span id="cb10-45"><a href="#cb10-45"></a></span>
<span id="cb10-48"><a href="#cb10-48"></a><span class="in">```{julia}</span></span>
<span id="cb10-49"><a href="#cb10-49"></a><span class="in">#| echo: false</span></span>
<span id="cb10-50"><a href="#cb10-50"></a></span>
<span id="cb10-51"><a href="#cb10-51"></a><span class="in"># Get labels:</span></span>
<span id="cb10-52"><a href="#cb10-52"></a><span class="in">df_labels = CSV.read(joinpath(BLOG_DIR,"data/labels.csv"), DataFrame, drop=[1])</span></span>
<span id="cb10-53"><a href="#cb10-53"></a><span class="in">labels = df_labels[:,1]</span></span>
<span id="cb10-54"><a href="#cb10-54"></a></span>
<span id="cb10-55"><a href="#cb10-55"></a><span class="in"># Get data:</span></span>
<span id="cb10-56"><a href="#cb10-56"></a><span class="in">df_train = CSV.read(joinpath(BLOG_DIR,"data/train.csv"), DataFrame, drop=[1])</span></span>
<span id="cb10-57"><a href="#cb10-57"></a><span class="in">df_cal = CSV.read(joinpath(BLOG_DIR,"data/calibration.csv"), DataFrame, drop=[1])</span></span>
<span id="cb10-58"><a href="#cb10-58"></a><span class="in">df_full_train = vcat(df_train, df_cal)</span></span>
<span id="cb10-59"><a href="#cb10-59"></a><span class="in">train_ratio = round(nrow(df_train)/nrow(df_full_train), digits=2)</span></span>
<span id="cb10-60"><a href="#cb10-60"></a><span class="in">df_test = CSV.read(joinpath(BLOG_DIR,"data/test.csv"), DataFrame, drop=[1])</span></span>
<span id="cb10-61"><a href="#cb10-61"></a></span>
<span id="cb10-62"><a href="#cb10-62"></a><span class="in"># Preprocess data:</span></span>
<span id="cb10-63"><a href="#cb10-63"></a><span class="in">queries_train, y_train = collect(df_train.text), categorical(df_train.labels .+ 1)</span></span>
<span id="cb10-64"><a href="#cb10-64"></a><span class="in">queries_cal, y_cal = collect(df_cal.text), categorical(df_cal.labels .+ 1)</span></span>
<span id="cb10-65"><a href="#cb10-65"></a><span class="in">queries, y = collect(df_full_train.text), categorical(df_full_train.labels .+ 1)</span></span>
<span id="cb10-66"><a href="#cb10-66"></a><span class="in">queries_test, y_test = collect(df_test.text), categorical(df_test.labels .+ 1)</span></span>
<span id="cb10-67"><a href="#cb10-67"></a><span class="in">```</span></span>
<span id="cb10-68"><a href="#cb10-68"></a></span>
<span id="cb10-69"><a href="#cb10-69"></a><span class="fu">## ü§ó HuggingFace Model</span></span>
<span id="cb10-70"><a href="#cb10-70"></a></span>
<span id="cb10-71"><a href="#cb10-71"></a>The model can be loaded from HF straight into our running Julia session using the <span class="co">[</span><span class="ot">`Transformers.jl`</span><span class="co">](https://github.com/chengchingwen/Transformers.jl/tree/master)</span> package. Below we load the tokenizer <span class="in">`tkr`</span> and the model <span class="in">`mod`</span>. The tokenizer is used to convert the text into a sequence of integers, which is then fed into the model. The model outputs a hidden state, which is then fed into a classifier to get the logits for each class. Finally, the logits are then passed through a softmax function to get the corresponding predicted probabilities. Below we run a few queries through the model to see how it performs.</span>
<span id="cb10-72"><a href="#cb10-72"></a></span>
<span id="cb10-75"><a href="#cb10-75"></a><span class="in">```{julia}</span></span>
<span id="cb10-76"><a href="#cb10-76"></a><span class="in">#| output: true</span></span>
<span id="cb10-77"><a href="#cb10-77"></a></span>
<span id="cb10-78"><a href="#cb10-78"></a><span class="in"># Load model from HF ü§ó:</span></span>
<span id="cb10-79"><a href="#cb10-79"></a><span class="in">tkr = hgf"mrm8488/distilroberta-finetuned-banking77:tokenizer"</span></span>
<span id="cb10-80"><a href="#cb10-80"></a><span class="in">mod = hgf"mrm8488/distilroberta-finetuned-banking77:ForSequenceClassification"</span></span>
<span id="cb10-81"><a href="#cb10-81"></a></span>
<span id="cb10-82"><a href="#cb10-82"></a><span class="in"># Test model:</span></span>
<span id="cb10-83"><a href="#cb10-83"></a><span class="in">query = [</span></span>
<span id="cb10-84"><a href="#cb10-84"></a><span class="in">    "What is the base of the exchange rates?",</span></span>
<span id="cb10-85"><a href="#cb10-85"></a><span class="in">    "Why is my card not working?",</span></span>
<span id="cb10-86"><a href="#cb10-86"></a><span class="in">    "My Apple Pay is not working, what should I do?",</span></span>
<span id="cb10-87"><a href="#cb10-87"></a><span class="in">]</span></span>
<span id="cb10-88"><a href="#cb10-88"></a><span class="in">a = encode(tkr, query)</span></span>
<span id="cb10-89"><a href="#cb10-89"></a><span class="in">b = mod.model(a)</span></span>
<span id="cb10-90"><a href="#cb10-90"></a><span class="in">c = mod.cls(b.hidden_state)</span></span>
<span id="cb10-91"><a href="#cb10-91"></a><span class="in">d = softmax(c.logit)</span></span>
<span id="cb10-92"><a href="#cb10-92"></a><span class="in">[labels[i] for i in Flux.onecold(d)]</span></span>
<span id="cb10-93"><a href="#cb10-93"></a><span class="in">```</span></span>
<span id="cb10-94"><a href="#cb10-94"></a></span>
<span id="cb10-95"><a href="#cb10-95"></a><span class="fu">## üîÅ `MLJ` Interface</span></span>
<span id="cb10-96"><a href="#cb10-96"></a></span>
<span id="cb10-97"><a href="#cb10-97"></a>Since our package is interfaced to <span class="co">[</span><span class="ot">`MLJ.jl`</span><span class="co">](https://alan-turing-institute.github.io/MLJ.jl/dev/)</span>, we need to define a wrapper model that conforms to the <span class="in">`MLJ`</span> interface. In order to add the model for general use, we would probably go through <span class="co">[</span><span class="ot">`MLJFlux.jl`</span><span class="co">](https://github.com/FluxML/MLJFlux.jl)</span>, but for this tutorial, we will make our life easy and simply overload the <span class="in">`MLJBase.fit`</span> and <span class="in">`MLJBase.predict`</span> methods. Since the model from HF is already pre-trained and we are not interested in further fine-tuning, we will simply return the model object in the <span class="in">`MLJBase.fit`</span> method. The <span class="in">`MLJBase.predict`</span> method will then take the model object and the query and return the predicted probabilities. We also need to define the <span class="in">`MLJBase.target_scitype`</span> and <span class="in">`MLJBase.predict_mode`</span> methods. The former tells <span class="in">`MLJ`</span> what the output type of the model is, and the latter can be used to retrieve the label with the highest predicted probability.</span>
<span id="cb10-98"><a href="#cb10-98"></a></span>
<span id="cb10-101"><a href="#cb10-101"></a><span class="in">```{julia}</span></span>
<span id="cb10-102"><a href="#cb10-102"></a><span class="in">struct IntentClassifier &lt;: MLJBase.Probabilistic</span></span>
<span id="cb10-103"><a href="#cb10-103"></a><span class="in">    tkr::TextEncoders.AbstractTransformerTextEncoder</span></span>
<span id="cb10-104"><a href="#cb10-104"></a><span class="in">    mod::HuggingFace.HGFRobertaForSequenceClassification</span></span>
<span id="cb10-105"><a href="#cb10-105"></a><span class="in">end</span></span>
<span id="cb10-106"><a href="#cb10-106"></a></span>
<span id="cb10-107"><a href="#cb10-107"></a><span class="in">function IntentClassifier(;</span></span>
<span id="cb10-108"><a href="#cb10-108"></a><span class="in">    tokenizer::TextEncoders.AbstractTransformerTextEncoder, </span></span>
<span id="cb10-109"><a href="#cb10-109"></a><span class="in">    model::HuggingFace.HGFRobertaForSequenceClassification,</span></span>
<span id="cb10-110"><a href="#cb10-110"></a><span class="in">)</span></span>
<span id="cb10-111"><a href="#cb10-111"></a><span class="in">    IntentClassifier(tkr, mod)</span></span>
<span id="cb10-112"><a href="#cb10-112"></a><span class="in">end</span></span>
<span id="cb10-113"><a href="#cb10-113"></a></span>
<span id="cb10-114"><a href="#cb10-114"></a><span class="in">function get_hidden_state(clf::IntentClassifier, query::Union{AbstractString, Vector{&lt;:AbstractString}})</span></span>
<span id="cb10-115"><a href="#cb10-115"></a><span class="in">    token = encode(clf.tkr, query)</span></span>
<span id="cb10-116"><a href="#cb10-116"></a><span class="in">    hidden_state = clf.mod.model(token).hidden_state</span></span>
<span id="cb10-117"><a href="#cb10-117"></a><span class="in">    return hidden_state</span></span>
<span id="cb10-118"><a href="#cb10-118"></a><span class="in">end</span></span>
<span id="cb10-119"><a href="#cb10-119"></a></span>
<span id="cb10-120"><a href="#cb10-120"></a><span class="in"># This doesn't actually retrain the model, but it retrieves the classifier object</span></span>
<span id="cb10-121"><a href="#cb10-121"></a><span class="in">function MLJBase.fit(clf::IntentClassifier, verbosity, X, y)</span></span>
<span id="cb10-122"><a href="#cb10-122"></a><span class="in">    cache=nothing</span></span>
<span id="cb10-123"><a href="#cb10-123"></a><span class="in">    report=nothing</span></span>
<span id="cb10-124"><a href="#cb10-124"></a><span class="in">    fitresult = (clf = clf.mod.cls, labels = levels(y))</span></span>
<span id="cb10-125"><a href="#cb10-125"></a><span class="in">    return fitresult, cache, report</span></span>
<span id="cb10-126"><a href="#cb10-126"></a><span class="in">end</span></span>
<span id="cb10-127"><a href="#cb10-127"></a></span>
<span id="cb10-128"><a href="#cb10-128"></a><span class="in">function MLJBase.predict(clf::IntentClassifier, fitresult, Xnew)</span></span>
<span id="cb10-129"><a href="#cb10-129"></a><span class="in">    output = fitresult.clf(get_hidden_state(clf, Xnew))</span></span>
<span id="cb10-130"><a href="#cb10-130"></a><span class="in">    pÃÇ = UnivariateFinite(fitresult.labels,softmax(output.logit)',pool=missing)</span></span>
<span id="cb10-131"><a href="#cb10-131"></a><span class="in">    return pÃÇ</span></span>
<span id="cb10-132"><a href="#cb10-132"></a><span class="in">end</span></span>
<span id="cb10-133"><a href="#cb10-133"></a></span>
<span id="cb10-134"><a href="#cb10-134"></a><span class="in">MLJBase.target_scitype(clf::IntentClassifier) = AbstractVector{&lt;:Finite}</span></span>
<span id="cb10-135"><a href="#cb10-135"></a></span>
<span id="cb10-136"><a href="#cb10-136"></a><span class="in">MLJBase.predict_mode(clf::IntentClassifier, fitresult, Xnew) = mode.(MLJBase.predict(clf, fitresult, Xnew))</span></span>
<span id="cb10-137"><a href="#cb10-137"></a><span class="in">```</span></span>
<span id="cb10-138"><a href="#cb10-138"></a></span>
<span id="cb10-139"><a href="#cb10-139"></a>To test that everything is working as expected, we fit the model and generated predictions for a subset of the test data:</span>
<span id="cb10-140"><a href="#cb10-140"></a></span>
<span id="cb10-143"><a href="#cb10-143"></a><span class="in">```{julia}</span></span>
<span id="cb10-144"><a href="#cb10-144"></a><span class="in">#| output: true</span></span>
<span id="cb10-145"><a href="#cb10-145"></a></span>
<span id="cb10-146"><a href="#cb10-146"></a><span class="in">clf = IntentClassifier(tkr, mod)</span></span>
<span id="cb10-147"><a href="#cb10-147"></a><span class="in">top_n = 10</span></span>
<span id="cb10-148"><a href="#cb10-148"></a><span class="in">fitresult, _, _ = MLJBase.fit(clf, 1, nothing, y_test[1:top_n])</span></span>
<span id="cb10-149"><a href="#cb10-149"></a><span class="in">@time yÃÇ = MLJBase.predict(clf, fitresult, queries_test[1:top_n]);</span></span>
<span id="cb10-150"><a href="#cb10-150"></a><span class="in">```</span></span>
<span id="cb10-151"><a href="#cb10-151"></a></span>
<span id="cb10-152"><a href="#cb10-152"></a><span class="fu">## ü§ñ Conformal Chatbot</span></span>
<span id="cb10-153"><a href="#cb10-153"></a></span>
<span id="cb10-154"><a href="#cb10-154"></a>To turn the wrapped, pre-trained model into a conformal intent classifier, we can now rely on standard API calls. We first wrap our atomic model where we also specify the desired coverage rate and method. Since even simple forward passes are computationally expensive for our (small) LLM, we rely on Simple Inductive Conformal Classification.</span>
<span id="cb10-155"><a href="#cb10-155"></a></span>
<span id="cb10-156"><a href="#cb10-156"></a><span class="in">```{.julia}</span></span>
<span id="cb10-157"><a href="#cb10-157"></a><span class="in">conf_model = conformal_model(clf; coverage=0.99, method=:simple_inductive, train_ratio=train_ratio)</span></span>
<span id="cb10-158"><a href="#cb10-158"></a><span class="in">mach = machine(conf_model, queries, y)</span></span>
<span id="cb10-159"><a href="#cb10-159"></a><span class="in">@time fit!(mach)</span></span>
<span id="cb10-160"><a href="#cb10-160"></a><span class="in">Serialization.serialize("dev/private/simple_inductive.jls", mach)</span></span>
<span id="cb10-161"><a href="#cb10-161"></a><span class="in">```</span></span>
<span id="cb10-162"><a href="#cb10-162"></a></span>
<span id="cb10-163"><a href="#cb10-163"></a>Finally, we use our conformal LLM to build a simple yet powerful chatbot that runs directly in the Julia REPL. Without dwelling on the details too much, the <span class="in">`conformal_chatbot`</span> works as follows:</span>
<span id="cb10-164"><a href="#cb10-164"></a></span>
<span id="cb10-165"><a href="#cb10-165"></a><span class="ss">1.  </span>Prompt user to explain their intent.</span>
<span id="cb10-166"><a href="#cb10-166"></a><span class="ss">2.  </span>Feed user input through conformal LLM and present the output to the user.</span>
<span id="cb10-167"><a href="#cb10-167"></a><span class="ss">3.  </span>If the conformal prediction set includes more than one label, prompt the user to either refine their input or choose one of the options included in the set.</span>
<span id="cb10-168"><a href="#cb10-168"></a></span>
<span id="cb10-171"><a href="#cb10-171"></a><span class="in">```{julia}</span></span>
<span id="cb10-172"><a href="#cb10-172"></a><span class="in">mach = Serialization.deserialize("dev/private/simple_inductive.jls")</span></span>
<span id="cb10-173"><a href="#cb10-173"></a></span>
<span id="cb10-174"><a href="#cb10-174"></a><span class="in">function prediction_set(mach, query::String)</span></span>
<span id="cb10-175"><a href="#cb10-175"></a><span class="in">    pÃÇ = MLJBase.predict(mach, query)[1]</span></span>
<span id="cb10-176"><a href="#cb10-176"></a><span class="in">    probs = pdf.(pÃÇ, collect(1:77))</span></span>
<span id="cb10-177"><a href="#cb10-177"></a><span class="in">    in_set = findall(probs .!= 0)</span></span>
<span id="cb10-178"><a href="#cb10-178"></a><span class="in">    labels_in_set = labels[in_set]</span></span>
<span id="cb10-179"><a href="#cb10-179"></a><span class="in">    probs_in_set = probs[in_set]</span></span>
<span id="cb10-180"><a href="#cb10-180"></a><span class="in">    _order = sortperm(-probs_in_set)</span></span>
<span id="cb10-181"><a href="#cb10-181"></a><span class="in">    plt = UnicodePlots.barplot(labels_in_set[_order], probs_in_set[_order], title="Possible Intents")</span></span>
<span id="cb10-182"><a href="#cb10-182"></a><span class="in">    return labels_in_set, plt</span></span>
<span id="cb10-183"><a href="#cb10-183"></a><span class="in">end</span></span>
<span id="cb10-184"><a href="#cb10-184"></a></span>
<span id="cb10-185"><a href="#cb10-185"></a><span class="in">function conformal_chatbot()</span></span>
<span id="cb10-186"><a href="#cb10-186"></a><span class="in">    println("üëã Hi, I'm a Julia, your conformal chatbot. I'm here to help you with your banking query. Ask me anything or type 'exit' to exit ...\n")</span></span>
<span id="cb10-187"><a href="#cb10-187"></a><span class="in">    completed = false</span></span>
<span id="cb10-188"><a href="#cb10-188"></a><span class="in">    queries = ""</span></span>
<span id="cb10-189"><a href="#cb10-189"></a><span class="in">    while !completed</span></span>
<span id="cb10-190"><a href="#cb10-190"></a><span class="in">        query = readline()</span></span>
<span id="cb10-191"><a href="#cb10-191"></a><span class="in">        queries = queries * "," * query</span></span>
<span id="cb10-192"><a href="#cb10-192"></a><span class="in">        labels, plt = prediction_set(mach, queries)</span></span>
<span id="cb10-193"><a href="#cb10-193"></a><span class="in">        if length(labels) &gt; 1</span></span>
<span id="cb10-194"><a href="#cb10-194"></a><span class="in">            println("ü§î Hmmm ... I can think of several options here. If any of these applies, simply type the corresponding number (e.g. '1' for the first option). Otherwise, can you refine your question, please?\n")</span></span>
<span id="cb10-195"><a href="#cb10-195"></a><span class="in">            println(plt)</span></span>
<span id="cb10-196"><a href="#cb10-196"></a><span class="in">        else</span></span>
<span id="cb10-197"><a href="#cb10-197"></a><span class="in">            println("ü•≥ I think you mean $(labels[1]). Correct?")</span></span>
<span id="cb10-198"><a href="#cb10-198"></a><span class="in">        end</span></span>
<span id="cb10-199"><a href="#cb10-199"></a></span>
<span id="cb10-200"><a href="#cb10-200"></a><span class="in">        # Exit:</span></span>
<span id="cb10-201"><a href="#cb10-201"></a><span class="in">        if query == "exit"</span></span>
<span id="cb10-202"><a href="#cb10-202"></a><span class="in">            println("üëã Bye!")</span></span>
<span id="cb10-203"><a href="#cb10-203"></a><span class="in">            break</span></span>
<span id="cb10-204"><a href="#cb10-204"></a><span class="in">        end</span></span>
<span id="cb10-205"><a href="#cb10-205"></a><span class="in">        if query ‚àà string.(collect(1:77))</span></span>
<span id="cb10-206"><a href="#cb10-206"></a><span class="in">            println("üëç Great! You've chosen '$(labels[parse(Int64, query)])'. I'm glad I could help you. Have a nice day!")</span></span>
<span id="cb10-207"><a href="#cb10-207"></a><span class="in">            completed = true</span></span>
<span id="cb10-208"><a href="#cb10-208"></a><span class="in">        end</span></span>
<span id="cb10-209"><a href="#cb10-209"></a><span class="in">    end</span></span>
<span id="cb10-210"><a href="#cb10-210"></a><span class="in">end</span></span>
<span id="cb10-211"><a href="#cb10-211"></a><span class="in">```</span></span>
<span id="cb10-212"><a href="#cb10-212"></a></span>
<span id="cb10-213"><a href="#cb10-213"></a>Below we show the output for two example queries. The first one is very ambiguous. As expected, the size of the prediction set is therefore large. </span>
<span id="cb10-214"><a href="#cb10-214"></a></span>
<span id="cb10-217"><a href="#cb10-217"></a><span class="in">```{julia}</span></span>
<span id="cb10-218"><a href="#cb10-218"></a><span class="in">#| output: true</span></span>
<span id="cb10-219"><a href="#cb10-219"></a></span>
<span id="cb10-220"><a href="#cb10-220"></a><span class="in">ambiguous_query = "transfer mondey?"</span></span>
<span id="cb10-221"><a href="#cb10-221"></a><span class="in">prediction_set(mach, ambiguous_query)[2]</span></span>
<span id="cb10-222"><a href="#cb10-222"></a><span class="in">```</span></span>
<span id="cb10-223"><a href="#cb10-223"></a></span>
<span id="cb10-224"><a href="#cb10-224"></a>The more refined version of the prompt yields a smaller prediction set: less ambiguous prompts result in lower predictive uncertainty. </span>
<span id="cb10-225"><a href="#cb10-225"></a></span>
<span id="cb10-228"><a href="#cb10-228"></a><span class="in">```{julia}</span></span>
<span id="cb10-229"><a href="#cb10-229"></a><span class="in">#| output: true</span></span>
<span id="cb10-230"><a href="#cb10-230"></a></span>
<span id="cb10-231"><a href="#cb10-231"></a><span class="in">refined_query = "I tried to transfer money to my friend, but it failed."</span></span>
<span id="cb10-232"><a href="#cb10-232"></a><span class="in">prediction_set(mach, refined_query)[2]</span></span>
<span id="cb10-233"><a href="#cb10-233"></a><span class="in">```</span></span>
<span id="cb10-234"><a href="#cb10-234"></a></span>
<span id="cb10-235"><a href="#cb10-235"></a>Below we include a short demo video that shows the REPL-based chatbot in action.</span>
<span id="cb10-236"><a href="#cb10-236"></a></span>
<span id="cb10-237"><a href="#cb10-237"></a><span class="al">![](www/demo.gif)</span></span>
<span id="cb10-238"><a href="#cb10-238"></a></span>
<span id="cb10-239"><a href="#cb10-239"></a><span class="fu">## üåØ Wrapping Up</span></span>
<span id="cb10-240"><a href="#cb10-240"></a></span>
<span id="cb10-241"><a href="#cb10-241"></a>This work was done in collaboration with colleagues at ING as part of the ING Analytics 2023 Experiment Week. Our team demonstrated that Conformal Prediction provides a powerful and principled alternative to top-*K* intent classification. We won the first prize by popular vote.</span>
<span id="cb10-242"><a href="#cb10-242"></a></span>
<span id="cb10-243"><a href="#cb10-243"></a>There are a lot of things that can be improved. As far as LLMs are concerned, we have of course used a fairly small model here. In terms of Conformal Prediction, we have relied on simple inductive conformal classification. This is a good starting point, but there are more advanced methods available (and implemented in the package). Another thing we did not take into consideration here is that we have many outcome classes and may in practice be interested in achieving class-conditional coverage. Stay tuned for more!</span>
<span id="cb10-244"><a href="#cb10-244"></a></span>
<span id="cb10-245"><a href="#cb10-245"></a><span class="fu">## üéì References</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" class="img-fluid" alt="License: MIT"></a> <a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg" class="img-fluid" alt="CC BY 4.0"></a> ¬© 2024, Patrick Altmeyer</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/pat-alt/pat-alt.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.patalt.org/">
      <i class="bi bi-house" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pat-alt">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://julialang.social/@patalt" rel="me">
      <i class="bi bi-mastodon" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://medium.com/@patrick.altmeyer">
      <i class="bi bi-medium" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>