<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-99.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Severin Bratus">
<meta name="author" content="Mark Ardman">
<meta name="author" content="Adelina Cazacu">
<meta name="author" content="Andrei Ionescu">
<meta name="author" content="Ivan Makarov">
<meta name="author" content="Patrick Altmeyer">
<meta name="dcterms.date" content="2023-07-04">
<meta name="description" content="A guest blog post by a team of students from TU Delft, who have contributed multiple improvements to LaplaceRedux.jl.">

<title>Patrick Altmeyer - Paving the Way Towards Low-Overhead Uncertainty Calibration</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../..//www/favicon.ico" rel="icon">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BEEZ30787D"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-BEEZ30787D', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Patrick Altmeyer - Paving the Way Towards Low-Overhead Uncertainty Calibration">
<meta property="og:description" content="A guest blog post by a team of students from TU Delft, who have contributed multiple improvements to LaplaceRedux.jl.">
<meta property="og:image" content="https://www.paltmeyer.com/blog/blog/posts/guest-students-laplace/www/intro.png">
<meta property="og:site_name" content="Patrick Altmeyer">
<meta property="og:image:height" content="772">
<meta property="og:image:width" content="1164">
<meta name="twitter:title" content="Patrick Altmeyer - Paving the Way Towards Low-Overhead Uncertainty Calibration">
<meta name="twitter:description" content="A guest blog post by a team of students from TU Delft, who have contributed multiple improvements to LaplaceRedux.jl.">
<meta name="twitter:image" content="https://www.paltmeyer.com/blog/blog/posts/guest-students-laplace/www/intro.png">
<meta name="twitter:image-height" content="772">
<meta name="twitter:image-width" content="1164">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../www/icon.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Patrick Altmeyer</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/publications/index.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/talks/index.html"> 
<span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../content/about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="../../../blog/index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pat-alt"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/paltmey"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#bayesian-learning" id="toc-bayesian-learning" class="nav-link active" data-scroll-target="#bayesian-learning">Bayesian Learning</a></li>
  <li><a href="#laplace-approximations" id="toc-laplace-approximations" class="nav-link" data-scroll-target="#laplace-approximations">Laplace Approximations</a></li>
  <li><a href="#hessian-approximations" id="toc-hessian-approximations" class="nav-link" data-scroll-target="#hessian-approximations">Hessian approximations</a></li>
  <li><a href="#our-contributions-to-laplaceredux.jl" id="toc-our-contributions-to-laplaceredux.jl" class="nav-link" data-scroll-target="#our-contributions-to-laplaceredux.jl">Our contributions to LaplaceRedux.jl</a></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology</a></li>
  <li><a href="#pain-points" id="toc-pain-points" class="nav-link" data-scroll-target="#pain-points">Pain Points</a></li>
  <li><a href="#highlights" id="toc-highlights" class="nav-link" data-scroll-target="#highlights">Highlights</a></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions">Conclusions</a></li>
  <li><a href="#acknowedgements" id="toc-acknowedgements" class="nav-link" data-scroll-target="#acknowedgements">Acknowedgements</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/pat-alt/pat-alt.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Paving the Way Towards Low-Overhead Uncertainty Calibration</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">An Accessible Intro to Laplace Approximations in Julia for Bayesian Deep Learning</p>
  <div class="quarto-categories">
    <div class="quarto-category">bayesian deep learning</div>
    <div class="quarto-category">laplace approximation</div>
    <div class="quarto-category">guest post</div>
    <div class="quarto-category">Julia</div>
  </div>
  </div>

<div>
  <div class="description">
    A guest blog post by a team of students from TU Delft, who have contributed multiple improvements to LaplaceRedux.jl.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Severin Bratus </p>
             <p>Mark Ardman </p>
             <p>Adelina Cazacu </p>
             <p>Andrei Ionescu </p>
             <p>Ivan Makarov </p>
             <p>Patrick Altmeyer </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 4, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Guest Blog Post
</div>
</div>
<div class="callout-body-container callout-body">
<p>This blog post was originally written by Severin Bratus and colleagues from TU Delft and published on <a href="https://medium.com/@sbratus/an-introduction-to-laplace-approximations-for-bayesian-deep-learning-in-julia-c5a30cfaf7b5">Medium</a>. This version of the post includes only minor edits. If you would like to contribute a guest blog post, please get in touch.</p>
</div>
</div>
<p>This post summarizes a quarter-long second-year BSc coursework project at TU Delft. Our team of five students has made multiple improvements to <a href="https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl">LaplaceRedux.jl</a>, due to Patrick Altmeyer. Inspired by its Pythonic counterpart, <a href="https://github.com/AlexImmer/Laplace">laplacet-torch</a>, this Julia library aims to provide low-overhead Bayesian uncertainty calibration to deep neural networks via Laplace Approximations <span class="citation" data-cites="daxberger2021laplace">(<a href="#ref-daxberger2021laplace" role="doc-biblioref">Daxberger et al. 2021</a>)</span>.</p>
<div class="img-fluid quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="www/intro.png" class="img-fluid figure-img"></p>
<figcaption>A nice image to attract your attention. The exact inverse Fisher information matrix for a MNIST classifier network (left), its block-diagonal and tri-block-diagonal approximations (middle), and the absolute error (right). Source: Martens &amp; Grosse (2015)</figcaption>
</figure>
</div>
<p>We will begin by demystifying the technical terms in the last sentence, in order to explain our contributions to the library and highlight some impressions from the experience. Note that our team has begun working on this PhD-tier subject only having had some introductory courses on probability and statistics, machine learning, and computational intelligence, without any prior exposure to Julia.</p>
<section id="bayesian-learning" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-learning">Bayesian Learning</h2>
<p>Uncertainty calibration remains a crucial issue in safety-critical applications of modern AI, as, for instance, in autonomous driving. You would want your car autopilot not only to make accurate predictions but also to indicate when a model prediction is uncertain, to give control back to the human driver.</p>
<p>A model is well-calibrated if the confidence of a prediction matches its true error rate. Note that you can have well-fit models that are badly calibrated, and <em>vice versa</em> (just like in life, you meet smart people, yet annoyingly arrogant).</p>
<p>The standard deep learning training process of gradient descent converges at a weight configuration that minimizes the loss function. The model obtained may be great, yet it is only a point estimate of what the weight parameters should look like.</p>
<p>However, with the sheer immensity of the weight space, neural networks are probably underspecified by the data (or, overfit). As neural networks can approximate highly complex functions, many weight configurations would yield roughly the same training loss, yet with varying abilities to generalize outside the training dataset. This is why there are so many regularization methods out there, to keep the models simpler. One radical, yet effective approach is described by <span class="citation" data-cites="lecun1989optimal">LeCun, Denker, and Solla (<a href="#ref-lecun1989optimal" role="doc-biblioref">1989</a>)</span>:</p>
<blockquote class="blockquote">
<p>… it is possible to take a perfectly reasonable network, delete half (or more) of the weights and wind up with a network that works just as well, or better.</p>
</blockquote>
<div id="fig-loss" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="www/grad_desc.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-loss-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: The loss landscape. One can imagine gradient descent as a particle, let’s say a ball, or a grain of sand, rolling to the bottom of a pit. Then for Bayesian Learning, we have as if a pile of sand poured around at that bottom point, with the pile being thicker where loss is lower. This proverbial sand pile would represent the posterior parameter distribution. Figure due to <span class="citation" data-cites="amini2019spatial">Amini et al. (<a href="#ref-amini2019spatial" role="doc-biblioref">2019</a>)</span>
</figcaption>
</figure>
</div>
<p>The way gradient is usually illustrated is with a picture like the one shown in <a href="#fig-loss" class="quarto-xref">Figure&nbsp;1</a> above a curved terrain of the loss function across the parameter space. Each point of the horizontal plane corresponds to some configuration of parameters. Gradient descent seeks the point at the bottom of this terrain, as the point with the lowest loss, however as the loss-curvature is highly non-convex and high-dimensional there are many directions in which we could move and still maintain a low loss. Thus instead of a singular point we would like to specify a probability distribution around that optimal point. Bayesian methods, and in particular Laplace Approximations, allow us to do this!</p>
<p>Firstly, the Bayesian approach to neural network uncertainty calibration is that of modelling the posterior using Bayes’ Theorem:</p>
<p><span class="math display">\[
p(\theta \mid \mathcal{D}) = \tfrac{1}{Z} \,p(\mathcal{D} \mid \theta) \, p(\theta), \qquad Z:= p(\mathcal{D}) = \textstyle\int p(\mathcal{D} \mid \theta) \, p(\theta) \,d\theta
\]</span></p>
<p>Here <span class="math inline">\(p(\mathcal{D} \mid \theta)\)</span> is the likelihood of the data given by the parameters <span class="math inline">\(\theta\)</span>. The prior distribution <span class="math inline">\(p(\theta)\)</span> specifies our beliefs about what the model parameters would be prior to observing the data. Finally, the intractable constant <span class="math inline">\(Z\)</span> is called the evidence: it characterizes the probability of observing <span class="math inline">\(\mathcal{D}\)</span> as a whole, across all possible parameter settings (see <a href="../../../blog/posts/effortsless-bayesian-dl/index.html">here</a> for details).</p>
<p>For models returning a probability distribution (e.g.&nbsp;classifiers), the loss is commonly defined as the negative log-likelihood. Thus if gradient descent minimizes loss, it maximizes the likelihood, producing the maximum likelihood estimate (MLE), which (assuming a uniform prior) also maximizes the posterior. This is why we call this point the <em>maximum a posteriori</em>, or the MAP. It makes sense to model this point as the mode of the posterior distribution, which could, for example, be a normal Gaussian distribution (see also the introductory <a href="../../../blog/posts/effortsless-bayesian-dl/index.html">post</a> on this blog).</p>
</section>
<section id="laplace-approximations" class="level2">
<h2 class="anchored" data-anchor-id="laplace-approximations">Laplace Approximations</h2>
<p>We do this by a simple-yet-smart trick introduced back in the late 18th century by Pierre-Simon Laplace, the self-proclaimed “greatest French mathematician of his time”. In general, the Laplace Approximation (LA) aims to find a Gaussian approximation to a probability density (in our case, the posterior) defined over a set of continuous variables (in our case, the weights) <span class="citation" data-cites="bishop2006pattern">(<a href="#ref-bishop2006pattern" role="doc-biblioref">Bishop 2006</a>)</span>. We can then estimate the loss (negative log-likelihood) as its second-order Taylor expansion:</p>
<p><span class="math display">\[
\mathcal{L}(\mathcal{D}; \theta) \approx \mathcal{L}(\mathcal{D}; \theta_\text{MAP}) + \tfrac{1}{2} (\theta - \theta_\text{MAP})^\intercal \left( \nabla^2 _\theta \mathcal{L}(\mathcal{D}; \theta) \vert_{\theta_\text{MAP}} \right)(\theta - \theta_\text{MAP})
\]</span></p>
<p>Note that the first-order Taylor term vanishes at the MAP since it contains the gradient, and the gradient is zero at MAP, since MAP is a maximum, by definition. What remains is the constant (zeroth-order) term, and the second-order term, containing the Hessian, which is a matrix of partial second-order derivatives.</p>
<p>Then from this approximation, we can derive the long-sought multivariate normal distribution with the MAP as the mean, and the inverted Hessian as the covariance:</p>
<p><span class="math display">\[
p(\theta \mid \mathcal{D}) \approx N(\theta; \theta_\text{MAP}, \varSigma) \qquad\text{with}\qquad \varSigma := \left( \nabla^2_\theta \mathcal{L}(\mathcal{D};\theta) \vert_{\theta_\text{MAP}} \right)^{-1}
\]</span></p>
<p>The evidence <span class="math inline">\(Z\)</span> is now also tractably approximated in closed form, allowing us to apply the Bayes’ theorem, to obtain the posterior distribution <span class="math inline">\(p(\theta \mid \mathcal{D})\)</span>. We can then express the <em>posterior predictive</em> distribution, for an input <span class="math inline">\(x_*\)</span>, prediction <span class="math inline">\(f(x_*)\)</span>, to obtain the probability for an output <span class="math inline">\(y\)</span>.</p>
<p>The evidence <span class="math inline">\(Z\)</span> is now also tractably approximated in closed form, allowing us to apply the Bayes’ theorem, to obtain the posterior distribution <span class="math inline">\(p(\theta \mid \mathcal{D})\)</span>. We can then express the posterior predictive distribution, to obtain the probability for an output <span class="math inline">\(y\)</span>, given a prediction <span class="math inline">\(f(x_*)\)</span> for an input <span class="math inline">\(x_*\)</span>.</p>
<p><span class="math display">\[
p(y \mid f(x_*), \mathcal{D}) = \int p(y \mid f_\theta(x_*)) \, p(\theta \mid \mathcal{D}) \,d\theta
\]</span></p>
<p>This is what we are really after, after all — instead of giving one singular point-estimate prediction <span class="math inline">\(\widehat{y} = f(x_*)\)</span>, we make the neural network give a distribution over <span class="math inline">\(y\)</span>.</p>
<p>However, since the Hessian, a square matrix, defines the covariance between all model parameters (upon inversion), of which there may be millions or billions, the computation and storage of the Hessian (not to speak of inversion!) become intractable, as its size scales quadratically with the number of parameters involved. Thus to apply Laplace approximations to large models, we must make some simplifications — which brings us to…</p>
</section>
<section id="hessian-approximations" class="level2">
<h2 class="anchored" data-anchor-id="hessian-approximations">Hessian approximations</h2>
<p>Multiple techniques to approximate the Hessian have arisen from a field adjacent, yet distinct from Bayesian learning — that of second-order optimization, where Hessians are used to accelerate gradient descent convergence.</p>
<p>One such approximation is the Fisher information matrix, or simply the Fisher:</p>
<p><span class="math display">\[
F := \textstyle\sum_{n=1}^N \mathbb{E}_{\widehat{y} \sim p(y \mid f_\theta(x_n))} \left[  gg^\intercal \right] \quad\text{with}\quad g = \nabla_\theta \log p(\widehat{y} \mid f_\theta(x_n)) \large\vert_{\theta_\text{MAP}}
\]</span></p>
<p>Note that if instead of sampling the prediction <span class="math inline">\(\widehat{y} ~ p(y \mid f(x_n))\)</span> from the model-defined distribution, we take the actual training-set label <span class="math inline">\(y_n\)</span>, the resulting matrix is called the empirical Fisher, which is distinct from the Fisher, yet aligns with it under some conditions, and does <em>not</em> generally capture second-order information. See Kunstner et al.&nbsp;(2019) for an excellent discussion on the distinction.</p>
<p>Instead of the Fisher, one can use the Generalized Gauss-Newton (GGN):</p>
<p><span class="math display">\[
G := \textstyle\sum_{n=1}^N J(x_n) \left( \nabla^2_{f} \log p(y_n \mid f) \Large\vert_{f=f_{\theta_\text{map}}(x_n)} \right) J(x_n)^\intercal
\text{with}\qquad J(x_n) := \nabla_\theta f_\theta(x_n) \vert_{\theta_\text{map}}
\]</span></p>
<p>Here <span class="math inline">\(J(x_n)\)</span> represents the Jacobian of the model output w.r.t. the parameters. The middle factor <span class="math inline">\(\nabla^2 …\)</span> is a Hessian of log-likelihood of <span class="math inline">\(y_n\)</span> w.r.t. model output. Note that the model does not necessarily output ready target probabilities — for instance, classifiers output <em>logits</em>, values that define a probability distribution only after the application of the soft-max.</p>
<p>Unlike the Fisher, GGN does not require the network to define a probabilistic model on its output <span class="citation" data-cites="botev2017practical">(<a href="#ref-botev2017practical" role="doc-biblioref">Botev, Ritter, and Barber 2017</a>)</span>. For models defining an exponential family distribution over the output, the two coincide <span class="citation" data-cites="kunstner2020limitations">(<a href="#ref-kunstner2020limitations" role="doc-biblioref">Kunstner, Balles, and Hennig 2020</a>)</span>. This applies to classifiers since they define a categorical distribution over the output, but not to simple regression models.</p>
<p>These matrices are quadratically large, it is infeasible to store them in full. The simplest estimation is to model the matrix as a diagonal — however one can easily contemplate how crude this approximation can be: for 100 parameters, only 1% of the full Hessian is captured.</p>
<p>A more sophisticated approach, due to Martens and Grosse (2015), is inspired by the observation that in practice the covariance matrices (i.e.&nbsp;inverted Hessians) for neural networks are block-diagonal-dominant. Thus we can effectively model the covariance matrix (and hence the Fisher) as a block-diagonal matrix, where blocks correspond to parameters grouped by layers. Additionally, each block is decomposed into two Kronecker factors, reducing the size of data stored several magnitudes more, at a cost of another assumption.</p>
<p>Lastly, a novel approach is to <em>sketch</em> a low-rank approximation of the Fisher <span class="citation" data-cites="sharma2021sketching">(<a href="#ref-sharma2021sketching" role="doc-biblioref">Sharma, Azizan, and Pavone 2021</a>)</span>. <a href="#fig-fact" class="quarto-xref">Figure&nbsp;2</a> shows four Hessian approximation structures:</p>
<div id="fig-fact" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fact-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="www/fact.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fact-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: (a) Hessian in full, intractable for large networks. (b) Low-rank. (c) Kronecker-factored Approximate Curvature, a block-diagonal method. (d) Diagonal. Source: <span class="citation" data-cites="daxberger2021laplace">Daxberger et al. (<a href="#ref-daxberger2021laplace" role="doc-biblioref">2021</a>)</span>
</figcaption>
</figure>
</div>
<p>It is also possible to cut the costs by treating only a subset of the model parameters, i.e.&nbsp;a subnetwork, probabilistically, fixing the remaining parameters at their MAP-estimated values. One special case of subnetwork Laplace that was found to perform well in practice is last-layer Laplace, where the selected subnetwork contains only the weights and biases of the last layer.</p>
</section>
<section id="our-contributions-to-laplaceredux.jl" class="level2">
<h2 class="anchored" data-anchor-id="our-contributions-to-laplaceredux.jl">Our contributions to LaplaceRedux.jl</h2>
<p>In the scope of the project we have added support for: - multi-class classification, in addition to regression and binary classification; - GGN, in addition to empirical Fisher; - hardware-parallelized batched computation of both the empirical Fisher and the GGN; - subnetwork and last-layer Laplace; - KFAC for multi-class classification with Fisher; and - interfacing with MLJ, a common machine learning framework for Julia.</p>
<p>We have also made quality assurance / quality-of-life additions to the repository, adding: - a formatting check in the CI/CD pipeline; - an extensive test suite comparing the results of LaplaceRedux.jl against those of its Python counter-part package laplace-torch; and - a benchmark pipeline tracking possible downturns in performance.</p>
</section>
<section id="methodology" class="level2">
<h2 class="anchored" data-anchor-id="methodology">Methodology</h2>
<p>We adhered to the Agile/Scrum practices, with two-week-long sprints, and weekly meetings with our formal client, Patrick Altmeyer. We have prioritized the expected requirements by the Moscow method into must-, could-, should-, and won’t-haves. This is all fairly standard for BSc software projects at TU Delft. By the end of the project, we have completed all of our self-assigned must-haves and should-haves.</p>
</section>
<section id="pain-points" class="level2">
<h2 class="anchored" data-anchor-id="pain-points">Pain Points</h2>
<p>Here we list some obstacles we have encountered along the way: - Julia is slow to compile and load dependencies on less powerful machines. - Stack traces are sometimes rather obscure, though it seems to be the price to pay for macros. - <code>Zygote.jl</code>, the automatic differentiation library, is <a href="https://github.com/FluxML/Zygote.jl/issues/1268">not self-autodifferentiable</a> – it cannot differentiate its own functions. We would want this since we apply <code>Zygote.jacobians</code> when making predictions with the LA. - There is no accessible tool reporting branch coverage on tests – only line coverage is available. - Limited LSP and Unicode support for Jupyter Lab. - Conversion between Flux and ONNX is <a href="https://github.com/FluxML/ONNX.jl">not yet implemented</a>. - There is no extension library for Zygote equivalent to BackPACK or ASDL for second-order information.</p>
<ul>
<li><code>Zygote.jl</code>, the automatic differentiation library, is not self-autodifferentiable: <a href="https://github.com/FluxML/Zygote.jl/issues/1268">issue</a>. We would want this since we apply <code>Zygote.jacobians</code> when making predictions with the LA.</li>
<li>There is no accessible tool reporting branch coverage on tests – only line coverage is available.</li>
<li>Limited LSP and Unicode support for Jupyter Lab.</li>
<li>No conversion between Flux and ONNX is implemented yet <a href="https://github.com/FluxML/ONNX.jl">ONNX.jl</a></li>
<li>There is no extension library for Zygote equivalent to <a href="https://github.com/f-dangel/backpack">BackPACK</a> or <a href="https://github.com/kazukiosawa/asdl/">ASDL</a> for second-order information.</li>
</ul>
</section>
<section id="highlights" class="level2">
<h2 class="anchored" data-anchor-id="highlights">Highlights</h2>
<p>And here is what we found refreshing: - Metaprogramming and first-class support for macros are something completely different for students who are used to Java &amp; Python. - The Julia standard API, and Flux/Zygote, are fairly straightforward to use, and well-thought-out for numerical computing and machine learning.</p>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>We have covered some elements of the theory behind Laplace Approximations, laid down our additions to the <code>LaplaceRedux.jl</code> package, and brought out some difficulties we, as complete newcomers to Julia, came across. Hope you have enjoyed the tour, and hopefully it has intrigued you enough to look deeper into Bayesian learning and/or Julia since both are developing at a lively pace. You can check out LaplaceRedux on the JuliaTrustworthyAI GitHub page here. Contributions and comments are welcome!</p>
</section>
<section id="acknowedgements" class="level2">
<h2 class="anchored" data-anchor-id="acknowedgements">Acknowedgements</h2>
<p>Our team members are Mark Ardman, Severin Bratus, Adelina Cazacu, Andrei Ionescu, and Ivan Makarov. We would like to thank Patrick Altmeyer for the opportunity to work on this unique project and for the continuous guidance throughout the development process. We are also grateful to Sebastijan Dumančić, our coach, Sven van der Voort, our TA mentor, and Antony Bartlett, our supporting advisor.</p>
</section>
<section id="references" class="level2">



<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-amini2019spatial" class="csl-entry" role="listitem">
Amini, Alexander, Ava Soleimany, Sertac Karaman, and Daniela Rus. 2019. <span>“Spatial <span>Uncertainty</span> <span>Sampling</span> for <span>End</span>-to-<span>End</span> <span>Control</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1805.04829">https://doi.org/10.48550/arXiv.1805.04829</a>.
</div>
<div id="ref-bishop2006pattern" class="csl-entry" role="listitem">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. <span>springer</span>.
</div>
<div id="ref-botev2017practical" class="csl-entry" role="listitem">
Botev, Aleksandar, Hippolyt Ritter, and David Barber. 2017. <span>“Practical <span>Gauss</span>-<span>Newton</span> <span>Optimisation</span> for <span>Deep</span> <span>Learning</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1706.03662">https://doi.org/10.48550/arXiv.1706.03662</a>.
</div>
<div id="ref-daxberger2021laplace" class="csl-entry" role="listitem">
Daxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. <span>“Laplace <span>Redux-Effortless Bayesian Deep Learning</span>.”</span> <em>Advances in Neural Information Processing Systems</em> 34.
</div>
<div id="ref-kunstner2020limitations" class="csl-entry" role="listitem">
Kunstner, Frederik, Lukas Balles, and Philipp Hennig. 2020. <span>“Limitations of the <span>Empirical</span> <span>Fisher</span> <span>Approximation</span> for <span>Natural</span> <span>Gradient</span> <span>Descent</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1905.12558">https://doi.org/10.48550/arXiv.1905.12558</a>.
</div>
<div id="ref-lecun1989optimal" class="csl-entry" role="listitem">
LeCun, Yann, John Denker, and Sara Solla. 1989. <span>“Optimal <span>Brain</span> <span>Damage</span>.”</span> In <em>Advances in <span>Neural</span> <span>Information</span> <span>Processing</span> <span>Systems</span></em>. Vol. 2. Morgan-Kaufmann. <a href="https://proceedings.neurips.cc/paper/1989/hash/6c9882bbac1c7093bd25041881277658-Abstract.html">https://proceedings.neurips.cc/paper/1989/hash/6c9882bbac1c7093bd25041881277658-Abstract.html</a>.
</div>
<div id="ref-sharma2021sketching" class="csl-entry" role="listitem">
Sharma, Apoorva, Navid Azizan, and Marco Pavone. 2021. <span>“Sketching <span>Curvature</span> for <span>Efficient</span> <span>Out</span>-of-<span>Distribution</span> <span>Detection</span> for <span>Deep</span> <span>Neural</span> <span>Networks</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2102.12567">https://doi.org/10.48550/arXiv.2102.12567</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{altmeyer2023,
  author = {Altmeyer, Patrick and Bratus, Severin and Ardman, Mark and
    Cazacu, Adelina and Ionescu, Andrei and Makarov, Ivan and Altmeyer,
    Patrick},
  title = {Paving the {Way} {Towards} {Low-Overhead} {Uncertainty}
    {Calibration}},
  date = {2023-07-04},
  url = {https://www.paltmeyer.com/blog//blog/posts/guest-students-laplace},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-altmeyer2023" class="csl-entry quarto-appendix-citeas" role="listitem">
Altmeyer, Patrick, Severin Bratus, Mark Ardman, Adelina Cazacu, Andrei
Ionescu, Ivan Makarov, and Patrick Altmeyer. 2023. <span>“Paving the Way
Towards Low-Overhead Uncertainty Calibration.”</span> July 4, 2023. <a href="https://www.paltmeyer.com/blog//blog/posts/guest-students-laplace">https://www.paltmeyer.com/blog//blog/posts/guest-students-laplace</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="pat-alt/pat-alt.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="an">title:</span><span class="co"> Paving the Way Towards Low-Overhead Uncertainty Calibration</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="an">subtitle:</span><span class="co"> An Accessible Intro to Laplace Approximations in Julia for Bayesian Deep Learning</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="an">date:</span><span class="co"> '2023-07-04'</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="an">categories:</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co">  - bayesian deep learning</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co">  - laplace approximation</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co">  - guest post</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="co">  - Julia</span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="an">description:</span><span class="co"> &gt;-</span></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="co">    A guest blog post by a team of students from TU Delft, who have contributed multiple improvements to LaplaceRedux.jl. </span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="an">image:</span><span class="co"> www/intro.png</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="an">author:</span><span class="co"> </span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="co">    - name: Severin Bratus</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="co">    - name: Mark Ardman</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="co">    - name: Adelina Cazacu</span></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="co">    - name: Andrei Ionescu</span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="co">    - name: Ivan Makarov</span></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="co">    - name: Patrick Altmeyer</span></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="an">draft:</span><span class="co"> false</span></span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="co">---</span></span>
<span id="cb1-22"><a href="#cb1-22"></a></span>
<span id="cb1-23"><a href="#cb1-23"></a>::: {.callout-note}</span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="fu">## Guest Blog Post</span></span>
<span id="cb1-25"><a href="#cb1-25"></a></span>
<span id="cb1-26"><a href="#cb1-26"></a>This blog post was originally written by Severin Bratus and colleagues from TU Delft and published on <span class="co">[</span><span class="ot">Medium</span><span class="co">](https://medium.com/@sbratus/an-introduction-to-laplace-approximations-for-bayesian-deep-learning-in-julia-c5a30cfaf7b5)</span>. This version of the post includes only minor edits. If you would like to contribute a guest blog post, please get in touch.</span>
<span id="cb1-27"><a href="#cb1-27"></a>:::</span>
<span id="cb1-28"><a href="#cb1-28"></a></span>
<span id="cb1-29"><a href="#cb1-29"></a>This post summarizes a quarter-long second-year BSc coursework project at TU Delft. Our team of five students has made multiple improvements to <span class="co">[</span><span class="ot">LaplaceRedux.jl</span><span class="co">](https://github.com/JuliaTrustworthyAI/LaplaceRedux.jl)</span>, due to Patrick Altmeyer. Inspired by its Pythonic counterpart, <span class="co">[</span><span class="ot">laplacet-torch</span><span class="co">](https://github.com/AlexImmer/Laplace)</span>, this Julia library aims to provide low-overhead Bayesian uncertainty calibration to deep neural networks via Laplace Approximations <span class="co">[</span><span class="ot">@daxberger2021laplace</span><span class="co">]</span>.</span>
<span id="cb1-30"><a href="#cb1-30"></a></span>
<span id="cb1-31"><a href="#cb1-31"></a><span class="al">![A nice image to attract your attention. The exact inverse Fisher information matrix for a MNIST classifier network (left), its block-diagonal and tri-block-diagonal approximations (middle), and the absolute error (right). Source: Martens &amp; Grosse (2015)](www/intro.png)</span></span>
<span id="cb1-32"><a href="#cb1-32"></a></span>
<span id="cb1-33"><a href="#cb1-33"></a>We will begin by demystifying the technical terms in the last sentence, in order to explain our contributions to the library and highlight some impressions from the experience. Note that our team has begun working on this PhD-tier subject only having had some introductory courses on probability and statistics, machine learning, and computational intelligence, without any prior exposure to Julia.</span>
<span id="cb1-34"><a href="#cb1-34"></a></span>
<span id="cb1-35"><a href="#cb1-35"></a><span class="fu">## Bayesian Learning</span></span>
<span id="cb1-36"><a href="#cb1-36"></a></span>
<span id="cb1-37"><a href="#cb1-37"></a>Uncertainty calibration remains a crucial issue in safety-critical applications of modern AI, as, for instance, in autonomous driving. You would want your car autopilot not only to make accurate predictions but also to indicate when a model prediction is uncertain, to give control back to the human driver.</span>
<span id="cb1-38"><a href="#cb1-38"></a></span>
<span id="cb1-39"><a href="#cb1-39"></a>A model is well-calibrated if the confidence of a prediction matches its true error rate. Note that you can have well-fit models that are badly calibrated, and *vice versa* (just like in life, you meet smart people, yet annoyingly arrogant).</span>
<span id="cb1-40"><a href="#cb1-40"></a></span>
<span id="cb1-41"><a href="#cb1-41"></a>The standard deep learning training process of gradient descent converges at a weight configuration that minimizes the loss function. The model obtained may be great, yet it is only a point estimate of what the weight parameters should look like.</span>
<span id="cb1-42"><a href="#cb1-42"></a></span>
<span id="cb1-43"><a href="#cb1-43"></a>However, with the sheer immensity of the weight space, neural networks are probably underspecified by the data (or, overfit). As neural networks can approximate highly complex functions, many weight configurations would yield roughly the same training loss, yet with varying abilities to generalize outside the training dataset. </span>
<span id="cb1-44"><a href="#cb1-44"></a>This is why there are so many regularization methods out there, to keep the models simpler. One radical, yet effective approach is described by @lecun1989optimal:</span>
<span id="cb1-45"><a href="#cb1-45"></a></span>
<span id="cb1-46"><a href="#cb1-46"></a><span class="at">&gt; … it is possible to take a perfectly reasonable network, delete half (or more) of the weights and wind up with a network that works just as well, or better.</span></span>
<span id="cb1-47"><a href="#cb1-47"></a></span>
<span id="cb1-48"><a href="#cb1-48"></a><span class="al">![The loss landscape. One can imagine gradient descent as a particle, let’s say a ball, or a grain of sand, rolling to the bottom of a pit. Then for Bayesian Learning, we have as if a pile of sand poured around at that bottom point, with the pile being thicker where loss is lower. This proverbial sand pile would represent the posterior parameter distribution. Figure due to @amini2019spatial](www/grad_desc.png)</span>{#fig-loss}</span>
<span id="cb1-49"><a href="#cb1-49"></a></span>
<span id="cb1-50"><a href="#cb1-50"></a>The way gradient is usually illustrated is with a picture like the one shown in @fig-loss above a curved terrain of the loss function across the parameter space. Each point of the horizontal plane corresponds to some configuration of parameters. Gradient descent seeks the point at the bottom of this terrain, as the point with the lowest loss, however as the loss-curvature is highly non-convex and high-dimensional there are many directions in which we could move and still maintain a low loss. Thus instead of a singular point we would like to specify a probability distribution around that optimal point. Bayesian methods, and in particular Laplace Approximations, allow us to do this!</span>
<span id="cb1-51"><a href="#cb1-51"></a></span>
<span id="cb1-52"><a href="#cb1-52"></a>Firstly, the Bayesian approach to neural network uncertainty calibration is that of modelling the posterior using Bayes’ Theorem:</span>
<span id="cb1-53"><a href="#cb1-53"></a></span>
<span id="cb1-54"><a href="#cb1-54"></a>$$ </span>
<span id="cb1-55"><a href="#cb1-55"></a>p(\theta \mid \mathcal{D}) = \tfrac{1}{Z} \,p(\mathcal{D} \mid \theta) \, p(\theta), \qquad Z:= p(\mathcal{D}) = \textstyle\int p(\mathcal{D} \mid \theta) \, p(\theta) \,d\theta</span>
<span id="cb1-56"><a href="#cb1-56"></a>$$</span>
<span id="cb1-57"><a href="#cb1-57"></a></span>
<span id="cb1-58"><a href="#cb1-58"></a>Here $p(\mathcal{D} \mid \theta)$ is the likelihood of the data given by the parameters $\theta$.</span>
<span id="cb1-59"><a href="#cb1-59"></a>The prior distribution $p(\theta)$ specifies our beliefs about what the model parameters would be prior to observing the data. Finally, the intractable constant $Z$ is called the evidence: it characterizes the probability of observing $\mathcal{D}$ as a whole, across all possible parameter settings (see <span class="co">[</span><span class="ot">here</span><span class="co">](../effortsless-bayesian-dl/index.qmd)</span> for details).</span>
<span id="cb1-60"><a href="#cb1-60"></a></span>
<span id="cb1-61"><a href="#cb1-61"></a>For models returning a probability distribution (e.g. classifiers), the loss is commonly defined as the negative log-likelihood. Thus if gradient descent minimizes loss, it maximizes the likelihood, producing the maximum likelihood estimate (MLE), which (assuming a uniform prior) also maximizes the posterior. This is why we call this point the *maximum a posteriori*, or the MAP. It makes sense to model this point as the mode of the posterior distribution, which could, for example, be a normal Gaussian distribution (see also the introductory <span class="co">[</span><span class="ot">post</span><span class="co">](../effortsless-bayesian-dl/index.qmd)</span> on this blog).</span>
<span id="cb1-62"><a href="#cb1-62"></a></span>
<span id="cb1-63"><a href="#cb1-63"></a><span class="fu">## Laplace Approximations</span></span>
<span id="cb1-64"><a href="#cb1-64"></a></span>
<span id="cb1-65"><a href="#cb1-65"></a>We do this by a simple-yet-smart trick introduced back in the late 18th century by Pierre-Simon Laplace, the self-proclaimed “greatest French mathematician of his time”. In general, the Laplace Approximation (LA) aims to find a Gaussian approximation to a probability density (in our case, the posterior) defined over a set of continuous variables (in our case, the weights) <span class="co">[</span><span class="ot">@bishop2006pattern</span><span class="co">]</span>. We can then estimate the loss (negative log-likelihood) as its second-order Taylor expansion:</span>
<span id="cb1-66"><a href="#cb1-66"></a></span>
<span id="cb1-67"><a href="#cb1-67"></a>$$</span>
<span id="cb1-68"><a href="#cb1-68"></a>\mathcal{L}(\mathcal{D}; \theta) \approx \mathcal{L}(\mathcal{D}; \theta_\text{MAP}) + \tfrac{1}{2} (\theta - \theta_\text{MAP})^\intercal \left( \nabla^2 _\theta \mathcal{L}(\mathcal{D}; \theta) \vert_{\theta_\text{MAP}} \right)(\theta - \theta_\text{MAP})</span>
<span id="cb1-69"><a href="#cb1-69"></a>$$</span>
<span id="cb1-70"><a href="#cb1-70"></a></span>
<span id="cb1-71"><a href="#cb1-71"></a></span>
<span id="cb1-72"><a href="#cb1-72"></a>Note that the first-order Taylor term vanishes at the MAP since it contains the gradient, and the gradient is zero at MAP, since MAP is a maximum, by definition. What remains is the constant (zeroth-order) term, and the second-order term, containing the Hessian, which is a matrix of partial second-order derivatives.</span>
<span id="cb1-73"><a href="#cb1-73"></a></span>
<span id="cb1-74"><a href="#cb1-74"></a>Then from this approximation, we can derive the long-sought multivariate normal distribution with the MAP as the mean, and the inverted Hessian as the covariance:</span>
<span id="cb1-75"><a href="#cb1-75"></a></span>
<span id="cb1-76"><a href="#cb1-76"></a>$$ </span>
<span id="cb1-77"><a href="#cb1-77"></a>p(\theta \mid \mathcal{D}) \approx N(\theta; \theta_\text{MAP}, \varSigma) \qquad\text{with}\qquad \varSigma := \left( \nabla^2_\theta \mathcal{L}(\mathcal{D};\theta) \vert_{\theta_\text{MAP}} \right)^{-1}</span>
<span id="cb1-78"><a href="#cb1-78"></a>$$</span>
<span id="cb1-79"><a href="#cb1-79"></a></span>
<span id="cb1-80"><a href="#cb1-80"></a>The evidence $Z$ is now also tractably approximated in closed form, allowing us to apply the Bayes' theorem, to obtain the posterior distribution $p(\theta \mid \mathcal{D})$.</span>
<span id="cb1-81"><a href="#cb1-81"></a>We can then express the *posterior predictive* distribution, for an input $x_*$, prediction $f(x_*)$, to obtain the probability for an output $y$.</span>
<span id="cb1-82"><a href="#cb1-82"></a></span>
<span id="cb1-83"><a href="#cb1-83"></a>The evidence $Z$ is now also tractably approximated in closed form, allowing us to apply the Bayes’ theorem, to obtain the posterior distribution $p(\theta \mid \mathcal{D})$.</span>
<span id="cb1-84"><a href="#cb1-84"></a>We can then express the posterior predictive distribution, to obtain the probability for an output $y$, given a prediction $f(x_*)$ for an input $x_*$.</span>
<span id="cb1-85"><a href="#cb1-85"></a></span>
<span id="cb1-86"><a href="#cb1-86"></a>$$ </span>
<span id="cb1-87"><a href="#cb1-87"></a>p(y \mid f(x_*), \mathcal{D}) = \int p(y \mid f_\theta(x_*)) \, p(\theta \mid \mathcal{D}) \,d\theta</span>
<span id="cb1-88"><a href="#cb1-88"></a>$$</span>
<span id="cb1-89"><a href="#cb1-89"></a></span>
<span id="cb1-90"><a href="#cb1-90"></a></span>
<span id="cb1-91"><a href="#cb1-91"></a>This is what we are really after, after all — instead of giving one singular point-estimate prediction $\widehat{y} = f(x_*)$, we make the neural network give a distribution over $y$.</span>
<span id="cb1-92"><a href="#cb1-92"></a></span>
<span id="cb1-93"><a href="#cb1-93"></a>However, since the Hessian, a square matrix, defines the covariance between all model parameters (upon inversion), of which there may be millions or billions, the computation and storage of the Hessian (not to speak of inversion!) become intractable, as its size scales quadratically with the number of parameters involved. Thus to apply Laplace approximations to large models, we must make some simplifications — which brings us to…</span>
<span id="cb1-94"><a href="#cb1-94"></a></span>
<span id="cb1-95"><a href="#cb1-95"></a><span class="fu">## Hessian approximations</span></span>
<span id="cb1-96"><a href="#cb1-96"></a></span>
<span id="cb1-97"><a href="#cb1-97"></a>Multiple techniques to approximate the Hessian have arisen from a field adjacent, yet distinct from Bayesian learning — that of second-order optimization, where Hessians are used to accelerate gradient descent convergence.</span>
<span id="cb1-98"><a href="#cb1-98"></a></span>
<span id="cb1-99"><a href="#cb1-99"></a>One such approximation is the Fisher information matrix, or simply the Fisher:</span>
<span id="cb1-100"><a href="#cb1-100"></a></span>
<span id="cb1-101"><a href="#cb1-101"></a>$$</span>
<span id="cb1-102"><a href="#cb1-102"></a>F := \textstyle\sum_{n=1}^N \mathbb{E}_{\widehat{y} \sim p(y \mid f_\theta(x_n))} \left[  gg^\intercal \right] \quad\text{with}\quad g = \nabla_\theta \log p(\widehat{y} \mid f_\theta(x_n)) \large\vert_{\theta_\text{MAP}}</span>
<span id="cb1-103"><a href="#cb1-103"></a>$$</span>
<span id="cb1-104"><a href="#cb1-104"></a></span>
<span id="cb1-105"><a href="#cb1-105"></a>Note that if instead of sampling the prediction $\widehat{y} ~ p(y \mid f(x_n))$ from the model-defined distribution, we take the actual training-set label $y_n$,</span>
<span id="cb1-106"><a href="#cb1-106"></a>the resulting matrix is called the empirical Fisher, which is distinct from the Fisher, yet aligns with it under some conditions, and does *not* generally capture second-order information. See Kunstner et al. (2019) for an excellent discussion on the distinction.</span>
<span id="cb1-107"><a href="#cb1-107"></a></span>
<span id="cb1-108"><a href="#cb1-108"></a>Instead of the Fisher, one can use the Generalized Gauss-Newton (GGN):</span>
<span id="cb1-109"><a href="#cb1-109"></a></span>
<span id="cb1-110"><a href="#cb1-110"></a>$$</span>
<span id="cb1-111"><a href="#cb1-111"></a>G := \textstyle\sum_{n=1}^N J(x_n) \left( \nabla^2_{f} \log p(y_n \mid f) \Large\vert_{f=f_{\theta_\text{map}}(x_n)} \right) J(x_n)^\intercal</span>
<span id="cb1-112"><a href="#cb1-112"></a>\text{with}\qquad J(x_n) := \nabla_\theta f_\theta(x_n) \vert_{\theta_\text{map}}</span>
<span id="cb1-113"><a href="#cb1-113"></a>$$</span>
<span id="cb1-114"><a href="#cb1-114"></a></span>
<span id="cb1-115"><a href="#cb1-115"></a>Here $J(x_n)$ represents the Jacobian of the model output w.r.t. the parameters. The middle factor $\nabla^2 …$ is a Hessian of log-likelihood of $y_n$ w.r.t. model output. Note that the model does not necessarily output ready target probabilities — for instance, classifiers output *logits*, values that define a probability distribution only after the application of the soft-max.</span>
<span id="cb1-116"><a href="#cb1-116"></a></span>
<span id="cb1-117"><a href="#cb1-117"></a>Unlike the Fisher, GGN does not require the network to define a probabilistic model on its output <span class="co">[</span><span class="ot">@botev2017practical</span><span class="co">]</span>.</span>
<span id="cb1-118"><a href="#cb1-118"></a>For models defining an exponential family distribution over the output, the two coincide <span class="co">[</span><span class="ot">@kunstner2020limitations</span><span class="co">]</span>.</span>
<span id="cb1-119"><a href="#cb1-119"></a>This applies to classifiers since they define a categorical distribution over the output, but not to simple regression models.</span>
<span id="cb1-120"><a href="#cb1-120"></a></span>
<span id="cb1-121"><a href="#cb1-121"></a>These matrices are quadratically large, it is infeasible to store them in full.</span>
<span id="cb1-122"><a href="#cb1-122"></a>The simplest estimation is to model the matrix as a diagonal — however one can easily contemplate how crude this approximation can be: for 100 parameters, only 1% of the full Hessian is captured.</span>
<span id="cb1-123"><a href="#cb1-123"></a></span>
<span id="cb1-124"><a href="#cb1-124"></a>A more sophisticated approach, due to Martens and Grosse (2015), is inspired by the observation that in practice the covariance matrices (i.e. inverted Hessians) for neural networks are block-diagonal-dominant. Thus we can effectively model the covariance matrix (and hence the Fisher) as a block-diagonal matrix, where blocks correspond to parameters grouped by layers. Additionally, each block is decomposed into two Kronecker factors, reducing the size of data stored several magnitudes more, at a cost of another assumption.</span>
<span id="cb1-125"><a href="#cb1-125"></a></span>
<span id="cb1-126"><a href="#cb1-126"></a>Lastly, a novel approach is to *sketch* a low-rank approximation of the Fisher <span class="co">[</span><span class="ot">@sharma2021sketching</span><span class="co">]</span>. @fig-fact shows four Hessian approximation structures:</span>
<span id="cb1-127"><a href="#cb1-127"></a></span>
<span id="cb1-128"><a href="#cb1-128"></a><span class="al">![(a) Hessian in full, intractable for large networks. (b) Low-rank. (c) Kronecker-factored Approximate Curvature, a block-diagonal method. (d) Diagonal. Source: @daxberger2021laplace](www/fact.png)</span>{#fig-fact}</span>
<span id="cb1-129"><a href="#cb1-129"></a></span>
<span id="cb1-130"><a href="#cb1-130"></a>It is also possible to cut the costs by treating only a subset of the model parameters, i.e. a subnetwork, probabilistically, fixing the remaining parameters at their MAP-estimated values.</span>
<span id="cb1-131"><a href="#cb1-131"></a>One special case of subnetwork Laplace that was found to perform well in practice is last-layer Laplace, where the selected subnetwork contains only the weights and biases of the last layer.</span>
<span id="cb1-132"><a href="#cb1-132"></a></span>
<span id="cb1-133"><a href="#cb1-133"></a><span class="fu">## Our contributions to LaplaceRedux.jl</span></span>
<span id="cb1-134"><a href="#cb1-134"></a></span>
<span id="cb1-135"><a href="#cb1-135"></a>In the scope of the project we have added support for:</span>
<span id="cb1-136"><a href="#cb1-136"></a><span class="ss">- </span>multi-class classification, in addition to regression and binary classification;</span>
<span id="cb1-137"><a href="#cb1-137"></a><span class="ss">- </span>GGN, in addition to empirical Fisher;</span>
<span id="cb1-138"><a href="#cb1-138"></a><span class="ss">- </span>hardware-parallelized batched computation of both the empirical Fisher and the GGN;</span>
<span id="cb1-139"><a href="#cb1-139"></a><span class="ss">- </span>subnetwork and last-layer Laplace;</span>
<span id="cb1-140"><a href="#cb1-140"></a><span class="ss">- </span>KFAC for multi-class classification with Fisher; and</span>
<span id="cb1-141"><a href="#cb1-141"></a><span class="ss">- </span>interfacing with MLJ, a common machine learning framework for Julia.</span>
<span id="cb1-142"><a href="#cb1-142"></a></span>
<span id="cb1-143"><a href="#cb1-143"></a>We have also made quality assurance / quality-of-life additions to the repository, adding:</span>
<span id="cb1-144"><a href="#cb1-144"></a><span class="ss">- </span>a formatting check in the CI/CD pipeline;</span>
<span id="cb1-145"><a href="#cb1-145"></a><span class="ss">- </span>an extensive test suite comparing the results of LaplaceRedux.jl against those of its Python counter-part package laplace-torch; and</span>
<span id="cb1-146"><a href="#cb1-146"></a><span class="ss">- </span>a benchmark pipeline tracking possible downturns in performance.</span>
<span id="cb1-147"><a href="#cb1-147"></a></span>
<span id="cb1-148"><a href="#cb1-148"></a><span class="fu">## Methodology</span></span>
<span id="cb1-149"><a href="#cb1-149"></a></span>
<span id="cb1-150"><a href="#cb1-150"></a>We adhered to the Agile/Scrum practices, with two-week-long sprints, and weekly meetings with our formal client, Patrick Altmeyer.</span>
<span id="cb1-151"><a href="#cb1-151"></a>We have prioritized the expected requirements by the Moscow method into must-, could-, should-, and won't-haves.</span>
<span id="cb1-152"><a href="#cb1-152"></a>This is all fairly standard for BSc software projects at TU Delft.</span>
<span id="cb1-153"><a href="#cb1-153"></a>By the end of the project, we have completed all of our self-assigned must-haves and should-haves.</span>
<span id="cb1-154"><a href="#cb1-154"></a></span>
<span id="cb1-155"><a href="#cb1-155"></a><span class="fu">## Pain Points</span></span>
<span id="cb1-156"><a href="#cb1-156"></a></span>
<span id="cb1-157"><a href="#cb1-157"></a>Here we list some obstacles we have encountered along the way:</span>
<span id="cb1-158"><a href="#cb1-158"></a><span class="ss">- </span>Julia is slow to compile and load dependencies on less powerful machines.</span>
<span id="cb1-159"><a href="#cb1-159"></a><span class="ss">- </span>Stack traces are sometimes rather obscure, though it seems to be the price to pay for macros.</span>
<span id="cb1-160"><a href="#cb1-160"></a><span class="ss">- </span><span class="in">`Zygote.jl`</span>, the automatic differentiation library, is <span class="co">[</span><span class="ot">not self-autodifferentiable</span><span class="co">](https://github.com/FluxML/Zygote.jl/issues/1268)</span> -- it cannot differentiate its own functions. We would want this since we apply <span class="in">`Zygote.jacobians`</span> when making predictions with the LA.</span>
<span id="cb1-161"><a href="#cb1-161"></a><span class="ss">- </span>There is no accessible tool reporting branch coverage on tests -- only line coverage is available.</span>
<span id="cb1-162"><a href="#cb1-162"></a><span class="ss">- </span>Limited LSP and Unicode support for Jupyter Lab.</span>
<span id="cb1-163"><a href="#cb1-163"></a><span class="ss">- </span>Conversion between Flux and ONNX is <span class="co">[</span><span class="ot">not yet implemented</span><span class="co">](https://github.com/FluxML/ONNX.jl)</span>.</span>
<span id="cb1-164"><a href="#cb1-164"></a><span class="ss">- </span>There is no extension library for Zygote equivalent to BackPACK or ASDL for second-order information.</span>
<span id="cb1-165"><a href="#cb1-165"></a></span>
<span id="cb1-166"><a href="#cb1-166"></a><span class="ss">- </span><span class="in">`Zygote.jl`</span>, the automatic differentiation library, is not self-autodifferentiable: <span class="co">[</span><span class="ot">issue</span><span class="co">](https://github.com/FluxML/Zygote.jl/issues/1268)</span>. We would want this since we apply <span class="in">`Zygote.jacobians`</span> when making predictions with the LA.</span>
<span id="cb1-167"><a href="#cb1-167"></a><span class="ss">- </span>There is no accessible tool reporting branch coverage on tests -- only line coverage is available.</span>
<span id="cb1-168"><a href="#cb1-168"></a><span class="ss">- </span>Limited LSP and Unicode support for Jupyter Lab.</span>
<span id="cb1-169"><a href="#cb1-169"></a><span class="ss">- </span>No conversion between Flux and ONNX is implemented yet <span class="co">[</span><span class="ot">ONNX.jl</span><span class="co">](https://github.com/FluxML/ONNX.jl)</span></span>
<span id="cb1-170"><a href="#cb1-170"></a><span class="ss">- </span>There is no extension library for Zygote equivalent to <span class="co">[</span><span class="ot">BackPACK</span><span class="co">](https://github.com/f-dangel/backpack)</span></span>
<span id="cb1-171"><a href="#cb1-171"></a>or</span>
<span id="cb1-172"><a href="#cb1-172"></a><span class="co">[</span><span class="ot">ASDL</span><span class="co">](https://github.com/kazukiosawa/asdl/)</span> for second-order information.</span>
<span id="cb1-173"><a href="#cb1-173"></a></span>
<span id="cb1-174"><a href="#cb1-174"></a><span class="fu">## Highlights</span></span>
<span id="cb1-175"><a href="#cb1-175"></a></span>
<span id="cb1-176"><a href="#cb1-176"></a>And here is what we found refreshing:</span>
<span id="cb1-177"><a href="#cb1-177"></a><span class="ss">- </span>Metaprogramming and first-class support for macros are something completely different for students who are used to Java &amp; Python.</span>
<span id="cb1-178"><a href="#cb1-178"></a><span class="ss">- </span>The Julia standard API, and Flux/Zygote, are fairly straightforward to use, and well-thought-out for numerical computing and machine learning.</span>
<span id="cb1-179"><a href="#cb1-179"></a></span>
<span id="cb1-180"><a href="#cb1-180"></a><span class="fu">## Conclusions</span></span>
<span id="cb1-181"><a href="#cb1-181"></a></span>
<span id="cb1-182"><a href="#cb1-182"></a>We have covered some elements of the theory behind Laplace Approximations, laid down our additions to the <span class="in">`LaplaceRedux.jl`</span> package, and brought out some difficulties we, as complete newcomers to Julia, came across. Hope you have enjoyed the tour, and hopefully it has intrigued you enough to look deeper into Bayesian learning and/or Julia since both are developing at a lively pace. You can check out LaplaceRedux on the JuliaTrustworthyAI GitHub page here. Contributions and comments are welcome!</span>
<span id="cb1-183"><a href="#cb1-183"></a></span>
<span id="cb1-184"><a href="#cb1-184"></a><span class="fu">## Acknowedgements</span></span>
<span id="cb1-185"><a href="#cb1-185"></a></span>
<span id="cb1-186"><a href="#cb1-186"></a>Our team members are Mark Ardman, Severin Bratus, Adelina Cazacu, Andrei Ionescu, and Ivan Makarov. We would like to thank Patrick Altmeyer for the opportunity to work on this unique project and for the continuous guidance throughout the development process. We are also grateful to Sebastijan Dumančić, our coach, Sven van der Voort, our TA mentor, and Antony Bartlett, our supporting advisor.</span>
<span id="cb1-187"><a href="#cb1-187"></a></span>
<span id="cb1-188"><a href="#cb1-188"></a><span class="fu">## References</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2023, Patrick Altmeyer</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/pat-alt/pat-alt.github.io/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.paltmeyer.com/">
      <i class="bi bi-house" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pat-alt">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/paltmey">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://medium.com/\@patrick.altmeyer">
      <i class="bi bi-medium" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>