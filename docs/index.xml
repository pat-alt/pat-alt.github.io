<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Patrick Altmeyer</title>
    <link>https://www.paltmeyer.com/</link>
      <atom:link href="https://www.paltmeyer.com/index.xml" rel="self" type="application/rss+xml" />
    <description>Patrick Altmeyer</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2022 Patrick Altmeyer</copyright><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.paltmeyer.com/media/icon_huf71aeb422d2dbec20c1fa0f7ef6934b2_32911_512x512_fill_lanczos_center_3.png</url>
      <title>Patrick Altmeyer</title>
      <link>https://www.paltmeyer.com/</link>
    </image>
    
    <item>
      <title>Python basics</title>
      <link>https://www.paltmeyer.com/courses/example/python/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/courses/example/python/</guid>
      <description>&lt;p&gt;Build a foundation in Python.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/rfscVS0vtbw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the difference between lists and tuples?&lt;/summary&gt;
  &lt;p&gt;&lt;p&gt;Lists&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lists are mutable - they can be changed&lt;/li&gt;
&lt;li&gt;Slower than tuples&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_list = [1, 2.0, &#39;Hello world&#39;]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tuples&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tuples are immutable - they can&amp;rsquo;t be changed&lt;/li&gt;
&lt;li&gt;Tuples are faster than lists&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_tuple = (1, 2.0, &#39;Hello world&#39;)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Is Python case-sensitive?&lt;/summary&gt;
  &lt;p&gt;Yes&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Visualization</title>
      <link>https://www.paltmeyer.com/courses/example/visualization/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/courses/example/visualization/</guid>
      <description>&lt;p&gt;Learn how to visualize data with Plotly.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/hSPmj7mK6ng&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;When is a heatmap useful?&lt;/summary&gt;
  &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Write Plotly code to render a bar chart&lt;/summary&gt;
  &lt;p&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; plotly.express &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; px
data_canada &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; px&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gapminder()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;query(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;country == &amp;#39;Canada&amp;#39;&amp;#34;&lt;/span&gt;)
fig &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; px&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bar(data_canada, x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;year&amp;#39;&lt;/span&gt;, y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pop&amp;#39;&lt;/span&gt;)
fig&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Statistics</title>
      <link>https://www.paltmeyer.com/courses/example/stats/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/courses/example/stats/</guid>
      <description>&lt;p&gt;Introduction to statistics for data science.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;
&lt;p&gt;The general form of the &lt;strong&gt;normal&lt;/strong&gt; probability density function is:&lt;/p&gt;
&lt;p&gt;$$
f(x) = \frac{1}{\sigma \sqrt{2\pi} } e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the parameter $\mu$?&lt;/summary&gt;
  &lt;p&gt;The parameter $\mu$ is the mean or expectation of the distribution.&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>https://www.paltmeyer.com/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Logistic Regression</title>
      <link>https://www.paltmeyer.com/post/bayesian-logistic-regression/</link>
      <pubDate>Mon, 15 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/post/bayesian-logistic-regression/</guid>
      <description>
&lt;script src=&#34;https://www.paltmeyer.com/post/bayesian-logistic-regression/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;uncertainty&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Uncertainty&lt;/h2&gt;
&lt;div class=&#34;intro-gif&#34;&gt;
&lt;figure&gt;
&lt;img src=&#34;www/toy.gif&#34;&gt;
&lt;figcaption&gt;
Simulation of changing parameter distribution.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;If you’ve ever searched for evaluation metrics to assess model accuracy, chances are that you found many different options to choose from (too many?). Accuracy is in some sense the holy grail of prediction so it’s not at all surprising that the machine learning community spends a lot time thinking about it. In a world where more and more high-stake decisions are being automated, model accuracy is in fact a very valid concern.&lt;/p&gt;
&lt;p&gt;But does this recipe for model evaluation seem like a sound and complete approach to automated decision-making? Haven’t we forgot anything? Some would argue that we need to pay more attention to &lt;strong&gt;model uncertainty&lt;/strong&gt;. No matter how many times you have cross-validated your model, the loss metric that it is being optimized against as well as its parameters and predictions remain inherently random variables. Focusing merely on prediction accuracy and ignoring uncertainty altogether can install a false level of confidence in automated decision-making systems. Any &lt;strong&gt;trustworthy&lt;/strong&gt; approach to learning from data should therefore at the very least be transparent about its own uncertainty.&lt;/p&gt;
&lt;p&gt;How can we estimate uncertainty around model parameters and predictions? &lt;strong&gt;Frequentist&lt;/strong&gt; methods for uncertainty quantification generally involve either closed-form solutions based on asymptotic theory or bootstrapping (see for example &lt;a href=&#34;https://web.stanford.edu/class/archive/stats/stats200/stats200.1172/Lecture26.pdf&#34;&gt;here&lt;/a&gt; for the case of logistic regression). In Bayesian statistics and machine learning we are instead concerned with modelling the &lt;strong&gt;posterior distribution&lt;/strong&gt; over model parameters. This approach to uncertainty quantification is known as &lt;strong&gt;Bayesian Inference&lt;/strong&gt; because we treat model parameters in a Bayesian way: we make assumptions about their distribution based on &lt;strong&gt;prior&lt;/strong&gt; knowledge or beliefs and update these beliefs in light of new evidence. The frequentist approach avoids the need for being explicit about prior beliefs, which in the past has sometimes been considered as &lt;em&gt;un&lt;/em&gt;scientific. However, frequentist methods come with their own assumptions and pitfalls (see for example &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-murphy2012machine&#34; role=&#34;doc-biblioref&#34;&gt;Murphy&lt;/a&gt; (&lt;a href=&#34;#ref-murphy2012machine&#34; role=&#34;doc-biblioref&#34;&gt;2012&lt;/a&gt;)&lt;/span&gt;) for a discussion). Without diving further into this argument, let us now see how &lt;strong&gt;Bayesian Logistic Regression&lt;/strong&gt; can be implemented from the bottom up.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-ground-truth&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The ground truth&lt;/h2&gt;
&lt;p&gt;In this post we will work with a synthetic toy data set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{D}\)&lt;/span&gt; composed of &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; binary labels &lt;span class=&#34;math inline&#34;&gt;\(y_n\in\{0,1\}\)&lt;/span&gt; and corresponding feature vectors &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_n\in \mathbb{R}^D\)&lt;/span&gt;. Working with synthetic data has the benefit that we have control over the &lt;strong&gt;ground truth&lt;/strong&gt; that generates our data. In particular, we will assume that the binary labels &lt;span class=&#34;math inline&#34;&gt;\(y_n\)&lt;/span&gt; are generated by a logistic regression model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:logreg&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; p(y_n|\mathbf{x}_n;\mathbf{w})&amp;amp;\sim\text{Ber}(y_n|\sigma(\mathbf{w}^T\mathbf{x}_n)) \\
\end{aligned}
\tag{1}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma(a)=1/(1+e^{-a})\)&lt;/span&gt; is the &lt;strong&gt;sigmoid&lt;/strong&gt; or &lt;strong&gt;logit&lt;/strong&gt; function &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-murphy2022probabilistic&#34; role=&#34;doc-biblioref&#34;&gt;Murphy 2022&lt;/a&gt;)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Features are generated from a mixed Gaussian model.&lt;/p&gt;
&lt;p&gt;To add a little bit of life to our example we will assume that the binary labels classify samples into cats and dogs, based on their height and tail length. Figure &lt;a href=&#34;#fig:ground&#34;&gt;1&lt;/a&gt; shows the synthetic data in the two-dimensional feature domain. Following an introduction to Bayesian Logistic Regression in the next section we will use the synthetic data &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{D}\)&lt;/span&gt; to estimate our model.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:ground&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/bayesian-logistic-regression/index_files/figure-html/ground-1.png&#34; alt=&#34;Ground truth labels.&#34; width=&#34;480&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Ground truth labels.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-maths&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The maths&lt;/h2&gt;
&lt;p&gt;Estimation usually boils down to finding the vector of parameters &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{w}}\)&lt;/span&gt; that maximizes the likelihood of observing &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{D}\)&lt;/span&gt; under the assumed model. That estimate can then be used to compute predictions for some new unlabelled data set &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{D}=\{x_m:m=1,...,M\}\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;problem-setup&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Problem setup&lt;/h3&gt;
&lt;p&gt;The starting point for Bayesian Logistic Regression is &lt;strong&gt;Bayes’ Theorem&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:posterior&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; p(\mathbf{w}|\mathcal{D})&amp;amp;\propto p(\mathcal{D}|\mathbf{w})p(\mathbf{w}) \\
\end{aligned}
\tag{2}
\end{equation}
\]&lt;/span&gt;
Formally, this says that the posterior distribution of parameters &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt; is proportional to the product of the likelihood of observing &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{D}\)&lt;/span&gt; given &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt; and the prior density of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt;. Applied to our context this can intuitively be understood as follows: our posterior beliefs around &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt; are formed by both our prior beliefs and the evidence we observe. Yet another way to look at this is that maximising &lt;a href=&#34;#eq:posterior&#34;&gt;(2)&lt;/a&gt; with respect to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt; corresponds to maximum likelihood estimation regularized by prior beliefs (we will come back to this).&lt;/p&gt;
&lt;p&gt;Under the assumption that individual label-feature pairs are &lt;strong&gt;independently&lt;/strong&gt; and &lt;strong&gt;identically&lt;/strong&gt; distributed, their joint likelihood is simply the product over their individual densities. The prior beliefs around &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt; are at our discretion. In practice they may be derived from previous experiments. Here we will use a zero-mean spherical Gaussian prior for reasons explained further below. To sum this up we have&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:prior&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; p(\mathcal{D}|\mathbf{w})&amp;amp; \sim \prod_{n=1}^N p(y_n|\mathbf{x}_n;\mathbf{w})\\
&amp;amp;&amp;amp; p(\mathbf{w})&amp;amp; \sim \mathcal{N} \left( \mathbf{w} | \mathbf{w}_0, \Sigma_0 \right) \\
\end{aligned}
\tag{3}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}_0=\mathbf{0}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\Sigma_0=\sigma^2\mathbf{I}\)&lt;/span&gt;. Plugging this into Bayes’ rule we finally have&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp;&amp;amp; p(\mathbf{w}|\mathcal{D})&amp;amp;\propto\prod_{n=1}^N \text{Ber}(y_n|\sigma(\mathbf{w}^T\mathbf{x}_n))\mathcal{N} \left( \mathbf{w} | \mathbf{w}_0, \Sigma_0 \right) \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Unlike with linear regression there are no closed-form analytical solutions to estimating or maximising this posterior, but fortunately accurate approximations do exist &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-murphy2022probabilistic&#34; role=&#34;doc-biblioref&#34;&gt;Murphy 2022&lt;/a&gt;)&lt;/span&gt;. One of the simplest approaches called &lt;strong&gt;Laplace Approximation&lt;/strong&gt; is straight-forward to implement and computationally very efficient. It relies on the observation that under the assumption of a Gaussian prior, the posterior of logistic regression is also approximately Gaussian: in particular, this Gaussian distribution is centered around the &lt;strong&gt;maximum a posteriori&lt;/strong&gt; (MAP) estimate &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{w}}=\arg\max_{\mathbf{w}} p(\mathbf{w}|\mathcal{D})\)&lt;/span&gt; with a covariance matrix equal to the inverse Hessian evaluated at the mode &lt;span class=&#34;math inline&#34;&gt;\(\hat{\Sigma}=(\mathbf{H}(\hat{\mathbf{w}}))^{-1}\)&lt;/span&gt;. With that in mind, finding &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{w}}\)&lt;/span&gt; seems like a natural next step.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;solving-the-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Solving the problem&lt;/h3&gt;
&lt;p&gt;In practice we do not maximize the posterior &lt;span class=&#34;math inline&#34;&gt;\(p(\mathbf{w}|\mathcal{D})\)&lt;/span&gt; directly. Instead we minimize the negative log likelihood, which is an equivalent optimization problem and easier to implement. In &lt;a href=&#34;#eq:likeli&#34;&gt;(4)&lt;/a&gt; below I have denoted the negative log likelihood as &lt;span class=&#34;math inline&#34;&gt;\(\ell(\mathbf{w})\)&lt;/span&gt; indicating that this is the &lt;strong&gt;loss function&lt;/strong&gt; we aim to minimize. The following two lines in &lt;a href=&#34;#eq:likeli&#34;&gt;(4)&lt;/a&gt; show the gradient and Hessian - so the first- and second-order derivatives of &lt;span class=&#34;math inline&#34;&gt;\(\ell\)&lt;/span&gt; with respect to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt; - where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{H}_0=\Sigma_0^{-1}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_n=\sigma(\mathbf{w}^T\mathbf{x}_n)\)&lt;/span&gt;. To understand how exactly the gradient and Hessian are derived see for example chapter 10 in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-murphy2022probabilistic&#34; role=&#34;doc-biblioref&#34;&gt;Murphy&lt;/a&gt; (&lt;a href=&#34;#ref-murphy2022probabilistic&#34; role=&#34;doc-biblioref&#34;&gt;2022&lt;/a&gt;)&lt;/span&gt;.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:likeli&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \ell(\mathbf{w})&amp;amp;=- \sum_{n=1}^{N} [y_n \log \mu_n + (1-y_n)\log (1-\mu_n)] + \frac{1}{2} (\mathbf{w}-\mathbf{w}_0)^T\mathbf{H}_0(\mathbf{w}-\mathbf{w}_0) \\
&amp;amp;&amp;amp; \nabla_{\mathbf{w}}\ell(\mathbf{w})&amp;amp;= \sum_{n=1}^{N} (\mu_n-y_n) \mathbf{x}_n + \mathbf{H}_0(\mathbf{w}-\mathbf{w}_0) \\
&amp;amp;&amp;amp; \nabla^2_{\mathbf{w}}\ell(\mathbf{w})&amp;amp;= \sum_{n=1}^{N} (\mu_n-y_n) \left( \mu_n(1-\mu_n) \mathbf{x}_n \mathbf{x}_n^T \right) + \mathbf{H}_0\\
\end{aligned}
\tag{4}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;sidenote&#34;&gt;
&lt;p&gt;&lt;strong&gt;SIDENOTE&lt;/strong&gt; 💡&lt;/p&gt;
&lt;p&gt;Note how earlier I mentioned that maximising the posterior likelihood can be seen as regularized maximum likelihood estimation. We can now make that connection explicit: in &lt;a href=&#34;#eq:likeli&#34;&gt;(4)&lt;/a&gt; let us assume that &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}_0=\mathbf{0}\)&lt;/span&gt;. Then since &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{H}_0=\lambda\mathbf{I}\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(1/\sigma^2\)&lt;/span&gt; the second term in the first line is simply &lt;span class=&#34;math inline&#34;&gt;\(\lambda \frac{1}{2} \mathbf{w}^T\mathbf{w}=\lambda \frac{1}{2} ||\mathbf{w}||_2^2\)&lt;/span&gt;. This is equivalent to running logistic regression with an &lt;span class=&#34;math inline&#34;&gt;\(\ell_2\)&lt;/span&gt;-penalty &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-bishop2006pattern&#34; role=&#34;doc-biblioref&#34;&gt;Bishop 2006&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Since minimizing the loss function in &lt;a href=&#34;#eq:likeli&#34;&gt;(4)&lt;/a&gt; is a convex optimization problem we have many efficient algorithms to choose from in order to solve this problem. With the Hessian at hand it seems natural to use a second-order method, because incorporating information about the curvature of the loss function generally leads to faster convergence. Here we will implement &lt;strong&gt;Newton’s method&lt;/strong&gt; in line with the presentation in chapter 8 of &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-murphy2022probabilistic&#34; role=&#34;doc-biblioref&#34;&gt;Murphy&lt;/a&gt; (&lt;a href=&#34;#ref-murphy2022probabilistic&#34; role=&#34;doc-biblioref&#34;&gt;2022&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posterior-predictive&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Posterior predictive&lt;/h3&gt;
&lt;p&gt;Suppose now that we have trained the Bayesian Logistic Regression model as our binary classifier &lt;span class=&#34;math inline&#34;&gt;\(g_N(\mathbf{x})\)&lt;/span&gt; using our training data &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{D}\)&lt;/span&gt;. A new unlabelled sample &lt;span class=&#34;math inline&#34;&gt;\((\mathbf{x}_{N+1},?)\)&lt;/span&gt; arrives. As with any binary classifier we can predict the missing label by simply plugging the new sample into our classifier &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_{N+1}=g_N(\mathbf{x}_{N+1})=\sigma(\hat{\mathbf{w}}^T\mathbf{x}_{N+1})\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{w}}\)&lt;/span&gt; is the MAP estimate as before. If at training phase we have found &lt;span class=&#34;math inline&#34;&gt;\(g_N(\mathbf{x})\)&lt;/span&gt; to achieve good accuracy, we may expect &lt;span class=&#34;math inline&#34;&gt;\((\mathbf{x}_{N+1},\hat{y}_{N+1})\)&lt;/span&gt; to be a reasonably good approximation of the true and unobserved pair &lt;span class=&#34;math inline&#34;&gt;\((\mathbf{x}_{N+1},y_{N+1})\)&lt;/span&gt;. But since we are still dealing with an expected value of a random variable, we would generally like to have an idea of how noisy this prediction is.&lt;/p&gt;
&lt;p&gt;Formally, we are interested in the &lt;strong&gt;posterior predictive&lt;/strong&gt; distribution:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:posterior-pred&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; p(y=1|\mathbf{x}, \mathcal{D})&amp;amp;= \int \sigma(\mathbf{w}^T \mathbf{x})p(\mathbf{w}|\mathcal{D})d\mathbf{w} \\
\end{aligned}
\tag{5}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;sidenote&#34;&gt;
&lt;p&gt;&lt;strong&gt;SIDENOTE&lt;/strong&gt; 💡&lt;/p&gt;
&lt;p&gt;The approach that ignores uncertainty altogether corresponds to what is referred to as &lt;strong&gt;plugin&lt;/strong&gt; approximation of the posterior predictive. Formally, it imposes &lt;span class=&#34;math inline&#34;&gt;\(p(y=1|\mathbf{x}, \mathcal{D})\approx p(y=1|\mathbf{x}, \hat{\mathbf{w}})\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;With the posterior distribution over model parameters &lt;span class=&#34;math inline&#34;&gt;\(p(\mathbf{w}|\mathcal{D})\)&lt;/span&gt; at hand we have the necessary ingredients to estimate the posterior predictive distribution &lt;span class=&#34;math inline&#34;&gt;\(p(y=1|\mathbf{x}, \mathcal{D})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;An obvious, but computationally expensive way to estimate it is through Monte Carlo: draw &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}_s\)&lt;/span&gt; from &lt;span class=&#34;math inline&#34;&gt;\(p(\mathbf{w}|\mathcal{D})\)&lt;/span&gt; for &lt;span class=&#34;math inline&#34;&gt;\(s=1:S\)&lt;/span&gt; and compute fitted values &lt;span class=&#34;math inline&#34;&gt;\(\sigma(\mathbf{w_s}^T\mathbf{x})\)&lt;/span&gt; each. Then the posterior predictive distribution corresponds to the average over all fitted values, &lt;span class=&#34;math inline&#34;&gt;\(p(y=1|\mathbf{x}, \mathcal{D})=1/S \sum_{s=1}^{S}\sigma(\mathbf{w_s}^T\mathbf{x})\)&lt;/span&gt;. By the law of large numbers the Monte Carlo estimate is an accurate estimate of the true posterior predictive for large enough &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;. Of course, “large enough” is somewhat loosely defined here and depending on the problem can mean “very large.” Consequently, the computational costs involved essentially know no upper bound.&lt;/p&gt;
&lt;p&gt;Fortunately, it turns out that we can trade off a little bit of accuracy in return for a convenient analytical solution. In particular, we have that &lt;span class=&#34;math inline&#34;&gt;\(\sigma(a) \approx \Phi(\lambda a)\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\Phi(.)\)&lt;/span&gt; is the standard Gaussian cdf and &lt;span class=&#34;math inline&#34;&gt;\(\lambda=\pi/8\)&lt;/span&gt; ensures that the two functions have the same slope at the origin (Figure &lt;a href=&#34;#fig:probit&#34;&gt;2&lt;/a&gt;). Without dwelling further on the details we can use this finding to approximate the integral in &lt;a href=&#34;#eq:posterior-pred&#34;&gt;(5)&lt;/a&gt; as a sigmoid function. This is called &lt;strong&gt;probit approximation&lt;/strong&gt; and implemented below.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:probit&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/bayesian-logistic-regression/index_files/figure-html/probit-1.png&#34; alt=&#34;Demonstration of the probit approximation.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Demonstration of the probit approximation.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The code&lt;/h2&gt;
&lt;p&gt;We now have all the necessary ingredients to code Bayesian Logistic Regression up from scratch. While in practice we would usually want to rely on existing packages that have been properly tested, I often find it very educative and rewarding to program algorithms from the bottom up. You will see that Julia’s syntax so closely resembles the mathematical formulas we have seen above, that going from maths to code is incredibly easy. Seeing those formulas and algorithms then actually doing their magic is quite fun! The code chunk below, for example, shows the implementation of the loss function and its derivatives from &lt;a href=&#34;#eq:likeli&#34;&gt;(4)&lt;/a&gt; above. Take a moment to go through the code line-by-line and try to understand how it relates back to the equations in &lt;a href=&#34;#eq:likeli&#34;&gt;(4)&lt;/a&gt;. Isn’t it amazing how closely the code resembles the actual equations?&lt;/p&gt;
&lt;script src=&#34;https://gist.github.com/pat-alt/cc53a11470e4fb736f24bb6de2393f54.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;Aside from the optimization routine this is essentially all there is to coding up Bayesian Logistic Regression from scratch in Julia Language. If you are curious to see the full source code in detail you can check out this &lt;a href=&#34;https://colab.research.google.com/github/pat-alt/pat-alt.github.io/blob/main/content/post/2021-11-15-bayesian-logistic-regression/julia_implementation.ipynb&#34;&gt;interactive notebook&lt;/a&gt;. Now let us finally turn back to our synthetic data and see how Bayesian Logistic Regression can help us understand the uncertainty around our model predictions.&lt;/p&gt;
&lt;div class=&#34;disclaimer&#34;&gt;
&lt;p&gt;&lt;strong&gt;DISCLAIMER&lt;/strong&gt; ❗️&lt;/p&gt;
&lt;p&gt;I should mention that this is the first time I program in Julia, so for any Julia pros out there: please bear with me! Happy to hear your suggestions/comments.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-estimates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The estimates&lt;/h2&gt;
&lt;p&gt;Figure &lt;a href=&#34;#fig:posterior&#34;&gt;3&lt;/a&gt; below shows the resulting posterior distribution for &lt;span class=&#34;math inline&#34;&gt;\(w_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(w_3\)&lt;/span&gt; at varying degrees of prior uncertainty &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. The constant &lt;span class=&#34;math inline&#34;&gt;\(w_1\)&lt;/span&gt; is held constant at the mode (&lt;span class=&#34;math inline&#34;&gt;\(\hat{w}_1\)&lt;/span&gt;). The red dot indicates the MLE. Note how for the choice of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\rightarrow 0\)&lt;/span&gt; the posterior is equal to the prior. This is intuitive since we have imposed that we have no uncertainty around our prior beliefs and hence no amount of new evidence can move us in any direction. Conversely, for &lt;span class=&#34;math inline&#34;&gt;\(\sigma \rightarrow \infty\)&lt;/span&gt; the posterior distribution is centered around the unconstrained MLE: prior knowledge is very uncertain and hence the posterior is dominated by the likelihood of the data.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:posterior&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;www/posterior.png&#34; alt=&#34;Posterior distribution for $w_2$ and $w_3$ at varying degrees of prior uncertainty $\sigma$.&#34; width=&#34;750&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Posterior distribution for &lt;span class=&#34;math inline&#34;&gt;\(w_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(w_3\)&lt;/span&gt; at varying degrees of prior uncertainty &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;What about the posterior predictive? The story is similar: since for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\rightarrow 0\)&lt;/span&gt; the posterior is completely dominated by the zero-mean prior we have &lt;span class=&#34;math inline&#34;&gt;\(p(y=1|\mathbf{x},\hat{\mathbf{w}})=0.5\)&lt;/span&gt; everywhere (top left panel in Figure &lt;a href=&#34;#fig:predictive&#34;&gt;4&lt;/a&gt;). As we gradually increase uncertainty around our prior the predictive posterior depends more and more on the data &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{D}\)&lt;/span&gt;: uncertainty around predicted labels is high only in regions that are not populated by samples &lt;span class=&#34;math inline&#34;&gt;\((y_n, \mathbf{x}_n)\)&lt;/span&gt;. Not surprisingly, this effect is strongest for the MLE (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\rightarrow \infty\)&lt;/span&gt;) where we see some evidence of overfitting.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:predictive&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;www/predictive.png&#34; alt=&#34;Predictive posterior distribution at varying degrees of prior uncertainty $\sigma$.&#34; width=&#34;750&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Predictive posterior distribution at varying degrees of prior uncertainty &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;wrapping-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wrapping up&lt;/h2&gt;
&lt;p&gt;In this post we have seen how Bayesian Logistic Regression can be implemented from scratch in Julia language. The estimated posterior distribution over model parameters can be used to quantify uncertainty around coefficients and model predictions. I have argued that it is important to be transparent about model uncertainty to avoid being overly confident in estimates.&lt;/p&gt;
&lt;p&gt;There are many more benefits associated with Bayesian (probabilistic) machine learning. Understanding where in the input domain our model exerts high uncertainty can for example be instrumental in labelling data: see for example &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-gal2017deep&#34; role=&#34;doc-biblioref&#34;&gt;Gal, Islam, and Ghahramani&lt;/a&gt; (&lt;a href=&#34;#ref-gal2017deep&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; and follow-up works for an interesting application to &lt;strong&gt;active learning&lt;/strong&gt; for image data. Similarly, there is a recent work that uses estimates of the posterior predictive in the context of &lt;strong&gt;algorithmic recourse&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-schut2021generating&#34; role=&#34;doc-biblioref&#34;&gt;Schut et al. 2021&lt;/a&gt;)&lt;/span&gt;. For a brief introduction to algorithmic recourse see one of my &lt;a href=&#34;../2021-04-26-individual-recourse-for-black-box-models/index.html&#34;&gt;previous posts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As a great reference for further reading about probabilistic machine learning I can highly recommend &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-murphy2022probabilistic&#34; role=&#34;doc-biblioref&#34;&gt;Murphy&lt;/a&gt; (&lt;a href=&#34;#ref-murphy2022probabilistic&#34; role=&#34;doc-biblioref&#34;&gt;2022&lt;/a&gt;)&lt;/span&gt;. An electronic version of the book is currently freely available as a draft. Finally, remember that if you want to try yourself at the code, you can check out this &lt;a href=&#34;https://colab.research.google.com/github/pat-alt/pat-alt.github.io/blob/main/content/post/2021-11-15-bayesian-logistic-regression/julia_implementation.ipynb&#34;&gt;interactive notebook&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;&gt;
&lt;div id=&#34;ref-bishop2006pattern&#34; class=&#34;csl-entry&#34;&gt;
Bishop, Christopher M. 2006. &lt;em&gt;Pattern Recognition and Machine Learning&lt;/em&gt;. springer.
&lt;/div&gt;
&lt;div id=&#34;ref-gal2017deep&#34; class=&#34;csl-entry&#34;&gt;
Gal, Yarin, Riashat Islam, and Zoubin Ghahramani. 2017. &lt;span&gt;“Deep Bayesian Active Learning with Image Data.”&lt;/span&gt; In &lt;em&gt;International Conference on Machine Learning&lt;/em&gt;, 1183–92. PMLR.
&lt;/div&gt;
&lt;div id=&#34;ref-murphy2012machine&#34; class=&#34;csl-entry&#34;&gt;
Murphy, Kevin P. 2012. &lt;em&gt;Machine Learning: A Probabilistic Perspective&lt;/em&gt;. MIT press.
&lt;/div&gt;
&lt;div id=&#34;ref-murphy2022probabilistic&#34; class=&#34;csl-entry&#34;&gt;
———. 2022. &lt;em&gt;Probabilistic Machine Learning: An Introduction&lt;/em&gt;. MIT Press.
&lt;/div&gt;
&lt;div id=&#34;ref-schut2021generating&#34; class=&#34;csl-entry&#34;&gt;
Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. &lt;span&gt;“Generating Interpretable Counterfactual Explanations by Implicit Minimisation of Epistemic and Aleatoric Uncertainties.”&lt;/span&gt; In &lt;em&gt;International Conference on Artificial Intelligence and Statistics&lt;/em&gt;, 1756–64. PMLR.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;We let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}=(10, 0.75, -2.5)^T\)&lt;/span&gt; define the true coefficients.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Note that the author works with the negative log likelihood scaled by the sample size&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Deep Vector Autoregression</title>
      <link>https://www.paltmeyer.com/publication/agusti2021deep/</link>
      <pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/publication/agusti2021deep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Individual recourse for Black Box Models</title>
      <link>https://www.paltmeyer.com/post/2021-04-26-individual-recourse-for-black-box-models/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/post/2021-04-26-individual-recourse-for-black-box-models/</guid>
      <description>
&lt;script src=&#34;https://www.paltmeyer.com/post/2021-04-26-individual-recourse-for-black-box-models/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;blockquote&gt;
&lt;p&gt;“You cannot appeal to [algorithms]. They do not listen. Nor do they bend.”&lt;/p&gt;
&lt;p&gt;— Cathy O’Neil&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src =&#34;www/toy.gif&#34; style=&#34;float:right; margin-left: auto; margin-right: auto; width:200px; height:200px;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In her popular book &lt;a href=&#34;https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction&#34;&gt;Weapons of Math Destruction&lt;/a&gt; Cathy O’Neil presents the example of public school teacher Sarah Wysocki, who lost her job after a teacher evaluation algorithm had rendered her redundant &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-o2016weapons&#34; role=&#34;doc-biblioref&#34;&gt;O’neil 2016&lt;/a&gt;)&lt;/span&gt;. Sarah was highly popular among her peers, supervisors and students.&lt;/p&gt;
&lt;p&gt;This post looks at a novel algorithmic solution to the problem that individuals like Sarah, who are faced with an undesirable outcome, should be provided with means to revise that outcome. The literature commonly refers to this as &lt;em&gt;individual recourse&lt;/em&gt;. One of the first approaches towards individual recourse was proposed by &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-ustun2019actionable&#34; role=&#34;doc-biblioref&#34;&gt;Ustun, Spangher, and Liu&lt;/a&gt; (&lt;a href=&#34;#ref-ustun2019actionable&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt;. In a recent follow-up paper, &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;Joshi et al.&lt;/a&gt; (&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; propose a methodology coined &lt;code&gt;REVISE&lt;/code&gt;, which extends the earlier approach in at least three key ways:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;REVISE&lt;/code&gt; provides a framework that avoids suggesting an unrealistic set of changes by imposing a threshold likelihood on the revised attributes.&lt;/li&gt;
&lt;li&gt;It is applicable to a broader class of models including Black Box classifiers and structural causal models.&lt;/li&gt;
&lt;li&gt;It can be used to detect poorly defined proxies and biases.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For a detailed discussion of these points you may check out this &lt;a href=&#34;paper_presentation.pdf&#34;&gt;slide deck&lt;/a&gt; or consult the paper directly (freely available on &lt;a href=&#34;https://deepai.org/publication/towards-realistic-individual-recourse-and-actionable-explanations-in-black-box-decision-making-systems&#34;&gt;DeepAI&lt;/a&gt;). Here, we will abstract from some of these complications and instead look at an application of a slightly simplified version of &lt;code&gt;REVISE&lt;/code&gt;. This should help us to first build a good intuition. Readers interested in the technicalities and code may find all of this in the annex below.&lt;/p&gt;
&lt;div id=&#34;from-to&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;From 🐱 to 🐶&lt;/h2&gt;
&lt;p&gt;We will explain &lt;code&gt;REVISE&lt;/code&gt; through a short tale of cats and dogs. The protagonist of this tale is Kitty 🐱, a young cat that identifies as a dog. Unfortunately, Kitty is not very tall and her tail, though short for a cat, is longer than that of the average dog (Figure &lt;a href=&#34;#fig:density&#34;&gt;1&lt;/a&gt;).&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:density&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-04-26-individual-recourse-for-black-box-models/index_files/figure-html/density-1.png&#34; alt=&#34;Empirical distributions of simulated data set describing cats and dogs. Vertical stalks represent Kitty&#39;s attribute values.&#34; width=&#34;864&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Empirical distributions of simulated data set describing cats and dogs. Vertical stalks represent Kitty’s attribute values.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Much to her dismay, Kitty has been recognized as a cat by a linear classifier &lt;span class=&#34;math inline&#34;&gt;\(g_n(X)\)&lt;/span&gt; that we trained through stochastic gradient descent using the data on animals’ height and tail length. Once again interested readers may find technical details and code in the annex below. Figure &lt;a href=&#34;#fig:class&#34;&gt;2&lt;/a&gt; shows the resulting linear separation in the attribute space with the decision boundary in solid black and Kitty’s location indicated by a red circle. Can we provide individual recourse to Kitty?&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:class&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-04-26-individual-recourse-for-black-box-models/index_files/figure-html/class-1.png&#34; alt=&#34;Linear separation of cats and dogs in the 2-dimensional attribute space with the decision boundary of the fitted classifier in solid black. Kitty&#39;s location is indicated by a red circle.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Linear separation of cats and dogs in the 2-dimensional attribute space with the decision boundary of the fitted classifier in solid black. Kitty’s location is indicated by a red circle.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Let’s see if and how we can apply &lt;code&gt;REVISE&lt;/code&gt; to Kitty’s problem. The following summary should give you some flavour of how the algorithm works:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Initialize &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i&amp;#39;^{(0)}\)&lt;/span&gt;, that is the attributes that will be revised recursively. Kitty’s original attributes seem like a reasonable place to start.&lt;/li&gt;
&lt;li&gt;Through gradient descent recursively revise &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i&amp;#39;^{(t)}\)&lt;/span&gt; until &lt;span class=&#34;math inline&#34;&gt;\(g_n(\mathbf{x}_i&amp;#39;^{(T)})=\)&lt;/span&gt;🐶. At this point &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; the descent terminates since for these revised attributes the classifier labels Kitty as a dog.&lt;/li&gt;
&lt;li&gt;Return &lt;span class=&#34;math inline&#34;&gt;\(\delta_i=\mathbf{x}_i&amp;#39;^{(T)}-\mathbf{x}_i\)&lt;/span&gt;, that is the individual recourse for Kitty.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Figure &lt;a href=&#34;#fig:revise&#34;&gt;3&lt;/a&gt; illustrates what happens when this approach is applied to Kitty’s problem. The different panels show the results for different values of a regularization parameter &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; that governs the trade-off between achieving the desired label switch and keeping the distance between the original (&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i\)&lt;/span&gt;) and revised (&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i&amp;#39;\)&lt;/span&gt;) attributes small. In all but one case, &lt;code&gt;REVISE&lt;/code&gt; converges: a decrease in tail length along with an increase in height eventually allows Kitty to cross the decision boundary. In other words, we have successfully turned Kitty into a dog - at least in the eyes of the linear classifier!&lt;/p&gt;
&lt;p&gt;We also observe that as we increase &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; for a fixed learning rate, &lt;code&gt;REVISE&lt;/code&gt; takes longer to converge. This should come as no surprise, since higher values of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; lead to greater regularization with respect to the penalty we place on the distance that Kitty has to travel. When we penalize too much (&lt;span class=&#34;math inline&#34;&gt;\(\lambda=10\)&lt;/span&gt;), Kitty never reaches the decision boundary, because she is reluctant to change her characteristics beyond a certain point. While not visible to the naked eye, in this particular example &lt;span class=&#34;math inline&#34;&gt;\(\lambda=0.001\)&lt;/span&gt; corresponds to the best choice among the candidate values.&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:revise&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;www/revise.gif&#34; alt=&#34;The simplified `REVISE` algorithm in action: how Kitty crosses the decision boundary by changing her attributes. Regularization with respect to the distance penalty increases from top left to bottom right.&#34;  /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: The simplified &lt;code&gt;REVISE&lt;/code&gt; algorithm in action: how Kitty crosses the decision boundary by changing her attributes. Regularization with respect to the distance penalty increases from top left to bottom right.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;discussion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;While hopefully Kitty’s journey has provided you with some useful intuition, the story is of course very silly. Even if your cat ever seems to signal that she wants to be a dog, helping her cross that decision boundary will be tricky. Some attributes are simply immutable or very difficult to change, which &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;Joshi et al.&lt;/a&gt; (&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; do not fail to account for in their framework. Their proposed methodology offers a simple and ingenious approach towards providing individual recourse. Instead of concerning ourselves with Black Box interpretability, why not simply provide remedy in case things go wrong?&lt;/p&gt;
&lt;p&gt;To some extent that idea has its merit. As this post has hopefully shown, &lt;code&gt;REVISE&lt;/code&gt; is straight-forward to understand and readily applicable. It could be a very useful tool to provide individual recourse in many real-world applications. As the implementation of our simplified version of &lt;code&gt;REVISE&lt;/code&gt; demonstrates, researchers should also find it relatively easy to develop the methodology further and tailor it to specific use cases. The simpler version here, for example, may be useful in settings where the dimensionality is relatively small and one can reasonably model the distribution of attributes without the need for generative models.&lt;/p&gt;
&lt;p&gt;Still, you may be wondering: if the original classifier is based on poorly defined rules and proxies, then what good does &lt;code&gt;REVISE&lt;/code&gt; really do? Going back to the example of high-school teacher Sarah Wysocki, one of the key attributes determining teachers’ evaluations was their students’ performance. Realizing this, some teachers took the shortest route to success by artificially inflating their students’ test scores. That same course of action may well have been suggested by &lt;code&gt;REVISE&lt;/code&gt;. As &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;Joshi et al.&lt;/a&gt; (&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; demonstrate, this very property of &lt;code&gt;REVISE&lt;/code&gt; may actually proof useful in detecting weaknesses of decision making systems before setting them loose (key contribution 3).&lt;/p&gt;
&lt;p&gt;Nonetheless, the example above also demonstrates that approaches like &lt;code&gt;REVISE&lt;/code&gt;, useful as they may be, tend to provide solutions for very particular problems. In reality data-driven decision making systems are often subject to many different problems and hence research on trustworthy AI will need to tackle the issue from various angles. A few places to start include the question of dealing with data that is inherently biased, improving ad-hoc and post-hoc model interpretability and continuing efforts around causality-inspired AI.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;&gt;
&lt;div id=&#34;ref-joshi2019towards&#34; class=&#34;csl-entry&#34;&gt;
Joshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. &lt;span&gt;“Towards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.”&lt;/span&gt; &lt;em&gt;arXiv Preprint arXiv:1907.09615&lt;/em&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-o2016weapons&#34; class=&#34;csl-entry&#34;&gt;
O’neil, Cathy. 2016. &lt;em&gt;Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy&lt;/em&gt;. Crown.
&lt;/div&gt;
&lt;div id=&#34;ref-ustun2019actionable&#34; class=&#34;csl-entry&#34;&gt;
Ustun, Berk, Alexander Spangher, and Yang Liu. 2019. &lt;span&gt;“Actionable Recourse in Linear Classification.”&lt;/span&gt; In &lt;em&gt;Proceedings of the Conference on Fairness, Accountability, and Transparency&lt;/em&gt;, 10–19.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;annex&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Annex&lt;/h2&gt;
&lt;p&gt;In my blog posts I aim to implement interesting ideas from scratch even if that sometimes means that things need to undergo some sort of simplification. The benefit of this approach is that the experience is educationally rewarding - both for myself and hopefully also for readers. The first two sections of this annex show how &lt;code&gt;REVISE&lt;/code&gt; and linear classification can be implemented in R. The final section just shows how the synthetic data was generated. To also inspect the code that generates the visualizations and everything else, you can find the source code of this file on &lt;a href=&#34;https://github.com/pat-alt/patalt/blob/master/content/post/2021-04-26-individual-recourse-for-black-box-models/index.Rmd&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;linear-classifier&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Linear classifier&lt;/h3&gt;
&lt;p&gt;Linear classification is implemented through stochastic gradient descent (SGD) with Hinge loss&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp;&amp;amp; \ell(-\mathbf{w}^T\mathbf{x}_i y_i)&amp;amp;=(1-\mathbf{w}^T\mathbf{x}_i y_i)_+ \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt; is a coefficient vector, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i\)&lt;/span&gt; is the attribute vector of individual &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is the individual’s outcome. Since we apply SGD in order to minimize the loss function &lt;span class=&#34;math inline&#34;&gt;\(\ell\)&lt;/span&gt; by varying &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt;, we need an expression for its gradient with respect to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt;, which is given by:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:hinge&#34;&gt;\[\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \nabla_{\mathbf{W}} \left( \ell(-\mathbf{w}^T\mathbf{x}_i y_i) \right) &amp;amp;= \begin{cases} -\mathbf{x}_i y_i &amp;amp; \text{if} \ \ \ \mathbf{w}^T\mathbf{x}_i y_i \le 1\\ 0 &amp;amp; \text{otherwise} \end{cases} \\
\end{aligned}
\tag{1}
\end{equation}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The code below uses this analytical solution to perform SGD over &lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt; iterations or as long as updates yield feasible parameter values. As the final vector of coefficients the function returns &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\bar{w}}= \frac{1}{T} \sum_{t=1}^{T} \mathbf{w}_t\)&lt;/span&gt;. Denoting the optimal coefficient vector as &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}^*\)&lt;/span&gt;, it can be shown that under certain conditions &lt;span class=&#34;math inline&#34;&gt;\(\ell(\mathbf{\bar{w}})\rightarrow\ell(\mathbf{w}^*)\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(T\rightarrow\infty\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#&amp;#39; Stochastic gradient descent
#&amp;#39;
#&amp;#39; @param X Feature matrix.
#&amp;#39; @param y Vector containing training labels.
#&amp;#39; @param eta Learning rate.
#&amp;#39; @param n_iter Maximum number of iterations.
#&amp;#39; @param w_init Initial parameter values.
#&amp;#39; @param save_steps Boolean checking if coefficients should be saved at each step.
#&amp;#39;
#&amp;#39; @return
#&amp;#39; @export
#&amp;#39;
#&amp;#39; @author Patrick Altmeyer
linear_classifier &amp;lt;- function(X,y,eta=0.001,n_iter=1000,w_init=NULL,save_steps=FALSE) {
  # Initialization: ----
  n &amp;lt;- nrow(X) # number of observations
  d &amp;lt;- ncol(X) # number of dimensions
  if (is.null(w_init)) {
    w &amp;lt;- matrix(rep(0,d)) # initialize coefficients as zero...
  } else {
    w &amp;lt;- matrix(w_init) # ...unless initial values have been provided.
  }
  w_avg &amp;lt;- 1/n_iter * w # initialize average coefficients
  iter &amp;lt;- 1 # iteration count
  if (save_steps) {
    steps &amp;lt;- data.table(iter=0, w=c(w), d=1:d) # if desired, save coefficient at each step
  } else {
    steps &amp;lt;- NA
  }
  feasible_w &amp;lt;- TRUE # to check if coefficients are finite, non-nan, ...
  # Surrogate loss:
  l &amp;lt;- function(X,y,w) {
    x &amp;lt;- (-1) * crossprod(X,w) * y
    pmax(0,1 + x) # Hinge loss
  }
  grad &amp;lt;- function(X,y,w) {
    X %*% ifelse(crossprod(X,w) * y&amp;lt;=1,-y,0) # Gradient of Hinge loss
  }
  # Stochastic gradient descent: ----
  while (feasible_w &amp;amp; iter&amp;lt;n_iter) {
    t &amp;lt;- sample(1:n,1) # random draw
    X_t &amp;lt;- matrix(X[t,])
    y_t &amp;lt;- matrix(y[t])
    v_t &amp;lt;- grad(X_t,y_t,w) # compute estimate of gradient
    # Update:
    w &amp;lt;- w - eta * v_t # update coefficient vector
    feasible_w &amp;lt;- all(sapply(w, function(i) !is.na(i) &amp;amp; is.finite(i))) # check if feasible
    if (feasible_w) {
      w_avg &amp;lt;- w_avg + 1/n_iter * w # update average
    }
    if (save_steps) {
      steps &amp;lt;- rbind(steps, data.table(iter=iter, w=c(w), d=1:d))
    }
    iter &amp;lt;- iter + 1 # increase counter
  }
  # Output: ----
  output &amp;lt;- list(
    X = X,
    y = matrix(y),
    coefficients = w_avg,
    eta = eta,
    n_iter = n_iter,
    steps = steps
  )
  class(output) &amp;lt;- &amp;quot;classifier&amp;quot; # assign S3 class
  return(output)
}

# Methods: ----
print.classifier &amp;lt;- function(classifier) {
  print(&amp;quot;Coefficients:&amp;quot;)
  print(classifier$coefficients)
}
print &amp;lt;- function(classifier) {
  UseMethod(&amp;quot;print&amp;quot;)
}

predict.classifier &amp;lt;- function(classifier, newdata=NULL, discrete=TRUE) {
  if (!is.null(newdata)) {
    fitted &amp;lt;- newdata %*% classifier$coefficients # out-of-sampple prediction
  } else {
    fitted &amp;lt;- classifier$X %*% classifier$coefficients # in-sample fit
  }
  if (discrete) {
    fitted &amp;lt;- sign(fitted) # map to {-1,1}
  }
  return(fitted)
}
predict &amp;lt;- function(classifier, newdata=NULL, discrete=TRUE) {
  UseMethod(&amp;quot;predict&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;revise-simplified&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;REVISE&lt;/code&gt; (simplified)&lt;/h3&gt;
&lt;p&gt;As flagged above, we are looking at a slightly simplified version of the algorithm presented in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;Joshi et al.&lt;/a&gt; (&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt;. In particular, the approach here does not incorporate the threshold on the likelihood nor does it account for immutable attributes.&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(y\in\{-1,1\}\)&lt;/span&gt; be a binary outcome variable, &lt;span class=&#34;math inline&#34;&gt;\(X\in\mathbb{R}^d\)&lt;/span&gt; a feature matrix containing individuals’ attributes and &lt;span class=&#34;math inline&#34;&gt;\(g_n(X)\)&lt;/span&gt; a corresponding data-dependent classifier. Suppose &lt;span class=&#34;math inline&#34;&gt;\(y_i=-1\)&lt;/span&gt; (the negative outcome) for some individual characterized by attributes &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i\)&lt;/span&gt;. Then we want to find &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i&amp;#39;\)&lt;/span&gt; closest to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_i\)&lt;/span&gt; such that the classifier assigns the positive outcome &lt;span class=&#34;math inline&#34;&gt;\(g(\mathbf{x}_i^{&amp;#39;})=1\)&lt;/span&gt;. In order to do so, we use gradient descent with Hinge loss &lt;span class=&#34;math inline&#34;&gt;\(\ell\)&lt;/span&gt; to minimize the following function&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp;&amp;amp; \min_{\mathbf{x}_i^{&amp;#39;}}&amp;amp; \ \ell(g_n(\mathbf{x}_i^{&amp;#39;}),1) + \lambda d(\mathbf{x}_i^{&amp;#39;},\mathbf{x}_i) \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(d=||\mathbf{x}_i^{&amp;#39;}-\mathbf{x}_i||\)&lt;/span&gt; denotes the Euclidean distance. Note that this time we take the coefficient vector defining &lt;span class=&#34;math inline&#34;&gt;\(g_n\)&lt;/span&gt; as given and instead vary the attributes. In particular, we will perform gradient descent steps as follows&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp;&amp;amp; {\mathbf{x}_i^{&amp;#39;}}^t&amp;amp;\leftarrow {\mathbf{x}_i^{&amp;#39;}}^{t-1} + \eta \nabla_{{\mathbf{x}_i^{&amp;#39;}}} \left( \ell(g_n(\mathbf{x}_i^{&amp;#39;}),1) + \lambda d(\mathbf{x}_i^{&amp;#39;},\mathbf{x}_i)  \right)  \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; is the learning rate. The descent step is almost equivalent to the one described in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;Joshi et al.&lt;/a&gt; (&lt;a href=&#34;#ref-joshi2019towards&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt;, but here we greatly simplify things by optimizing directly in the attribute space instead of a latent space. The gradient of the loss function looks very similar to &lt;a href=&#34;#eq:hinge&#34;&gt;(1)&lt;/a&gt;. With respect to the Euclidean distance partial derivatives are of the following form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp;&amp;amp;  \frac{\partial ||\mathbf{x}_i^{&amp;#39;}-\mathbf{x}_i||}{\partial {x_i&amp;#39;}^{(d)}}  &amp;amp;= \frac{{x_i&amp;#39;}^{(d)}-{x_i}^{(d)}}{||\mathbf{x}_i^{&amp;#39;}-\mathbf{x}_i||} \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The code that implements this optimization follows below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#&amp;#39; REVISE algoritm - a simplified version
#&amp;#39;
#&amp;#39; @param classifier The fitted classifier.
#&amp;#39; @param x_star Attributes of individual seeking individual recourse.
#&amp;#39; @param eta Learning rate.
#&amp;#39; @param lambda Regularization parameter.
#&amp;#39; @param n_iter Maximum number of operations.
#&amp;#39; @param save_steps Boolean indicating if intermediate steps should be saved.
#&amp;#39;
#&amp;#39; @return
#&amp;#39; @export
#&amp;#39;
#&amp;#39; @author Patrick Altmeyer
revise.classifier &amp;lt;- function(classifier,x_star,eta=1,lambda=0.01,n_iter=1000,save_steps=FALSE) {
  # Initialization: ----
  d &amp;lt;- length(x_star) # number of dimensions
  if (!is.null(names(x_star))) {
    d_names &amp;lt;- names(x_star) # names of attributes, if provided
  } else {
    d_names &amp;lt;- sprintf(&amp;quot;X%i&amp;quot;, 1:d)
  }
  w &amp;lt;- classifier$coefficients # coefficient vector
  x &amp;lt;- x_star # initialization of revised attributes
  distance &amp;lt;- 0 # initial distance from starting point
  converged &amp;lt;- predict(classifier, newdata = x)[1,1]==1 # positive outcome?
  iter &amp;lt;- 1 # counter
  if (save_steps) {
    steps &amp;lt;- data.table(iter=1, x=x, d=d_names) # save intermediate steps, if desired
  } else {
    steps &amp;lt;- NA
  }
  # Gradients:
  grad &amp;lt;- function(x,y,w) {
    w %*% ifelse(crossprod(x,w) * y&amp;lt;=1,-y,0) # gradient of Hinge loss with respect to X
  }
  grad_dist &amp;lt;- function(x,x_star) {
    d &amp;lt;- length(x_star)
    distance &amp;lt;- dist(matrix(cbind(x_star,x),nrow=d,byrow = T))
    matrix((x-x_star) / distance) # gradient of Euclidean distance with respect to X
  }
  # Gradient descent: ----
  while(!converged &amp;amp; iter&amp;lt;n_iter) {
    if (distance!=0) {
      x &amp;lt;- c(x - eta * (grad(x=matrix(x),y=1,w) + lambda * grad_dist(x,x_star))) # gradient descent step
    } else {
      x &amp;lt;- c(x - eta * grad(x=matrix(x),y=1,w)) # gradient with respect to distance not defined at zero
    }
    converged &amp;lt;- predict(classifier, newdata = x)[1,1]==1 # positive outcome?
    iter &amp;lt;- iter + 1 # update counter
    if (save_steps) {
      steps &amp;lt;- rbind(steps, data.table(iter=iter, x=x, d=d_names))
    }
    distance &amp;lt;- dist(matrix(cbind(x_star,x),nrow=d,byrow = T)) # update distance
  }
  # Output: ----
  if (converged) {
    revise &amp;lt;- x - x_star
  } else {
    revise &amp;lt;- NA
  }
  output &amp;lt;- list(
    x_star = x_star,
    revise = revise,
    classifier = classifier,
    steps = steps,
    lambda = lambda,
    distance = distance,
    mean_distance = mean(abs(revise))
  )
  return(output)
}

revise &amp;lt;- function(classifier,x_star,eta=1,lambda=0.01,n_iter=1000,save_steps=FALSE) {
  UseMethod(&amp;quot;revise&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;simulated-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Simulated data&lt;/h3&gt;
&lt;p&gt;The synthetic data describing cats and dogs was generated as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_data &amp;lt;- function(n=100,averages,noise=0.1) {
  d &amp;lt;- ncol(averages)
  y &amp;lt;- 2*(rbinom(n,1,0.5)-0.5) # generate binary outcome: 1=dog, -1=cat
  X &amp;lt;- as.matrix(averages[(y+1)/2+1,]) # generate attributes conditional on y
  dogs &amp;lt;- y==1 # boolean index for dogs
  cats &amp;lt;- y==-1 # boolean index for cats
  X[cats,] &amp;lt;- X[cats,] + 
    matrix(rnorm(sum(cats)*d),nrow=sum(cats)) %*% diag(noise*averages[2,]) # add noise for y=1 (cats)
  X[dogs,] &amp;lt;- X[dogs,] + 
    matrix(rnorm(sum(dogs)*d),nrow=sum(dogs)) %*% diag(noise*averages[2,]) # add noise for y=1 (dogs)
  return(list(X=X,y=y))
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Optimal subsampling</title>
      <link>https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/</guid>
      <description>
&lt;script src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#optimal-subsampling&#34;&gt;Optimal subsampling&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#bias-variance-tradeoff&#34;&gt;Bias-variance tradeoff&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsampling&#34;&gt;Subsampling methods&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#ols-and-wls&#34;&gt;OLS and WLS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#uniform-subsampling-unif&#34;&gt;Uniform subsampling (UNIF)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#basic-leveraging-blev&#34;&gt;Basic leveraging (BLEV)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#predictor-length-sampling-pl&#34;&gt;Predictor-length sampling (PL)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#comparison-of-methods&#34;&gt;Comparison of methods&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lin-reg&#34;&gt;Linear regression model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#a-review-of-zhu2015optimal&#34;&gt;A review of &lt;span class=&#34;citation&#34;&gt;&lt;span&gt;Zhu et al.&lt;/span&gt; (&lt;span&gt;2015&lt;/span&gt;)&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#computational-performance&#34;&gt;Computational performance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#further-work&#34;&gt;Further work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#app-wls&#34;&gt;Weighted least-squares&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#app-svd&#34;&gt;From SVD to leverage scores&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#app-pl&#34;&gt;From optimal to prediction-length subsampling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#app-dens&#34;&gt;Synthetic data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#app-sin&#34;&gt;Subsampling applied to sinusoidal function&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;optimal-subsampling&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Optimal subsampling&lt;/h1&gt;
&lt;p&gt;When working with very large sample data, even the estimation of ordinary least-squares can be computationally prohibitive. Since we increasingly find ourselves in situations where the sample size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is extremely high, a body of literature concerned with optimal subsampling has recently emerged. This post summarises some of the main ideas and methodologies that have emerged from that literature. The post is structured as follows: to set the stage for the remainder of the analysis the first section briefly introduces the bias-variance trade-off. The following section then introduces various subsampling methods. Finally, we will looks at a small empirical exercise that illustrates the improvements associated with non-uniform subsampling.&lt;/p&gt;
&lt;div id=&#34;bias-variance-tradeoff&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bias-variance tradeoff&lt;/h2&gt;
&lt;p&gt;All computations are done in R. Code is reported only where it is deemed useful, but as always full details can be found in the &lt;a href=&#34;https://github.com/pat-alt/patalt&#34;&gt;GitHub repository&lt;/a&gt;. In some places I use &lt;a href=&#34;https://github.com/pat-alt/fromScratchR&#34;&gt;fromScratchR&lt;/a&gt;, a package I am working on. The package is very much a work-in-progress and at this point primarily serves the purpose of collecting any programs I code up from scratch. It can be installed from GitHub through &lt;code&gt;devtools::install_github(&#34;pat-alt/fromScratchR&#34;)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To set the stage for the remainder of this note we will briefly revisit the bias-variance trade-off in this section. In particular we will illustrate the effect of varying the sample size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. Readers familiar with this topic may choose to skip this section.&lt;/p&gt;
&lt;p&gt;As as in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-bishop2006pattern&#34; role=&#34;doc-biblioref&#34;&gt;Bishop&lt;/a&gt; (&lt;a href=&#34;#ref-bishop2006pattern&#34; role=&#34;doc-biblioref&#34;&gt;2006&lt;/a&gt;)&lt;/span&gt; we consider synthetic data generated by the sinusoidal function &lt;span class=&#34;math inline&#34;&gt;\(f(x)=\sin(2\pi x)\)&lt;/span&gt;. To simulate random samples of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{y}\)&lt;/span&gt; we sample &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; input values from &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X} \sim \text{unif}(0,1)\)&lt;/span&gt; and introduce a random noise component &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon \sim \mathcal{N}(0,0.3)\)&lt;/span&gt;. Figure &lt;a href=&#34;#fig:p-sim&#34;&gt;1&lt;/a&gt; shows &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{y}\)&lt;/span&gt; along with random draws &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{y}^*_n\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:p-sim&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/figure-html/p-sim-1.png&#34; alt=&#34;Sinusoidal function and random draws.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Sinusoidal function and random draws.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Following &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-bishop2006pattern&#34; role=&#34;doc-biblioref&#34;&gt;Bishop&lt;/a&gt; (&lt;a href=&#34;#ref-bishop2006pattern&#34; role=&#34;doc-biblioref&#34;&gt;2006&lt;/a&gt;)&lt;/span&gt; we will use a Gaussian linear model with Gaussian kernels &lt;span class=&#34;math inline&#34;&gt;\(\exp(-\frac{(x_k-\mu_p)^{2}}{2s^2})\)&lt;/span&gt; as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:model&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \mathbf{y}|\mathbf{X}&amp;amp; =f(x) \sim \mathcal{N} \left( \sum_{j=0}^{p-1} \phi_j(x)\beta_j, v \mathbb{I}_p \right) \\
\end{aligned}
\tag{1}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(v=0.3\)&lt;/span&gt; to estimate &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{y}}_k\)&lt;/span&gt; from random draws &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_k\)&lt;/span&gt;. We fix the number of kernels &lt;span class=&#34;math inline&#34;&gt;\(p=24\)&lt;/span&gt; (and hence the number of features &lt;span class=&#34;math inline&#34;&gt;\(M=p+1=25\)&lt;/span&gt;) as well as the spatial scale &lt;span class=&#34;math inline&#34;&gt;\(s=0.1\)&lt;/span&gt;. To vary the complexity of the model we use a form of regularized least-squares (&lt;em&gt;Ridge regression&lt;/em&gt;) and let the regularization parameter &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; vary&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:reg-ls&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \hat\beta&amp;amp;=(\lambda I + \Phi^T \Phi)^{-1}\Phi^Ty \\
\end{aligned}
\tag{2}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where high values of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; in &lt;a href=&#34;#eq:reg-ls&#34;&gt;(2)&lt;/a&gt; shrink parameter values towards zero. (Note that a choice &lt;span class=&#34;math inline&#34;&gt;\(\lambda=0\)&lt;/span&gt; corresponds to the OLS estimator which is defined as long as &lt;span class=&#34;math inline&#34;&gt;\(p \le n\)&lt;/span&gt;.)&lt;/p&gt;
&lt;p&gt;As in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-bishop2006pattern&#34; role=&#34;doc-biblioref&#34;&gt;Bishop&lt;/a&gt; (&lt;a href=&#34;#ref-bishop2006pattern&#34; role=&#34;doc-biblioref&#34;&gt;2006&lt;/a&gt;)&lt;/span&gt; we proceed as follows for each choice of &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; and each sample draw to illustrate the bias-variance trade-off:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Draw &lt;span class=&#34;math inline&#34;&gt;\(N=25\)&lt;/span&gt; time from &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{u}_k \sim \text{unif}(0,1)\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_k^*=\mathbf{u}_k+\varepsilon_k\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon \sim \mathcal{N}(0, 0.3)\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Compute &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{y}_k^*=\sin(2\pi \mathbf{X}^*_k)\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Extract features &lt;span class=&#34;math inline&#34;&gt;\(\Phi_k\)&lt;/span&gt; from &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_k^*\)&lt;/span&gt; and estimate the parameter vector &lt;span class=&#34;math inline&#34;&gt;\(\beta_k^*(\Phi_k,\mathbf{y}^*_k,\lambda)\)&lt;/span&gt; through regularized least-squares.&lt;/li&gt;
&lt;li&gt;Predict &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{y}}_k^*=\Phi \beta_k^*\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Applying the above procedure we can construct the familiar picture that demonstrates how increased model complexity increases variance while reducing bias (Figure &lt;a href=&#34;#fig:plot-bias-var&#34;&gt;2&lt;/a&gt;). Recall that for the mean-squared error (MSE) we have&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:mse&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \mathbb{E} \left( (\hat{f}_n(x)-f(x))^2 \right)
&amp;amp;= \text{var} (\hat{f}_n(x)) + \left( \mathbb{E} \left( \hat{f}_n(x) \right) - f(x) \right)^2 \\
\end{aligned}
\tag{3}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the first term on the right-hand side corresponds to the variance of our prediction and the second term to its (squared) bias. In Figure &lt;a href=&#34;#fig:plot-bias-var&#34;&gt;2&lt;/a&gt; as model complexity increases the variance component of the MSE increases, while the bias term diminishes. A similar pattern would have been observed if instead of using regularization we had used OLS and let the number of Gaussian kernels (and hence the number of features &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;) vary where higher values of &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; correspond to increased model complexity.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:plot-bias-var&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/figure-html/plot-bias-var-1.png&#34; alt=&#34;Bias-variance trade-off.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Bias-variance trade-off.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The focus of this note is instead on varying the sample size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. It should not be surprising that both the variance and bias component of the MSE decrease as the sample size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; increases (Figure &lt;a href=&#34;#fig:plot-bias-var-n&#34;&gt;3&lt;/a&gt;). But in today’s world &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; can potentially be very large, so much so that even computing simple linear models can be hard. Suppose for example you wanted to use patient data that is generated in real-time as a global pandemic unfolds to predict the trajectory of said pandemic. Or consider the vast quantities of potentially useful user-generated data that online service providers have access to. In the remainder of this note we will investigate how systematic subsampling can help improve model accuracy in these situations.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:plot-bias-var-n&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/figure-html/plot-bias-var-n-1.png&#34; alt=&#34;Bias-variance trade-off. The effect of sample size.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Bias-variance trade-off. The effect of sample size.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;subsampling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Subsampling methods&lt;/h2&gt;
&lt;p&gt;The case for subsampling generally involves &lt;span class=&#34;math inline&#34;&gt;\(n &amp;gt;&amp;gt; p\)&lt;/span&gt;, so very large values of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. In such cases we may be interested in estimating &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_m\)&lt;/span&gt; instead of &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_n\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(p\le m&amp;lt;&amp;lt;n\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; freely chosen by us. In practice we may want to do this to avoid high computational costs associated with large &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; as discussed above. The basic algorithm for estimating &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_m\)&lt;/span&gt; is simple:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Subsample with replacement from the data with some sampling probability &lt;span class=&#34;math inline&#34;&gt;\(\{\pi_i\}^n_{i=1}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Estimate least-squares estimator &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_m\)&lt;/span&gt; using the subsample.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But there are at least two questions about this algorithm: firstly, how do we choose &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_m=({\mathbf{X}^{(1)}}^T,...,{\mathbf{X}^{(m)}}^T)^T\)&lt;/span&gt;? Secondly, how should we construct &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_m\)&lt;/span&gt;? With respect to the former, a better idea than just randomly selecting &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_m\)&lt;/span&gt; might be to choose observations with high influence. We will look at a few of the different subsampling methods investigated and proposed in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;, which differ primarily in their choice of subsampling probabilities &lt;span class=&#34;math inline&#34;&gt;\(\{\pi_i\}^n_{i=1}\)&lt;/span&gt;:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Uniform subsampling (UNIF): &lt;span class=&#34;math inline&#34;&gt;\(\{\pi_i\}^n_{i=1}=1/n\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Basic leveraging (BLEV): &lt;span class=&#34;math inline&#34;&gt;\(\{\pi_i\}^n_{i=1}=h_{ii}/ \text{tr}(\mathbf{H})=h_{ii}/p\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{H}\)&lt;/span&gt; is the &lt;em&gt;hat matrix&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Optimal (OPT) and predictor-length sampling (PL): involving &lt;span class=&#34;math inline&#34;&gt;\(||\mathbf{X}_i||/ \sum_{j=1}^{n}||\mathbf{X}_j||\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(||\mathbf{X}||\)&lt;/span&gt; denotes the &lt;span class=&#34;math inline&#34;&gt;\(L_2\)&lt;/span&gt; norm of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Methods involving predictor-lengths are proposed by the authors with the former shown to be optimal (more on this below). PL subsampling is shown to scale very well and a good approximation of optimal subsampling conditional on leverage scores &lt;span class=&#34;math inline&#34;&gt;\(h_{ii}\)&lt;/span&gt; being fairly homogeneous.&lt;/p&gt;
&lt;p&gt;With respect to the second question &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; investigate both ordinary least-squares (OLS) and weighted least-squares (WLS), where weights simply correspond to subsampling probabilities &lt;span class=&#34;math inline&#34;&gt;\(\{\pi_i\}^n_{i=1}\)&lt;/span&gt;. The authors present empirical evidence that OLS is more efficient than WLS in that the mean-squared error (MSE) for predicting &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X} \beta\)&lt;/span&gt; is lower for OLS. The authors also note though that subsampling using OLS is not consistent for non-uniform subsampling methods meaning that the bias cannot be controlled. Given Equation &lt;a href=&#34;#eq:mse&#34;&gt;(3)&lt;/a&gt; the fact that OLS is nonetheless more efficient than WLS implies that the higher variance terms associated with WLS dominates the effect of relatively higher bias with OLS. In fact this is consistent with the theoretical results presented in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; (more on this below).&lt;/p&gt;
&lt;p&gt;Next we will briefly run through different estimation and subsampling methods in some more detail and see how they can be implemented in R. In the following section we will then look at how the different approaches perform empirically.&lt;/p&gt;
&lt;div id=&#34;ols-and-wls&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;OLS and WLS&lt;/h3&gt;
&lt;p&gt;Both OLS and WLS are implemented here using QR decomposition. As for OLS this is very easily done in R. Given some feature matrix &lt;code&gt;X&lt;/code&gt; and a corresponding outcome variable &lt;code&gt;y&lt;/code&gt; we can use &lt;code&gt;qr.solve(X, y)&lt;/code&gt; to compute &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta\)&lt;/span&gt;. For WLS we need to first weigh observations by their corresponding subsampling probabilities. Following &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; we can construct a weighting matrix &lt;span class=&#34;math inline&#34;&gt;\(\Phi= \text{diag}\{\pi_i\}^m_{i=1}\)&lt;/span&gt; and compute the weighted least-squares estimator as: (see &lt;a href=&#34;#app-wls&#34;&gt;appendix&lt;/a&gt; for derivation)&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:wls&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \hat\beta_m^{WLS}&amp;amp;= \left( \mathbf{X}^T \Phi^{-1} \mathbf{X} \right)^{-1} \mathbf{X}^T\Phi^{-1}\mathbf{y}\\
\end{aligned}
\tag{4}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In R weighted least-squares can be implemented (from scratch) as follows&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;function (X, y, weights) 
{
    Phi &amp;lt;- diag(weights)
    beta &amp;lt;- qr.solve(t(X) %*% Phi %*% X, t(X) %*% Phi %*% y)
    return(beta)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where in order to implement the algorithm propose in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; the weights we need to supply as the function arguments are &lt;span class=&#34;math inline&#34;&gt;\(w=\{1/\pi_i\}^m_{i=1}\)&lt;/span&gt;. This follows from the following property of diagonal matrices:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
&amp;amp;&amp;amp; \Phi^{-1}&amp;amp;= \begin{pmatrix}
1\over\phi_{11} &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; ... &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1\over \phi_{nn}
\end{pmatrix}
 \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;uniform-subsampling-unif&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Uniform subsampling (UNIF)&lt;/h3&gt;
&lt;p&gt;A simple function for uniform subsampling in R is shown in the code chunk below. Note that to streamline the comparison of the different methods in the following section the function takes an unused argument &lt;code&gt;weighted=F&lt;/code&gt; which for the other subsampling methods can be used to determine whether OLS or WLS should be used. Of course, with uniform subsampling the weights are all identical and hence &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta^{OLS}=\hat\beta^{WLS}\)&lt;/span&gt; so the argument is passed to but not evaluated in &lt;code&gt;sub_UNIF&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;function (vars, weighted = F, rand_state = NULL, fit_model = T) 
{
    if (!is.null(rand_state)) {
        set.seed(rand_state)
    }
    invisible(list2env(vars, envir = environment()))
    indices &amp;lt;- sample(indices_maj, size = n_min)
    indices &amp;lt;- c(indices_min, indices)
    X_m &amp;lt;- X[indices, ]
    y_m &amp;lt;- y[indices]
    weights &amp;lt;- NULL
    if (fit_model) {
        beta_hat &amp;lt;- glm(y_m ~ X_m, family = &amp;quot;binomial&amp;quot;)$coefficients
        if (!all(X[, 1] == 1)) {
            X &amp;lt;- cbind(1, X)
        }
        y_hat &amp;lt;- c(X %*% beta_hat)
        p_y &amp;lt;- exp(y_hat)/(1 + exp(y_hat))
        return(list(X_m = X_m, y_m = y_m, linear_predictors = y_hat, fitted = p_y, coeff = beta_hat))
    }
    else {
        return(list(X = X_m, y = y_m, weights = weights))
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-leveraging-blev&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Basic leveraging (BLEV)&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;sub_UNIF&lt;/code&gt; function can be extended easily to the case with basic leveraging (see code below). Note that in this case the &lt;code&gt;weighted&lt;/code&gt; argument is actually evaluated.&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;function (X, y, m, weighted = F, rand_state = NULL, plot_wgts = F, prob_only = F) 
{
    svd_X &amp;lt;- svd(X)
    U &amp;lt;- svd_X$u
    H &amp;lt;- tcrossprod(U)
    h &amp;lt;- diag(H)
    prob &amp;lt;- h/ncol(X)
    if (plot_wgts) {
        plot(prob, t = &amp;quot;l&amp;quot;, ylab = &amp;quot;Sampling probability&amp;quot;)
    }
    if (prob_only) {
        return(prob)
    }
    else {
        indices &amp;lt;- sample(x = 1:n, size = m, replace = T, prob = prob)
        X_m &amp;lt;- X[indices, ]
        y_m &amp;lt;- y[indices]
        weights &amp;lt;- 1/prob[indices]
        if (weighted) {
            beta_hat &amp;lt;- wls_qr(X_m, y_m, weights)
        }
        else {
            beta_hat &amp;lt;- qr.solve(X_m, y_m)
        }
        y_hat &amp;lt;- c(X %*% beta_hat)
        return(list(fitted = y_hat, coeff = beta_hat, prob = prob))
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;a-note-on-computing-leverage-scores&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;A note on computing leverage scores&lt;/h4&gt;
&lt;p&gt;Recall that for the &lt;em&gt;hat matrix&lt;/em&gt; we have&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:hat-mat&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \mathbf{H}&amp;amp;=\mathbf{X} (\mathbf{X}^T \mathbf{X})^{-1}\mathbf{X}^T \\
\end{aligned}
\tag{5}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the diagonal elements &lt;span class=&#34;math inline&#34;&gt;\(h_{ii}\)&lt;/span&gt; correspond to the leverage scores we’re after. Following &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; we will use (compact) singular value decomposition to obtain &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{H}\)&lt;/span&gt; rather than computing &lt;a href=&#34;#eq:hat-mat&#34;&gt;(5)&lt;/a&gt; directly. This has the benefit that there exist exceptionally stable numerical algorithms to compute SVD. To see how and why we can use SVD to obtain &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{H}\)&lt;/span&gt; see &lt;a href=&#34;#app-svd&#34;&gt;appendix&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Clearly to get &lt;span class=&#34;math inline&#34;&gt;\(h_{ii}\)&lt;/span&gt; we first need to compute &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{H}\)&lt;/span&gt; which in terms of computational costs is of order &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{O}(np^2)=\max(\mathcal{O}(np^2),\mathcal{O}(p^3))\)&lt;/span&gt;. The fact that we use all &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; rows of &lt;span class=&#34;math inline&#34;&gt;\(\Phi\)&lt;/span&gt; to compute leverage scores even though we explicitly stated our goal was to only use &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; observations may rightly seem like a bit of a paradox. This is why fast algorithms that approximate leverage scores have been proposed. We will not look at them specifically here mainly because the PL method proposed by &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; does not depend on leverage scores and promises to be computationally even more efficient.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;predictor-length-sampling-pl&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Predictor-length sampling (PL)&lt;/h3&gt;
&lt;p&gt;The basic characteristic of PL subsampling - choosing &lt;span class=&#34;math inline&#34;&gt;\(\{\pi_i\}^n_{i=1}= ||\mathbf{X}_i||/ \sum_{j=1}^{n}||\mathbf{X}_j||\)&lt;/span&gt; - was already introduced above. Again it is very easy to modify the subsampling functions from above to this case:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;function (X, y, m, weighted = F, rand_state = NULL, plot_wgts = F, prob_only = F) 
{
    predictor_len &amp;lt;- sqrt(X^2 %*% rep(1, ncol(X)))
    prob &amp;lt;- predictor_len/sum(predictor_len)
    if (plot_wgts) {
        plot(prob, t = &amp;quot;l&amp;quot;, ylab = &amp;quot;Sampling probability&amp;quot;)
    }
    if (prob_only) {
        return(prob)
    }
    else {
        indices &amp;lt;- sample(x = 1:n, size = m, replace = T, prob = prob)
        X_m &amp;lt;- X[indices, ]
        y_m &amp;lt;- y[indices]
        weights &amp;lt;- 1/prob[indices]
        if (weighted) {
            beta_hat &amp;lt;- wls_qr(X_m, y_m, weights)
        }
        else {
            beta_hat &amp;lt;- qr.solve(X_m, y_m)
        }
        y_hat &amp;lt;- c(X %*% beta_hat)
        return(list(fitted = y_hat, coeff = beta_hat, prob = prob))
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;a-note-on-optimal-subsampling-opt&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;A note on optimal subsampling (OPT)&lt;/h4&gt;
&lt;p&gt;In fact, PL subsampling is an approximate version of optimal subsampling (OPT). &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; show that asymptotically we have:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:plim&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp;\text{plim} \left( \text{var} (\hat{f}_n(x)) \right) &amp;gt; \text{plim} \left(\left( \mathbb{E} \left( \hat{f}_n(x) \right) - f(x) \right)^2 \right)  \\
\end{aligned}
\tag{6}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Given this result minimizing the MSE (Equation &lt;a href=&#34;#eq:mse&#34;&gt;(3)&lt;/a&gt;) with respect to subsampling probabilities &lt;span class=&#34;math inline&#34;&gt;\(\{\pi_i\}^n_{i=1}\)&lt;/span&gt; corresponds to minimizing &lt;span class=&#34;math inline&#34;&gt;\(\text{var} (\hat{f}_n(x))\)&lt;/span&gt;. They further show that this minimization problem has the following closed-form solution:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:opt&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \pi_i&amp;amp;= \frac{\sqrt{(1-h_{ii})}||\mathbf{X}_i||}{\sum_{j=1}^n\sqrt{(1-h_{jj})}||\mathbf{X}_j||}\\
\end{aligned}
\tag{7}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This still has computational costs of order &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{O}(np^2)\)&lt;/span&gt;. But it should now be clear why PL subsampling is optimal conditional on leverage scores being homogeneous (see &lt;a href=&#34;#app-pl&#34;&gt;appendix&lt;/a&gt;). PL subsampling is associated with computational costs of order &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{O}(np)\)&lt;/span&gt;, so a potentially massive improvement. The code for optimal subsampling is shown below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;function (X, y, m, weighted = F, rand_state = NULL, plot_wgts = F, prob_only = F) 
{
    n &amp;lt;- nrow(X)
    svd_X &amp;lt;- svd(X)
    U &amp;lt;- svd_X$u
    H &amp;lt;- tcrossprod(U)
    h &amp;lt;- diag(H)
    predictor_len &amp;lt;- sqrt(X^2 %*% rep(1, ncol(X)))
    prob &amp;lt;- (sqrt(1 - h) * predictor_len)/crossprod(sqrt(1 - h), predictor_len)[1]
    if (plot_wgts) {
        plot(prob, t = &amp;quot;l&amp;quot;, ylab = &amp;quot;Sampling probability&amp;quot;)
    }
    if (prob_only) {
        return(prob)
    }
    else {
        indices &amp;lt;- sample(x = 1:n, size = m, replace = T, prob = prob)
        X_m &amp;lt;- X[indices, ]
        y_m &amp;lt;- y[indices]
        weights &amp;lt;- 1/prob[indices]
        if (weighted) {
            beta_hat &amp;lt;- wls_qr(X_m, y_m, weights)
        }
        else {
            beta_hat &amp;lt;- qr.solve(X_m, y_m)
        }
        y_hat &amp;lt;- c(X %*% beta_hat)
        return(list(fitted = y_hat, coeff = beta_hat, prob = prob))
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;a-note-on-computing-predictor-lengths&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;A note on computing predictor lengths&lt;/h4&gt;
&lt;p&gt;Computing the Euclidean norms &lt;span class=&#34;math inline&#34;&gt;\(||\mathbf{X}_i||\)&lt;/span&gt; in R can be done explicitly by looping over the rows of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; and computing the norm in each iteration. It turns out that this computationally very expensive. A much more efficient way of computing the vector of predictor lengths is as follows&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34; id=&#34;eq:norm&#34;&gt;\[
\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \mathbf{pl}&amp;amp;=\sqrt{\mathbf{X}^2 \mathbf{1}} \\
\end{aligned}
\tag{8}
\end{equation}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}^2\)&lt;/span&gt; indicates &lt;em&gt;elements squared&lt;/em&gt;, the square root is also taken &lt;em&gt;element-wise&lt;/em&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{1}\)&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;\((p \times 1)\)&lt;/span&gt; vectors of ones. A performance benchmark of the two approaches is shown in Figure &lt;a href=&#34;#fig:mbm-norm&#34;&gt;4&lt;/a&gt; below.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:mbm-norm&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/figure-html/mbm-norm-1.png&#34; alt=&#34;Benchmark of Euclidean norm computations.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Benchmark of Euclidean norm computations.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;comparison-of-methods&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Comparison of methods&lt;/h3&gt;
&lt;p&gt;As discussed in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; both OPT and PL subsampling tend to inflate subsampling probabilities of observations with low leverage scores and shrink those of high-leverage observations relative to BLEV. They show explicitly that this always holds for orthogonal design matrices. As a quick sense-check of the functions introduced above we can generate a random orthogonal design matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; and plot subsampling probabilities with OPT and PL against those obtained with BLEV. Figure &lt;a href=&#34;#fig:comp-methods&#34;&gt;5&lt;/a&gt; illustrates this relationship nicely.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:comp-methods&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/figure-html/comp-methods-1.png&#34; alt=&#34;Comparison of subsampling probabilities.&#34; width=&#34;576&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: Comparison of subsampling probabilities.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The design matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\((n \times p)\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(n=1000\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(p=100\)&lt;/span&gt; was generated using SVD:&lt;/p&gt;
&lt;pre class=&#34;r fold-show&#34;&gt;&lt;code&gt;function (n, p) 
{
    M &amp;lt;- matrix(rnorm(n * p), n, p)
    X &amp;lt;- svd(M)$u
    return(X)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;lin-reg&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear regression model&lt;/h2&gt;
&lt;div id=&#34;a-review-of-zhu2015optimal&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A review of &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;To illustrate the improvements associated with the methods proposed in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;, we will briefly replicate their main empirical findings here. The evaluate the performance of the different methods we will proceed as follows:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Empirical exercise&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Generate synthetic data &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; of dimension &lt;span class=&#34;math inline&#34;&gt;\((n \times m)\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(n&amp;gt;&amp;gt;m\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Set some true model parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta=(\mathbf{1}^T_{\overline{m*0.6}},\mathbf{1}^T_{\underline{m*0.4}})^T\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Model the outcome variable as &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{y}=\mathbf{X}\beta+\epsilon\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon \sim \mathcal{N}(\mathbf{0},\sigma^2 \mathbf{I}_n)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma=10\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Estimate the full-sample OLS estimator &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_n\)&lt;/span&gt; (a benchmark estimator of sorts in this setting).&lt;/li&gt;
&lt;li&gt;Use one of the subsampling methods to estimate iteratively &lt;span class=&#34;math inline&#34;&gt;\(\{\hat\beta^{(b)}_m\}^B_{b=1}\)&lt;/span&gt;. Note that all subsampling methods are stochastic so &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_m\)&lt;/span&gt; varies across iterations.&lt;/li&gt;
&lt;li&gt;Evaluate average model performance of &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_m\)&lt;/span&gt; under the mean-squared error criterium: &lt;span class=&#34;math inline&#34;&gt;\(MSE= \frac{1}{B} \sum_{b=1}^{B} MSE^{(b)}\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(MSE^{(b)}\)&lt;/span&gt; corresponds to the in-sample estimator of the mean-squared error of the &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;-th iteration.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; we will generate the design matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; from 5 different distributions: 1) Gaussian (GA) with &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{N}(\mathbf{0},\Sigma)\)&lt;/span&gt;; 2) Mixed-Gaussian (MG) with &lt;span class=&#34;math inline&#34;&gt;\(0.5\mathcal{N}(\mathbf{0},\Sigma)+0.5\mathcal{N}(\mathbf{0},25\Sigma)\)&lt;/span&gt;; 3) Log-Gaussian (LN) with &lt;span class=&#34;math inline&#34;&gt;\(\log\mathcal{N}(\mathbf{0},\Sigma)\)&lt;/span&gt;; 4) T-distribution with 1 degree of freedom (T1) and &lt;span class=&#34;math inline&#34;&gt;\(\Sigma\)&lt;/span&gt;; 5) T-distribution as in 4) but truncated at &lt;span class=&#34;math inline&#34;&gt;\([-p,p]\)&lt;/span&gt;. All parameters are chosen in the same way as in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; with exception of &lt;span class=&#34;math inline&#34;&gt;\(n=1000\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(p=3\)&lt;/span&gt;, which are significantly smaller choices in order to decrease the computational costs. The corresponding densities of the 5 data sets are shown in Figure &lt;a href=&#34;#fig:dens&#34;&gt;8&lt;/a&gt; in the &lt;a href=&#34;#app-dens&#34;&gt;appendix&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
library(expm)
matrix_grid &amp;lt;- expand.grid(i=1:p,j=1:p)
Sigma &amp;lt;- matrix(rep(0,p^2),p,p)
for (x in 1:nrow(matrix_grid)) {
  i &amp;lt;- matrix_grid$i[x]
  j &amp;lt;- matrix_grid$j[x]
  Sigma[i,j] &amp;lt;- 2 * (0.8)^(abs(i-j))
}
# 1.) Design matrix (as in Zhu et al): ----
GA &amp;lt;- matrix(rnorm(n*p), nrow = n, ncol = p) %*% sqrtm(t(Sigma))
# Gaussian mixture:
gaus_mix &amp;lt;- list(
  gaus_1 = matrix(rnorm(n*p), nrow = n, ncol = p) %*% sqrtm(t(Sigma)),
  gaus_2 = matrix(rnorm(n*p), nrow = n, ncol = p) %*% sqrtm((25 * t(Sigma)))
)
MG &amp;lt;- matrix(rep(0,n*p),n,p)
for (i in 1:nrow(MG)) {
  x &amp;lt;- sample(1:2,1)
  MG[i,] &amp;lt;- gaus_mix[[x]][i,]
}
# Log-Gaussian:
LN &amp;lt;- exp(GA)
# T-distribution:
T1 &amp;lt;- matrix(rt(n*p,1), nrow = n, ncol = p) %*% sqrtm(t(Sigma))
# Truncated T:
TT &amp;lt;- T1
TT[TT&amp;gt;p] &amp;lt;- p
TT[TT&amp;lt;(-p)] &amp;lt;- -p
data_sets &amp;lt;- list(
  GA = list(X = GA),
  MG = list(X = MG),
  LN = list(X = LN),
  TT = list(X = TT),
  T1 = list(X = T1)
)
# 2.) Outcome:
data_sets &amp;lt;- lapply(
  data_sets,
  function(i) {
    X &amp;lt;- i[[&amp;quot;X&amp;quot;]]
    beta &amp;lt;- c(rep(1,ceiling(0.6*p)),rep(0.1,floor(0.4*p)))
    eps &amp;lt;- rnorm(n=n,mean=0,sd=10)
    y &amp;lt;- X %*% beta + eps
    list(X=X, y=y)
  }
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will run the empirical exercise for each data set and each subsampling method introduced above. Figure &lt;a href=&#34;#fig:plot-smpl-prob&#34;&gt;6&lt;/a&gt; shows logarithms of the sampling probabilities corresponding to the different subsampling methods (UNIF not shown for obvious reasons). The plots look very similar to the one in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; and is shown here primarily to reassure ourselves that we have implemented their ideas correctly. One interesting observation is worth pointing out however: note how the distributions for OPT and PL have lower standard deviations compared to BLEV. This should not be altogether surprising since we already saw above that for orthogonal design matrices the former methods inflate small leverage scores while shrinking high scores. But it is interesting to see that the same appears to hold for design matrices that are explicitly not orthogonal given our choice of &lt;span class=&#34;math inline&#34;&gt;\(\Sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:plot-smpl-prob&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/figure-html/plot-smpl-prob-1.png&#34; alt=&#34;Sampling probabilities for different subsampling methods.&#34; width=&#34;960&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 6: Sampling probabilities for different subsampling methods.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Figures &lt;a href=&#34;#fig:wls-zhu&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;#fig:ols-zhu&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt; show the resulting MSE, squared bias and variance for the different subsampling methods and data sets using weighed least-squares and ordinary least-squares, respectively. The subsampling size increases along the horizontal axis. The figures are interactive to allow readers to zoom in etc.&lt;/p&gt;
&lt;p&gt;For the data sets that are also shown in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; we find the same overall pattern: PL and OPT outperform other methods when using weighted least-squares, while BLEV outperforms other methods when using unweighted/ordinary least-squares.&lt;/p&gt;
&lt;p&gt;For Gaussian data (GA) the differences between the methods are minimal since data points are homogeneous. A similar picture emerges when running the method comparison for the sinusoidal data introduced above (see &lt;a href=&#34;#app-sin&#34;&gt;appendix&lt;/a&gt;). In fact, &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; recommend to just rely on uniform subsampling when data is Gaussian. Another interesting observation is that for t-distributed data (T1) the non-uniform subsampling methods significantly outperform uniform subsampling methods. This is despite the fact that in the case of T1 data the conditions used to establish asymptotic consistency of the non-uniform subsampling methods in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; are not fulfilled: in particular the fourth moment is not finite (in fact it is not defined).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;computational-performance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Computational performance&lt;/h3&gt;
&lt;p&gt;We have already seen above that theoretically speaking both BLEV and OPT subsampling are computationally more expensive than PL subsampling (with UNIF subsampling the least expensive). It should be obvious that in light of their computational costs &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{O}(np^2)\)&lt;/span&gt; the former two methods do not scale well in higher-dimensional problems (higher &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;). &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; demonstrate this through empirical exercises to an extent that is beyond the scope of this note. Instead we will just quickly benchmark the different functions for non-uniform subsampling introduced above: &lt;code&gt;sub_BLEV&lt;/code&gt;, &lt;code&gt;sub_OPT&lt;/code&gt;, &lt;code&gt;sub_PL&lt;/code&gt; for &lt;span class=&#34;math inline&#34;&gt;\(n=200\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p=100\)&lt;/span&gt;. We are only interested in how long it takes to compute subsampling probabilities, and since for &lt;code&gt;sub_UNIF&lt;/code&gt; all subsampling probabilities are simply &lt;span class=&#34;math inline&#34;&gt;\(\pi_i=1/n\)&lt;/span&gt; we neglect this here. Figure &lt;a href=&#34;#fig:mbm-methods&#34;&gt;7&lt;/a&gt; benchmarks the three non-uniform subsampling methods. Evidently PL subsampling is computationally much less costly.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:mbm-methods&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/figure-html/mbm-methods-1.png&#34; alt=&#34;Benchmark of computational performance of different methods.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 7: Benchmark of computational performance of different methods.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;further-work&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Further work&lt;/h2&gt;
&lt;p&gt;We have looked at subsampling of linear regression problems, but of course the story does not end here. For binary classification problems, for example, we cannot directly apply the methods used here, but the same general ideas still apply. &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-wang2018optimal&#34; role=&#34;doc-biblioref&#34;&gt;Wang, Zhu, and Ma&lt;/a&gt; (&lt;a href=&#34;#ref-wang2018optimal&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; explore optimal subsampling for large sample logistic regression - a paper that is very much related to &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;Zhu et al.&lt;/a&gt; (&lt;a href=&#34;#ref-zhu2015optimal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;. For a brief summary and a (cautious) application to imbalanced learning see &lt;a href=&#34;https://pat-alt.github.io/fromScratch/optimal-subsampling.html#classification-problems&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Very recently an &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0885064X20300558&#34;&gt;article&lt;/a&gt; has been published that investigates optimal subsampling in the context of quantile regression. More interesting work in this certain to emerge from this field, which researches some of the most pressing questions in large sample statistics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;&gt;
&lt;div id=&#34;ref-bishop2006pattern&#34; class=&#34;csl-entry&#34;&gt;
Bishop, Christopher M. 2006. &lt;em&gt;Pattern Recognition and Machine Learning&lt;/em&gt;. springer.
&lt;/div&gt;
&lt;div id=&#34;ref-wang2018optimal&#34; class=&#34;csl-entry&#34;&gt;
Wang, HaiYing, Rong Zhu, and Ping Ma. 2018. &lt;span&gt;“Optimal Subsampling for Large Sample Logistic Regression.”&lt;/span&gt; &lt;em&gt;Journal of the American Statistical Association&lt;/em&gt; 113 (522): 829–44.
&lt;/div&gt;
&lt;div id=&#34;ref-zhu2015optimal&#34; class=&#34;csl-entry&#34;&gt;
Zhu, Rong, Ping Ma, Michael W Mahoney, and Bin Yu. 2015. &lt;span&gt;“Optimal Subsampling Approaches for Large Sample Linear Regression.”&lt;/span&gt; &lt;em&gt;arXiv&lt;/em&gt;, arXiv–1509.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Appendix&lt;/h2&gt;
&lt;div id=&#34;app-wls&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;Weighted least-squares&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;www/wls.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Weighted least-squares&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;app-svd&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;From SVD to leverage scores&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;www/svd_leverage.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;From SVD to leverage&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;app-pl&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;From optimal to prediction-length subsampling&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;www/PL.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;From OPT to PL&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;app-dens&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;Synthetic data&lt;/h3&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:dens&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/figure-html/dens-1.png&#34; alt=&#34;Densities of synthetic design matrices.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 8: Densities of synthetic design matrices.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;app-sin&#34; class=&#34;section level3 unnumbered&#34;&gt;
&lt;h3&gt;Subsampling applied to sinusoidal function&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://www.paltmeyer.com/post/2021-03-10-optimal-subsampling/index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A peek inside the &#39;Black Box&#39; - interpreting neural networks</title>
      <link>https://www.paltmeyer.com/post/2021-02-01-a-peek-inside-the-black-box-interpreting-neural-networks/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/post/2021-02-01-a-peek-inside-the-black-box-interpreting-neural-networks/</guid>
      <description>
&lt;script src=&#34;https://www.paltmeyer.com/post/2021-02-01-a-peek-inside-the-black-box-interpreting-neural-networks/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#motivation&#34;&gt;Motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#interpretable-dl&#34;&gt;Interpretable DL - a whistle-stop tour&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rate&#34;&gt;An entropy-based approach to variable importance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#interpreting-bnns&#34;&gt;Application to Bayesian neural networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;motivation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;p&gt;Propelled by advancements in modern computer technology, deep learning has re-emerged as perhaps the most promising artificial intelligence (AI) technology of the last two decades. By treating problems as a nested, hierarchy of hidden layers deep artificial neural networks achieve the power and flexibility necessary for AI systems to navigate complex real-world environments. Unfortunately, their very nature has earned them a reputation as &lt;em&gt;Black Box&lt;/em&gt; algorithms and their lack of interpretability remains a major impediment to their more wide-spread application.&lt;/p&gt;
&lt;p&gt;In science, research questions usually demand not just answers but also explanations and variable selection is often as important as prediction &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al. 2019&lt;/a&gt;)&lt;/span&gt;. Economists, for example, recognise the undeniable potential of deep learning, but are rightly hesitant to employ novel tools that are not fully transparent and ultimately cannot be trusted. Similarly, real-world applications of AI have come under increasing scrutiny with regulators imposing that individuals influenced by algorithms should have the right to obtain explanations &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;Fan, Xiong, and Wang 2020&lt;/a&gt;)&lt;/span&gt;. In high-risk decision-making fields such as AI systems that drive autonomous vehicles the need for explanations is self-evident &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al. 2019&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In light of these challenges it is not surprising that research on explainable AI has recently gained considerable momentum &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-arrieta2020explainable&#34; role=&#34;doc-biblioref&#34;&gt;Arrieta et al. 2020&lt;/a&gt;)&lt;/span&gt;. While in this short essay we will focus on deep learning in particular, it should be noted that this growing body of literature is concerned with a broader realm of machine learning models. The rest of this note is structured as follows: the first section provides a brief overview of recent advancements towards interpreting deep neural networks largely drawing on &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;Fan, Xiong, and Wang&lt;/a&gt; (&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;; the second section considers a novel entropy-based approach towards interpretability proposed by &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;Crawford et al.&lt;/a&gt; (&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt;; finally, in the last section we will see how this approach can be applied to deep neural networks as proposed in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al.&lt;/a&gt; (&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;interpretable-dl&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Interpretable DL - a whistle-stop tour&lt;/h1&gt;
&lt;p&gt;Before delving further into &lt;em&gt;how&lt;/em&gt; the intrinsics of deep neural networks can be disentangled we should first clarify &lt;em&gt;what&lt;/em&gt; interpretability in the context of algorithms actually means. &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;Fan, Xiong, and Wang&lt;/a&gt; (&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; describes model interpretability simply as the extent to which humans can “understand and reason” the model. This may concern an understanding of both the &lt;em&gt;ad-hoc&lt;/em&gt; workings of the algorithm as well as the &lt;em&gt;post-hoc&lt;/em&gt; interpretability of its output. In the context of linear regression, for example, &lt;em&gt;ad-hoc&lt;/em&gt; workings of the model are often described through the intuitive idea of linearly projecting the outcome variable &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{y}\)&lt;/span&gt; onto the column space of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt;. &lt;em&gt;Post-hoc&lt;/em&gt; interpretations usually center around variable importance – the main focus of the following sections. Various recent advancements tackle interpretability of DNNs from different angles depending on whether the focus is on &lt;em&gt;ad-hoc&lt;/em&gt; or &lt;em&gt;post-hoc&lt;/em&gt; interpretability. &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;Fan, Xiong, and Wang&lt;/a&gt; (&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; further asses that model interpretability hinges on three main aspects of &lt;em&gt;simulatability&lt;/em&gt;, &lt;em&gt;decomposability&lt;/em&gt; and &lt;em&gt;algorithmic transparency&lt;/em&gt;, but for the purpose of this short note the &lt;em&gt;ad-hoc&lt;/em&gt; vs. &lt;em&gt;post-hoc&lt;/em&gt; taxonomy provides a simpler more natural framework.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Understanding the &lt;em&gt;ad-hoc&lt;/em&gt; intrinsic mechanisms of a DNN is inherently difficult. While generally transparency may be preserved in the presence of nonlinearity (e.g. decision trees), multiple hidden layers of networks (each of them) involving nonlinear operations are usually out of the realm of human comprehension &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;Fan, Xiong, and Wang 2020&lt;/a&gt;)&lt;/span&gt;. Training also generally involves optimization of non-convex functions that involve an increasing number of saddle points as the dimensionality increases &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;Fan, Xiong, and Wang 2020&lt;/a&gt;)&lt;/span&gt;. Methods to circumvent this problematic usually boil down to decreasing the overall complexity, either by regularizing the model or through proxy methods. Regularization – while traditionally done to avoid overfitting – has been found to be useful to create more interpretable representations. Monotonicity constraints, for example, impose that as the value of a specified covariate increases model predictions either monotonically decrease or increase. Proxy methods construct simpler representations of a learned DNN, such as a rule-based decision tree. This essentially involves repeatedly querying the trained network while varying the inputs and then deriving decision rules based on the model output.&lt;/p&gt;
&lt;p&gt;Post-hoc interpretability usually revolves around the understanding of feature importance. A greedy approach to this issue involves simply removing features one by one and checking how model predictions change. A more sophisticated approach along these lines is &lt;em&gt;Shapley&lt;/em&gt; value, which draws on cooperative game theory. The Shapley value assigns varying payouts to players depending on their contribution to overall payout. In the context of neural networks input covariate &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_p\)&lt;/span&gt; represents a player while overall payout is represented by the difference between average and individual outcome predictions.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; Exact computations of Shapley values are prohibitive as the dimensionality increases, though approximate methods have recently been developed &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-fan2020interpretability&#34; role=&#34;doc-biblioref&#34;&gt;Fan, Xiong, and Wang 2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The remainder of this note focuses on a novel approach to feature extraction that measures entropy shifts in a learned probabilistic neural network in response to model inputs &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X_1},...,\mathbf{X}_P\)&lt;/span&gt;. We will first introduce this methodology in the context of Gaussian Process regression in the following section before finally turning to its application to Bayesian neural networks.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rate&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;An entropy-based approach to variable importance&lt;/h1&gt;
&lt;p&gt;&lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al.&lt;/a&gt; (&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; motivate their methodology for interpreting neural networks through Gaussian Process regression. Consider the following Bayesian regression model with Gaussian priors:&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:bayes&#34;&gt;\[\begin{equation}
\begin{aligned}
&amp;amp;&amp;amp; f(\mathbf{X}|\mathbf{w})&amp;amp;=\phi(\mathbf{X})^T\mathbf{w} + \varepsilon, &amp;amp;&amp;amp;\varepsilon \sim \mathcal{N}(0,\mathbf{I}) \\
&amp;amp;&amp;amp; \mathbf{w}&amp;amp; \sim \mathcal{N}(0,{1\over{\lambda}} \mathbf{I})\\
\end{aligned}
\tag{1}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;This naturally gives rise to a particular example of a Gaussian Process (GP). In particular, since &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{u}(\mathbf{X})=\Phi(\mathbf{X})^T\mathbf{w}\)&lt;/span&gt; is just a linear combination fo Gaussian random variables it follows a Gaussian Process itself&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:khbs&#34;&gt;\[\begin{equation}
\begin{aligned}
&amp;amp;&amp;amp; \mathbf{u}(\mathbf{X})=\Phi(\mathbf{X})^T\mathbf{w}&amp;amp; \sim \mathcal{N}(\mathbf{0}, \mathbf{K}) \\
\end{aligned}
\tag{2}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{K}\)&lt;/span&gt; is the Kernel (or Gram) matrix and &lt;span class=&#34;math inline&#34;&gt;\(K_{i,j}=k(\mathbf{X_i,\mathbf{X}_j})={1\over{\lambda}}\phi(\mathbf{X_i})^T\phi(\mathbf{X_m})\)&lt;/span&gt; is the kernel function &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-bishop2006pattern&#34; role=&#34;doc-biblioref&#34;&gt;Bishop 2006&lt;/a&gt;)&lt;/span&gt;. In other words, the prior distribution over &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}\)&lt;/span&gt; induces a probability distribution over random functions &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{u}(\mathbf{X})\)&lt;/span&gt;. Similarly, the GP can be understood as a prior distribution over a an infinite-dimensional reproducible kernel Hilbert space (RKHS) &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;Crawford et al. 2019&lt;/a&gt;)&lt;/span&gt;, which in a finite-dimensional setting becomes multivariate Gaussian.&lt;/p&gt;
&lt;p&gt;In a standard linear regression model coefficients characterize the projection of the outcome variable &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{y}\)&lt;/span&gt; onto the column space of the regressors &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt;. In particular, with ordinary least square we define:&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:ols&#34;&gt;\[\begin{equation}
\begin{aligned}
&amp;amp;&amp;amp; \beta&amp;amp;=(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y} \\
\end{aligned}
\tag{3}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;The primary focus here is to learn the mapping from input to output. The key differentiating feature between this approach and the non-parametric model in &lt;a href=&#34;#eq:bayes&#34;&gt;(1)&lt;/a&gt; is the fact that in case of the latter we are interested in learning not only the mapping from inputs to outputs, but also the representation (&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{u}(\mathbf{X})\)&lt;/span&gt;) of the inputs (see for example &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-goodfellow2016deep&#34; role=&#34;doc-biblioref&#34;&gt;Goodfellow, Bengio, and Courville 2016&lt;/a&gt;)&lt;/span&gt;). To be even more specific, treating the feature representation itself as random as in &lt;a href=&#34;#eq:bayes&#34;&gt;(1)&lt;/a&gt; allows us to learn non-linear relationships between the covariates &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt;, since they are implicitly captured by the RKHS &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;Crawford et al. 2019&lt;/a&gt;)&lt;/span&gt;. Neural networks share this architecture and hence it is worth dwelling on it a bit further: the fact that the learned model inherently incorporates variable interactions leads to the observation that an individual feature is rarely important on its own with respect to the mapping from &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{y}\)&lt;/span&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al. 2019&lt;/a&gt;)&lt;/span&gt;. Hence, in order to gain an understanding of individual variable importance, one should aim to understand what role feature &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt; plays &lt;em&gt;within&lt;/em&gt; the learned model, thereby taking into account its interactions with other covariates. Formally, &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;Crawford et al.&lt;/a&gt; (&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; and define the &lt;em&gt;effect size analogue&lt;/em&gt; as the equivalent of the familiar regression coefficient in the non-parametric setting&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:effect-size&#34;&gt;\[\begin{equation}
\begin{aligned}
&amp;amp;&amp;amp; \tilde\beta&amp;amp;=\mathbf{X}^+\Phi^T\mathbf{w}=\mathbf{X}^+\mathbf{u} \\
\end{aligned}
\tag{4}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}^+=\lim_{\alpha} (\mathbf{X}^T\mathbf{X}+\alpha \mathbf{I})^{-1}\mathbf{X}^T\)&lt;/span&gt; denotes the Moore-Penrose pseudo-inverse (see for example &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-goodfellow2016deep&#34; role=&#34;doc-biblioref&#34;&gt;Goodfellow, Bengio, and Courville&lt;/a&gt; (&lt;a href=&#34;#ref-goodfellow2016deep&#34; role=&#34;doc-biblioref&#34;&gt;2016&lt;/a&gt;)&lt;/span&gt;). Intuitively the effect size analogue can be thought of as the resulting coefficients from regressing the fitted values &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mathbf{u}}\)&lt;/span&gt; from the learned probabilistic model on the covariates &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt;. It can be interpreted in the same way as linear regression coefficients, in the sense that &lt;span class=&#34;math inline&#34;&gt;\(\tilde\beta_j\)&lt;/span&gt; describes the marginal change in &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{u}\)&lt;/span&gt; given a unit increase in &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt; holding all else constant. Note here the subtle, but crucial difference between &lt;a href=&#34;#eq:ols&#34;&gt;(3)&lt;/a&gt; – a projection from the outcome variable onto the column space of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; – and &lt;a href=&#34;#eq:effect-size&#34;&gt;(4)&lt;/a&gt; – a projection from the learned model to &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt;. In other words, looking at &lt;span class=&#34;math inline&#34;&gt;\(\tilde\beta\)&lt;/span&gt; can be thought of peeking directly into the &lt;em&gt;Block Box&lt;/em&gt;. Unfortunately, as &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;Crawford et al.&lt;/a&gt; (&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; point out, working with &lt;a href=&#34;#eq:effect-size&#34;&gt;(4)&lt;/a&gt; is usually not straight-forward. From a practitioner’s point of view, it may also not be obvious how to interpret a coefficient that describes marginal effects of input variables on a learned model. A more useful indicator in this context would provide a measure of how much individual variables contribute to the overall variation in the learned model. For this purpose &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;Crawford et al.&lt;/a&gt; (&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; propose to work with a distributional centrality measure based on &lt;span class=&#34;math inline&#34;&gt;\(\tilde\beta\)&lt;/span&gt;, which we shall turn to next.&lt;/p&gt;
&lt;p&gt;The proposed methodology in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;Crawford et al.&lt;/a&gt; (&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al.&lt;/a&gt; (&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; depends on the availability of a posterior distribution over &lt;span class=&#34;math inline&#34;&gt;\(\tilde\beta\)&lt;/span&gt; in that it measures its entropic shifts in response to the introduction of covariates. The intuition is straight-forward: within the context of the learned probabilistic model is covariate &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt; informative or not? More formally this boils down to determining if the posterior distribution of &lt;span class=&#34;math inline&#34;&gt;\(p(\tilde\beta_{-j})\)&lt;/span&gt; is dependent on the effect of &lt;span class=&#34;math inline&#34;&gt;\(\tilde\beta_j\)&lt;/span&gt;. This can be quantified through the Kullback-Leibler divergence (KLD) between &lt;span class=&#34;math inline&#34;&gt;\(p(\tilde\beta_{-j})\)&lt;/span&gt; and the conditional posterior &lt;span class=&#34;math inline&#34;&gt;\(p(\tilde\beta_{-j}|\tilde\beta_j)\)&lt;/span&gt;:&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:kld&#34;&gt;\[\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \text{KLD}_j&amp;amp;=\text{KL}\left(p(\tilde\beta_{-j}) || p(\tilde\beta_{-j}|\tilde\beta_j)\right) \\
\end{aligned}
\tag{5}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;Covariates that contribute significant information to the model will have &lt;span class=&#34;math inline&#34;&gt;\(\text{KLD}&amp;gt;0\)&lt;/span&gt;, while for insignificant covariates &lt;span class=&#34;math inline&#34;&gt;\(\text{KLD}\approx0\)&lt;/span&gt;. The measure of induced entropy change gives rise to a ranking of the covariates in terms of their relative importance in the model. The RATE criterion of variable &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt; is then simply defined as&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:rate&#34;&gt;\[\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \gamma_j&amp;amp;=\frac{\text{KLD}_j}{\sum_{p=1}^{P}\text{KLD}_p}\in[0,1] \\
\end{aligned}
\tag{6}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;which in light of its bounds can naturally be interpreted as &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_j\)&lt;/span&gt;`s percentage contribution to the learned model. It is worth noting that &lt;span class=&#34;math inline&#34;&gt;\(p(\tilde\beta_{-j}|\tilde\beta_j)\)&lt;/span&gt; of course depends on the value of the conditioning variable. A natural choice is &lt;span class=&#34;math inline&#34;&gt;\(\tilde\beta_j=0\)&lt;/span&gt; which usually corresponds to the null hypothesis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;interpreting-bnns&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Application to Bayesian neural networks&lt;/h1&gt;
&lt;p&gt;In order to use the RATE criterion in the context of deep learning we need to work in the Bayesian setting. Contrary to standard artificial neural networks which work under the assumption that weights have some true latent value, Bayesian neural networks place a prior distribution over network parameters and hence treat weights as random variables &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-goan2020bayesian&#34; role=&#34;doc-biblioref&#34;&gt;Goan and Fookes 2020&lt;/a&gt;)&lt;/span&gt;. Not only does it perhaps seem more natural to treat unobserved weights as random, but the Bayesian setting also naturally gives rise to reason about uncertainty in predictions, which can ultimately help us develop more trustworthy models &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-goan2020bayesian&#34; role=&#34;doc-biblioref&#34;&gt;Goan and Fookes 2020&lt;/a&gt;)&lt;/span&gt;. A drawback of BNNs is that exact computation of posteriors is computationally challenging and often intractable (a non-trivial issue that we will turn back to in a moment).&lt;/p&gt;
&lt;p&gt;When the prior placed over parameters is Gaussian, the output of the BNN approaches a Gaussian Process as the width of the network grows, in line with the discussion in the previous section. This is exactly the assumption that &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al.&lt;/a&gt; (&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; work with. They propose an architecture for a multi-layer perceptron (MLP) composed of (1) an input layer collecting covariates &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_1,...,\mathbf{X}_p\)&lt;/span&gt;, (2) a single deterministic, hidden layer and (3) an outer layer producing predictions from a probabilistic model &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{u}(\mathbf{X})\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt; be a &lt;span class=&#34;math inline&#34;&gt;\((N \times P)\)&lt;/span&gt; matrix of covariates. Then formally, we have&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:bnn&#34;&gt;\[\begin{equation} 
\begin{aligned}
&amp;amp;&amp;amp; \hat{\mathbf{y}}&amp;amp;=\sigma(\mathbf{u}) \\
&amp;amp;&amp;amp; \mathbf{u}(\mathbf{Z})&amp;amp;=\mathbf{Z}(\mathbf{X})\mathbf{w}^{(L+1)}, &amp;amp;&amp;amp; \mathbf{w}^{(L+1)} \sim \mathcal{N}(\mathbf{m}, \mathbf{V}) \\
&amp;amp;&amp;amp; \mathbf{Z}(\mathbf{X})&amp;amp;=f(\mathbf{X}\mathbf{w}^{(L)}) \\
\end{aligned}
\tag{7}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma(.)\)&lt;/span&gt; is a link function and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{u}(\mathbf{X})\)&lt;/span&gt; represents the probabilistic model learned in the outer layer with weights &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}^{(L+1)}\)&lt;/span&gt; assumed to be Gaussian random variables.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; Finally, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{Z}(\mathbf{X})\)&lt;/span&gt; denotes the inner (or more generally penultimate) layer, an &lt;span class=&#34;math inline&#34;&gt;\((N \times P)\)&lt;/span&gt; matrix of neural activations through &lt;span class=&#34;math inline&#34;&gt;\(f:(\mathbf{X}\mathbf{w}^{(L)})\mapsto \mathbf{Z}\)&lt;/span&gt;. &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al.&lt;/a&gt; (&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; work with a simple single-layer MLP, but it should be evident that this be extended to arbitrary depth and complexity, while still maintaining the high-level structure imposed by &lt;a href=&#34;#eq:bnn&#34;&gt;(7)&lt;/a&gt;. This flexibility allows RATE to be applied to a wide range of Bayesian network architectures, since all that is really required is the posterior distribution over weights &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{w}^{(L+1)}\)&lt;/span&gt;, which arises from the probabilistic outer layer. The fact that only the outer layer needs to be probabilistic has the additional benefit of mitigating the computational burden that comes with Bayesian inference, which was mentioned earlier.&lt;/p&gt;
&lt;!-- ![An MLP with a single, deterministic hidden layer and probabilistic outer layer.](www/bnn.png){#fig:bnn width=&#34;500&#34;} --&gt;
&lt;p&gt;Having established this basic, flexible set-up the &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al.&lt;/a&gt; (&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; go on to derive closed-form expressions for RATE in this setting. The details are omitted here since the logic is largely analogous to what we learned above, but can be found in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al.&lt;/a&gt; (&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;The RATE criterion originally proposed by &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;Crawford et al.&lt;/a&gt; (&lt;a href=&#34;#ref-crawford2019variable&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; and shown to be applicable to Bayesian neural networks in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;Ish-Horowicz et al.&lt;/a&gt; (&lt;a href=&#34;#ref-ish2019interpreting&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; offers an intuitive way to measure variable importance in the context of deep learning. By defining variable importance as the contribution inputs make to a probabilistic model, it implicitly incorporates the interactions between covariates and nonlinearities that the model has learned. In other words, it allows researchers to peek directly into the &lt;em&gt;Black Box&lt;/em&gt;. This opens up interesting avenues for future research, as the approach can be readily applied in academic disciplines and real-world applications that rely heavily on explainability of outcomes.&lt;/p&gt;
&lt;div style=&#34;page-break-after: always;&#34;&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;&gt;
&lt;div id=&#34;ref-arrieta2020explainable&#34; class=&#34;csl-entry&#34;&gt;
Arrieta, Alejandro Barredo, Natalia Diaz-Rodriguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garcia, et al. 2020. &lt;span&gt;“Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges Toward Responsible AI.”&lt;/span&gt; &lt;em&gt;Information Fusion&lt;/em&gt; 58: 82–115.
&lt;/div&gt;
&lt;div id=&#34;ref-bishop2006pattern&#34; class=&#34;csl-entry&#34;&gt;
Bishop, Christopher M. 2006. &lt;em&gt;Pattern Recognition and Machine Learning&lt;/em&gt;. springer.
&lt;/div&gt;
&lt;div id=&#34;ref-crawford2019variable&#34; class=&#34;csl-entry&#34;&gt;
Crawford, Lorin, Seth R Flaxman, Daniel E Runcie, and Mike West. 2019. &lt;span&gt;“Variable Prioritization in Nonlinear Black Box Methods: A Genetic Association Case Study.”&lt;/span&gt; &lt;em&gt;The Annals of Applied Statistics&lt;/em&gt; 13 (2): 958.
&lt;/div&gt;
&lt;div id=&#34;ref-fan2020interpretability&#34; class=&#34;csl-entry&#34;&gt;
Fan, Fenglei, Jinjun Xiong, and Ge Wang. 2020. &lt;span&gt;“On Interpretability of Artificial Neural Networks.”&lt;/span&gt; &lt;em&gt;Preprint at Https://Arxiv. Org/Abs/2001.02522&lt;/em&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-goan2020bayesian&#34; class=&#34;csl-entry&#34;&gt;
Goan, Ethan, and Clinton Fookes. 2020. &lt;span&gt;“Bayesian Neural Networks: An Introduction and Survey.”&lt;/span&gt; In &lt;em&gt;Case Studies in Applied Bayesian Data Science&lt;/em&gt;, 45–87. Springer.
&lt;/div&gt;
&lt;div id=&#34;ref-goodfellow2016deep&#34; class=&#34;csl-entry&#34;&gt;
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. &lt;em&gt;Deep Learning&lt;/em&gt;. MIT Press.
&lt;/div&gt;
&lt;div id=&#34;ref-ish2019interpreting&#34; class=&#34;csl-entry&#34;&gt;
Ish-Horowicz, Jonathan, Dana Udwin, Seth Flaxman, Sarah Filippi, and Lorin Crawford. 2019. &lt;span&gt;“Interpreting Deep Neural Networks Through Variable Importance.”&lt;/span&gt; &lt;em&gt;arXiv Preprint arXiv:1901.09839&lt;/em&gt;.
&lt;/div&gt;
&lt;/div&gt;
&lt;div style=&#34;page-break-after: always;&#34;&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Simulatability describes the overall, high-level understandability of the mechanisms underlying the model – put simply, the less complex the model, the higher its simulatability. Decomposability concerns the extent to which the model can be taken apart into smaller pieces – neural networks by there very nature are compositions of multiple layers. Finally, algorithmic transparency refers to the extent to which the training of the algorithm is well-understood and to some extent observable – since DNNs generally deal with optimization of non-convex functions and often lack unique solution they are inherently intransparent.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;For more detail see for example &lt;a href=&#34;https://christophm.github.io/interpretable-ml-book/shapley.html&#34;&gt;here&lt;/a&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;For simplicity I have omitted the deterministic bias term.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How I&#39;m building this website in R</title>
      <link>https://www.paltmeyer.com/post/how-i-m-building-this-website-in-r/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/post/how-i-m-building-this-website-in-r/</guid>
      <description>
&lt;script src=&#34;https://www.paltmeyer.com/post/how-i-m-building-this-website-in-r/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#getting-started&#34;&gt;Getting started&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deploying-your-website&#34;&gt;Deploying your website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#why-all-the-trouble&#34;&gt;Why all the trouble?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#a-simple-coding-example&#34;&gt;A simple coding example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#embedding-existing-work&#34;&gt;Embedding existing work&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#resources&#34;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;getting-started&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting started&lt;/h2&gt;
&lt;p&gt;It turns out building a static website in R is remarkably easy, as long as you know your way around R Markdown. Knowledge of HTML and CSS helps, but is not strictly necessary and can be acquired along the way. My package of choice for this website is &lt;code&gt;blogdown&lt;/code&gt; by &lt;a href=&#34;https://yihui.org/&#34;&gt;Yihui Xie&lt;/a&gt; who has had a major impact on the R community through his many package contributions (&lt;code&gt;knitr&lt;/code&gt;, &lt;code&gt;bookdown&lt;/code&gt;, &lt;code&gt;pagedown&lt;/code&gt;, …) and certainly made my life a lot easier on many occasions.&lt;/p&gt;
&lt;p&gt;To get started just follow the instructions on &lt;code&gt;blogdown&lt;/code&gt;’s &lt;a href=&#34;https://github.com/rstudio/blogdown&#34;&gt;GitHub repository&lt;/a&gt; or keep reading here for a high-level overview. Setting up a basic website in R requires exactly two steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Set up a local directory for the website. Let’s suppose you create it here &lt;code&gt;~/Documents/myAwesomeWebsite&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In R, navigate to the directory and simply run &lt;code&gt;blogdown::newsite()&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This will set up a basic template which you can develop. Changing the theme and playing with the basic structure of the website is relatively straight-forward. Personally I have so far managed to work things out based on a working knowledge of HTML and CSS that I’ve developed in the past through my work with R Shiny.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;deploying-your-website&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Deploying your website&lt;/h2&gt;
&lt;p&gt;There are various ways to deploy your website, i.e. make it accessible to the public. This website is deployed through GitHub pages. Detailed instructions on how to do this can be found &lt;a href=&#34;https://bookdown.org/yihui/blogdown/github-pages.html&#34;&gt;here&lt;/a&gt;. Since I already had an existing local clone of my &lt;code&gt;pat-alt.github.io&lt;/code&gt; repo, I just dropped it in the source directory of the website:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source/
│
├── config.yaml
├── content/
├── themes/
└── ...

patalt.github.io/
│
├── .git/
├── .nojekyll
├── index.html
├── about/
└── ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After adding &lt;code&gt;publishDir: pat-alt.github.io&lt;/code&gt; to my &lt;code&gt;config.yaml&lt;/code&gt; and then running &lt;code&gt;blogdown::hugo_build()&lt;/code&gt; the website was built inside the clone. All that was left to do was to commit changes from the local clone to the &lt;code&gt;pat-alt.github.io&lt;/code&gt; remote repo. A few moments later the website was already up and running.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-all-the-trouble&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why all the trouble?&lt;/h2&gt;
&lt;p&gt;There are certainly easier ways to build a website. But if like me you do pretty much all your work in R Markdown and want to share some of it, then you will love &lt;code&gt;blogdown&lt;/code&gt;. The beauty of it is that once the basic infrastructure is set up, adding content is as simple as running the following wrapper function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blogdown::new_post(&amp;quot;Your new post&amp;quot;, ext = &amp;quot;.Rmd&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where the first argument is just the title of your post and the &lt;code&gt;ext&lt;/code&gt; argument can be used to specify that you want to create an R Markdown document that can include code chucks. The wrapper function will automatically set up a directory for your post under &lt;code&gt;/post/&lt;/code&gt;. R Studio will redirect you to the relevant &lt;code&gt;.Rmd&lt;/code&gt; file that you can then fill with content. By default that folder will look roughly like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;├── index.Rmd
├── index.html
└── index_files
    └── header-attrs
        └── header-attrs.js&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;a-simple-coding-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A simple coding example&lt;/h2&gt;
&lt;p&gt;As you can probably tell from the code chunks above this post was created just in the way I described. So I thought I might as well go ahead with a simple coding example to add some flavour. Suppose you have built some function that you think is worth sharing with the world or simply learned something new and interesting. As a case in point, I recently had a look at the &lt;code&gt;Rcpp&lt;/code&gt; package and wrote a small program in C++ to be used in R. Since R Markdown supports &lt;code&gt;Rcpp&lt;/code&gt; code chunks (along with Python, bash, SQL, …) it is straight-forward to show-case that code on this website.&lt;/p&gt;
&lt;p&gt;The program can be used to simulate data from a categorical distribution. This distribution describes the possible results of a random variable that can take on one of &lt;span class=&#34;math inline&#34;&gt;\(K\)&lt;/span&gt; possible categories with different probabilities. In base R we could use &lt;code&gt;rmultinom(n=1000,1,p=c(0.5,0.1,0.4))&lt;/code&gt; to simulate draws from one such distribution with three different categories. Alternatively, we could write the program in C++ as follows:&lt;/p&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;#include &amp;lt;Rcpp.h&amp;gt;
using namespace Rcpp;

// [[Rcpp::export]]
NumericMatrix simCategorical(int n, NumericVector p) {
  int k = p.size();
  NumericMatrix mat(k, n);
  // Normalise prob if necessary:
  if (sum(p)!=1) {
    p = p/sum(p);
  }
  NumericVector emp_cdf = cumsum(p);
  NumericVector u = Rcpp::runif(n, 0, 1);
  // Matrix for 1-hot-encoding:
  for (int j = 0; j &amp;lt; n; j++) {
    // Perform binary search:
    int l = 0;
    int r = k;
    double target = u[j];
    while (l &amp;lt; r) {
      int m = floor((l+r)/2);
      if (emp_cdf[m] &amp;gt; target) {
        r = m;
      } else {
        l = m+1;
      }
    }
    mat(r,j) = 1;
  }
  return mat;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In terms of performance it turns out that the simple C++ program actually does somewhat better than the base R alternative:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(microbenchmark)
library(ggplot2)
n &amp;lt;- 1000
p &amp;lt;- c(0.5,0.1,0.4)
mb &amp;lt;- microbenchmark(
    &amp;quot;rmultinom&amp;quot; = {rmultinom(n, 1, p)},
    &amp;quot;Rcpp&amp;quot; = {simCategorical(n, p)}
)
autoplot(mb)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.paltmeyer.com/post/how-i-m-building-this-website-in-r/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;embedding-existing-work&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Embedding existing work&lt;/h2&gt;
&lt;p&gt;If you have some existing work that you would like to share you can just use it to overwrite the &lt;code&gt;index.Rmd&lt;/code&gt; file. &lt;code&gt;blogdown&lt;/code&gt; supports any kind of R Markdown documents so you can use all of your favourite markdown packages (&lt;code&gt;bookdown&lt;/code&gt;, &lt;code&gt;pagedown&lt;/code&gt;, …). Just make sure to specify HTML output in the YAML header.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;resources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;p&gt;For more information about &lt;code&gt;blogdown&lt;/code&gt; see &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;here&lt;/a&gt;. To inspect the code that builds this website check out my &lt;a href=&#34;https://github.com/pat-alt/patalt&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Welcome</title>
      <link>https://www.paltmeyer.com/post/welcome/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/post/welcome/</guid>
      <description>
&lt;script src=&#34;https://www.paltmeyer.com/post/welcome/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Welcome to my website!&lt;/p&gt;
&lt;p&gt;Having worked with R Markdown and some of &lt;a href=&#34;https://yihui.org/&#34;&gt;Yihui Xie&lt;/a&gt;’s amazing packages for years, I have only now come across his &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;blogdown&lt;/a&gt; package. For a while I have been thinking about a good way to share some of my work and actually started collecting snippets in a &lt;a href=&#34;https://pat-alt.github.io/fromScratch/&#34;&gt;Gitbook&lt;/a&gt; through &lt;a href=&#34;https://bookdown.org/yihui/bookdown/&#34;&gt;bookdown&lt;/a&gt; quite some time ago. While the book is a work-in-progress that I aim to finish eventually, I will use this website to regularly share content related to my work, research and other things.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://www.paltmeyer.com/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;porridge &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; porridge &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;:
    print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;{{% speaker_note %}}
&lt;span style=&#34;color:#66d9ef&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;span style=&#34;color:#66d9ef&#34;&gt;-&lt;/span&gt; Press &lt;span style=&#34;color:#e6db74&#34;&gt;`S`&lt;/span&gt; key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;{{&amp;lt; &lt;span style=&#34;color:#f92672&#34;&gt;slide&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;background-image&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &amp;gt;}}
{{&amp;lt; &lt;span style=&#34;color:#f92672&#34;&gt;slide&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;background-color&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &amp;gt;}}
{{&amp;lt; &lt;span style=&#34;color:#f92672&#34;&gt;slide&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;reveal&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;section&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;h1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;
.&lt;span style=&#34;color:#a6e22e&#34;&gt;reveal&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;section&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;h2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;
.&lt;span style=&#34;color:#a6e22e&#34;&gt;reveal&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;section&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;h3&lt;/span&gt; {
  &lt;span style=&#34;color:#66d9ef&#34;&gt;color&lt;/span&gt;: &lt;span style=&#34;color:#66d9ef&#34;&gt;navy&lt;/span&gt;;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>https://www.paltmeyer.com/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>https://www.paltmeyer.com/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.paltmeyer.com/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title>About me</title>
      <link>https://www.paltmeyer.com/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/about/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Work and Outreach</title>
      <link>https://www.paltmeyer.com/work/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.paltmeyer.com/work/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
