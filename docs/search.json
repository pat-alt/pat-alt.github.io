[
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Posts",
    "section": "",
    "text": "TrillionDollarWords.jl\n\n\nThe Trillion Dollar Words dataset and model in Julia\n\n\nA short post introducing a small new Julia package that facilitates working with the Trillion Dollar Words dataset and model published in a recent ACL 2023 paper.\n\n\n\n\n\n\nFeb 14, 2024\n\n\nPatrick Altmeyer\n\n\n6 min\n\n\n2/15/24, 3:36:53 PM\n\n\n\n\n\n\n  \n\n\n\n\nECCCos from the Black Box\n\n\nFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals\n\n\nECCCo is a new way to generate faithful model explanations through counterfactuals that are as plausible as the underlying model permits. Companion post to our AAAI 2024 paper.\n\n\n\n\n\n\nFeb 8, 2024\n\n\nPatrick Altmeyer\n\n\n17 min\n\n\n2/16/24, 9:02:03 AM\n\n\n\n\n\n\n  \n\n\n\n\nSpurious Sparks of AGI\n\n\nOn the Unsurprising Finding of Patterns in Latent Spaces\n\n\nThis post questions the idea that finding patterns in latent embeddings of models is indicative of AGI or even surprising. I illustrate this using examples from Economics, a discipline that does not typically anthropomorphize the models it produces.\n\n\n\n\n\n\nFeb 7, 2024\n\n\nPatrick Altmeyer, Patrick Altmeyer\n\n\n30 min\n\n\n2/15/24, 3:36:53 PM\n\n\n\n\n\n\n  \n\n\n\n\nStuck in the Past\n\n\nWhy we should treat research like software and how Quarto can help\n\n\nAn opinionated post on outdated publication and peer review practices, as well as modern solutions. It introduces a Quarto extension for JuliaCon Proceedings that I have been working on.\n\n\n\n\n\n\nNov 25, 2023\n\n\nPatrick Altmeyer\n\n\n12 min\n\n\n11/26/23, 1:00:10 PM\n\n\n\n\n\n\n  \n\n\n\n\nBuilding a Conformal Chatbot in Julia\n\n\nHuggingFace, Transformers, and Conformal Prediction - Part 1\n\n\nFor this year‚Äôs edition of the ING Analytics Experiment Week, we put ConformalPrediction.jl to work and built a chatbot that can be used for Conformal Intent Recognition.\n\n\n\n\n\n\nJul 5, 2023\n\n\nPatrick Altmeyer\n\n\n7 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nPaving the Way Towards Low-Overhead Uncertainty Calibration\n\n\nAn Accessible Intro to Laplace Approximations in Julia for Bayesian Deep Learning\n\n\nA guest blog post by a team of students from TU Delft, who have contributed multiple improvements to LaplaceRedux.jl.\n\n\n\n\n\n\nJul 4, 2023\n\n\nPatrick Altmeyer, Severin Bratus, Mark Ardman, Adelina Cazacu, Andrei Ionescu, Ivan Makarov, Patrick Altmeyer\n\n\n11 min\n\n\n11/26/23, 1:01:20 PM\n\n\n\n\n\n\n  \n\n\n\n\nA Leap of Faith into Julia‚Äôs Metaverse\n\n\nGetting started with metaprogramming in Julia\n\n\nIn this slightly different post, I talk about my first experience with metaprogramming in Julia.\n\n\n\n\n\n\nMar 13, 2023\n\n\nPatrick Altmeyer\n\n\n14 min\n\n\n1/3/24, 3:57:29 PM\n\n\n\n\n\n\n  \n\n\n\n\nQuarto on Steroids: Advanced Customization through Quarto Extensions\n\n\nUsing and Contributing Quarto Extensions for Custom Formats.\n\n\nA short introduction to using, building and contributing Quarto Extensions.\n\n\n\n\n\n\nJan 16, 2023\n\n\nPatrick Altmeyer\n\n\n5 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nPrediction Intervals for any Regression Model\n\n\nConformal Prediction in Julia ‚Äî Part 3\n\n\nThis third post introduces conformal regression by going through a standard machine learning workflow using MLJ.jl and ConformalPrediction.jl.\n\n\n\n\n\n\nDec 12, 2022\n\n\nPatrick Altmeyer\n\n\n11 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nHow to Conformalize a Deep Image Classifier\n\n\nConformal Prediction in Julia ‚Äî Part 2\n\n\nA guide demonstrating how to use ConformalPrediction.jl to conformalize a deep image classifier in a few lines of code.\n\n\n\n\n\n\nDec 5, 2022\n\n\nPatrick Altmeyer\n\n\n9 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nA year of using Quarto with Julia\n\n\nTips and tricks for Julia practitioners\n\n\nA short companion post to my presentation on using Quarto with Julia at the 2nd JuliaLang Eindhoven meetup in November, 2022.\n\n\n\n\n\n\nNov 21, 2022\n\n\nPatrick Altmeyer\n\n\n8 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nConformal Prediction in Julia üü£üî¥üü¢\n\n\nConformal Prediction in Julia ‚Äî Part 1\n\n\nA (very) gentle introduction to Conformal Prediction in Julia using my new package ConformalPrediction.jl.\n\n\n\n\n\n\nOct 25, 2022\n\n\nPatrick Altmeyer\n\n\n15 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nA new tool for explainable AI\n\n\nCounterfactual Explanations in Julia ‚Äî Part I\n\n\nThis post introduces a new Julia package for generating counterfactual explanations. The package can be used to explain machine learning algorithms developed and trained in Julia as well as other popular programming languages like Python and R.\n\n\n\n\n\n\nApr 20, 2022\n\n\nPatrick Altmeyer\n\n\n12 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nJulia and Quarto: a match made in heaven? üå§\n\n\nA new way to publish science\n\n\nAn opinionated, practical review celebrating the open-source community. I discuss why Quarto is nothing short of revolutionary and how I‚Äôve been using it with Julia.\n\n\n\n\n\n\nApr 7, 2022\n\n\nPatrick Altmeyer\n\n\n16 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nGo deep, but also ‚Ä¶ go Bayesian!\n\n\nEffortless Bayesian Deep Learning in Julia ‚Äî Part I\n\n\nAn introduction to effortless Bayesian deep learning through Laplace approximation coded from scratch in Julia.\n\n\n\n\n\n\nFeb 18, 2022\n\n\nPatrick Altmeyer\n\n\n12 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nBayesian Logistic Regression\n\n\nFrom scratch in Julia Language\n\n\nAn introduction to Bayesian Logistic Regression from the bottom up with examples in Julia language.\n\n\n\n\n\n\nNov 15, 2021\n\n\nPatrick Altmeyer\n\n\n14 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nIndividual recourse for Black Box Models\n\n\nExplained through a tale of üê±‚Äôs and üê∂‚Äôs\n\n\nAn introduction to algorithmic recourse and an implementation of a simplified version of REVISE (Joshi et al., 2019). This post was prepared as part of my PhD application.\n\n\n\n\n\n\nApr 27, 2021\n\n\nPatrick Altmeyer\n\n\n11 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nA peek inside the ‚ÄòBlack Box‚Äô - interpreting neural networks\n\n\n\n\n\nResearch on explainable AI has recently gained considerable momentum. In this post I explore a Bayesian approach to ex-post explainability of Deep Neural Networks.a\n\n\n\n\n\n\nFeb 7, 2021\n\n\nPatrick Altmeyer\n\n\n11 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nHow I‚Äôm building this website in R\n\n\n\n\n\nA small post on how I (used to!) build this website using blogdown.\n\n\n\n\n\n\nFeb 2, 2021\n\n\nPatrick Altmeyer\n\n\n6 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\n  \n\n\n\n\nWelcome\n\n\n\n\n\nThe obligatory welcome post and a shout-out to Yihui Xie and the folks behind quarto.\n\n\n\n\n\n\nFeb 1, 2021\n\n\nPatrick Altmeyer, Patrick Altmeyer\n\n\n1 min\n\n\n10/7/23, 11:42:43 AM\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/meta-programming/index.html",
    "href": "blog/posts/meta-programming/index.html",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "",
    "text": "A leap of faith into Julia‚Äôs metaverse.\nOn this blog, I typically talk about things that I have some understanding of. In this post, I want to try something a little different and instead cover a topic that I am utterly clueless about. There‚Äôs an interesting aspect about Julia, which I know embarrassingly little about at this point: Metaprogramming.\nHaving worked with Julia for about 1.5 years now, I have so far employed a successful strategy of occasionally taking a glimpse at that part of the Julia documentation and then deciding to go back to pretending it never existed. Meanwhile, Karandeep Singh has stepped on the Julia scence around 5 minutes ago and already developed a package that literally oozes macro: Tidier.jl. The package API is such a joy to work with that I have felt inspired to finally take a serious look at what metaprogramming is all about.\nMy goal for this post is to get to the point where I can confidently write my first macro for CounterfactualExplanations.jl - more on this below! If you are as clueless and curious about the topic as I am, then follow along on a journey into the metaverse. Buckle in though, it‚Äôs going to be a bumpy ride! You have been warned."
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#all-right-where-to-start",
    "href": "blog/posts/meta-programming/index.html#all-right-where-to-start",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "ü§î All right, where to start?",
    "text": "ü§î All right, where to start?\nYou guessed it, we‚Äôll start with the official Julia documentation on the topic:\n\nLike Lisp, Julia represents its own code as a data structure of the language itself.\n\nHmmm ‚Ä¶ I know nothing about Lisp and this is already beyond me. Code as a data structure?\nLet‚Äôs first try to understand what exactly metaprogramming is, outside of Julia and Lisp. We‚Äôll take a quick detour before we‚Äôre back. Wikipedia has the following to say on the topic:\n\nMetaprogramming is a programming technique in which computer programs have the ability to treat other programs as their data.\n\nRight ‚Ä¶ What about ChatGPT? I wanted to try out ReplGPT anyway so here goes1:\njulia&gt; using ReplGPT\nChatGPT&gt; Hey hey, can you please explain metaprogramming to me (I have no computer science background, but am experienced with programming and data science)\n  Metaprogramming is a programming technique where a program is capable of creating or manipulating code at\n  runtime. It involves writing computer programs that create, modify, or analyze other computer programs or data\n  about those programs.\nSo, in layman‚Äôs terms, metaprogramming involves code that generates code - I guess we really have entered the metaverse!"
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#julia-docs",
    "href": "blog/posts/meta-programming/index.html#julia-docs",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "üìñ Julia docs",
    "text": "üìñ Julia docs\nLet‚Äôs head back to the Julia documentation (v1.8) and look at the first couple of examples.\n\nCode as Data Structures\nSkipping the details here, it turns out that when I write 1 + 1 in the REPL, Julia first parses this program as a string \"1 + 1 into an expression ex=:(1 + 1)::Expr, which is then evaluated eval(ex) (Figure¬†1). I‚Äôve used a quote here to generate the expression because I‚Äôve used quoting before for use with Documenter.jl.\n\n\n\nFigure¬†1: Key concept: code as a data structure.\n\n\nAnd if I understand this correctly, the expression ex::Expr is literally code as a data structure:\n\n\nCode\nex = :(sum([1,2,3]))\ndump(ex)\n\n\nExpr\n  head: Symbol call\n  args: Array{Any}((2,))\n    1: Symbol sum\n    2: Expr\n      head: Symbol vect\n      args: Array{Any}((3,))\n        1: Int64 1\n        2: Int64 2\n        3: Int64 3\n\n\nThat data structure can be ‚Äúmanipulated from within the language‚Äù.\nLet‚Äôs try that! Currently, evaluating this expression yields the sum of the Array:\n\n\nCode\neval(ex)\n\n\n6\n\n\nUpon manipulation (that sounds weird!), we have:\n\n\nCode\nex.args[1] = :maximum\neval(ex)\n\n\n3\n\n\nOk ok, things are starting to make sense now!\n\n\nInterpolation\nBack to the Julia documentation and next on the agenda we have Interpolation. Skipping the details again, it seems like I can interpolate an expression much like strings. Using interpolation I can recreate the expression from above as follows:\n\n\nCode\nfun = maximum\nx = [1,2,3]\nex_from_ex_interpoliation = :($fun($x))\na = eval(ex_from_ex_interpoliation)\n\n\nUsing string interpolation is quite similar:\n\n\nCode\nfun = maximum\nx = [1,2,3]\nex_from_string_interpolation = Meta.parse(\"$fun($x)\")\neval(ex_from_string_interpolation) == a\n\n\ntrue\n\n\nAnd much like with function arguments, we can also use splatting:\n\n\nCode\neval(:(zeros($x...)))\n\n\n1√ó2√ó3 Array{Float64, 3}:\n[:, :, 1] =\n 0.0  0.0\n\n[:, :, 2] =\n 0.0  0.0\n\n[:, :, 3] =\n 0.0  0.0\n\n\nNext off, we have nested quotes. I can‚Äôt see myself using these anytime soon but anyway it seems that for each $ sign that we prepend to x, an evaluation is trigged:\n\n\nCode\neval(quote quote $$:(x) end end)\n\n\n\nquote\n    #= In[9]:2 =#\n    [1, 2, 3]\nend\n\n\n\nMoving on, we have QuoteNodes, which I will steer clear of because I probably won‚Äôt be doing any super advanced metaprogramming anytime soon. The next two sections on evaluating expressions and functions on Expressions also look somewhat more involved than what I need right now, but I expect I‚Äôll find myself back here when I write that first macro for CounterfactualExplanations.jl.\n\n\nMacros\nAhhh, I see we‚Äôve finally arrived in Macroland!\n\nA macro maps a tuple of arguments to a returned expression, and the resulting expression is compiled directly rather than requiring a runtime eval call.\n\n\n\n\nArrived in Macroland.\n\n\nLet‚Äôs see if we can make sense of this as we move on. The Hello, world! example makes the concept quite clear:\n\n\nCode\nmacro sayhello(name)\n    return :( println(\"Hello, \", $name) )   # return the expression ...\nend\n@sayhello \"reader\"                          # ... to be immediately compiled.\n\n\nHello, reader\n\n\nIt seems that a macro is a way to build and return expressions inside a block (a bit like a function) but on call that expression is immediately evaluated. In other words, we can use macros to write code that generates code that is then evaluated.\nTo fully grasp the next part, I should have not skipped the part on functions on Expressions. We‚Äôll leave that little nugget for Future Me. That same guy will also have to suffer the consequences of Present Me merely skimming the details in the next section on macro invocation. Present Me is impatient and overly confident in the level of knowledge that we have just acquired about metaprogramming.\nLet‚Äôs get ahead of ourselves and meet the final boss of the metaverse: an Advanced Macro."
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#build-an-advanced-macro",
    "href": "blog/posts/meta-programming/index.html#build-an-advanced-macro",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "üî• BUILD AN ADVANCED MACRO",
    "text": "üî• BUILD AN ADVANCED MACRO\nI‚Äôll leave it to you to thoroughly read that section in the Julia docs. Here, we‚Äôll jump straight into building the macro I want to have for CounterfactualExplanations.jl. I now think it‚Äôll be less involved than I thought ‚Äî optimism in the face of uncertainty!\n\n\n\nAdvanced Macro: the final boss.\n\n\n\nFrom Off-the-Shelf Counterfactual Generators ‚Ä¶\nCounterfactualExplanations.jl is a package for generating Counterfactual Explanations for predictive models \\(f: \\mathcal{X} \\mapsto \\mathcal{Y}\\). This is a relatively recent approach to Explainable AI that I am (probably a little too) excited about and won‚Äôt dwell on here. For what follows, it suffices to say that generating Counterfactual Explanations can be seen as a generative modelling task because it involves generating samples in the input space: \\(x \\sim \\mathcal{X}\\). To this end, the package has previously shipped with a number of Generators: composite types that contain information about how counterfactuals ought to be generated.\nThis has allowed users to specify the type of generator they want to use by instantiating it. For example, the DiCE generator by Mothilal, Sharma, and Tan (2020) could (and still can) be instantiated as follows:\n\n\nCode\ngenerator = DiCEGenerator()\n\n\nThis has been a straightforward way for users to use off-the-shelf counterfactual generators. But relying on separate composite types for this task may have been an overkill. In fact, all this time there was some untapped potential here, as we will see next.\n\n\n‚Ä¶ To Composable Generators\nOne of my key objectives for the package has always been composability. It turns out that many of the various counterfactual generators that have been proposed in the literature, essentially do the same thing: they optimize an objective function. In Altmeyer et al. (2023), we denote that objective formally as follows,\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\left\\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)}+ \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\right\\}\n\\end{aligned}\n\\tag{1}\\]\nwhere \\(\\text{yloss}\\) denotes the main loss function and \\(\\text{cost}\\) is a penalty term. I won‚Äôt cover this in any more detail here, but you can read about it in the package docs. The important thing is that Equation¬†1 very closely describes how counterfactual search is actually implemented in the package.\nIn other words, all generators currently implemented share a common starting point. They largely just vary in the exact way the objective function is specified. This gives rise to an interesting idea:\n\nWhy not compose generators that combine ideas from different off-the-shelf generators?\n\nI want to give users an easy way to do that, without having to build custom Generator types from scratch. This (I think) is a good use case for metaprogramming.\nLet‚Äôs try and see if we can make that work. We‚Äôll simply extend CounterfactualExplanations right here in this repo hosting the blog (easily done in Julia) and provided everything works out well create a pull request. I already have a GitHub issue for this with a linked branch, so that‚Äôs the one I‚Äôll use in my environment:\n(metaprogramming) pkg&gt; add https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl#118-add-losses-and-penalties-modules-or-group-under-objectives-module\njulia&gt; using CounterfactualExplanations\nBy the time you‚Äôre reading this, all changes to that branch will have hopefully already been committed and merged.\nLet‚Äôs start by instantiating a generic generator:\n\n\nCode\ngenerator = GenericGenerator()\n\n\nOur goal is to create macros that build expressions that, when evaluated, mutate the generator instance.\n\n\nDefine your @objective\nOur first and most important macro shall define the counterfactual search objective. In particular, the @objective macro should accept an expression that looks much like the right-hand-side of Equation¬†1, which is essentially just a weighted sum.\n\n\n\nSketch of the envisioned @objective macro.\n\n\nLet‚Äôs start with that part. Naively, we could begin by writing it out very literally:\nex = :(yloss + Œª*cost)\neval(ex)\nOf course, evaluating this expression throws an error because none of the variables are actually defined. Let‚Äôs work on that ‚Ä¶\nFor the loss and penalty functions, we will use methods available from the CounterfactualExplanations.Objectives module, while for \\(\\lambda\\) we will use a literal:\n\n\nCode\nex = :(logitbinarycrossentropy + 0.1 * distance_l2)\n\n\nLet‚Äôs try to make sense of the data structure we have created:\n\n\nCode\nex.args\n\n\n3-element Vector{Any}:\n :+\n :logitbinarycrossentropy\n :(0.1distance_l2)\n\n\nMy first naive approach is shown below. It errors because I forgot to interpolate the variables inside the quote.\nmacro objective(generator, ex)\n    loss = ex.args[2]\n    ex_penalty = ex.args[3]\n    Œª = ex_penalty.args[2]\n    cost = ex_penalty.args[3]\n    ex_generator = quote \n        generator.loss = loss\n        generator.cost = cost\n        generator.Œª = Œª\n    end\n    return ex_generator\nend\nHaving fixed that below, I still get an error because loss and cost functions are not part of the global scope. I am pretty sure that this error would have occurred anyway and has nothing to do with the fact that I‚Äôm writing a macro.\nmacro objective(generator, ex)\n    loss = ex.args[2]\n    ex_penalty = ex.args[3]\n    Œª = ex_penalty.args[2]\n    cost = ex_penalty.args[3]\n    ex_generator = quote \n        $generator.loss = $loss\n        $generator.cost = $cost\n        $generator.Œª = $Œª\n    end\n    return ex_generator\nend\nInstead of importing the functions, I just get them explicitly from the Objectives module,\n\n\nCode\nmacro objective(generator, ex)\n    loss = getfield(CounterfactualExplanations.Objectives, ex.args[2])\n    ex_penalty = ex.args[3]\n    Œª = ex_penalty.args[2]\n    cost = getfield(CounterfactualExplanations.Objectives, ex_penalty.args[3])\n    ex_generator = quote \n        $generator.loss = $loss\n        $generator.penalty = $cost\n        $generator.Œª = $Œª\n        generator\n    end\n    return ex_generator\nend\n\n\nand, finally, this works:\n\n\nCode\n@objective(generator, logitbinarycrossentropy + 0.1distance_l2)\n\n\nCounterfactualExplanations.Generators.GradientBasedGenerator(Flux.Losses.logitbinarycrossentropy, CounterfactualExplanations.Objectives.distance_l2, 0.1, false, false, Flux.Optimise.Descent(0.1))\n\n\nBut what about adding multiple penalties? The DiCE generator, for example, also takes into account how diverse the counterfactual explanations are (Mothilal, Sharma, and Tan 2020). The corresponding penalty is called ddp_diversity. Let‚Äôs start with the expression again:\n\n\nCode\nex = :(logitbinarycrossentropy + 0.1distance_l2 + 1.0ddp_diversity)\nex.args\n\n\n4-element Vector{Any}:\n :+\n :logitbinarycrossentropy\n :(0.1distance_l2)\n :(1.0ddp_diversity)\n\n\n\n\nThis time there‚Äôs a second nested Expression among the arguments: :(1.0ddp_diversity).\n\n\n\n\nCode\nmacro objective(generator, ex)\n    loss = getfield(CounterfactualExplanations.Objectives, ex.args[2])\n    Œõ = Vector{AbstractFloat}()\n    costs = Vector{Function}()\n    for i in 3:length(ex.args)\n        ex_penalty = ex.args[i]\n        Œª = ex_penalty.args[2]\n        push!(Œõ, Œª)\n        cost = getfield(CounterfactualExplanations.Objectives, ex_penalty.args[3])\n        push!(costs, cost)\n    end\n    ex_generator = quote \n        $generator.loss = $loss\n        $generator.penalty = $costs\n        $generator.Œª = $Œõ\n        generator\n    end\n    return ex_generator\nend\n\n\nThat works well,\n\n\nCode\n@objective(generator, logitbinarycrossentropy + 0.05distance_l2 + 1.0ddp_diversity)\n\n\nCounterfactualExplanations.Generators.GradientBasedGenerator(Flux.Losses.logitbinarycrossentropy, Function[CounterfactualExplanations.Objectives.distance_l2, CounterfactualExplanations.Objectives.ddp_diversity], AbstractFloat[0.05, 1.0], false, false, Flux.Optimise.Descent(0.1))\n\n\nbut we should still make sure that this generator is also compatible with our package. Below we go through some of the typical workflows associated with Counterfactual Explanations. Firstly, we load some synthetic data and fit a black-box model to it.\n\n\nCode\nn_dim = 2\nn_classes = 4\nn_samples = 400\nmodel_name = :MLP\ncounterfactual_data = CounterfactualExplanations.load_blobs(n_samples; k=n_dim, centers=n_classes)\nM = fit_model(counterfactual_data, model_name)\nplot(M, counterfactual_data)\n\n\nNext, we begin by specifying our target and factual label. We then draw a random sample from the non-target (factual) class.\n\n\nCode\n# Factual and target:\ntarget = 2\nfactual = 4\nchosen = rand(findall(predict_label(M, counterfactual_data) .== factual))\nx = select_factual(counterfactual_data,chosen)\n\n\nFinally, we use our generator to generate counterfactuals:\n\n\nCode\nce = generate_counterfactual(\n    x, target, counterfactual_data, M, generator;\n    num_counterfactuals = 5,\n    converge_when = :generator_conditions\n)\n\n\nIt worked! üéâ The resulting counterfactual search is illustrated in Figure¬†2. I may have overspecified the size of the ddp_diversity penalty a little bit here, but it sure makes for a cool chart!\n\n\n\n\n\nFigure¬†2: Counterfactual search using our composed generator.\n\n\n\n\nTime for me to add this all to CounterfactualExplanations.jl ‚Ä¶ ‚è≥"
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#hygiene",
    "href": "blog/posts/meta-programming/index.html#hygiene",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "üßº Hygiene",
    "text": "üßº Hygiene\n‚Ä¶ aaand I‚Äôm back. There was one thing I had ignored that ended up causing a minor complication: macro hygiene.\nAgain, I‚Äôll leave it to you to read up on the details, but the bottom line is that when writing macros, we need to keep variable scopes in mind. CounterfactualExplanations.jl is composed of various (sub)modules, and when I initially added the macro to the CounterfactualExplanations.Generators module, it errored.\nThe problem was (I believe) that the generator variable existed in the global scope (Main) but it was not accessible for the @objective macro that at runtime lives in Main.Generators. Fortunately, it is easy to make the variable accessible by wrapping it inside an esc() call:\n\nThis escaping mechanism can be used to ‚Äúviolate‚Äù hygiene when necessary, in order to introduce or manipulate user variables.\n\nThis may not be the ideal way to do this, and as always, if you have any suggestions I‚Äôd be happy to hear about them.\nIf you want to find out more about how macros can now be used to easily compose counterfactual generators, check out the new section in the package documentation."
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#wrapping-up",
    "href": "blog/posts/meta-programming/index.html#wrapping-up",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "üåØ Wrapping Up",
    "text": "üåØ Wrapping Up\nIn this blog post, I‚Äôve done something I usually try to avoid: talk about things I don‚Äôt know. Metaprogramming is an exciting topic and if you‚Äôre still here, you just got to experience it through the lens of an absolute novice. During our leap of faith into Julia‚Äôs metaverse we‚Äôve learned the following things:\n\nCode in Julia is internally represented as a mutable data structure.\nMacros are a way to take such data structures and transform them before they get evaluated at runtime.\nAn important thing to keep in mind when writing macros is variable scopes.\n\nThroughout this post, I have skipped various important details that (I think) were not immediately relevant to the goal I had in mind: adding my first macro to CounterfactualExplanations.jl. In the future, I may write about this topic again and cover some of these missing details (hopefully with a bit more insight at that point!)."
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#footnotes",
    "href": "blog/posts/meta-programming/index.html#footnotes",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA very cool package! Funny story, though, I somehow managed to commit my OpenAI API key to GitHub on the first go (developing)‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/conformal-llm/index.html",
    "href": "blog/posts/conformal-llm/index.html",
    "title": "Building a Conformal Chatbot in Julia",
    "section": "",
    "text": "Short demo of our conformal chatbot.\nLarge Language Models are all the buzz right now. They are used for a variety of tasks, including text classification, question answering, and text generation. In this tutorial, we will show how to conformalize a transformer language model for text classification. We will use the Banking77 dataset (Casanueva et al. 2020), which consists of 13,083 queries from 77 intents. On the model side, we will use the DistilRoBERTa model, which is a distilled version of RoBERTa (Liu et al. 2019) finetuned on the Banking77 dataset."
  },
  {
    "objectID": "blog/posts/conformal-llm/index.html#huggingface-model",
    "href": "blog/posts/conformal-llm/index.html#huggingface-model",
    "title": "Building a Conformal Chatbot in Julia",
    "section": "ü§ó HuggingFace Model",
    "text": "ü§ó HuggingFace Model\nThe model can be loaded from HF straight into our running Julia session using the Transformers.jl package. Below we load the tokenizer tkr and the model mod. The tokenizer is used to convert the text into a sequence of integers, which is then fed into the model. The model outputs a hidden state, which is then fed into a classifier to get the logits for each class. Finally, the logits are then passed through a softmax function to get the corresponding predicted probabilities. Below we run a few queries through the model to see how it performs.\n\n\nCode\n# Load model from HF ü§ó:\ntkr = hgf\"mrm8488/distilroberta-finetuned-banking77:tokenizer\"\nmod = hgf\"mrm8488/distilroberta-finetuned-banking77:ForSequenceClassification\"\n\n# Test model:\nquery = [\n    \"What is the base of the exchange rates?\",\n    \"Why is my card not working?\",\n    \"My Apple Pay is not working, what should I do?\",\n]\na = encode(tkr, query)\nb = mod.model(a)\nc = mod.cls(b.hidden_state)\nd = softmax(c.logit)\n[labels[i] for i in Flux.onecold(d)]\n\n\n3-element Vector{String}:\n \"exchange_rate\"\n \"card_not_working\"\n \"apple_pay_or_google_pay\""
  },
  {
    "objectID": "blog/posts/conformal-llm/index.html#mlj-interface",
    "href": "blog/posts/conformal-llm/index.html#mlj-interface",
    "title": "Building a Conformal Chatbot in Julia",
    "section": "üîÅ MLJ Interface",
    "text": "üîÅ MLJ Interface\nSince our package is interfaced to MLJ.jl, we need to define a wrapper model that conforms to the MLJ interface. In order to add the model for general use, we would probably go through MLJFlux.jl, but for this tutorial, we will make our life easy and simply overload the MLJBase.fit and MLJBase.predict methods. Since the model from HF is already pre-trained and we are not interested in further fine-tuning, we will simply return the model object in the MLJBase.fit method. The MLJBase.predict method will then take the model object and the query and return the predicted probabilities. We also need to define the MLJBase.target_scitype and MLJBase.predict_mode methods. The former tells MLJ what the output type of the model is, and the latter can be used to retrieve the label with the highest predicted probability.\n\n\nCode\nstruct IntentClassifier &lt;: MLJBase.Probabilistic\n    tkr::TextEncoders.AbstractTransformerTextEncoder\n    mod::HuggingFace.HGFRobertaForSequenceClassification\nend\n\nfunction IntentClassifier(;\n    tokenizer::TextEncoders.AbstractTransformerTextEncoder, \n    model::HuggingFace.HGFRobertaForSequenceClassification,\n)\n    IntentClassifier(tkr, mod)\nend\n\nfunction get_hidden_state(clf::IntentClassifier, query::Union{AbstractString, Vector{&lt;:AbstractString}})\n    token = encode(clf.tkr, query)\n    hidden_state = clf.mod.model(token).hidden_state\n    return hidden_state\nend\n\n# This doesn't actually retrain the model, but it retrieves the classifier object\nfunction MLJBase.fit(clf::IntentClassifier, verbosity, X, y)\n    cache=nothing\n    report=nothing\n    fitresult = (clf = clf.mod.cls, labels = levels(y))\n    return fitresult, cache, report\nend\n\nfunction MLJBase.predict(clf::IntentClassifier, fitresult, Xnew)\n    output = fitresult.clf(get_hidden_state(clf, Xnew))\n    pÃÇ = UnivariateFinite(fitresult.labels,softmax(output.logit)',pool=missing)\n    return pÃÇ\nend\n\nMLJBase.target_scitype(clf::IntentClassifier) = AbstractVector{&lt;:Finite}\n\nMLJBase.predict_mode(clf::IntentClassifier, fitresult, Xnew) = mode.(MLJBase.predict(clf, fitresult, Xnew))\n\n\nTo test that everything is working as expected, we fit the model and generated predictions for a subset of the test data:\n\n\nCode\nclf = IntentClassifier(tkr, mod)\ntop_n = 10\nfitresult, _, _ = MLJBase.fit(clf, 1, nothing, y_test[1:top_n])\n@time yÃÇ = MLJBase.predict(clf, fitresult, queries_test[1:top_n]);\n\n\n  6.818024 seconds (11.29 M allocations: 799.165 MiB, 2.47% gc time, 91.04% compilation time)"
  },
  {
    "objectID": "blog/posts/conformal-llm/index.html#conformal-chatbot",
    "href": "blog/posts/conformal-llm/index.html#conformal-chatbot",
    "title": "Building a Conformal Chatbot in Julia",
    "section": "ü§ñ Conformal Chatbot",
    "text": "ü§ñ Conformal Chatbot\nTo turn the wrapped, pre-trained model into a conformal intent classifier, we can now rely on standard API calls. We first wrap our atomic model where we also specify the desired coverage rate and method. Since even simple forward passes are computationally expensive for our (small) LLM, we rely on Simple Inductive Conformal Classification.\nconf_model = conformal_model(clf; coverage=0.95, method=:simple_inductive, train_ratio=train_ratio)\nmach = machine(conf_model, queries, y)\n@time fit!(mach)\nSerialization.serialize(\"dev/artifacts/models/banking77/simple_inductive.jls\", mach)\nFinally, we use our conformal LLM to build a simple yet powerful chatbot that runs directly in the Julia REPL. Without dwelling on the details too much, the conformal_chatbot works as follows:\n\nPrompt user to explain their intent.\nFeed user input through conformal LLM and present the output to the user.\nIf the conformal prediction set includes more than one label, prompt the user to either refine their input or choose one of the options included in the set.\n\n\n\nCode\nmach = Serialization.deserialize(\"blog/posts/conformal-llm/simple_inductive.jls\")\n\nfunction prediction_set(mach, query::String)\n    pÃÇ = MLJBase.predict(mach, query)[1]\n    probs = pdf.(pÃÇ, collect(1:77))\n    in_set = findall(probs .!= 0)\n    labels_in_set = labels[in_set]\n    probs_in_set = probs[in_set]\n    _order = sortperm(-probs_in_set)\n    plt = UnicodePlots.barplot(labels_in_set[_order], probs_in_set[_order], title=\"Possible Intents\")\n    return labels_in_set, plt\nend\n\nfunction conformal_chatbot()\n    println(\"üëã Hi, I'm a Julia, your conformal chatbot. I'm here to help you with your banking query. Ask me anything or type 'exit' to exit ...\\n\")\n    completed = false\n    queries = \"\"\n    while !completed\n        query = readline()\n        queries = queries * \",\" * query\n        labels, plt = prediction_set(mach, queries)\n        if length(labels) &gt; 1\n            println(\"ü§î Hmmm ... I can think of several options here. If any of these applies, simply type the corresponding number (e.g. '1' for the first option). Otherwise, can you refine your question, please?\\n\")\n            println(plt)\n        else\n            println(\"ü•≥ I think you mean $(labels[1]). Correct?\")\n        end\n\n        # Exit:\n        if query == \"exit\"\n            println(\"üëã Bye!\")\n            break\n        end\n        if query ‚àà string.(collect(1:77))\n            println(\"üëç Great! You've chosen '$(labels[parse(Int64, query)])'. I'm glad I could help you. Have a nice day!\")\n            completed = true\n        end\n    end\nend\n\n\nBelow we show the output for two example queries. The first one is very ambiguous. As expected, the size of the prediction set is therefore large.\n\n\nCode\nambiguous_query = \"transfer mondey?\"\nprediction_set(mach, ambiguous_query)[2]\n\n\n\n                                                        Possible Intents              \n                                           ‚îå                                        ‚îê \n                   beneficiary_not_allowed ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.150517   \n   balance_not_updated_after_bank_transfer ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.111409           \n                     transfer_into_account ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.0939535             \n        transfer_not_received_by_recipient ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.091163               \n            top_up_by_bank_transfer_charge ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.089306               \n                           failed_transfer ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.0888322              \n                           transfer_timing ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.0641952                   \n                      transfer_fee_charged ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.0361131                         \n                          pending_transfer ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.0270795                           \n                           receiving_money ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.0252126                           \n                         declined_transfer ‚î§‚ñ†‚ñ†‚ñ† 0.0164443                             \n                           cancel_transfer ‚î§‚ñ†‚ñ†‚ñ† 0.0150444                             \n                                           ‚îî                                        ‚îò \n\n\n\nThe more refined version of the prompt yields a smaller prediction set: less ambiguous prompts result in lower predictive uncertainty.\n\n\nCode\nrefined_query = \"I tried to transfer money to my friend, but it failed.\"\nprediction_set(mach, refined_query)[2]\n\n\n\n                                                        Possible Intents              \n                                           ‚îå                                        ‚îê \n                           failed_transfer ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.59042   \n                   beneficiary_not_allowed ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.139806                          \n        transfer_not_received_by_recipient ‚î§‚ñ†‚ñ† 0.0449783                              \n   balance_not_updated_after_bank_transfer ‚î§‚ñ†‚ñ† 0.037894                               \n                         declined_transfer ‚î§‚ñ† 0.0232856                               \n                     transfer_into_account ‚î§‚ñ† 0.0108771                               \n                           cancel_transfer ‚î§ 0.00876369                               \n                                           ‚îî                                        ‚îò \n\n\n\nBelow we include a short demo video that shows the REPL-based chatbot in action."
  },
  {
    "objectID": "blog/posts/conformal-llm/index.html#wrapping-up",
    "href": "blog/posts/conformal-llm/index.html#wrapping-up",
    "title": "Building a Conformal Chatbot in Julia",
    "section": "üåØ Wrapping Up",
    "text": "üåØ Wrapping Up\nThis work was done in collaboration with colleagues at ING as part of the ING Analytics 2023 Experiment Week. Our team demonstrated that Conformal Prediction provides a powerful and principled alternative to top-K intent classification. We won the first prize by popular vote.\nThere are a lot of things that can be improved. As far as LLMs are concerned, we have of course used a fairly small model here. In terms of Conformal Prediction, we have relied on simple inductive conformal classification. This is a good starting point, but there are more advanced methods available (and implemented in the package). Another thing we did not take into consideration here is that we have many outcome classes and may in practice be interested in achieving class-conditional coverage. Stay tuned for more!"
  },
  {
    "objectID": "blog/posts/eccco/index.html",
    "href": "blog/posts/eccco/index.html",
    "title": "ECCCos from the Black Box",
    "section": "",
    "text": "Counterfactual explanations offer an intuitive and straightforward way to explain opaque machine learning (ML) models. They work under the premise of perturbing inputs to achieve a desired change in the predicted output. There are typically many ways to achieve this, in other words, many different counterfactuals may yield the same desired outcome. A key challenge for researchers has therefore been to, firstly, define certain desirable characteristics of counterfactual explanations and, secondly, come up with efficient ways to achieve them.\nOne of the most important and studied characteristics of counterfactual explanations is ‚Äòplausibility‚Äô: explanations should look realistic to humans. Plausibility is positively associated with actionability, robustness (Artelt et al. 2021) and causal validity (Mahajan, Tan, and Sharma 2020). To achieve plausibility, many existing approaches rely on surrogate models. This is straightforward but it also convolutes things further: it essentially reallocates the task of learning plausible explanations for the data from the model itself to the surrogate.\nIn our AAAI 2024 paper, Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals (ECCCo), we propose that we should not only look for explanations that please us but rather focus on generating counterfactuals that faithfully explain model behavior. It turns out that we can achieve both faithfulness and plausibility by relying solely on the model itself, leveraging recent advances in energy-based modelling and conformal prediction. We support this claim through extensive empirical studies and believe that ECCCo opens avenues for researchers and practitioners seeking tools to better distinguish trustworthy from unreliable models."
  },
  {
    "objectID": "blog/posts/eccco/index.html#sec-poison",
    "href": "blog/posts/eccco/index.html#sec-poison",
    "title": "ECCCos from the Black Box",
    "section": "Pick your Poison",
    "text": "Pick your Poison\nThere are two main philosophical debates in the field of Explainable AI (XAI). The first one centers around the role of explainability in AI: do we even need explanations and if so, why? Some have argued that we need not care about explaining models as long as they produce reliable outcomes (Robbins 2019). Humans have not shied away from this in other domains either: doctors, for example, have prescribed aspirin for decades without understanding why it is a reliable drug for pain relief (London 2019). While this reasoning may rightfully apply in some cases, experiments conducted by my colleagues at TU Delft have shown that humans do not make better decisions if aided by a reliable and yet opaque model (He, Buijsman, and Gadiraju 2023). In these studies, subjects tended to ignore the AI model indicating that they did not trust its decisions. Beyond this, explainability comes with numerous advantages such as accountability, control, contestability and the potential for uncovering causal relationships.\n\n\n\n\n\n\nIntermezzo: Why Bother?\n\n\n\nIf we can blindly rely on the decisions made by an AI, why should we even bother to come up with explanations? I must confess I had never even seriously considered this as an option until attending Stefan Buijsman‚Äôs recent talk at a Delft Design for Values workshop, which inspired the previous paragraph. As a philosopher and AI ethicist at TU Delft, some of Stefan‚Äôs most recent research investigates causal human-in-the-loop explanations for AI models (Biswas et al. 2022). I do not think that he adheres to the view that we should simply trust AI models blindly. In fact, he and his colleagues have shown that most humans do not tend to simply trust AI models even if they have been assured about their reliability (He, Buijsman, and Gadiraju 2023).\nStill, the question of why we even bother is an interesting challenge, especially considering that the field of XAI has so far struggled to produce satisfactory and robust results with meaningful real-world impact. Numerous studies related to He, Buijsman, and Gadiraju (2023) have shown that explanations for AI models either fail to help users or even mislead them (Mittelstadt, Russell, and Wachter 2019; Alufaisan et al. 2021; Lakkaraju and Bastani 2020). It seems that neither blind trust nor explanations are a silver bullet.\nSo, have our efforts toward explainable AI been in vain? Should we simply stop explaining black-box models altogether as proposed by Rudin (2019)? Having worked in this field for a little over 2 years now, I have personally grown more and more skeptical of certain trends I have observed. In particular, I think that the community has focused too much on finding explanations that please us independent of the model itself (ideally model-agnostic, really!). This is a bit like applying a band-aid to a wound without first cleaning it. At best, plausible explanations for untrustworthy models provide a false sense of security. At worst, they can be used to manipulate and deceive. The AAAI paper presented in this post is very much born out of skepticism about this trend.\nNonetheless, I do not think all hope is lost for XAI. I strongly believe that there is a need for algorithmic recourse as long as we continue to deploy black-box models for automated decision-making. While I am fully supportive of the idea that we should always strive to use models that are as interpretable as possible (Rudin 2019), I also think that there are cases where this is not feasible or it is simply too convenient to use a black-box model instead. The aspirin example mentioned above is a striking example of this. But it is easy enough to stretch that example further to illustrate why explainability is important. What if the use of aspirin was prohibited for a small minority of people and there was a reliable, opaque model to decide who belonged to that group? If you were part of that group, would you not want to know why? Why should you have to endure headaches for the rest of your life while others do not?\nIn summary, I think that‚Äîlike it or not‚Äîwe do need to bother.\n\n\nThe second major debate is about what constitutes a good explanation, because, crucially, explanations are not unique: was your headache cured by the aspirin you took before going to sleep or sleep itself? Or a combination of both? This multiplicity of explanations arises almost naturally in the context of counterfactual explanations. Unless the combination of input features for which the model predicts the target class or value is unique, there is always more than one possible explanation. As an illustrative example, consider the counterfactuals presented in Figure¬†1. All of these are valid explanations for turning a ‚Äònine‚Äô into ‚Äòseven‚Äô according to the underlying classifier (a simple multi-layer perceptron). They are all valid in the sense the model predicts the target label with high probability in each case. The troubling part is that even though all of the generated counterfactuals provide valid explanations for why the model predicts ‚Äòseven‚Äô instead of ‚Äònine‚Äô, they all look very different.\n\n\n\nFigure¬†1: Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using Wachter (Wachter, Mittelstadt, and Russell 2017), Schut (Schut et al. 2021) and REVISE (Joshi et al. 2019).\n\n\nSo, which explanations do we trust most? Which one would you choose to present to an audience to explain how the classifier decides which digit to predict? Arguably, the counterfactual on the far right looks most like a ‚Äòseven‚Äô, so I am willing to bet that most people would simply choose that one. It is valid after all and it looks plausible, while the other two counterfactuals might just lead to awkward questions from more interrogative audience members. In any case, I mentioned earlier that more plausible explanations tend to also be more actionable and robust, so this seems fair game. The counterfactual produced by REVISE (Joshi et al. 2019) is the poison we will pick‚Äîdump the rest and move on. Plausibility is all we need!2\nI am exaggerating but I do think that as a community of researchers studying counterfactual explanations, we have become so absorbed by the pursuit of a few desiderata that we have forgotten that ultimately we are in the business of explaining models. Our primary mandate is to design tools that help us understand why models predict certain outcomes. How useful is a plausible, actionable, sparse, causally valid explanation in gaining that understanding, if there exist a whole bunch of other valid explanations that do not meet these desiderata? Have we significantly improved our understanding of the underlying classifier in Figure¬†1 and therefore established a higher degree of trust in the model, simply because we have found a plausible counterfactual?\nIn my mind, we most certainly have not. I would argue that the existence of a valid and plausible explanation merely serves to reassure us that the model is not entirely ignorant about meaningful representations in the data. But as long as entirely implausible counterfactuals are also valid according to the model, selectively relying only on the subset of plausible counterfactuals may lead to a wrong sense of trust in untrustworthy models. That is why in our paper we argue that explanations should be faithful first, and plausible second."
  },
  {
    "objectID": "blog/posts/eccco/index.html#faithful-first-plausible-second",
    "href": "blog/posts/eccco/index.html#faithful-first-plausible-second",
    "title": "ECCCos from the Black Box",
    "section": "Faithful First, Plausible Second",
    "text": "Faithful First, Plausible Second\nTo navigate the interplay between faithfulness and plausibility, we propose a way to generate counterfactuals that are consistent with what the model has learned about the data. In doing so, we can also achieve plausibility but only in case the model has learned something meaningful.\n\nFaithful Counterfactuals\nWhen inquiring about what is ‚Äúconsistent with what the model has learned about the data‚Äù, we are essentially asking about the model‚Äôs posterior conditional distribution of the input data given the target output. It turns out that we can approximate that distribution using ideas relevant to energy-based modelling. In particular, we can use something called Stochastic Gradient Langevin Dynamics (SGLD) to sample from the model‚Äôs posterior conditional distribution (Welling and Teh 2011).\nWithout going into too much detail here, the idea is to use the model‚Äôs energy function to guide the sampling process. The energy function is a scalar function that assigns a value to each possible configuration of the input data. The lower the energy, the higher the likelihood corresponding to the configuration. This is a powerful tool: Grathwohl et al. (2020), for example, use SGLD in this fashion to train hybrid models‚Äîjoint-energy models (JEM)‚Äîthat are trained to both classify and generate data.\nFigure¬†2 illustrates this concept. It shows samples (yellow stars) drawn from the posterior of a simple JEM trained on linearly separable data. The contour shows the kernel density estimate (KDE) for the learned conditional distribution. Although it seems that the posterior is too sharp in this case, the learned conditional distribution is overall consistent with the data (at least the mode is).\n\n\n\n\n\nFigure¬†2: Kernel Density Estimate (KDE) for the learned conditional distribution. Yellow stars indicate samples generated through Stochastic Gradient Langevin Dynamics for a joint energy model (JEM).\n\n\nAlso shown in Figure¬†2 is a single counterfactual path from the orange to the blue class. I have relied on the baseline approach proposed in Wachter, Mittelstadt, and Russell (2017) here using only a small penalty for the distance between the counterfactual and the original input. A truly faithful counterfactual, as we define it in our paper, would be one that we could expect to sample from the learned conditional distribution (with high probability)3. Based on this notion, we would not characterize the counterfactual in Figure¬†2 as faithful, but it also is not too far off.\nIt is easy to see how other desiderata may conflict with faithfulness. If I had penalized the distance between the counterfactual and the original input more, for example, then the counterfactual would have been less costly but also less faithful. This is the sort of trade-off between different desiderata that we always need to navigate carefully in the context of counterfactual explanations. As we will see next, the same also applies to plausibility but in a different way.\n\n\nPlausible Counterfactuals\nIf you have followed the discussion so far, then you have already understood the trickiest concept in our paper. Plausibility can be defined much like we have done for faithfulness, but it is a bit more straightforward. In our paper, we broadly define plausible counterfactals as those that are indistinguishable from the observed data in the target domain. We already touched on this above when discussing the counterfactual images in Figure¬†1.\n\n\n\n\n\nFigure¬†3: KDE for the conditional distribution based on observed data. Counterfactual path as in Figure¬†2.\n\n\nFigure¬†3 illustrates the same concept for the same JEM as in Figure¬†2. The KDE in Figure¬†3 shows the conditional distribution based on the observed data. The counterfactual path is the same as in Figure¬†2. The counterfactual is plausible in this case since it is not easily distinguishable from the observed data in the target domain.\nLooking at both Figure¬†2 and Figure¬†3, it becomes evident why the interplay between faithfulness and plausibility need not necessary be a trade-off. In this case, the counterfactual is neither terribly unfaithful nor implausible. This is because the learned conditional distribution is broadly consistent with the observed distribution of the data."
  },
  {
    "objectID": "blog/posts/eccco/index.html#our-approach-eccco",
    "href": "blog/posts/eccco/index.html#our-approach-eccco",
    "title": "ECCCos from the Black Box",
    "section": "Our approach: ECCCo",
    "text": "Our approach: ECCCo\nNow that we have covered the two major concepts in our paper, we can move on to our proposed approach for generating faithful counterfactuals: ECCCo. As the title of the paper suggests, ECCCo is an acronym for Energy-Constrained Conformal Counterfactuals. We leverage ideas from energy-based modelling and conformal prediction, in particular from Grathwohl et al. (2020) and Stutz et al. (2022), respectively. Our proposed counterfactual generation process involves little to no overhead and is broadly applicable to any model that can be trained using stochastic gradient descent. Technical details can be found in the paper. For now, let us focus on the high-level idea.\nFigure¬†4 compares the counterfactual path generated by Wachter (Wachter, Mittelstadt, and Russell 2017) to those generated by ECCCo, where we use ablation to remove the energy constraint‚ÄîECCCo (no EBM)‚Äîand the conformal prediction component‚ÄîECCCo (no CP). In this case, the counterfactual generated by Wachter is neither faithful nor plausible. It does, however, minimize the distance between the counterfactual and the original input.\nThe counterfactual generated by ECCCo (no EBM) is deeper inside the blue class and has avoided points near the decision boundary on its path to its final destination. This is because ECCCo (no EBM) involves a penalty term for predictive uncertainty, which is high near the decision boundary. Intuitively, we would expect that avoiding regions of high predictive uncertainty in our counterfactual search should help with plausibility (Schut et al. 2021). In this particular case, the final counterfactual is neither more faithful nor more plausible than the one generated by Wachter, but in our experiments we have generally found that penalizing predictive uncertainty alone can help to generate more faithful and plausible counterfactuals.\nThe counterfactual generated by ECCCo (no CP) is more faithful than the one generated by Wachter and ECCCo (no EBM). This is because the energy constraint induces counterfactuals that are more consistent with the learned conditional distribution (as in Figure¬†2). Since the model has learned something meaningful about the data, the counterfactual is also more plausible than the one generated by Wachter and ECCCo (no EBM) in this case.\nThe counterfactual path generated by ECCCo combines benefits from both the energy constraint and the conformal prediction component. It avoids regions of high predictive uncertainty and ends up at a point that is consistent with the learned conditional distribution.\n\n\n\nFigure¬†4: Gradient fields and counterfactual paths for different generators."
  },
  {
    "objectID": "blog/posts/eccco/index.html#results",
    "href": "blog/posts/eccco/index.html#results",
    "title": "ECCCos from the Black Box",
    "section": "Results",
    "text": "Results\nIn the paper, we present results from extensive empirical studies involving eight datasets from different domains and a variety of models. We compare ECCCo to state-of-the-art counterfactual generators and show that it consistently outperforms these in terms of faithfulness and often achieves the highest degrees of plausibility. Here we will highlight some visual results from the MNIST dataset.\nFigure¬†5 shows counterfactuals generated using different counterfactual generators on the MNIST dataset. In this example, the goal is to generate a counterfactual in class ‚Äòfive‚Äô for the factual ‚Äòthree‚Äô. The ECCCo+ generator is a variant of ECCCo that performs gradient search in the space spanned by the first few principal components. This reduces computational costs and often helps with plausibility, sometimes at a small cost of faithfulness. The counterfactuals generated by ECCCo and ECCCo+ are visibly more plausible than those generated by the other generators. In the paper, we quantify this using custom metrics for plausibility and faithfulness that we propose.\n\n\n\nFigure¬†5: Results for different generators (from 3 to 5).\n\n\nWe also find that the counterfactuals generated by ECCCo are more faithful in this case. The underlying model is a LeNet-5 convolutional neural network (LeCun et al. 1998). Even today, convolutional neural networks are still among the most popular neural network architectures for image classification. Contrary to the simple multi-layer perceptron (MLP) used in Figure¬†1, the LeNet-5 model is a bit more complex and it is not surprising that it has distilled more meaningful representations in the data.\nMore generally, we find that ECCCo is particularly effective at producing plausible counterfactuals for models that we would expect to have learned more meaningful representations of the data. This is consistent with our claim that ECCCo generates faithful counterfactuals. Figure¬†5 shows the results for applying ECCCo to the same factual ‚Äònine‚Äô as in Figure¬†1 for different models from left to right and top to bottom: (a) an MLP, (b) a deep ensemble of MLPs, (c) a JEM, and, (d) a deep ensemble of JEMs. The plausibility of the generated counterfactual gradually improves from left to right and top to bottom as we get more rigorous about model complexity and training: deep ensembling can help to capture predictive uncertainty and joint-energy modelling is explicitly concerned with learning meaningful representations in the data.\n\n\n\n\n\nFigure¬†6: Turning a 9 into a 7. ECCCo applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).\n\n\nWe would argue that in general, this is a desirable property of a counterfactual explainer, because it helps to distinguish trustworthy from unreliable models. The generated counterfactual for the MLP in (a) in Figure¬†6 is grainy and altogether not very plausible. But this is precisely because the MLP is not very trustworthy: it is sensitive to input perturbations that are not meaningful. We think that explanations should reflect these kinds of shortcomings of models instead of hiding them."
  },
  {
    "objectID": "blog/posts/eccco/index.html#conclusion",
    "href": "blog/posts/eccco/index.html#conclusion",
    "title": "ECCCos from the Black Box",
    "section": "Conclusion",
    "text": "Conclusion\nThis post has provided a brief and accessible overview of our AAAI 2024 paper that introduces ECCCo: a new way to generate faithful model explanations through energy-constrained conformal counterfactuals. The post has covered some of the main points from the paper:\n\nWe have argued that explanations should be faithful first, and plausible second.\nWe show that ECCCo consistently outperforms state-of-the-art counterfactual generators in terms of faithfulness and often achieves the highest degrees of plausibility.\nWe believe that ECCCo opens avenues for researchers and practitioners seeking tools to better distinguish trustworthy from unreliable models."
  },
  {
    "objectID": "blog/posts/eccco/index.html#software",
    "href": "blog/posts/eccco/index.html#software",
    "title": "ECCCos from the Black Box",
    "section": "Software",
    "text": "Software\nThe code for the experiments in the paper is available on GitHub: https://github.com/pat-alt/ECCCo.jl. The repo contains job scripts for running the experiments on a SLURM cluster, as well as the source code for the ECCCo package. The package is written in Julia and built on top of CounterfactualExplanations.jl, which will eventually absorb the functionality of ECCCo."
  },
  {
    "objectID": "blog/posts/eccco/index.html#footnotes",
    "href": "blog/posts/eccco/index.html#footnotes",
    "title": "ECCCos from the Black Box",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBesides my co-authors, I also want to thank the anonymous reviewers at both NeurIPS and AAAI for their valuable feedback as well as Nico Potyka and Francesco Leofante for interesting discussions on the topic.‚Ü©Ô∏é\nConsidering how much I have cited Joshi et al. (2019) in the past, I think it should go without saying that I very much like this paper, despite taking a critical stance on it here.‚Ü©Ô∏é\nI have had an interesting chat with Nico Potyka and Francesco Leofante, recently, where they rightly pointed out that this definition of faithfulness needs to be refined. In particular, one might wonder what constitutes a ‚Äòhigh probability‚Äô in this context. I think this is a very valid point and I am looking forward to discussing this further with them.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/effortsless-bayesian-dl/index.html",
    "href": "blog/posts/effortsless-bayesian-dl/index.html",
    "title": "Go deep, but also ‚Ä¶ go Bayesian!",
    "section": "",
    "text": "A Bayesian Neural Network gradually learns.\nDeep learning has dominated AI research in recent years1 - but how much promise does it really hold? That is very much an ongoing and increasingly polarising debate that you can follow live on Twitter. On one side you have optimists like Ilya Sutskever, chief scientist of OpenAI, who believes that large deep neural networks may already be slightly conscious - that‚Äôs ‚Äúmay‚Äù and ‚Äúslightly‚Äù and only if you just go deep enough? On the other side you have prominent skeptics like Judea Pearl who has long since argued that deep learning still boils down to curve fitting - purely associational and not even remotely intelligent (Pearl and Mackenzie 2018)."
  },
  {
    "objectID": "blog/posts/effortsless-bayesian-dl/index.html#the-case-for-bayesian-deep-learning",
    "href": "blog/posts/effortsless-bayesian-dl/index.html#the-case-for-bayesian-deep-learning",
    "title": "Go deep, but also ‚Ä¶ go Bayesian!",
    "section": "The case for Bayesian Deep Learning",
    "text": "The case for Bayesian Deep Learning\nWhatever side of this entertaining twitter dispute you find yourself on, the reality is that deep-learning systems have already been deployed at large scale both in academia and industry. More pressing debates therefore revolve around the trustworthiness of these existing systems. How robust are they and in what way exactly do they arrive at decisions that affect each and every one of us? Robustifying deep neural networks generally involves some form of adversarial training, which is costly, can hurt generalization (Raghunathan et al. 2019) and does ultimately not guarantee stability (Bastounis, Hansen, and Vlaƒçiƒá 2021). With respect to interpretability, surrogate explainers like LIME and SHAP are among the most popular tools, but they too have been shown to lack robustness (Slack et al. 2020).\nExactly why are deep neural networks unstable and in-transparent? Let \\(\\mathcal{D}=\\{x,y\\}_{n=1}^N\\) denote our feature-label pairs and let \\(f(x;\\theta)=y\\) denote some deep neural network specified by its parameters \\(\\theta\\). Then the first thing to note is that the number of free parameters \\(\\theta\\) is typically huge (if you ask Mr Sutskever it really probably cannot be huge enough!). That alone makes it very hard to monitor and interpret the inner workings of deep-learning algorithms. Perhaps more importantly though, the number of parameters relative to the size of \\(\\mathcal{D}\\) is generally huge:\n\n[‚Ä¶] deep neural networks are typically very underspecified by the available data, and [‚Ä¶] parameters [therefore] correspond to a diverse variety of compelling explanations for the data. (Wilson 2020)\n\nIn other words, training a single deep neural network may (and usually does) lead to one random parameter specification that fits the underlying data very well. But in all likelihood there are many other specifications that also fit the data very well. This is both a strength and vulnerability of deep learning: it is a strength because it typically allows us to find one such ‚Äúcompelling explanation‚Äù for the data with ease through stochastic optimization; it is a vulnerability because one has to wonder:\n\nHow compelling is an explanation really if it competes with many other equally compelling, but potentially very different explanations?\n\nA scenario like this very much calls for treating predictions from deep learning models probabilistically [Wilson (2020)]23.\nFormally, we are interested in estimating the posterior predictive distribution as the following Bayesian model average (BMA):\n\\[\np(y|x,\\mathcal{D}) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D})d\\theta\n\\]\nThe integral implies that we essentially need many predictions from many different specifications of \\(\\theta\\). Unfortunately, this means more work for us or rather our computers. Fortunately though, researchers have proposed many ingenious ways to approximate the equation above in recent years: Gal and Ghahramani (2016) propose using dropout at test time while Lakshminarayanan, Pritzel, and Blundell (2017) show that averaging over an ensemble of just five models seems to do the trick. Still, despite their simplicity and usefulness these approaches involve additional computational costs compared to training just a single network. As we shall see now though, another promising approach has recently entered the limelight: Laplace approximation (LA).\nIf you have read my previous post on Bayesian Logistic Regression, then the term Laplace should already sound familiar to you. As a matter of fact, we will see that all concepts covered in that previous post can be naturally extended to deep learning. While some of these concepts will be revisited below, I strongly recommend you check out the previous post before reading on here. Without further ado let us now see how LA can be used for truly effortless deep learning."
  },
  {
    "objectID": "blog/posts/effortsless-bayesian-dl/index.html#laplace-approximation",
    "href": "blog/posts/effortsless-bayesian-dl/index.html#laplace-approximation",
    "title": "Go deep, but also ‚Ä¶ go Bayesian!",
    "section": "Laplace Approximation",
    "text": "Laplace Approximation\nWhile LA was first proposed in the 18th century, it has so far not attracted serious attention from the deep learning community largely because it involves a possibly large Hessian computation. Daxberger et al. (2021) are on a mission to change the perception that LA has no use in DL: in their NeurIPS 2021 paper they demonstrate empirically that LA can be used to produce Bayesian model averages that are at least at par with existing approaches in terms of uncertainty quantification and out-of-distribution detection and significantly cheaper to compute. They show that recent advancements in autodifferentation can be leveraged to produce fast and accurate approximations of the Hessian and even provide a fully-fledged Python library that can be used with any pretrained Torch model. For this post, I have built a much less comprehensive, pure-play equivalent of their package in Julia - LaplaceRedux.jl can be used with deep learning models built in Flux.jl, which is Julia‚Äôs main DL library. As in the previous post on Bayesian logistic regression I will rely on Julia code snippits instead of equations to convey the underlying maths. If you‚Äôre curious about the maths, the NeurIPS 2021 paper provides all the detail you need.\n\nFrom Bayesian Logistic Regression ‚Ä¶\nLet‚Äôs recap: in the case of logistic regression we had a assumed a zero-mean Gaussian prior \\(p(\\mathbf{w}) \\sim \\mathcal{N} \\left( \\mathbf{w} | \\mathbf{0}, \\sigma_0^2 \\mathbf{I} \\right)=\\mathcal{N} \\left( \\mathbf{w} | \\mathbf{0}, \\mathbf{H}_0^{-1} \\right)\\) for the weights that are used to compute logits \\(\\mu_n=\\mathbf{w}^T\\mathbf{x}_n\\), which in turn are fed to a sigmoid function to produce probabilities \\(p(y_n=1)=\\sigma(\\mu_n)\\). We saw that under this assumption solving the logistic regression problem corresponds to minimizing the following differentiable loss function:\n\\[\n\\ell(\\mathbf{w})= - \\sum_{n}^N [y_n \\log \\mu_n + (1-y_n)\\log (1-\\mu_n)] + \\\\ \\frac{1}{2} (\\mathbf{w}-\\mathbf{w}_0)^T\\mathbf{H}_0(\\mathbf{w}-\\mathbf{w}_0)\n\\]\nAs our first step towards Bayesian deep learning, we observe the following: the loss function above corresponds to the objective faced by a single-layer artificial neural network with sigmoid activation and weight decay4. In other words, regularized logistic regression is equivalent to a very simple neural network architecture and hence it is not surprising that underlying concepts can in theory be applied in much the same way.\nSo let‚Äôs quickly recap the next core concept: LA relies on the fact that the second-order Taylor expansion of our loss function \\(\\ell\\) evaluated at the maximum a posteriori (MAP) estimate \\(\\mathbf{\\hat{w}}=\\arg\\max_{\\mathbf{w}} p(\\mathbf{w}|\\mathcal{D})\\) amounts to a multi-variate Gaussian distribution. In particular, that Gaussian is centered around the MAP estimate with covariance equal to the inverse Hessian evaluated at the mode \\(\\hat{\\Sigma}=(\\mathbf{H}(\\mathbf{\\hat{w}}))^{-1}\\) (Murphy 2022).\nThat is basically all there is to the story: if we have a good estimate of \\(\\mathbf{H}(\\mathbf{\\hat{w}})\\) we have an analytical expression for an (approximate) posterior over parameters. So let‚Äôs go ahead and start by run Bayesian Logistic regression using Flux.jl. We begin by loading some required packages including LaplaceRedux.jl. It ships with a helper function toy_data_linear that creates a toy data set composed of linearly separable samples evenly balanced across the two classes.\n\n\nCode\n# Import libraries.\nusing Flux, Plots, Random, PlotThemes, Statistics, LaplaceRedux\ntheme(:wong)\n# Number of points to generate.\nxs, y = toy_data_linear(100)\nX = hcat(xs...); # bring into tabular format\ndata = zip(xs,y);\n\n\nThen we proceed to prepare the single-layer neural network with weight decay. The term \\(\\lambda\\) determines the strength of the \\(\\ell2\\) penalty: we regularize parameters \\(\\theta\\) more heavily for higher values. Equivalently, we can say that from the Bayesian perspective it governs the strength of the prior \\(p(\\theta) \\sim \\mathcal{N} \\left( \\theta | \\mathbf{0}, \\sigma_0^2 \\mathbf{I} \\right)= \\mathcal{N} \\left( \\mathbf{w} | \\mathbf{0}, \\lambda_0^{-2} \\mathbf{I} \\right)\\): a higher value of \\(\\lambda\\) indicates a higher conviction about our prior belief that \\(\\theta=\\mathbf{0}\\), which is of course equivalent to regularizing more heavily. The exact choice of \\(\\lambda=0.5\\) for this toy example is somewhat arbitrary (it made for good visualizations below). Note that I have used \\(\\theta\\) to denote our neural parameters to distinguish the case from Bayesian logistic regression, but we are in fact still solving the same problem.\n\n\nCode\nnn = Chain(Dense(2,1))\nŒª = 0.5\nsqnorm(x) = sum(abs2, x)\nweight_regularization(Œª=Œª) = 1/2 * Œª^2 * sum(sqnorm, Flux.params(nn))\nloss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y) + weight_regularization();\n\n\nBefore we apply Laplace approximation we train our model:\n\n\nCode\nusing Flux.Optimise: update!, ADAM\nopt = ADAM()\nepochs = 50\n\nfor epoch = 1:epochs\n  for d in data\n    gs = gradient(params(nn)) do\n      l = loss(d...)\n    end\n    update!(opt, params(nn), gs)\n  end\nend\n\n\nUp until this point we have just followed the standard recipe for training a regularized artificial neural network in Flux.jl for a simple binary classification task. To compute the Laplace approximation using LaplaceRedux.jl we need just two more lines of code:\n\n\nCode\nla = laplace(nn, Œª=Œª)\nfit!(la, data);\n\n\nUnder the hood the Hessian is approximated through the empirical Fisher, which can be computed using only the gradients of our loss function \\(\\nabla_{\\theta}\\ell(f(\\mathbf{x}_n;\\theta,y_n))\\) where \\(\\{\\mathbf{x}_n,y_n\\}\\) are training data (see NeurIPS 2021 paper for details). Finally, LaplaceRedux.jl ships with a function predict(ùë≥::LaplaceRedux, X::AbstractArray; link_approx=:probit) that computes the posterior predictive using a probit approximation, much like we saw in the previous post. That function is used under the hood of the plot_contour function below to create the right panel of Figure¬†1. It visualizes the posterior predictive distribution in the 2D feature space. For comparison I have added the corresponding plugin estimate as well. Note how for the Laplace approximation the predicted probabilities fan out indicating that confidence decreases in regions scarce of data.\n\n\nCode\np_plugin = plot_contour(X',y,la;title=\"Plugin\",type=:plugin);\np_laplace = plot_contour(X',y,la;title=\"Laplace\")\n# Plot the posterior distribution with a contour plot.\nplt = plot(p_plugin, p_laplace, layout=(1,2), size=(1000,400))\nsavefig(plt, \"www/posterior_predictive_logit.png\");\n\n\n\n\n\nFigure¬†1: Posterior predictive distribution of Logistic regression in the 2D feature space using plugin estimator (left) and Laplace approximation (right).\n\n\n\n\n‚Ä¶ to Bayesian Neural Networks\nNow let‚Äôs step it up a notch: we will repeat the exercise from above, but this time for data that is not linearly separable using a simple MLP instead of the single-layer neural network we used above. The code below is almost the same as above, so I will not go through the various steps again.\n\n\nCode\n# Number of points to generate:\nxs, y = toy_data_non_linear(200)\nX = hcat(xs...); # bring into tabular format\ndata = zip(xs,y)\n\n# Build MLP:\nn_hidden = 32\nD = size(X)[1]\nnn = Chain(\n    Dense(D, n_hidden, œÉ),\n    Dense(n_hidden, 1)\n)  \nŒª = 0.01\nsqnorm(x) = sum(abs2, x)\nweight_regularization(Œª=Œª) = 1/2 * Œª^2 * sum(sqnorm, Flux.params(nn))\nloss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y) + weight_regularization()\n\n# Training:\nepochs = 200\nfor epoch = 1:epochs\n  for d in data\n    gs = gradient(params(nn)) do\n      l = loss(d...)\n    end\n    update!(opt, params(nn), gs)\n  end\nend\n\n\nFitting the Laplace approximation is also analogous, but note that this we have added an argument: subset_of_weights=:last_layer. This specifies that we only want to use the parameters of the last layer of our MLP. While we could have used all of them (subset_of_weights=:all), Daxberger et al. (2021) find that the last-layer Laplace approximation produces satisfying results, while be computationally cheaper. Figure¬†2 demonstrates that once again the Laplace approximation yields a posterior predictive distribution that is more conservative than the over-confident plugin estimate.\n\n\nCode\nla = laplace(nn, Œª=Œª, subset_of_weights=:last_layer)\nfit!(la, data);\np_plugin = plot_contour(X',y,la;title=\"Plugin\",type=:plugin)\np_laplace = plot_contour(X',y,la;title=\"Laplace\")\n# Plot the posterior distribution with a contour plot.\nplt = plot(p_plugin, p_laplace, layout=(1,2), size=(1000,400))\nsavefig(plt, \"www/posterior_predictive_mlp.png\");\n\n\n\n\n\nFigure¬†2: Posterior predictive distribution of MLP in the 2D feature space using plugin estimator (left) and Laplace approximation (right).\n\n\nTo see why this is a desirable outcome consider the zoomed out version of Figure¬†2 below: the plugin estimator classifies with full confidence in regions completely scarce of any data. Arguably Laplace approximation produces a much more reasonable picture, even though it too could likely be improved by fine-tuning our choice of \\(\\lambda\\) and the neural network architecture.\n\n\nCode\nzoom=-50\np_plugin = plot_contour(X',y,la;title=\"Plugin\",type=:plugin,zoom=zoom);\np_laplace = plot_contour(X',y,la;title=\"Laplace\",zoom=zoom);\n# Plot the posterior distribution with a contour plot.\nplt = plot(p_plugin, p_laplace, layout=(1,2), size=(1000,400));\nsavefig(plt, \"www/posterior_predictive_mlp_zoom.png\");\n\n\n\n\n\nFigure¬†3: Posterior predictive distribution of MLP in the 2D feature space using plugin estimator (left) and Laplace approximation (right). Zoomed out."
  },
  {
    "objectID": "blog/posts/effortsless-bayesian-dl/index.html#wrapping-up",
    "href": "blog/posts/effortsless-bayesian-dl/index.html#wrapping-up",
    "title": "Go deep, but also ‚Ä¶ go Bayesian!",
    "section": "Wrapping up",
    "text": "Wrapping up\nRecent state-of-the-art research on neural information processing suggests that Bayesian deep learning can be effortless: Laplace approximation for deep neural networks appears to work very well and it does so at minimal computational cost (Daxberger et al. 2021). This is great news, because the case for turning Bayesian is strong: society increasingly relies on complex automated decision-making systems that need to be trustworthy. More and more of these systems involve deep learning which in and of itself is not trustworthy. We have seen that typically there exist various viable parameterizations of deep neural networks each with their own distinct and compelling explanation for the data at hand. When faced with many viable options, don‚Äôt put all of your eggs in one basket. In other words, go Bayesian!"
  },
  {
    "objectID": "blog/posts/effortsless-bayesian-dl/index.html#resources",
    "href": "blog/posts/effortsless-bayesian-dl/index.html#resources",
    "title": "Go deep, but also ‚Ä¶ go Bayesian!",
    "section": "Resources",
    "text": "Resources\nTo get started with Bayesian deep learning I have found many useful and free resources online, some of which are listed below:\n\nTuring.jl tutorial on Bayesian deep learning in Julia.\nVarious RStudio AI blog posts including this one and this one.\nTensorFlow blog post on regression with probabilistic layers.\nKevin Murphy‚Äôs draft text book, now also available as print."
  },
  {
    "objectID": "blog/posts/effortsless-bayesian-dl/index.html#footnotes",
    "href": "blog/posts/effortsless-bayesian-dl/index.html#footnotes",
    "title": "Go deep, but also ‚Ä¶ go Bayesian!",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee for example this article in the MIT Technology Review‚Ü©Ô∏é\nIn fact, not treating probabilistic deep learning models as such is sheer madness because remember that the underlying parameters \\(\\theta\\) are random variables. Frequentists and Bayesians alike will tell you that relying on a single point estimate of random variables is just nuts!‚Ü©Ô∏é\nProponents of Causal AI like Judea Pearl would argue that the Bayesian treatment still does not go far enough: in their view model explanations can only be truly compelling if they are causally found.‚Ü©Ô∏é\nSee this answer on Stack Exchange for a detailed discussion.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html",
    "href": "blog/posts/bayesian-logit/index.html",
    "title": "Bayesian Logistic Regression",
    "section": "",
    "text": "Simulation of changing parameter distribution.\n\n\n\nIf you‚Äôve ever searched for evaluation metrics to assess model accuracy, chances are that you found many different options to choose from (too many?). Accuracy is in some sense the holy grail of prediction so it‚Äôs not at all surprising that the machine learning community spends a lot time thinking about it. In a world where more and more high-stake decisions are being automated, model accuracy is in fact a very valid concern.\nBut does this recipe for model evaluation seem like a sound and complete approach to automated decision-making? Haven‚Äôt we forgot anything? Some would argue that we need to pay more attention to model uncertainty. No matter how many times you have cross-validated your model, the loss metric that it is being optimized against as well as its parameters and predictions remain inherently random variables. Focusing merely on prediction accuracy and ignoring uncertainty altogether can install a false level of confidence in automated decision-making systems. Any trustworthy approach to learning from data should therefore at the very least be transparent about its own uncertainty.\nHow can we estimate uncertainty around model parameters and predictions? Frequentist methods for uncertainty quantification generally involve either closed-form solutions based on asymptotic theory or bootstrapping (see for example here for the case of logistic regression). In Bayesian statistics and machine learning we are instead concerned with modelling the posterior distribution over model parameters. This approach to uncertainty quantification is known as Bayesian Inference because we treat model parameters in a Bayesian way: we make assumptions about their distribution based on prior knowledge or beliefs and update these beliefs in light of new evidence. The frequentist approach avoids the need for being explicit about prior beliefs, which in the past has sometimes been considered as unscientific. However, frequentist methods come with their own assumptions and pitfalls (see for example Murphy (2012)) for a discussion). Without diving further into this argument, let us now see how Bayesian Logistic Regression can be implemented from the bottom up."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#uncertainty",
    "href": "blog/posts/bayesian-logit/index.html#uncertainty",
    "title": "Bayesian Logistic Regression",
    "section": "",
    "text": "Simulation of changing parameter distribution.\n\n\n\nIf you‚Äôve ever searched for evaluation metrics to assess model accuracy, chances are that you found many different options to choose from (too many?). Accuracy is in some sense the holy grail of prediction so it‚Äôs not at all surprising that the machine learning community spends a lot time thinking about it. In a world where more and more high-stake decisions are being automated, model accuracy is in fact a very valid concern.\nBut does this recipe for model evaluation seem like a sound and complete approach to automated decision-making? Haven‚Äôt we forgot anything? Some would argue that we need to pay more attention to model uncertainty. No matter how many times you have cross-validated your model, the loss metric that it is being optimized against as well as its parameters and predictions remain inherently random variables. Focusing merely on prediction accuracy and ignoring uncertainty altogether can install a false level of confidence in automated decision-making systems. Any trustworthy approach to learning from data should therefore at the very least be transparent about its own uncertainty.\nHow can we estimate uncertainty around model parameters and predictions? Frequentist methods for uncertainty quantification generally involve either closed-form solutions based on asymptotic theory or bootstrapping (see for example here for the case of logistic regression). In Bayesian statistics and machine learning we are instead concerned with modelling the posterior distribution over model parameters. This approach to uncertainty quantification is known as Bayesian Inference because we treat model parameters in a Bayesian way: we make assumptions about their distribution based on prior knowledge or beliefs and update these beliefs in light of new evidence. The frequentist approach avoids the need for being explicit about prior beliefs, which in the past has sometimes been considered as unscientific. However, frequentist methods come with their own assumptions and pitfalls (see for example Murphy (2012)) for a discussion). Without diving further into this argument, let us now see how Bayesian Logistic Regression can be implemented from the bottom up."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#the-ground-truth",
    "href": "blog/posts/bayesian-logit/index.html#the-ground-truth",
    "title": "Bayesian Logistic Regression",
    "section": "The ground truth",
    "text": "The ground truth\nIn this post we will work with a synthetic toy data set \\(\\mathcal{D}\\) composed of \\(N\\) binary labels \\(y_n\\in\\{0,1\\}\\) and corresponding feature vectors \\(\\mathbf{x}_n\\in \\mathbb{R}^D\\). Working with synthetic data has the benefit that we have control over the ground truth that generates our data. In particular, we will assume that the binary labels \\(y_n\\) are generated by a logistic regression model\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& p(y_n|\\mathbf{x}_n;\\mathbf{w})&\\sim\\text{Ber}(y_n|\\sigma(\\mathbf{w}^T\\mathbf{x}_n)) \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{1}\\]\nwhere \\(\\sigma(a)=1/(1+e^{-a})\\) is the sigmoid or logit function (Murphy 2022).1 Features are generated from a mixed Gaussian model.\nTo add a little bit of life to our example we will assume that the binary labels classify samples into cats and dogs, based on their height and tail length. Figure¬†1 shows the synthetic data in the two-dimensional feature domain. Following an introduction to Bayesian Logistic Regression in the next section we will use the synthetic data \\(\\mathcal{D}\\) to estimate our model.\n\n\n\n\n\nFigure¬†1: Ground truth labels."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#the-maths",
    "href": "blog/posts/bayesian-logit/index.html#the-maths",
    "title": "Bayesian Logistic Regression",
    "section": "The maths",
    "text": "The maths\nEstimation usually boils down to finding the vector of parameters \\(\\hat{\\mathbf{w}}\\) that maximizes the likelihood of observing \\(\\mathcal{D}\\) under the assumed model. That estimate can then be used to compute predictions for some new unlabelled data set \\(\\mathcal{D}=\\{x_m:m=1,...,M\\}\\).\n\nProblem setup\nThe starting point for Bayesian Logistic Regression is Bayes‚Äô Theorem:\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& p(\\mathbf{w}|\\mathcal{D})&\\propto p(\\mathcal{D}|\\mathbf{w})p(\\mathbf{w}) \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{2}\\]\nFormally, this says that the posterior distribution of parameters \\(\\mathbf{w}\\) is proportional to the product of the likelihood of observing \\(\\mathcal{D}\\) given \\(\\mathbf{w}\\) and the prior density of \\(\\mathbf{w}\\). Applied to our context this can intuitively be understood as follows: our posterior beliefs around \\(\\mathbf{w}\\) are formed by both our prior beliefs and the evidence we observe. Yet another way to look at this is that maximising Equation¬†2 with respect to \\(\\mathbf{w}\\) corresponds to maximum likelihood estimation regularized by prior beliefs (we will come back to this).\nUnder the assumption that individual label-feature pairs are independently and identically distributed, their joint likelihood is simply the product over their individual densities. The prior beliefs around \\(\\mathbf{w}\\) are at our discretion. In practice they may be derived from previous experiments. Here we will use a zero-mean spherical Gaussian prior for reasons explained further below. To sum this up we have\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& p(\\mathcal{D}|\\mathbf{w})& \\sim \\prod_{n=1}^N p(y_n|\\mathbf{x}_n;\\mathbf{w})\\\\\n&& p(\\mathbf{w})& \\sim \\mathcal{N} \\left( \\mathbf{w} | \\mathbf{w}_0, \\Sigma_0 \\right) \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{3}\\]\nwith \\(\\mathbf{w}_0=\\mathbf{0}\\) and \\(\\Sigma_0=\\sigma^2\\mathbf{I}\\). Plugging this into Bayes‚Äô rule we finally have\n\\[\n\\begin{aligned}\n&& p(\\mathbf{w}|\\mathcal{D})&\\propto\\prod_{n=1}^N \\text{Ber}(y_n|\\sigma(\\mathbf{w}^T\\mathbf{x}_n))\\mathcal{N} \\left( \\mathbf{w} | \\mathbf{w}_0, \\Sigma_0 \\right) \\\\\n\\end{aligned}\n\\]\nUnlike with linear regression there are no closed-form analytical solutions to estimating or maximising this posterior, but fortunately accurate approximations do exist (Murphy 2022). One of the simplest approaches called Laplace Approximation is straight-forward to implement and computationally very efficient. It relies on the observation that under the assumption of a Gaussian prior, the posterior of logistic regression is also approximately Gaussian: in particular, this Gaussian distribution is centered around the maximum a posteriori (MAP) estimate \\(\\hat{\\mathbf{w}}=\\arg\\max_{\\mathbf{w}} p(\\mathbf{w}|\\mathcal{D})\\) with a covariance matrix equal to the inverse Hessian evaluated at the mode \\(\\hat{\\Sigma}=(\\mathbf{H}(\\hat{\\mathbf{w}}))^{-1}\\). With that in mind, finding \\(\\hat{\\mathbf{w}}\\) seems like a natural next step.\n\n\nSolving the problem\nIn practice we do not maximize the posterior \\(p(\\mathbf{w}|\\mathcal{D})\\) directly. Instead we minimize the negative log likelihood, which is an equivalent optimization problem and easier to implement. In Equation¬†4 below I have denoted the negative log likelihood as \\(\\ell(\\mathbf{w})\\) indicating that this is the loss function we aim to minimize. The following two lines in Equation¬†4 show the gradient and Hessian - so the first- and second-order derivatives of \\(\\ell\\) with respect to \\(\\mathbf{w}\\) - where \\(\\mathbf{H}_0=\\Sigma_0^{-1}\\) and \\(\\mu_n=\\sigma(\\mathbf{w}^T\\mathbf{x}_n)\\). To understand how exactly the gradient and Hessian are derived see for example chapter 10 in Murphy (2022).2.\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& \\ell(\\mathbf{w})&=- \\sum_{n=1}^{N} [y_n \\log \\mu_n + (1-y_n)\\log (1-\\mu_n)] + \\frac{1}{2} (\\mathbf{w}-\\mathbf{w}_0)^T\\mathbf{H}_0(\\mathbf{w}-\\mathbf{w}_0) \\\\\n&& \\nabla_{\\mathbf{w}}\\ell(\\mathbf{w})&= \\sum_{n=1}^{N} (\\mu_n-y_n) \\mathbf{x}_n + \\mathbf{H}_0(\\mathbf{w}-\\mathbf{w}_0) \\\\\n&& \\nabla^2_{\\mathbf{w}}\\ell(\\mathbf{w})&= \\sum_{n=1}^{N} (\\mu_n-y_n) \\left( \\mu_n(1-\\mu_n) \\mathbf{x}_n \\mathbf{x}_n^T \\right) + \\mathbf{H}_0\\\\\n\\end{aligned}\n\\end{equation}\n\\tag{4}\\]\n\nSIDENOTE üí°\nNote how earlier I mentioned that maximising the posterior likelihood can be seen as regularized maximum likelihood estimation. We can now make that connection explicit: in Equation¬†4 let us assume that \\(\\mathbf{w}_0=\\mathbf{0}\\). Then since \\(\\mathbf{H}_0=\\lambda\\mathbf{I}\\) with \\(1/\\sigma^2\\) the second term in the first line is simply \\(\\lambda \\frac{1}{2} \\mathbf{w}^T\\mathbf{w}=\\lambda \\frac{1}{2} ||\\mathbf{w}||_2^2\\). This is equivalent to running logistic regression with an \\(\\ell_2\\)-penalty (Bishop 2006).\n\n\nSince minimizing the loss function in Equation¬†4 is a convex optimization problem we have many efficient algorithms to choose from in order to solve this problem. With the Hessian at hand it seems natural to use a second-order method, because incorporating information about the curvature of the loss function generally leads to faster convergence. Here we will implement Newton‚Äôs method in line with the presentation in chapter 8 of Murphy (2022).\n\n\nPosterior predictive\nSuppose now that we have trained the Bayesian Logistic Regression model as our binary classifier \\(g_N(\\mathbf{x})\\) using our training data \\(\\mathcal{D}\\). A new unlabelled sample \\((\\mathbf{x}_{N+1},?)\\) arrives. As with any binary classifier we can predict the missing label by simply plugging the new sample into our classifier \\(\\hat{y}_{N+1}=g_N(\\mathbf{x}_{N+1})=\\sigma(\\hat{\\mathbf{w}}^T\\mathbf{x}_{N+1})\\), where \\(\\hat{\\mathbf{w}}\\) is the MAP estimate as before. If at training phase we have found \\(g_N(\\mathbf{x})\\) to achieve good accuracy, we may expect \\((\\mathbf{x}_{N+1},\\hat{y}_{N+1})\\) to be a reasonably good approximation of the true and unobserved pair \\((\\mathbf{x}_{N+1},y_{N+1})\\). But since we are still dealing with an expected value of a random variable, we would generally like to have an idea of how noisy this prediction is.\nFormally, we are interested in the posterior predictive distribution:\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& p(y=1|\\mathbf{x}, \\mathcal{D})&= \\int \\sigma(\\mathbf{w}^T \\mathbf{x})p(\\mathbf{w}|\\mathcal{D})d\\mathbf{w} \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{5}\\]\n\nSIDENOTE üí°\nThe approach that ignores uncertainty altogether corresponds to what is referred to as plugin approximation of the posterior predictive. Formally, it imposes \\(p(y=1|\\mathbf{x}, \\mathcal{D})\\approx p(y=1|\\mathbf{x}, \\hat{\\mathbf{w}})\\).\n\n\nWith the posterior distribution over model parameters \\(p(\\mathbf{w}|\\mathcal{D})\\) at hand we have the necessary ingredients to estimate the posterior predictive distribution \\(p(y=1|\\mathbf{x}, \\mathcal{D})\\).\nAn obvious, but computationally expensive way to estimate it is through Monte Carlo: draw \\(\\mathbf{w}_s\\) from \\(p(\\mathbf{w}|\\mathcal{D})\\) for \\(s=1:S\\) and compute fitted values \\(\\sigma(\\mathbf{w_s}^T\\mathbf{x})\\) each. Then the posterior predictive distribution corresponds to the average over all fitted values, \\(p(y=1|\\mathbf{x}, \\mathcal{D})=1/S \\sum_{s=1}^{S}\\sigma(\\mathbf{w_s}^T\\mathbf{x})\\). By the law of large numbers the Monte Carlo estimate is an accurate estimate of the true posterior predictive for large enough \\(S\\). Of course, ‚Äúlarge enough‚Äù is somewhat loosely defined here and depending on the problem can mean ‚Äúvery large‚Äù. Consequently, the computational costs involved essentially know no upper bound.\nFortunately, it turns out that we can trade off a little bit of accuracy in return for a convenient analytical solution. In particular, we have that \\(\\sigma(a) \\approx \\Phi(\\lambda a)\\) where \\(\\Phi(.)\\) is the standard Gaussian cdf and \\(\\lambda=\\pi/8\\) ensures that the two functions have the same slope at the origin (Figure¬†2). Without dwelling further on the details we can use this finding to approximate the integral in Equation¬†5 as a sigmoid function. This is called probit approximation and implemented below.\n\n\n\n\n\nFigure¬†2: Demonstration of the probit approximation."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#the-code",
    "href": "blog/posts/bayesian-logit/index.html#the-code",
    "title": "Bayesian Logistic Regression",
    "section": "The code",
    "text": "The code\nWe now have all the necessary ingredients to code Bayesian Logistic Regression up from scratch. While in practice we would usually want to rely on existing packages that have been properly tested, I often find it very educative and rewarding to program algorithms from the bottom up. You will see that Julia‚Äôs syntax so closely resembles the mathematical formulas we have seen above, that going from maths to code is incredibly easy. Seeing those formulas and algorithms then actually doing their magic is quite fun! The code chunk below, for example, shows the implementation of the loss function and its derivatives from Equation¬†4 above. Take a moment to go through the code line-by-line and try to understand how it relates back to the equations in Equation¬†4. Isn‚Äôt it amazing how closely the code resembles the actual equations?\n\nAside from the optimization routine this is essentially all there is to coding up Bayesian Logistic Regression from scratch in Julia Language. If you are curious to see the full source code in detail you can check out this interactive notebook. Now let us finally turn back to our synthetic data and see how Bayesian Logistic Regression can help us understand the uncertainty around our model predictions.\n\nDISCLAIMER ‚ùóÔ∏è\nI should mention that this is the first time I program in Julia, so for any Julia pros out there: please bear with me! Happy to hear your suggestions/comments."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#the-estimates",
    "href": "blog/posts/bayesian-logit/index.html#the-estimates",
    "title": "Bayesian Logistic Regression",
    "section": "The estimates",
    "text": "The estimates\nFigure¬†3 below shows the resulting posterior distribution for \\(w_2\\) and \\(w_3\\) at varying degrees of prior uncertainty \\(\\sigma\\). The constant \\(w_1\\) is held constant at the mode (\\(\\hat{w}_1\\)). The red dot indicates the MLE. Note how for the choice of \\(\\sigma\\rightarrow 0\\) the posterior is equal to the prior. This is intuitive since we have imposed that we have no uncertainty around our prior beliefs and hence no amount of new evidence can move us in any direction. Conversely, for \\(\\sigma \\rightarrow \\infty\\) the posterior distribution is centered around the unconstrained MLE: prior knowledge is very uncertain and hence the posterior is dominated by the likelihood of the data.\n\n\n\nFigure¬†3: Posterior distribution for \\(w_2\\) and \\(w_3\\) at varying degrees of prior uncertainty \\(\\sigma\\).\n\n\nWhat about the posterior predictive? The story is similar: since for \\(\\sigma\\rightarrow 0\\) the posterior is completely dominated by the zero-mean prior we have \\(p(y=1|\\mathbf{x},\\hat{\\mathbf{w}})=0.5\\) everywhere (top left panel in Figure¬†4. As we gradually increase uncertainty around our prior the predictive posterior depends more and more on the data \\(\\mathcal{D}\\): uncertainty around predicted labels is high only in regions that are not populated by samples \\((y_n, \\mathbf{x}_n)\\). Not surprisingly, this effect is strongest for the MLE (\\(\\sigma\\rightarrow \\infty\\)) where we see some evidence of overfitting.\n\n\n\nFigure¬†4: Predictive posterior distribution at varying degrees of prior uncertainty \\(\\sigma\\)."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#wrapping-up",
    "href": "blog/posts/bayesian-logit/index.html#wrapping-up",
    "title": "Bayesian Logistic Regression",
    "section": "Wrapping up",
    "text": "Wrapping up\nIn this post we have seen how Bayesian Logistic Regression can be implemented from scratch in Julia language. The estimated posterior distribution over model parameters can be used to quantify uncertainty around coefficients and model predictions. I have argued that it is important to be transparent about model uncertainty to avoid being overly confident in estimates.\nThere are many more benefits associated with Bayesian (probabilistic) machine learning. Understanding where in the input domain our model exerts high uncertainty can for example be instrumental in labelling data: see for example Gal, Islam, and Ghahramani (2017) and follow-up works for an interesting application to active learning for image data. Similarly, there is a recent work that uses estimates of the posterior predictive in the context of algorithmic recourse (Schut et al. 2021). For a brief introduction to algorithmic recourse see one of my previous posts.\nAs a great reference for further reading about probabilistic machine learning I can highly recommend Murphy (2022). An electronic version of the book is currently freely available as a draft. Finally, remember that if you want to try yourself at the code, you can check out this interactive notebook."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#references",
    "href": "blog/posts/bayesian-logit/index.html#references",
    "title": "Bayesian Logistic Regression",
    "section": "References",
    "text": "References\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. springer.\n\n\nGal, Yarin, Riashat Islam, and Zoubin Ghahramani. 2017. ‚ÄúDeep Bayesian Active Learning with Image Data.‚Äù In International Conference on Machine Learning, 1183‚Äì92. PMLR.\n\n\nMurphy, Kevin P. 2012. Machine Learning: A Probabilistic Perspective. MIT press.\n\n\n‚Äî‚Äî‚Äî. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#footnotes",
    "href": "blog/posts/bayesian-logit/index.html#footnotes",
    "title": "Bayesian Logistic Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe let \\(\\mathbf{w}=(10, 0.75, -2.5)^T\\) define the true coefficients.‚Ü©Ô∏é\nNote that the author works with the negative log likelihood scaled by the sample size‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html",
    "title": "A year of using Quarto with Julia",
    "section": "",
    "text": "A year of using Quarto with Julia.\nEarlier this year in July, I gave a short Experience Talk at JuliaCon. In a related blog post I explained how the introduction of Quarto made my transition from R to Julia painless: I would be able to start learning Julia without having to give up on all the benefits associated with R Markdown.\nIn November, 2022, I am presenting on this topic again at the 2nd JuliaLang Eindhoven meetup. In addition to the slides, I thought I‚Äôd share a small companion blog post that highlights some useful tips and tricks for anyone interested in using Quarto with Julia."
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#general-things",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#general-things",
    "title": "A year of using Quarto with Julia",
    "section": "General things",
    "text": "General things\nWe will start in this section with a few general recommendations.\n\nSetup\nI continue to recommend using VSCode for any work with Quarto and Julia. The Quarto docs explain how to get started by installing the necessary Quarto and IJulia extensions. Since most Julia users will regularly want to update their Julia version, I would additionally recommend to add IJulia.jl to your ~/.julia/config/startup.jl file:1\n# Setup OhMyREPL, Revise and Term\nimport Pkg\nlet\n    pkgs = [\"Revise\", \"OhMyREPL\", \"Term\", \"IJulia\"]\n    for pkg in pkgs\n        if Base.find_package(pkg) === nothing\n            Pkg.add(pkg)\n        end\n    end\nend\nAdditionally, you only need to remember that ‚Ä¶\n\n‚Ä¶ if you install a new Julia binary [‚Ä¶], you must update the IJulia installation [‚Ä¶] by running Pkg.build(\"IJulia\")\n‚Äî Source: IJulia docs\n\nI guess this step can also be automated in ~/.julia/config/startup.jl, but haven‚Äôt tried that yet.\n\n\nUsing .ipynb vs .qmd\nI also continue to recommend working with Quarto notebooks as opposed to Jupyter notebooks (files ending in .qmd and .ipynb, respectively). This is partially just based on preference (from R Markdown I‚Äôm used to working with .Rmd files), but there is also a good reason to consider using .qmd, even if you‚Äôre used to working with Jupyter: the code chunks in your Quarto notebook automatically link to the Julia REPL in VSCode. In other words, you can run code chunks in your notebook and then access any variable that you may have created in the REPL. I find this quite useful, cause it allows me to quickly test code. Perhaps there‚Äôs a good way to do this with Jupyter notebooks as well, but when I last used them I would always have to insert new code cells to test stuff.\nEither way switching between Jupyter and Quarto notebooks is straight-forward: quarto convert notebook.qmd will convert any Quarto notebook into a Jupyter notebook and vice versa. One potential benefit of Jupyter notebooks is their connection to Google Colab: it is possible to store Jupyter notebooks on Github and make them available on Colab, allowing users to quickly interact with your code without the need to clone anything. If this is important to you, you can still work with .qmd documents and simply specify keep-ipynb: true in the YAML header.\n\n\nDynamic Content\n\nThe world and the data that describes it is not static üìà. Why should scientific outputs be?\n\nOne of the things I have always really loved about R Markdown was the ability to use inline code: the Knitr engine allows you to call and render any object x that you have created in preceding R chunks like this: r x. This is very powerful, because it enables us to bridge the gap between computations and output. In other words, it allows us to easily produce reproducible and dynamic content.\nUntil recently I had not been aware that this is also possible for Julia. Consider the following example. The code below depends on remote data that is continuously updated:\n\n\nCode\nusing MarketData\nsnp = yahoo(\"^GSPC\")\n\nusing Dates\nlast_trade_day = timestamp(snp[end])[1]\np_close = values(snp[end,:Close])[1]\nlast_trade_day_formatted = Dates.format(last_trade_day, \"U d, yyyy\")\n\n\nIt loads the most recent publicly available data on equity prices from Yahoo finance. In an ideal world, we‚Äôd like any updates to these inputs to be reflected in our output. That way you can just re-render the Quarto notebook to get an updated report. To render Julia code inline, we use Markdown.jl like so:\n\n\nCode\nusing Markdown\nMarkdown.parse(\"\"\"\nWhen the S&P 500 last traded, on $(last_trade_day_formatted), it closed at $(p_close). \n\"\"\")\n\n\nWhen the S&P 500 last traded, on February 23, 2023, it closed at 4012.320068.\n\n\nIn practice, one would of course set #| echo: false in this case. Whatever content you publish, this approach will keep it up-to-date. This practice of simply re-rendering the source notebook also ensures that any other output remains up-to-date (e.g. Figure¬†1)\n\n\n\n\n\nFigure¬†1: Price history of the S&P 500.\n\n\n\n\n\n\nCode Execution\nRelated to the previous point, I typically define the following execution options in my _quarto.yml or _metadata.yml. The freeze: auto option ensures that documents are only rerendered if the source changes. In cases where code should always be re-executed you whould want to set freeze: false, instead. I set output: false because typically I have a lot of code chunks that don‚Äôt generate any output that is of immediate interest to readers.\nexecute:\n  freeze: auto\n  eval: true\n  echo: true\n  output: false\n\n\nReproducibility\nTo ensure that your content can be repoduced easily, it may additionally be helpful to explicitly specify the Julia version you used (jupyter: julia-1.8) and set up a global or local Julia environments. Inserting the following at the beginning of your Quarto notebook\nusing Pkg; Pkg.activate(\"&lt;path&gt;\")\nensures that the desired environemnt that lives in &lt;path&gt; is actually activated and used."
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#package-documentation",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#package-documentation",
    "title": "A year of using Quarto with Julia",
    "section": "Package Documentation",
    "text": "Package Documentation\nI have also continued to use Quarto in combination with Documenter.jl to document my Julia packages. This essentially boils down to writing up documentation using interactive .qmd notebooks and then rendering those to .md files as inputs for Documenter.jl. There are a few good reasons for this approach, especially if you‚Äôre used to working with Quarto anyway:\n\nRe-rendering any docs with eval: true provides an additional layer of quality assurance: if any of the code chunks throws an error, you know that your documentation is outdated (perhaps due to an API change). It also offers a straight-forward way to test package functions that produce non-testable (e.g.¬†stochastic) output. In such cases, the use of jldoctest is not always straight-forward (see here).\nYou get some stuff for free, e.g.¬†citation management. Unfortunately, as far as I‚Äôm aware there is still no support for cross-referencing.\nYou can use Quarto execution options like execute-dir: project and resources: www/ to globally specify the working directory and a directory for external resources like images.\n\nThere are also a few peculiarities to be aware of. To avoid any issues with Documenter.jl, I‚Äôve found it useful to ensure that the rendered .md files do not contain any raw HTML and to preserve text wrapping:\nformat: \n  commonmark:\n    variant: -raw_html\n    wrap: preserve\nWhen working with .qmd files you also need to use a slightly different syntax for admonitions. The following syntax inside the .qmd\n| !!! note \\\"An optional title\\\"\n|     Here is something that you should pay attention to.   \nwill generate the desired output inside the rendered .md:2\n!!! note \"An optional title\"\n    Here is something that you should pay attention to.   \nAny of my package repos ‚Äî CounterfactualExplanations.jl, LaplaceRedux.jl, ConformalPrediction.jl ‚Äî should provide additional colour on this topic."
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#quarto-for-academic-journal-articles",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#quarto-for-academic-journal-articles",
    "title": "A year of using Quarto with Julia",
    "section": "Quarto for Academic Journal Articles",
    "text": "Quarto for Academic Journal Articles\nQuarto supports \\(\\LaTeX\\) templates/classes, which has helped me with paper submissions in the past (e.g.¬†my pending JuliaCon Proceedings submissions). I‚Äôve found that rticles still has an edge here, but the list of out-of-the-box templates for journal articles is growing. Should I find some time in the future, I will try to add a template for JuliaCon Proceedings. The beauty of this is that it should enable publishers to not only use traditional forms of publication (PDF), but also include more dynamic formats with ease (think distill, but more than that.)"
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#wrapping-up",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#wrapping-up",
    "title": "A year of using Quarto with Julia",
    "section": "Wrapping up",
    "text": "Wrapping up\nThis short post has provided a bit of an update on using Quarto with Julia. From my own experience so far, things have been getting easier and better (thanks to the amazing work of Quarto dev team). I‚Äôm exicted to see things improve even further and still think that Quarto is a revolutionary new tool for scientific publishing. Let‚Äôs hope publishers eventually recognise this value üëÄ."
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#footnotes",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#footnotes",
    "title": "A year of using Quarto with Julia",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nUnrelated to Quarto, but this thread on discourse is full of other useful ideas for your startup.jl.‚Ü©Ô∏é\nSee related discussion.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html",
    "title": "Stuck in the Past",
    "section": "",
    "text": "Photo by Sergiu VƒÉlena»ô on Unsplash\nI‚Äôm officially a third-year PhD student folks! One of my favorite aspects of being a PhD is freedom: the freedom to explore, the freedom to learn, the freedom to create, and, last but not least, the freedom to choose the tools I want to use along the way. On this blog, I have repeatedly advocated for Quarto, my preferred tool for scientific publishing: it is open-source, straightforward to use, backed by an incredibly strong and responsive development team, works well with Julia‚Äîsee my previous posts here and here‚Äîand is highly customizable‚Äîsee my post on extensions.\nOne of my least favorite aspects of being a PhD is the old-fashioned way of publishing scientific papers. Having to deal with clunky LaTeX templates when all I want to do is write up my research is the bane of my existence. It makes me dread the writing process because I know that every time I‚Äôm forced to peek inside the LaTeX compiler log, my eyes will bleed. It shouldn‚Äôt be this way! I want to be able to look forward to writing. It should be the part where you finally get to reap the rewards for the hard work you put into your project. A creative process that allows you to communicate your findings in an engaging manner. Ideas should just be allowed to flow out freely, uninterrupted by frustration about formatting issues.\nThis frustration is amplified by the fact that I‚Äôm so painfully aware of the fact that there are better ways to do this. We have the technology to make the process of scientific publishing so much more enjoyable, efficient, engaging, accessible and reproducible. We also generally seem to agree that science can be much more effectively communicated through modern-day forms of media that involve animated or even interactive content. But for some reason, the academic community still insists on good old-fashioned PDFs as its gold standard for scientific publishing and communication, often enough locked behind paywalls. No wonder that the general public feels disconnected from academia."
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html#legacy-systems",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html#legacy-systems",
    "title": "Stuck in the Past",
    "section": "üìú Legacy Systems",
    "text": "üìú Legacy Systems\nScientists pride themselves in the fact that they are continuously pushing the boundaries of human knowledge, overturning old theories and replacing them with new ones. No idea is ever too good to be challenged. The better the idea, the more challenge it is likely going to attract. The scientific method, in its ideal form, is a transparent process of continuous refinement and creative destruction. And yet we treat our main scientific output, the research paper, as a static artifact: write it up, have it peer-reviewed, publish it, pad yourself on the back‚Äîyour work is now set in stone, the stamp of approval has been obtained, move on to the next one!\n\n‚ÄúTreating research outputs as static artifacts is fundamentally at odds with the dynamic nature of science.‚Äù\n\nI have a real issue with this approach and think that treating research outputs as static artifacts is fundamentally at odds with the dynamic nature of science. It incentivizes us to focus on quantity over quality. A static artifact creates the illusion of a finished product, which is not what science is about. It is about the process of discovery, not the end result. Even though we treat papers as if they were end results, they are really just interim results: the current version of knowledge.\nWait ‚Ä¶ did I say version? Don‚Äôt we have a well-established system for managing versions of digital knowledge artifacts? Yes, we do! It‚Äôs called version control and it is the backbone of modern software development. It allows us to keep track of changes to a digital artifact over time, to collaborate with others on the same artifact, and to easily revert to previous versions if necessary. It is a powerful tool that has revolutionized the way we develop software.\n\n‚ÄúReward researchers for the quality of their total contributions to the scientific community, not for the number of first-author papers they publish.‚Äù\n\nIf academia took the paradigm of continuous and transparent improvement seriously, it would treat research outputs like open-source software. It would use version control to keep track of changes to research outputs over time and create an environment that fosters open collaboration. It would not reward researchers for the number of first-author papers they publish but for the quality of their total contributions to the scientific community. Peer review would be a continuous process, not a one-off event. Peer review could come in many forms: from a simple comment on a GitHub issue to a full-blown pull request.\nMy dear colleagues and supervisors at TU Delft have recently published a position paper that argues for exactly this approach (Liem and Demetriou 2023). It is a well-written and thought-provoking piece that I hope will inspire many to rethink the way we do science. Among the things Liem and Demetriou (2023) point out is that there are clear parallels between the state of free and open-source software (FOSS) today and the goals of the open science movement. The current state of FOSS is characterized by the following:\n\n‚ÄúWhere in terms of ownership, public open-source repositories may have an active team of maintainers and owners of an artifact, other people not in these groups are explicitly welcome to raise issues or feature requests if they see points for improvement, and implement and suggest contributions themselves, that the maintainers and owners may choose to incorporate.‚Äù\n‚Äî Liem and Demetriou (2023)\n\nWhich is exactly what we should be doing in science:\n\n‚ÄúSimilarly, in scientific insight, a core team may work on a particular project, but other researchers and interested parties may suggest changes or improvements that could be incorporated with visible provenance.‚Äù\n‚Äî Liem and Demetriou (2023)\n\nTo get to that point, it seems obvious that we need to stop treating static papers as our gold standard. We need to start treating our research outputs as what they really are: interim results of a continuous process of discovery. We need to start treating them like software."
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html#signs-of-a-brighter-future",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html#signs-of-a-brighter-future",
    "title": "Stuck in the Past",
    "section": "üîÜ Signs of a Brighter Future",
    "text": "üîÜ Signs of a Brighter Future\nThis has been a bit of a rant so far and I‚Äôm not quite done yet. Some of you may be wondering what all the fuss is about. You may think that ‚Äòpublishing through LaTeX and PDF is just what we do; it‚Äôs a proven and reliable system; been there, done that; so why should we fix something that isn‚Äôt broken?‚Äô You might personally prefer engaging with research that is printed out on paper and the LaTeX compiler log doesn‚Äôt even scare you anymore. Perhaps all of this debate so far has simply been below your h-index. In that case, please don‚Äôt feel like you have to stick around! But if you‚Äôre still here reading this, then let me now show you some signs of a brave new world of scientific publishing that is already emerging.\n\nQuarto Journal Extensions\nQuarto journal extensions are the first sign of a brighter future. They allow you to write your paper in Quarto and then render it to a PDF that complies with some journal‚Äôs LaTeX template. This is a huge step forward because it allows you to focus on the content of your paper and not on the formatting. It also allows you to use the same document to render a PDF for submission to the journal and an HTML version for your website. This is a great way to make your work more accessible to the general public.\nThe current list of available journal extensions is admittedly still short. But the list is growing, partially due to the immense efforts of the Quarto team, and partially due to the fact that it is relatively straightforward to create your own journal extension (another hat tip to the dev team). While not everyone has the time and resources to create their own journal extension for every venue they submit to, I encourage you to give it a try. The dev team is very responsive and will help you along the way. Future generations of researchers will thank you for it!\n\n\nPeer Review meets Version Control\nAnother sign of a brighter future is the emergence of publication processes that combine peer review with version control. The Journal of Open Source Software (JOSS) is a great example of this. JOSS is a free and open-access journal that publishes research software packages. It uses GitHub as its platform for peer review and version control. While I have personally never submitted to JOSS, I have submitted my work to JuliaCon Proceedings, which follows a very similar process. This year, we published our first paper on CounterfactualExplanations.jl (Altmeyer, Deursen, et al. 2023). The review process was refreshingly transparent and collaborative. I was able to engage with reviewers and editors directly on GitHub and paper revisions were automatically rerendered through a bot. Since most of us, especially in the computational sciences, are already using GitHub or GitLab for version control, this approach seems like a no-brainer to me and I am somewhat puzzled that it hasn‚Äôt been adopted more widely yet."
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html#embracing-change",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html#embracing-change",
    "title": "Stuck in the Past",
    "section": "ü§ó Embracing Change",
    "text": "ü§ó Embracing Change\nWhile the publication process for JuliaCon Proceedings is already ahead of the game, I think it can be improved even further. In particular, I think that it could benefit from embracing Quarto. The community as a whole has certainly heard of Quarto by now: in 2022, the CEO of posit himself, J.J. Allaire, gave a talk at JuliaCon about Quarto; later that same year, yours truly gave a talk about using Quarto with Julia at Julia Eindhoven; other Julia developers like Ronny Bergmann have come up with clever ways to combine Quarto with existing documentation tools like Documenter.jl through GitHub actions. To my mind, JuliaCon Proceedings is the perfect place to turn to next for Quarto adoption.\n\nQuarto for JuliaCon Proceedings: A Proposal\nI have been working on just that: a Quarto journal extension for JuliaCon Proceedings that I would like to introduce in this blog post. The extension is called quarto-juliacon-proceedings. It is based on the existing JuliaCon Proceedings LaTeX template and will allow authors to write their JuliaCon Proceedings paper (and more!) in Quarto.\nIt is close to being finished but still needs some work. The repo contains a Quarto version of our JuliaCon Proceedings paper Explaining Black-Box Models through Counterfactuals (Altmeyer, Deursen, et al. 2023). The rendered PDF serves as a comparison to the published version of the paper. The remaining differences in formatting need to be sorted out. If you notice any differences that we have not already listed, please open an issue. There is also an open issue on JuliaConSubmission.jl which you may use to share your thoughts on this proposal with the JuliaCon Proceedings team (or simply support this proposal by giving it a thumbs up).\n\n\n\n\n\n\nWarning\n\n\n\nAt the time of writing, this is a proof-of-concept for how we could use Quarto for JuliaCon proceedings. For current submissions, please follow the official instructions here.\n\n\nProvided we can eventually get this extension to be officially supported by the JuliaCon Proceedings team, I think it would be a great step forward for the Julia community. It would reduce the process of complying with the JuliaCon Proceedings LaTeX template to a single line of code:\nquarto use template pat-alt/quarto-juliacon-proceedings\nSimply run this command and start writing your paper in Quarto. The extension will take care of the rest.\nBeyond making life easier for authors, I think that this extension would also be a great opportunity for the JuliaCon Proceedings team to rethink the way we publish JuliaCon Proceedings papers. I‚Äôll finish this post by brainstorming some ideas for how we could improve the current process even further by embracing Quarto.\n\nContinuous Peer Review\nThe current process is still very much based on the old-fashioned, print-based approach to scientific publishing. Once the paper is published, that‚Äôs that. This approach is at odds with the way developers treat the software they write about in their papers. Software is continuously updated and improved and aspects discussed in a paper may become outdated over time. I could imagine a world where the JuliaCon Proceedings paper is automatically updated and tagged whenever a new version of the package is released, just like the documentation. Standard code review processes that involve the community as a whole would then act as a form of continuous peer review.\n\n\nDynamic and Interactive Content\nOf course, Quarto adds a whole new dimension to the way we can communicate our work. Since the same Quarto document that is used to render the static PDF can also be used to generate HTML, we can now include animated and interactive content in our papers. Many developers already use thoughtful and illustrative animations in their package documentation. It seems like a lost opportunity to not feature these in the most condensed and public-facing output (the proceedings paper). Further down the road, I could even imagine a world where Quarto integrates seamlessly with Pluto.jl‚Äîboth Quarto documents and Pluto notebooks are essentially just code blended with Markdown‚Äîto allow for fully interactive versions of our papers.\n\n\nSynergies between Docs and Papers\nFinally, using Quarto for package documentation and JuliaCon Proceedings papers would allow us to create synergies between the two. Developers typically spend a lot of time carefully crafting their package documentation. Independent of whether or not they use Quarto to this end, the Markdown-based documentation files are already a great starting point for a JuliaCon Proceedings paper. Quarto makes it easier than LaTeX to recycle that content and turn it into a paper, since any Markdown file can be seamlessly converted to a Quarto document."
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html#wrap-up",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html#wrap-up",
    "title": "Stuck in the Past",
    "section": "üåØ Wrap Up",
    "text": "üåØ Wrap Up\nI hope that this post has given you some food for thought. I am aware that some of the ideas I have presented here are quite radical and that it will take time for the academic community to embrace them. I am also aware that there are many other aspects of the scientific publishing process that need to be rethought. But the tools I highlight in this post are freely accessible to us. We just need to start using them."
  },
  {
    "objectID": "blog/posts/conformal-prediction/index.html",
    "href": "blog/posts/conformal-prediction/index.html",
    "title": "Conformal Prediction in Julia üü£üî¥üü¢",
    "section": "",
    "text": "Prediction sets for two different samples  and changing coverage rates.  As coverage grows, so does the size of the  prediction sets.\nA first crucial step towards building trustworthy AI systems is to be transparent about predictive uncertainty. Model parameters are random variables and their values are estimated from noisy data. That inherent stochasticity feeds through to model predictions and should to be addressed, at the very least in order to avoid overconfidence in models.\nBeyond that obvious concern, it turns out that quantifying model uncertainty actually opens up a myriad of possibilities to improve up- and down-stream modeling tasks like active learning and robustness. In Bayesian Active Learning, for example, uncertainty estimates are used to guide the search for new input samples, which can make ground-truthing tasks more efficient (Houlsby et al. 2011). With respect to model performance in downstream tasks, uncertainty quantification can be used to improve model calibration and robustness (Lakshminarayanan, Pritzel, and Blundell 2017).\nIn previous posts we have looked at how uncertainty can be quantified in the Bayesian context (see here and here). Since in Bayesian modeling we are generally concerned with estimating posterior distributions, we get uncertainty estimates almost as a byproduct. This is great for all intends and purposes, but it hinges on assumptions about prior distributions. Personally, I have no quarrel with the idea of making prior distributional assumptions. On the contrary, I think the Bayesian framework formalizes the idea of integrating prior information in models and therefore provides a powerful toolkit for conducting science. Still, in some cases this requirement may be seen as too restrictive or we may simply lack prior information.\nEnter: Conformal Prediction (CP) ‚Äî a scalable frequentist approach to uncertainty quantification and coverage control. In this post we will go through the basic concepts underlying CP. A number of hands-on usage examples in Julia should hopefully help to convey some intuition and ideally attract people interested in contributing to a new and exciting open-source development."
  },
  {
    "objectID": "blog/posts/conformal-prediction/index.html#sec-background",
    "href": "blog/posts/conformal-prediction/index.html#sec-background",
    "title": "Conformal Prediction in Julia üü£üî¥üü¢",
    "section": "üìñ Background",
    "text": "üìñ Background\nConformal Prediction promises to be an easy-to-understand, distribution-free and model-agnostic way to generate statistically rigorous uncertainty estimates. That‚Äôs quite a mouthful, so let‚Äôs break it down: firstly, as I will hopefully manage to illustrate in this post, the underlying concepts truly are fairly straight-forward to understand; secondly, CP indeed relies on only minimal distributional assumptions; thirdly, common procedures to generate conformal predictions really do apply almost universally to all supervised models, therefore making the framework very intriguing to the ML community; and, finally, CP does in fact come with a frequentist coverage guarantee that ensures that conformal prediction sets contain the true value with a user-chosen probability. For a formal proof of this marginal coverage property and a detailed introduction to the topic, I recommend Angelopoulos and Bates (2022).\n\n\n\n\n\n\nNote\n\n\n\nIn what follows we will loosely treat the tutorial by Angelopoulos and Bates (2022) and the general framework it sets as a reference. You are not expected to have read the paper, but I also won‚Äôt reiterate any details here.\n\n\nCP can be used to generate prediction intervals for regression models and prediction sets for classification models (more on this later). There is also some recent work on conformal predictive distributions and probabilistic predictions. Interestingly, it can even be used to complement Bayesian methods. Angelopoulos and Bates (2022), for example, point out that prior information should be incorporated into prediction sets and demonstrate how Bayesian predictive distributions can be conformalized in order to comply with the frequentist notion of coverage. Relatedly, Hoff (2021) proposes a Bayes-optimal prediction procedure. And finally, Stanton, Maddox, and Wilson (2022) very recently proposed a way to introduce conformal prediction in Bayesian Optimization. I find this type of work that combines different schools of thought very promising, but I‚Äôm drifting off a little ‚Ä¶ So, without further ado, let us look at some code."
  },
  {
    "objectID": "blog/posts/conformal-prediction/index.html#sec-julia",
    "href": "blog/posts/conformal-prediction/index.html#sec-julia",
    "title": "Conformal Prediction in Julia üü£üî¥üü¢",
    "section": "üì¶ Conformal Prediction in Julia",
    "text": "üì¶ Conformal Prediction in Julia\nIn this section of this first short post on CP we will look at how conformal prediction can be implemented in Julia. In particular, we will look at an approach that is compatible with any of the many supervised machine learning models available in MLJ: a beautiful, comprehensive machine learning framework funded by the Alan Turing Institute and the New Zealand Strategic Science Investment Fund Blaom et al. (2020). We will go through some basic usage examples employing a new Julia package that I have been working on: ConformalPrediction.jl.\n\n\n\n\n\n\nConformalPrediction.jl\n\n\n\nConformalPrediction.jl is a package for uncertainty quantification through conformal prediction for machine learning models trained in MLJ. At the time of writing it is still in its early stages of development, but already implements a range of different approaches to CP. Contributions are very much welcome:\n\nDocumentation\nContributor‚Äôs Guide\n\n\n\n\nSplit Conformal Classification\nWe consider a simple binary classification problem. Let \\((X_i, Y_i), \\ i=1,...,n\\) denote our feature-label pairs and let \\(\\mu: \\mathcal{X} \\mapsto \\mathcal{Y}\\) denote the mapping from features to labels. For illustration purposes we will use the moons dataset üåô. Using MLJ.jl we first generate the data and split into into a training and test set:\n\n\nCode\nusing MLJ\nusing Random\nRandom.seed!(123)\n\n# Data:\nX, y = make_moons(500; noise=0.15)\ntrain, test = partition(eachindex(y), 0.8, shuffle=true)\n\n\nHere we will use a specific case of CP called split conformal prediction which can then be summarized as follows:1\n\nPartition the training into a proper training set and a separate calibration set: \\(\\mathcal{D}_n=\\mathcal{D}^{\\text{train}} \\cup \\mathcal{D}^{\\text{cali}}\\).\nTrain the machine learning model on the proper training set: \\(\\hat\\mu_{i \\in \\mathcal{D}^{\\text{train}}}(X_i,Y_i)\\).\nCompute nonconformity scores, \\(\\mathcal{S}\\), using the calibration data \\(\\mathcal{D}^{\\text{cali}}\\) and the fitted model \\(\\hat\\mu_{i \\in \\mathcal{D}^{\\text{train}}}\\).\nFor a user-specified desired coverage ratio \\((1-\\alpha)\\) compute the corresponding quantile, \\(\\hat{q}\\), of the empirical distribution of nonconformity scores, \\(\\mathcal{S}\\).\nFor the given quantile and test sample \\(X_{\\text{test}}\\), form the corresponding conformal prediction set:\n\n\\[\nC(X_{\\text{test}})=\\{y:s(X_{\\text{test}},y) \\le \\hat{q}\\}\n\\tag{1}\\]\nThis is the default procedure used for classification and regression in ConformalPrediction.jl.\nYou may want to take a look at the source code for the classification case here. As a first important step, we begin by defining a concrete type SimpleInductiveClassifier that wraps a supervised model from MLJ.jl and reserves additional fields for a few hyperparameters. As a second step, we define the training procedure, which includes the data-splitting and calibration step. Finally, as a third step we implement the procedure in Equation¬†1 to compute the conformal prediction set.\n\n\n\n\n\n\nDevelopment Status\n\n\n\nThe permalinks above take you to the version of the package that was up-to-date at the time of writing. Since the package is in its early stages of development, the code base and API can be expected to change.\n\n\nNow let‚Äôs take this to our üåô data. To illustrate the package functionality we will demonstrate the envisioned workflow. We first define our atomic machine learning model following standard MLJ.jl conventions. Using ConformalPrediction.jl we then wrap our atomic model in a conformal model using the standard API call conformal_model(model::Supervised; kwargs...). To train and predict from our conformal model we can then rely on the conventional MLJ.jl procedure again. In particular, we wrap our conformal model in data (turning it into a machine) and then fit it on the training set. Finally, we use our machine to predict the label for a new test sample Xtest:\n\n\nCode\n# Model:\nKNNClassifier = @load KNNClassifier pkg=NearestNeighborModels\nmodel = KNNClassifier(;K=50) \n\n# Training:\nusing ConformalPrediction\nconf_model = conformal_model(model; coverage=.9)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)\n\n# Conformal Prediction:\nXtest = selectrows(X, first(test))\nytest = y[first(test)]\npredict(mach, Xtest)[1]\n\n\nimport NearestNeighborModels\n\n\n ‚úî\n\n\n\n           UnivariateFinite{Multiclass{2}}      \n     ‚îå                                        ‚îê \n   0 ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.94   \n     ‚îî                                        ‚îò \n\n\n\nThe final predictions are set-valued. While the softmax output remains unchanged for the SimpleInductiveClassifier, the size of the prediction set depends on the chosen coverage rate, \\((1-\\alpha)\\).\n\n\nWhen specifying a coverage rate very close to one, the prediction set will typically include many (in some cases all) of the possible labels. Below, for example, both classes are included in the prediction set when setting the coverage rate equal to \\((1-\\alpha)\\)=1.0. This is intuitive, since high coverage quite literally requires that the true label is covered by the prediction set with high probability.\n\n\n\n\nCode\nconf_model = conformal_model(model; coverage=coverage)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)\n\n# Conformal Prediction:\nXtest = (x1=[1],x2=[0])\npredict(mach, Xtest)[1]\n\n\n\n           UnivariateFinite{Multiclass{2}}      \n     ‚îå                                        ‚îê \n   0 ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.5   \n   1 ‚î§‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ† 0.5   \n     ‚îî                                        ‚îò \n\n\n\n\n\nConversely, for low coverage rates, prediction sets can also be empty. For a choice of \\((1-\\alpha)\\)=0.1, for example, the prediction set for our test sample is empty. This is a bit difficult to think about intuitively and I have not yet come across a satisfactory, intuitive interpretation.2 When the prediction set is empty, the predict call currently returns missing:\n\n\n\n\nCode\nconf_model = conformal_model(model; coverage=coverage)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)\n\n# Conformal Prediction:\npredict(mach, Xtest)[1]\n\n\nmissing\n\n\nFigure¬†1 should provide some more intuition as to what exactly is happening here. It illustrates the effect of the chosen coverage rate on the predicted softmax output and the set size in the two-dimensional feature space. Contours are overlayed with the moon data points (including test data). The two samples highlighted in red, \\(X_1\\) and \\(X_2\\), have been manually added for illustration purposes. Let‚Äôs look at these one by one.\nFirstly, note that \\(X_1\\) (red cross) falls into a region of the domain that is characterized by high predictive uncertainty. It sits right at the bottom-right corner of our class-zero moon üåú (orange), a region that is almost entirely enveloped by our class-one moon üåõ (green). For low coverage rates the prediction set for \\(X_1\\) is empty: on the left-hand side this is indicated by the missing contour for the softmax probability; on the right-hand side we can observe that the corresponding set size is indeed zero. For high coverage rates the prediction set includes both \\(y=0\\) and \\(y=1\\), indicative of the fact that the conformal classifier is uncertain about the true label.\nWith respect to \\(X_2\\), we observe that while also sitting on the fringe of our class-zero moon, this sample populates a region that is not fully enveloped by data points from the opposite class. In this region, the underlying atomic classifier can be expected to be more certain about its predictions, but still not highly confident. How is this reflected by our corresponding conformal prediction sets?\n\n\nCode\nXtest_2 = (x1=[-0.5],x2=[0.25])\ncov_ = .9\nconf_model = conformal_model(model; coverage=cov_)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)\npÃÇ_2 = pdf(predict(mach, Xtest_2)[1], 0)\n\n\n\n\nWell, for low coverage rates (roughly \\(&lt;0.9\\)) the conformal prediction set does not include \\(y=0\\): the set size is zero (right panel). Only for higher coverage rates do we have \\(C(X_2)=\\{0\\}\\): the coverage rate is high enough to include \\(y=0\\), but the corresponding softmax probability is still fairly low. For example, for \\((1-\\alpha)=0.9\\) we have \\(\\hat{p}(y=0|X_2)=0.72.\\)\n\n\nThese two examples illustrate an interesting point: for regions characterised by high predictive uncertainty, conformal prediction sets are typically empty (for low coverage) or large (for high coverage). While set-valued predictions may be something to get used to, this notion is overall intuitive.\n\n\nCode\n# Setup\ncoverages = range(0.75,1.0,length=5)\nn = 100\nx1_range = range(extrema(X.x1)...,length=n)\nx2_range = range(extrema(X.x2)...,length=n)\n\nanim = @animate for coverage in coverages\n    conf_model = conformal_model(model; coverage=coverage)\n    mach = machine(conf_model, X, y)\n    fit!(mach, rows=train)\n    p1 = contourf_cp(mach, x1_range, x2_range; type=:proba, title=\"Softmax\", axis=nothing)\n    scatter!(p1, X.x1, X.x2, group=y, ms=2, msw=0, alpha=0.75)\n    scatter!(p1, Xtest.x1, Xtest.x2, ms=6, c=:red, label=\"X‚ÇÅ\", shape=:cross, msw=6)\n    scatter!(p1, Xtest_2.x1, Xtest_2.x2, ms=6, c=:red, label=\"X‚ÇÇ\", shape=:diamond, msw=6)\n    p2 = contourf_cp(mach, x1_range, x2_range; type=:set_size, title=\"Set size\", axis=nothing)\n    scatter!(p2, X.x1, X.x2, group=y, ms=2, msw=0, alpha=0.75)\n    scatter!(p2, Xtest.x1, Xtest.x2, ms=6, c=:red, label=\"X‚ÇÅ\", shape=:cross, msw=6)\n    scatter!(p2, Xtest_2.x1, Xtest_2.x2, ms=6, c=:red, label=\"X‚ÇÇ\", shape=:diamond, msw=6)\n    plot(p1, p2, plot_title=\"(1-Œ±)=$(round(coverage,digits=2))\", size=(800,300))\nend\n\ngif(anim, fps=0.5)\n\n\n\n\nFigure¬†1: The effect of the coverage rate on the conformal prediction set. Softmax probabilities are shown on the left. The size of the prediction set is shown on the right."
  },
  {
    "objectID": "blog/posts/conformal-prediction/index.html#conclusion",
    "href": "blog/posts/conformal-prediction/index.html#conclusion",
    "title": "Conformal Prediction in Julia üü£üî¥üü¢",
    "section": "üèÅ Conclusion",
    "text": "üèÅ Conclusion\nThis has really been a whistle-stop tour of Conformal Prediction: an active area of research that probably deserves much more attention. Hopefully, though, this post has helped to provide some color and, if anything, made you more curious about the topic. Let‚Äôs recap the TL;DR from above:\n\nConformal Prediction is an interesting frequentist approach to uncertainty quantification that can even be combined with Bayes (Section¬†1).\nIt is scalable and model-agnostic and therefore well applicable to machine learning (Section¬†1).\nConformalPrediction.jl implements CP in pure Julia and can be used with any supervised model available from MLJ.jl (Section¬†2).\nImplementing CP directly on top of an existing, powerful machine learning toolkit demonstrates the potential usefulness of this framework to the ML community (Section¬†2).\nStandard conformal classifiers produce set-valued predictions: for ambiguous samples these sets are typically large (for high coverage) or empty (for low coverage) (Section¬†2.1).\n\nBelow I will leave you with some further resources."
  },
  {
    "objectID": "blog/posts/conformal-prediction/index.html#further-resources",
    "href": "blog/posts/conformal-prediction/index.html#further-resources",
    "title": "Conformal Prediction in Julia üü£üî¥üü¢",
    "section": "üìö Further Resources",
    "text": "üìö Further Resources\nChances are that you have already come across the Awesome Conformal Prediction repo: Manokhin (2022) provides a comprehensive, up-to-date overview of resources related to the conformal prediction. Among the listed articles you will also find Angelopoulos and Bates (2022), which inspired much of this post. The repo also points to open-source implementations in other popular programming languages including Python and R."
  },
  {
    "objectID": "blog/posts/conformal-prediction/index.html#footnotes",
    "href": "blog/posts/conformal-prediction/index.html#footnotes",
    "title": "Conformal Prediction in Julia üü£üî¥üü¢",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn other places split conformal prediction is sometimes referred to as inductive conformal prediction.‚Ü©Ô∏é\nAny thoughts/comments welcome!‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html",
    "title": "Individual recourse for Black Box Models",
    "section": "",
    "text": "In her popular book Weapons of Math Destruction Cathy O‚ÄôNeil presents the example of public school teacher Sarah Wysocki, who lost her job after a teacher evaluation algorithm had rendered her redundant (O‚ÄôNeil 2016). Sarah was highly popular among her peers, supervisors and students.\nThis post looks at a novel algorithmic solution to the problem that individuals like Sarah, who are faced with an undesirable outcome, should be provided with means to revise that outcome. The literature commonly refers to this as individual recourse. One of the first approaches towards individual recourse was proposed by Ustun, Spangher, and Liu (2019). In a recent follow-up paper, Joshi et al. (2019) propose a methodology coined REVISE, which extends the earlier approach in at least three key ways:\nFor a detailed discussion of these points you may check out this slide deck or consult the paper directly (freely available on DeepAI). Here, we will abstract from some of these complications and instead look at an application of a slightly simplified version of REVISE. This should help us to first build a good intuition. Readers interested in the technicalities and code may find all of this in the annex below."
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html#from-to",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html#from-to",
    "title": "Individual recourse for Black Box Models",
    "section": "From üê± to üê∂",
    "text": "From üê± to üê∂\nWe will explain REVISE through a short tale of cats and dogs. The protagonist of this tale is Kitty üê±, a young cat that identifies as a dog. Unfortunately, Kitty is not very tall and her tail, though short for a cat, is longer than that of the average dog (Figure¬†1).\n\n\n\nFigure¬†1: Empirical distributions of simulated data set describing cats and dogs. Vertical stalks represent Kitty‚Äôs attribute values.\n\n\nMuch to her dismay, Kitty has been recognized as a cat by a linear classifier \\(g_n(X)\\) that we trained through stochastic gradient descent using the data on animals‚Äô height and tail length. Once again interested readers may find technical details and code in the annex below. Figure¬†2 shows the resulting linear separation in the attribute space with the decision boundary in solid black and Kitty‚Äôs location indicated by a red circle. Can we provide individual recourse to Kitty?\n\n\n\nFigure¬†2: Linear separation of cats and dogs in the 2-dimensional attribute space with the decision boundary of the fitted classifier in solid black. Kitty‚Äôs location is indicated by a red circle.\n\n\nLet‚Äôs see if and how we can apply REVISE to Kitty‚Äôs problem. The following summary should give you some flavour of how the algorithm works:\n\nInitialize \\(\\mathbf{x}_i'^{(0)}\\), that is the attributes that will be revised recursively. Kitty‚Äôs original attributes seem like a reasonable place to start.\nThrough gradient descent recursively revise \\(\\mathbf{x}_i'^{(t)}\\) until \\(g_n(\\mathbf{x}_i'^{(T)})=\\)üê∂. At this point \\(T\\) the descent terminates since for these revised attributes the classifier labels Kitty as a dog.\nReturn \\(\\delta_i=\\mathbf{x}_i'^{(T)}-\\mathbf{x}_i\\), that is the individual recourse for Kitty.\n\nFigure¬†3 illustrates what happens when this approach is applied to Kitty‚Äôs problem. The different panels show the results for different values of a regularization parameter \\(\\lambda\\) that governs the trade-off between achieving the desired label switch and keeping the distance between the original (\\(\\mathbf{x}_i\\)) and revised (\\(\\mathbf{x}_i'\\)) attributes small. In all but one case, REVISE converges: a decrease in tail length along with an increase in height eventually allows Kitty to cross the decision boundary. In other words, we have successfully turned Kitty into a dog - at least in the eyes of the linear classifier!\nWe also observe that as we increase \\(\\lambda\\) for a fixed learning rate, REVISE takes longer to converge. This should come as no surprise, since higher values of \\(\\lambda\\) lead to greater regularization with respect to the penalty we place on the distance that Kitty has to travel. When we penalize too much (\\(\\lambda=10\\)), Kitty never reaches the decision boundary, because she is reluctant to change her characteristics beyond a certain point. While not visible to the naked eye, in this particular example \\(\\lambda=0.001\\) corresponds to the best choice among the candidate values.\n\n\n\nFigure¬†3: The simplified REVISE algorithm in action: how Kitty crosses the decision boundary by changing her attributes. Regularization with respect to the distance penalty increases from top left to bottom right."
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html#discussion",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html#discussion",
    "title": "Individual recourse for Black Box Models",
    "section": "Discussion",
    "text": "Discussion\nWhile hopefully Kitty‚Äôs journey has provided you with some useful intuition, the story is of course very silly. Even if your cat ever seems to signal that she wants to be a dog, helping her cross that decision boundary will be tricky. Some attributes are simply immutable or very difficult to change, which Joshi et al. (2019) do not fail to account for in their framework. Their proposed methodology offers a simple and ingenious approach towards providing individual recourse. Instead of concerning ourselves with Black Box interpretability, why not simply provide remedy in case things go wrong?\nTo some extent that idea has its merit. As this post has hopefully shown, REVISE is straight-forward to understand and readily applicable. It could be a very useful tool to provide individual recourse in many real-world applications. As the implementation of our simplified version of REVISE demonstrates, researchers should also find it relatively easy to develop the methodology further and tailor it to specific use cases. The simpler version here, for example, may be useful in settings where the dimensionality is relatively small and one can reasonably model the distribution of attributes without the need for generative models.\nStill, you may be wondering: if the original classifier is based on poorly defined rules and proxies, then what good does REVISE really do? Going back to the example of high-school teacher Sarah Wysocki, one of the key attributes determining teachers‚Äô evaluations was their students‚Äô performance. Realizing this, some teachers took the shortest route to success by artificially inflating their students‚Äô test scores. That same course of action may well have been suggested by REVISE. As Joshi et al. (2019) demonstrate, this very property of REVISE may actually proof useful in detecting weaknesses of decision making systems before setting them loose (key contribution 3).\nNonetheless, the example above also demonstrates that approaches like REVISE, useful as they may be, tend to provide solutions for very particular problems. In reality data-driven decision making systems are often subject to many different problems and hence research on trustworthy AI will need to tackle the issue from various angles. A few places to start include the question of dealing with data that is inherently biased, improving ad-hoc and post-hoc model interpretability and continuing efforts around causality-inspired AI."
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html#references",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html#references",
    "title": "Individual recourse for Black Box Models",
    "section": "References",
    "text": "References\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nO‚ÄôNeil, Cathy. 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown.\n\n\nUstun, Berk, Alexander Spangher, and Yang Liu. 2019. ‚ÄúActionable Recourse in Linear Classification.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 10‚Äì19. https://doi.org/10.1145/3287560.3287566."
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html#annex",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html#annex",
    "title": "Individual recourse for Black Box Models",
    "section": "Annex",
    "text": "Annex\nIn my blog posts I aim to implement interesting ideas from scratch even if that sometimes means that things need to undergo some sort of simplification. The benefit of this approach is that the experience is educationally rewarding - both for myself and hopefully also for readers. The first two sections of this annex show how REVISE and linear classification can be implemented in R. The final section just shows how the synthetic data was generated. To also inspect the code that generates the visualizations and everything else, you can find the source code of this file on GitHub.\n\nLinear classifier\nLinear classification is implemented through stochastic gradient descent (SGD) with Hinge loss\n\\[\n\\begin{aligned}\n&& \\ell(-\\mathbf{w}^T\\mathbf{x}_i y_i)&=(1-\\mathbf{w}^T\\mathbf{x}_i y_i)_+ \\\\\n\\end{aligned}\n\\]\nwhere \\(\\mathbf{w}\\) is a coefficient vector, \\(\\mathbf{x}_i\\) is the attribute vector of individual \\(i\\) and \\(y_i\\) is the individual‚Äôs outcome. Since we apply SGD in order to minimize the loss function \\(\\ell\\) by varying \\(\\mathbf{w}\\), we need an expression for its gradient with respect to \\(\\mathbf{w}\\), which is given by:\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& \\nabla_{\\mathbf{W}} \\left( \\ell(-\\mathbf{w}^T\\mathbf{x}_i y_i) \\right) &= \\begin{cases} -\\mathbf{x}_i y_i & \\text{if} \\ \\ \\ \\mathbf{w}^T\\mathbf{x}_i y_i \\le 1\\\\ 0 & \\text{otherwise} \\end{cases} \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{1}\\]\nThe code below uses this analytical solution to perform SGD over \\(T\\) iterations or as long as updates yield feasible parameter values. As the final vector of coefficients the function returns \\(\\mathbf{\\bar{w}}= \\frac{1}{T} \\sum_{t=1}^{T} \\mathbf{w}_t\\). Denoting the optimal coefficient vector as \\(\\mathbf{w}^*\\), it can be shown that under certain conditions \\(\\ell(\\mathbf{\\bar{w}})\\rightarrow\\ell(\\mathbf{w}^*)\\) as \\(T\\rightarrow\\infty\\).\n\n\nCode\n#' Stochastic gradient descent\n#'\n#' @param X Feature matrix.\n#' @param y Vector containing training labels.\n#' @param eta Learning rate.\n#' @param n_iter Maximum number of iterations.\n#' @param w_init Initial parameter values.\n#' @param save_steps Boolean checking if coefficients should be saved at each step.\n#'\n#' @return\n#' @export\n#'\n#' @author Patrick Altmeyer\nlinear_classifier &lt;- function(X,y,eta=0.001,n_iter=1000,w_init=NULL,save_steps=FALSE) {\n  # Initialization: ----\n  n &lt;- nrow(X) # number of observations\n  d &lt;- ncol(X) # number of dimensions\n  if (is.null(w_init)) {\n    w &lt;- matrix(rep(0,d)) # initialize coefficients as zero...\n  } else {\n    w &lt;- matrix(w_init) # ...unless initial values have been provided.\n  }\n  w_avg &lt;- 1/n_iter * w # initialize average coefficients\n  iter &lt;- 1 # iteration count\n  if (save_steps) {\n    steps &lt;- data.table(iter=0, w=c(w), d=1:d) # if desired, save coefficient at each step\n  } else {\n    steps &lt;- NA\n  }\n  feasible_w &lt;- TRUE # to check if coefficients are finite, non-nan, ...\n  # Surrogate loss:\n  l &lt;- function(X,y,w) {\n    x &lt;- (-1) * crossprod(X,w) * y\n    pmax(0,1 + x) # Hinge loss\n  }\n  grad &lt;- function(X,y,w) {\n    X %*% ifelse(crossprod(X,w) * y&lt;=1,-y,0) # Gradient of Hinge loss\n  }\n  # Stochastic gradient descent: ----\n  while (feasible_w & iter&lt;n_iter) {\n    t &lt;- sample(1:n,1) # random draw\n    X_t &lt;- matrix(X[t,])\n    y_t &lt;- matrix(y[t])\n    v_t &lt;- grad(X_t,y_t,w) # compute estimate of gradient\n    # Update:\n    w &lt;- w - eta * v_t # update coefficient vector\n    feasible_w &lt;- all(sapply(w, function(i) !is.na(i) & is.finite(i))) # check if feasible\n    if (feasible_w) {\n      w_avg &lt;- w_avg + 1/n_iter * w # update average\n    }\n    if (save_steps) {\n      steps &lt;- rbind(steps, data.table(iter=iter, w=c(w), d=1:d))\n    }\n    iter &lt;- iter + 1 # increase counter\n  }\n  # Output: ----\n  output &lt;- list(\n    X = X,\n    y = matrix(y),\n    coefficients = w_avg,\n    eta = eta,\n    n_iter = n_iter,\n    steps = steps\n  )\n  class(output) &lt;- \"classifier\" # assign S3 class\n  return(output)\n}\n\n# Methods: ----\nprint.classifier &lt;- function(classifier) {\n  print(\"Coefficients:\")\n  print(classifier$coefficients)\n}\nprint &lt;- function(classifier) {\n  UseMethod(\"print\")\n}\n\npredict.classifier &lt;- function(classifier, newdata=NULL, discrete=TRUE) {\n  if (!is.null(newdata)) {\n    fitted &lt;- newdata %*% classifier$coefficients # out-of-sampple prediction\n  } else {\n    fitted &lt;- classifier$X %*% classifier$coefficients # in-sample fit\n  }\n  if (discrete) {\n    fitted &lt;- sign(fitted) # map to {-1,1}\n  }\n  return(fitted)\n}\npredict &lt;- function(classifier, newdata=NULL, discrete=TRUE) {\n  UseMethod(\"predict\")\n}\n\n\n\n\nREVISE (simplified)\nAs flagged above, we are looking at a slightly simplified version of the algorithm presented in Joshi et al. (2019). In particular, the approach here does not incorporate the threshold on the likelihood nor does it account for immutable attributes.\nLet \\(y\\in\\{-1,1\\}\\) be a binary outcome variable, \\(X\\in\\mathbb{R}^d\\) a feature matrix containing individuals‚Äô attributes and \\(g_n(X)\\) a corresponding data-dependent classifier. Suppose \\(y_i=-1\\) (the negative outcome) for some individual characterized by attributes \\(\\mathbf{x}_i\\). Then we want to find \\(\\mathbf{x}_i'\\) closest to \\(\\mathbf{x}_i\\) such that the classifier assigns the positive outcome \\(g(\\mathbf{x}_i^{'})=1\\). In order to do so, we use gradient descent with Hinge loss \\(\\ell\\) to minimize the following function\n\\[\n\\begin{aligned}\n&& \\min_{\\mathbf{x}_i^{'}}& \\ \\ell(g_n(\\mathbf{x}_i^{'}),1) + \\lambda d(\\mathbf{x}_i^{'},\\mathbf{x}_i) \\\\\n\\end{aligned}\n\\]\nwhere \\(d=||\\mathbf{x}_i^{'}-\\mathbf{x}_i||\\) denotes the Euclidean distance. Note that this time we take the coefficient vector defining \\(g_n\\) as given and instead vary the attributes. In particular, we will perform gradient descent steps as follows\n\\[\n\\begin{aligned}\n&& {\\mathbf{x}_i^{'}}^t&\\leftarrow {\\mathbf{x}_i^{'}}^{t-1} + \\eta \\nabla_{{\\mathbf{x}_i^{'}}} \\left( \\ell(g_n(\\mathbf{x}_i^{'}),1) + \\lambda d(\\mathbf{x}_i^{'},\\mathbf{x}_i)  \\right)  \\\\\n\\end{aligned}\n\\]\nwhere \\(\\eta\\) is the learning rate. The descent step is almost equivalent to the one described in Joshi et al. (2019), but here we greatly simplify things by optimizing directly in the attribute space instead of a latent space. The gradient of the loss function looks very similar to Equation¬†1. With respect to the Euclidean distance partial derivatives are of the following form:\n\\[\n\\begin{aligned}\n&&  \\frac{\\partial ||\\mathbf{x}_i^{'}-\\mathbf{x}_i||}{\\partial {x_i'}^{(d)}}  &= \\frac{{x_i'}^{(d)}-{x_i}^{(d)}}{||\\mathbf{x}_i^{'}-\\mathbf{x}_i||} \\\\\n\\end{aligned}\n\\]\nThe code that implements this optimization follows below.\n\n\nCode\n#' REVISE algoritm - a simplified version\n#'\n#' @param classifier The fitted classifier.\n#' @param x_star Attributes of individual seeking individual recourse.\n#' @param eta Learning rate.\n#' @param lambda Regularization parameter.\n#' @param n_iter Maximum number of operations.\n#' @param save_steps Boolean indicating if intermediate steps should be saved.\n#'\n#' @return\n#' @export\n#'\n#' @author Patrick Altmeyer\nrevise.classifier &lt;- function(classifier,x_star,eta=1,lambda=0.01,n_iter=1000,save_steps=FALSE) {\n  # Initialization: ----\n  d &lt;- length(x_star) # number of dimensions\n  if (!is.null(names(x_star))) {\n    d_names &lt;- names(x_star) # names of attributes, if provided\n  } else {\n    d_names &lt;- sprintf(\"X%i\", 1:d)\n  }\n  w &lt;- classifier$coefficients # coefficient vector\n  x &lt;- x_star # initialization of revised attributes\n  distance &lt;- 0 # initial distance from starting point\n  converged &lt;- predict(classifier, newdata = x)[1,1]==1 # positive outcome?\n  iter &lt;- 1 # counter\n  if (save_steps) {\n    steps &lt;- data.table(iter=1, x=x, d=d_names) # save intermediate steps, if desired\n  } else {\n    steps &lt;- NA\n  }\n  # Gradients:\n  grad &lt;- function(x,y,w) {\n    w %*% ifelse(crossprod(x,w) * y&lt;=1,-y,0) # gradient of Hinge loss with respect to X\n  }\n  grad_dist &lt;- function(x,x_star) {\n    d &lt;- length(x_star)\n    distance &lt;- dist(matrix(cbind(x_star,x),nrow=d,byrow = T))\n    matrix((x-x_star) / distance) # gradient of Euclidean distance with respect to X\n  }\n  # Gradient descent: ----\n  while(!converged & iter&lt;n_iter) {\n    if (distance!=0) {\n      x &lt;- c(x - eta * (grad(x=matrix(x),y=1,w) + lambda * grad_dist(x,x_star))) # gradient descent step\n    } else {\n      x &lt;- c(x - eta * grad(x=matrix(x),y=1,w)) # gradient with respect to distance not defined at zero\n    }\n    converged &lt;- predict(classifier, newdata = x)[1,1]==1 # positive outcome?\n    iter &lt;- iter + 1 # update counter\n    if (save_steps) {\n      steps &lt;- rbind(steps, data.table(iter=iter, x=x, d=d_names))\n    }\n    distance &lt;- dist(matrix(cbind(x_star,x),nrow=d,byrow = T)) # update distance\n  }\n  # Output: ----\n  if (converged) {\n    revise &lt;- x - x_star\n  } else {\n    revise &lt;- NA\n  }\n  output &lt;- list(\n    x_star = x_star,\n    revise = revise,\n    classifier = classifier,\n    steps = steps,\n    lambda = lambda,\n    distance = distance,\n    mean_distance = mean(abs(revise))\n  )\n  return(output)\n}\n\nrevise &lt;- function(classifier,x_star,eta=1,lambda=0.01,n_iter=1000,save_steps=FALSE) {\n  UseMethod(\"revise\")\n}\n\n\n\n\nSimulated data\nThe synthetic data describing cats and dogs was generated as follows:\n\n\nCode\nsim_data &lt;- function(n=100,averages,noise=0.1) {\n  d &lt;- ncol(averages)\n  y &lt;- 2*(rbinom(n,1,0.5)-0.5) # generate binary outcome: 1=dog, -1=cat\n  X &lt;- as.matrix(averages[(y+1)/2+1,]) # generate attributes conditional on y\n  dogs &lt;- y==1 # boolean index for dogs\n  cats &lt;- y==-1 # boolean index for cats\n  X[cats,] &lt;- X[cats,] + \n    matrix(rnorm(sum(cats)*d),nrow=sum(cats)) %*% diag(noise*averages[2,]) # add noise for y=1 (cats)\n  X[dogs,] &lt;- X[dogs,] + \n    matrix(rnorm(sum(dogs)*d),nrow=sum(dogs)) %*% diag(noise*averages[2,]) # add noise for y=1 (dogs)\n  return(list(X=X,y=y))\n}"
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html",
    "href": "blog/posts/guest-students-laplace/index.html",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "",
    "text": "Guest Blog Post\n\n\n\nThis blog post was originally written by Severin Bratus and colleagues from TU Delft and published on Medium. This version of the post includes only minor edits. If you would like to contribute a guest blog post, please get in touch.\nThis post summarizes a quarter-long second-year BSc coursework project at TU Delft. Our team of five students has made multiple improvements to LaplaceRedux.jl, due to Patrick Altmeyer. Inspired by its Pythonic counterpart, laplacet-torch, this Julia library aims to provide low-overhead Bayesian uncertainty calibration to deep neural networks via Laplace Approximations (Daxberger et al. 2021).\nWe will begin by demystifying the technical terms in the last sentence, in order to explain our contributions to the library and highlight some impressions from the experience. Note that our team has begun working on this PhD-tier subject only having had some introductory courses on probability and statistics, machine learning, and computational intelligence, without any prior exposure to Julia."
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html#bayesian-learning",
    "href": "blog/posts/guest-students-laplace/index.html#bayesian-learning",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "Bayesian Learning",
    "text": "Bayesian Learning\nUncertainty calibration remains a crucial issue in safety-critical applications of modern AI, as, for instance, in autonomous driving. You would want your car autopilot not only to make accurate predictions but also to indicate when a model prediction is uncertain, to give control back to the human driver.\nA model is well-calibrated if the confidence of a prediction matches its true error rate. Note that you can have well-fit models that are badly calibrated, and vice versa (just like in life, you meet smart people, yet annoyingly arrogant).\nThe standard deep learning training process of gradient descent converges at a weight configuration that minimizes the loss function. The model obtained may be great, yet it is only a point estimate of what the weight parameters should look like.\nHowever, with the sheer immensity of the weight space, neural networks are probably underspecified by the data (or, overfit). As neural networks can approximate highly complex functions, many weight configurations would yield roughly the same training loss, yet with varying abilities to generalize outside the training dataset. This is why there are so many regularization methods out there, to keep the models simpler. One radical, yet effective approach is described by LeCun, Denker, and Solla (1989):\n\n‚Ä¶ it is possible to take a perfectly reasonable network, delete half (or more) of the weights and wind up with a network that works just as well, or better.\n\n\n\n\nFigure¬†1: The loss landscape. One can imagine gradient descent as a particle, let‚Äôs say a ball, or a grain of sand, rolling to the bottom of a pit. Then for Bayesian Learning, we have as if a pile of sand poured around at that bottom point, with the pile being thicker where loss is lower. This proverbial sand pile would represent the posterior parameter distribution. Figure due to Amini et al. (2019)\n\n\nThe way gradient is usually illustrated is with a picture like the one shown in Figure¬†1 above a curved terrain of the loss function across the parameter space. Each point of the horizontal plane corresponds to some configuration of parameters. Gradient descent seeks the point at the bottom of this terrain, as the point with the lowest loss, however as the loss-curvature is highly non-convex and high-dimensional there are many directions in which we could move and still maintain a low loss. Thus instead of a singular point we would like to specify a probability distribution around that optimal point. Bayesian methods, and in particular Laplace Approximations, allow us to do this!\nFirstly, the Bayesian approach to neural network uncertainty calibration is that of modelling the posterior using Bayes‚Äô Theorem:\n\\[\np(\\theta \\mid \\mathcal{D}) = \\tfrac{1}{Z} \\,p(\\mathcal{D} \\mid \\theta) \\, p(\\theta), \\qquad Z:= p(\\mathcal{D}) = \\textstyle\\int p(\\mathcal{D} \\mid \\theta) \\, p(\\theta) \\,d\\theta\n\\]\nHere \\(p(\\mathcal{D} \\mid \\theta)\\) is the likelihood of the data given by the parameters \\(\\theta\\). The prior distribution \\(p(\\theta)\\) specifies our beliefs about what the model parameters would be prior to observing the data. Finally, the intractable constant \\(Z\\) is called the evidence: it characterizes the probability of observing \\(\\mathcal{D}\\) as a whole, across all possible parameter settings (see here for details).\nFor models returning a probability distribution (e.g.¬†classifiers), the loss is commonly defined as the negative log-likelihood. Thus if gradient descent minimizes loss, it maximizes the likelihood, producing the maximum likelihood estimate (MLE), which (assuming a uniform prior) also maximizes the posterior. This is why we call this point the maximum a posteriori, or the MAP. It makes sense to model this point as the mode of the posterior distribution, which could, for example, be a normal Gaussian distribution (see also the introductory post on this blog)."
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html#laplace-approximations",
    "href": "blog/posts/guest-students-laplace/index.html#laplace-approximations",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "Laplace Approximations",
    "text": "Laplace Approximations\nWe do this by a simple-yet-smart trick introduced back in the late 18th century by Pierre-Simon Laplace, the self-proclaimed ‚Äúgreatest French mathematician of his time‚Äù. In general, the Laplace Approximation (LA) aims to find a Gaussian approximation to a probability density (in our case, the posterior) defined over a set of continuous variables (in our case, the weights) (Bishop 2006). We can then estimate the loss (negative log-likelihood) as its second-order Taylor expansion:\n\\[\n\\mathcal{L}(\\mathcal{D}; \\theta) \\approx \\mathcal{L}(\\mathcal{D}; \\theta_\\text{MAP}) + \\tfrac{1}{2} (\\theta - \\theta_\\text{MAP})^\\intercal \\left( \\nabla^2 _\\theta \\mathcal{L}(\\mathcal{D}; \\theta) \\vert_{\\theta_\\text{MAP}} \\right)(\\theta - \\theta_\\text{MAP})\n\\]\nNote that the first-order Taylor term vanishes at the MAP since it contains the gradient, and the gradient is zero at MAP, since MAP is a maximum, by definition. What remains is the constant (zeroth-order) term, and the second-order term, containing the Hessian, which is a matrix of partial second-order derivatives.\nThen from this approximation, we can derive the long-sought multivariate normal distribution with the MAP as the mean, and the inverted Hessian as the covariance:\n\\[\np(\\theta \\mid \\mathcal{D}) \\approx N(\\theta; \\theta_\\text{MAP}, \\varSigma) \\qquad\\text{with}\\qquad \\varSigma := \\left( \\nabla^2_\\theta \\mathcal{L}(\\mathcal{D};\\theta) \\vert_{\\theta_\\text{MAP}} \\right)^{-1}\n\\]\nThe evidence \\(Z\\) is now also tractably approximated in closed form, allowing us to apply the Bayes‚Äô theorem, to obtain the posterior distribution \\(p(\\theta \\mid \\mathcal{D})\\). We can then express the posterior predictive distribution, for an input \\(x_*\\), prediction \\(f(x_*)\\), to obtain the probability for an output \\(y\\).\nThe evidence \\(Z\\) is now also tractably approximated in closed form, allowing us to apply the Bayes‚Äô theorem, to obtain the posterior distribution \\(p(\\theta \\mid \\mathcal{D})\\). We can then express the posterior predictive distribution, to obtain the probability for an output \\(y\\), given a prediction \\(f(x_*)\\) for an input \\(x_*\\).\n\\[\np(y \\mid f(x_*), \\mathcal{D}) = \\int p(y \\mid f_\\theta(x_*)) \\, p(\\theta \\mid \\mathcal{D}) \\,d\\theta\n\\]\nThis is what we are really after, after all ‚Äî instead of giving one singular point-estimate prediction \\(\\widehat{y} = f(x_*)\\), we make the neural network give a distribution over \\(y\\).\nHowever, since the Hessian, a square matrix, defines the covariance between all model parameters (upon inversion), of which there may be millions or billions, the computation and storage of the Hessian (not to speak of inversion!) become intractable, as its size scales quadratically with the number of parameters involved. Thus to apply Laplace approximations to large models, we must make some simplifications ‚Äî which brings us to‚Ä¶"
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html#hessian-approximations",
    "href": "blog/posts/guest-students-laplace/index.html#hessian-approximations",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "Hessian approximations",
    "text": "Hessian approximations\nMultiple techniques to approximate the Hessian have arisen from a field adjacent, yet distinct from Bayesian learning ‚Äî that of second-order optimization, where Hessians are used to accelerate gradient descent convergence.\nOne such approximation is the Fisher information matrix, or simply the Fisher:\n\\[\nF := \\textstyle\\sum_{n=1}^N \\mathbb{E}_{\\widehat{y} \\sim p(y \\mid f_\\theta(x_n))} \\left[  gg^\\intercal \\right] \\quad\\text{with}\\quad g = \\nabla_\\theta \\log p(\\widehat{y} \\mid f_\\theta(x_n)) \\large\\vert_{\\theta_\\text{MAP}}\n\\]\nNote that if instead of sampling the prediction \\(\\widehat{y} ~ p(y \\mid f(x_n))\\) from the model-defined distribution, we take the actual training-set label \\(y_n\\), the resulting matrix is called the empirical Fisher, which is distinct from the Fisher, yet aligns with it under some conditions, and does not generally capture second-order information. See Kunstner et al.¬†(2019) for an excellent discussion on the distinction.\nInstead of the Fisher, one can use the Generalized Gauss-Newton (GGN):\n\\[\nG := \\textstyle\\sum_{n=1}^N J(x_n) \\left( \\nabla^2_{f} \\log p(y_n \\mid f) \\Large\\vert_{f=f_{\\theta_\\text{map}}(x_n)} \\right) J(x_n)^\\intercal\n\\text{with}\\qquad J(x_n) := \\nabla_\\theta f_\\theta(x_n) \\vert_{\\theta_\\text{map}}\n\\]\nHere \\(J(x_n)\\) represents the Jacobian of the model output w.r.t. the parameters. The middle factor \\(\\nabla^2 ‚Ä¶\\) is a Hessian of log-likelihood of \\(y_n\\) w.r.t. model output. Note that the model does not necessarily output ready target probabilities ‚Äî for instance, classifiers output logits, values that define a probability distribution only after the application of the soft-max.\nUnlike the Fisher, GGN does not require the network to define a probabilistic model on its output (Botev, Ritter, and Barber 2017). For models defining an exponential family distribution over the output, the two coincide (Kunstner, Balles, and Hennig 2020). This applies to classifiers since they define a categorical distribution over the output, but not to simple regression models.\nThese matrices are quadratically large, it is infeasible to store them in full. The simplest estimation is to model the matrix as a diagonal ‚Äî however one can easily contemplate how crude this approximation can be: for 100 parameters, only 1% of the full Hessian is captured.\nA more sophisticated approach, due to Martens and Grosse (2015), is inspired by the observation that in practice the covariance matrices (i.e.¬†inverted Hessians) for neural networks are block-diagonal-dominant. Thus we can effectively model the covariance matrix (and hence the Fisher) as a block-diagonal matrix, where blocks correspond to parameters grouped by layers. Additionally, each block is decomposed into two Kronecker factors, reducing the size of data stored several magnitudes more, at a cost of another assumption.\nLastly, a novel approach is to sketch a low-rank approximation of the Fisher (Sharma, Azizan, and Pavone 2021). Figure¬†2 shows four Hessian approximation structures:\n\n\n\nFigure¬†2: (a) Hessian in full, intractable for large networks. (b) Low-rank. (c) Kronecker-factored Approximate Curvature, a block-diagonal method. (d) Diagonal. Source: Daxberger et al. (2021)\n\n\nIt is also possible to cut the costs by treating only a subset of the model parameters, i.e.¬†a subnetwork, probabilistically, fixing the remaining parameters at their MAP-estimated values. One special case of subnetwork Laplace that was found to perform well in practice is last-layer Laplace, where the selected subnetwork contains only the weights and biases of the last layer."
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html#our-contributions-to-laplaceredux.jl",
    "href": "blog/posts/guest-students-laplace/index.html#our-contributions-to-laplaceredux.jl",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "Our contributions to LaplaceRedux.jl",
    "text": "Our contributions to LaplaceRedux.jl\nIn the scope of the project we have added support for: - multi-class classification, in addition to regression and binary classification; - GGN, in addition to empirical Fisher; - hardware-parallelized batched computation of both the empirical Fisher and the GGN; - subnetwork and last-layer Laplace; - KFAC for multi-class classification with Fisher; and - interfacing with MLJ, a common machine learning framework for Julia.\nWe have also made quality assurance / quality-of-life additions to the repository, adding: - a formatting check in the CI/CD pipeline; - an extensive test suite comparing the results of LaplaceRedux.jl against those of its Python counter-part package laplace-torch; and - a benchmark pipeline tracking possible downturns in performance."
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html#methodology",
    "href": "blog/posts/guest-students-laplace/index.html#methodology",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "Methodology",
    "text": "Methodology\nWe adhered to the Agile/Scrum practices, with two-week-long sprints, and weekly meetings with our formal client, Patrick Altmeyer. We have prioritized the expected requirements by the Moscow method into must-, could-, should-, and won‚Äôt-haves. This is all fairly standard for BSc software projects at TU Delft. By the end of the project, we have completed all of our self-assigned must-haves and should-haves."
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html#pain-points",
    "href": "blog/posts/guest-students-laplace/index.html#pain-points",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "Pain Points",
    "text": "Pain Points\nHere we list some obstacles we have encountered along the way: - Julia is slow to compile and load dependencies on less powerful machines. - Stack traces are sometimes rather obscure, though it seems to be the price to pay for macros. - Zygote.jl, the automatic differentiation library, is not self-autodifferentiable ‚Äì it cannot differentiate its own functions. We would want this since we apply Zygote.jacobians when making predictions with the LA. - There is no accessible tool reporting branch coverage on tests ‚Äì only line coverage is available. - Limited LSP and Unicode support for Jupyter Lab. - Conversion between Flux and ONNX is not yet implemented. - There is no extension library for Zygote equivalent to BackPACK or ASDL for second-order information.\n\nZygote.jl, the automatic differentiation library, is not self-autodifferentiable: issue. We would want this since we apply Zygote.jacobians when making predictions with the LA.\nThere is no accessible tool reporting branch coverage on tests ‚Äì only line coverage is available.\nLimited LSP and Unicode support for Jupyter Lab.\nNo conversion between Flux and ONNX is implemented yet ONNX.jl\nThere is no extension library for Zygote equivalent to BackPACK or ASDL for second-order information."
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html#highlights",
    "href": "blog/posts/guest-students-laplace/index.html#highlights",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "Highlights",
    "text": "Highlights\nAnd here is what we found refreshing: - Metaprogramming and first-class support for macros are something completely different for students who are used to Java & Python. - The Julia standard API, and Flux/Zygote, are fairly straightforward to use, and well-thought-out for numerical computing and machine learning."
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html#conclusions",
    "href": "blog/posts/guest-students-laplace/index.html#conclusions",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "Conclusions",
    "text": "Conclusions\nWe have covered some elements of the theory behind Laplace Approximations, laid down our additions to the LaplaceRedux.jl package, and brought out some difficulties we, as complete newcomers to Julia, came across. Hope you have enjoyed the tour, and hopefully it has intrigued you enough to look deeper into Bayesian learning and/or Julia since both are developing at a lively pace. You can check out LaplaceRedux on the JuliaTrustworthyAI GitHub page here. Contributions and comments are welcome!"
  },
  {
    "objectID": "blog/posts/guest-students-laplace/index.html#acknowedgements",
    "href": "blog/posts/guest-students-laplace/index.html#acknowedgements",
    "title": "Paving the Way Towards Low-Overhead Uncertainty Calibration",
    "section": "Acknowedgements",
    "text": "Acknowedgements\nOur team members are Mark Ardman, Severin Bratus, Adelina Cazacu, Andrei Ionescu, and Ivan Makarov. We would like to thank Patrick Altmeyer for the opportunity to work on this unique project and for the continuous guidance throughout the development process. We are also grateful to Sebastijan Dumanƒçiƒá, our coach, Sven van der Voort, our TA mentor, and Antony Bartlett, our supporting advisor."
  },
  {
    "objectID": "blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html",
    "href": "blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html",
    "title": "A peek inside the ‚ÄòBlack Box‚Äô - interpreting neural networks",
    "section": "",
    "text": "Propelled by advancements in modern computer technology, deep learning has re-emerged as perhaps the most promising artificial intelligence (AI) technology of the last two decades. By treating problems as a nested, hierarchy of hidden layers deep artificial neural networks achieve the power and flexibility necessary for AI systems to navigate complex real-world environments. Unfortunately, their very nature has earned them a reputation as Black Box algorithms and their lack of interpretability remains a major impediment to their more wide-spread application.\nIn science, research questions usually demand not just answers but also explanations and variable selection is often as important as prediction (Ish-Horowicz et al. 2019). Economists, for example, recognise the undeniable potential of deep learning, but are rightly hesitant to employ novel tools that are not fully transparent and ultimately cannot be trusted. Similarly, real-world applications of AI have come under increasing scrutiny with regulators imposing that individuals influenced by algorithms should have the right to obtain explanations (Fan, Xiong, and Wang 2020). In high-risk decision-making fields such as AI systems that drive autonomous vehicles the need for explanations is self-evident (Ish-Horowicz et al. 2019).\nIn light of these challenges it is not surprising that research on explainable AI has recently gained considerable momentum (Arrieta et al. 2020). While in this short essay we will focus on deep learning in particular, it should be noted that this growing body of literature is concerned with a broader realm of machine learning models. The rest of this note is structured as follows: the first section provides a brief overview of recent advancements towards interpreting deep neural networks largely drawing on Fan, Xiong, and Wang (2020); the second section considers a novel entropy-based approach towards interpretability proposed by Crawford et al. (2019); finally, in the last section we will see how this approach can be applied to deep neural networks as proposed in Ish-Horowicz et al. (2019)."
  },
  {
    "objectID": "blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html#footnotes",
    "href": "blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html#footnotes",
    "title": "A peek inside the ‚ÄòBlack Box‚Äô - interpreting neural networks",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSimulatability describes the overall, high-level understandability of the mechanisms underlying the model ‚Äì put simply, the less complex the model, the higher its simulatability. Decomposability concerns the extent to which the model can be taken apart into smaller pieces ‚Äì neural networks by there very nature are compositions of multiple layers. Finally, algorithmic transparency refers to the extent to which the training of the algorithm is well-understood and to some extent observable ‚Äì since DNNs generally deal with optimization of non-convex functions and often lack unique solution they are inherently intransparent.‚Ü©Ô∏é\nFor more detail see for example here.‚Ü©Ô∏é\nFor simplicity I have omitted the deterministic bias term.‚Ü©Ô∏é"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome.",
    "section": "",
    "text": "Welcome.\nI‚Äôm a PhD Candidate in Trustworthy Artificial Intelligence at Delft University of Technology working on the intersection of Computer Science and Finance.\nMy current research revolves around Counterfactual Explanations and Probabilistic Machine Learning. Previously, I worked as an Economist for the Bank of England.\nI primarily code in Julia and publish through Quarto. Occasionally I also use R, Python and C++. As much as possible I contribute to open-source: Github.\nYou can find the code that builds this website using Quarto in this repo.\n\nNews\n\nOur work on Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals has been accepted at AAAI 2024 (main track). Details will follow soon!\nThe Taija package ecosystem for Trustworthy AI in Julia is slowly growing. If you‚Äôre interested in contributing, please get in touch!\nI recently gave a long presentation about faithful model explanations at the Dutch central bank (De Nederlandsche Bank). You can find the slides here.\nAs of September 15, 2023, I‚Äôm a third-year PhD student. I‚Äôm still loving the experience, although second year did get a bit rough at times. I‚Äôm looking forward to the next two years!\nIn one of my latest blog posts I put ConformalPrediction.jl to work and build a chatbot that can be used for Conformal Intent Recognition.\n\n\n\nFeatured Visual\n\n\n\nOne of my favorite animations from the blog: it shows how the posterior of a Bayesian neural network evolves as it observes new data.\n\n\n\n\nContact\nYou can best reach me via my work email or you can set up a chat."
  },
  {
    "objectID": "content/about/biography.html",
    "href": "content/about/biography.html",
    "title": "Patrick Altmeyer",
    "section": "",
    "text": "Researching Trustworthy Artificial Intelligence (AI) for Finance and Economics. I am an economist by background with an interest in cross-disciplinary research on the intersection of Trustworthy AI and Financial Economics. For my PhD in Trustworthy AI, I currently focus on Counterfactual Explanations and Probabilisitic Machine Learning under supervision of Cynthia Liem and Arie van Deursen at Delft University of Technology. I am also a member of the AI for Fintech Research Lab.\nPreviously, I worked as an economist for Bank of England where I was involved in research, monetary policy briefings and market intelligence. I hold two masters degrees from Barcelona School of Economics, one in Data Science and one in Finance. I also hold an undergraduate degree in Economics from the University of Edinburgh.\nüìÑ Resume: printable pdf or right here on this website."
  },
  {
    "objectID": "content/about/contact.html",
    "href": "content/about/contact.html",
    "title": "Patrick Altmeyer",
    "section": "",
    "text": "Contact\nYou can best reach me via my work email or you can set up a chat."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/index.html",
    "href": "content/talks/posts/2023-goethe/index.html",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "",
    "text": "Presentatieslides voor mijn eerste presentatie in het Nederlands."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/index.html",
    "href": "content/talks/posts/2023-julia-hpc-delft/index.html",
    "title": "Julia on HPC",
    "section": "",
    "text": "I gave a tutorial introducing a group of bachelor and master students to working with Julia on the DelftBlue supercomputer. The following topics were covered:\n\nNative and intuitive support for different forms of parallelization offered by CounterfactualExplanations.jl.\nCommon challenges and solutions when working with Julia on one of TU Delft‚Äôs clusters (see also this unpolished repo with examples).\nInteractive session where students were guided towards running their first benchmark of counterfactual explanations on DelftBlue (see also docs).\n\nYou can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/index.html",
    "href": "content/talks/posts/2023-ieee-satml/index.html",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "",
    "text": "In February 2023, I presented our paper ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse‚Äù at the first IEEE SaTML conference. You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/index.html",
    "href": "content/talks/posts/2023-delft-fintech/index.html",
    "title": "Echos from the Black Box",
    "section": "",
    "text": "In May 2023, I presented some of our work at the Delft FinTech Lab Launch organized by Mondai House of AI. You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/index.html",
    "href": "content/talks/posts/2024-aaai/index.html",
    "title": "Faithful Model Explanations through Energy-Based Conformal Counterfactuals",
    "section": "",
    "text": "In February 2024, I will present our work on Faithful Model Explanations through Energy-Based Conformal Counterfactuals at AAAI 2024."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/index.html#slides",
    "href": "content/talks/posts/2024-aaai/index.html#slides",
    "title": "Faithful Model Explanations through Energy-Based Conformal Counterfactuals",
    "section": "Slides",
    "text": "Slides\nYou can find the slides below or click here to open them in full screen.\nFor the PDF version of the slides use this link instead.\nFor more information about the paper see also here or the preprint of the paper itself."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/index.html#poster",
    "href": "content/talks/posts/2024-aaai/index.html#poster",
    "title": "Faithful Model Explanations through Energy-Based Conformal Counterfactuals",
    "section": "Poster",
    "text": "Poster\nYou can find the poster below or click here to open it in full screen."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/index.html",
    "href": "content/talks/posts/2023-insurance-academy/index.html",
    "title": "Faithful Model Explanations",
    "section": "",
    "text": "In October 2023, I presented some of our work at the Datamiddag 2023: van PET tot Haring organized by the Dutch Association of Insurers (Verbond van Verzekeraas). You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/index.html",
    "href": "content/talks/posts/2022-julia-eindhoven/index.html",
    "title": "A year of using Quarto with Julia",
    "section": "",
    "text": "In November, 2022, I gave talked about how I‚Äôve been using Quarto with Julia for the past year. You can find the slides below or click here to open them in full screen. There is also a companion blog post here"
  },
  {
    "objectID": "content/talks/posts/2023-ictopen/index.html",
    "href": "content/talks/posts/2023-ictopen/index.html",
    "title": "Taija - Trustworthy AI in Julia",
    "section": "",
    "text": "In April 2023, I gave a demo at the NWO ICT.Open about our ongoing efforts to build and grow Taija: an Open-Source ecosystem for Trustworthy Artificial Intelligence in Julia. You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/index.html",
    "href": "content/talks/posts/2022-dscc/index.html",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "",
    "text": "In November 2022, I gave a one-hour presentation about Counterfactual Explanations at the ING Data Science Community Conference (DSCC) 2022. You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/index.html",
    "href": "content/talks/posts/2023-dnb/index.html",
    "title": "Faithful Model Explanations",
    "section": "",
    "text": "In November 2023, I presented some of our work at the Dutch Central Bank (De Nederlandsche Bank). You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2022-boe/index.html",
    "href": "content/talks/posts/2022-boe/index.html",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "",
    "text": "In November 2022, I gave a New Methods Seminar at the Bank of England. You can find the slides below or click here to open them in a new tab."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/quarto.html#quarto-a-new-old-way-to-publish-science",
    "href": "content/talks/posts/2022-juliacon/quarto.html#quarto-a-new-old-way-to-publish-science",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "Quarto ‚Äì A New (Old) Way to Publish Science",
    "text": "Quarto ‚Äì A New (Old) Way to Publish Science\n\nHave used R Markdown for many years for essentially anything work-related.\nGenerate multiple different output formats with ease:\n\nThe old school: LaTeX and PDF (including Beamer); MS Office\nThe brave new world: beautiful HTML content\n\nwebsites\ne-books\napps\n‚Ä¶\n\n\nAll of this starting from the same place ‚Ä¶\n\n\nA plain Markdown document blended with your favourite programming language of your choice and a YAML header defining your output."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/quarto.html#julia-and-quarto-a-perfect-match",
    "href": "content/talks/posts/2022-juliacon/quarto.html#julia-and-quarto-a-perfect-match",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "Julia and Quarto: a perfect match üíôüíúüíö",
    "text": "Julia and Quarto: a perfect match üíôüíúüíö\n\n\n\n\nPreferred setup: VSCode, Quarto and Julia\n\nCan switch between Jupyter and .qmd with ease.\nWhen working with .qmd, code chunks connect to REPL.\n\n\n\n\nDocumenter.jl and Quarto\n\nGenerally play nicely with each other (both Markdown based).\n\nformat: \n  commonmark:\n    variant: -raw_html\n\nYou get some stuff for free, e.g.¬†citation management.\nUnfotunately lose support for cross-referencing ‚Ä¶\n\n\n\n\nSuggestion: Quarto for JuliaCon Proceedings\n\nQuarto supports LaTex templates/classes ‚Ä¶\n‚Ä¶ but why only publish proceedings in PDF form?\nQuarto opens gateway to more innovative forms of publishing!\n\n\n\n\n\nCode\nusing Javis, Animations, Colors\nwww_path = \"www\"\n\nsize = 600\nradius_factor = 0.33\n\nfunction ground(args...)\n    background(\"transparent\")\n    sethue(\"white\")\nend\n\nfunction rotate_anim(idx::Number, total::Number) \n    distance_circle = 0.875\n    steps = collect(range(distance_circle,1-distance_circle,length=total))\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [0, steps[idx]*2œÄ],\n        [sineio()],\n    )\nend\n\ntranslate_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(size*radius_factor, 0)],\n    [sineio()],\n)\n\ntranslate_back_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(-(size*radius_factor), 0)],\n    [sineio()],\n)\n\njulia_colours = Dict(\n    :blue =&gt; \"#4063D8\",\n    :green =&gt; \"#389826\",\n    :purple =&gt; \"#9558b2\",\n    :red =&gt; \"#CB3C33\"\n)\ncolour_order = [:red, :purple, :green, :blue]\nn_colours = length(julia_colours)\nfunction color_anim(start_colour::String, quarto_col::String=\"#4b95d0\")\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [Lab(color(start_colour)), Lab(color(quarto_col))],\n        [sineio()],\n    )\nend\n\nvideo = Video(size, size)\n\nframe_starts = 1:10:40\nn_total = 250\nn_frames = 150\nBackground(1:n_total, ground)\n\n# Blob:\nfunction element(; radius = 1)\n    circle(O, radius, :fill) # The 4 is to make the circle not so small\nend\n\n# Cross:\nfunction cross(color=\"black\";orientation=:horizontal)\n    sethue(color)\n    setline(10)\n    if orientation==:horizontal\n        out = line(Point(-size,0),Point(size,0), :stroke)\n    else\n        out = line(Point(0,-size),Point(0,size), :stroke)\n    end\n    return out\nend\n\nfor (i, frame_start) in enumerate(1:10:40)\n\n    # Julia circles:\n    blob = Object(frame_start:n_total, (args...;radius=1) -&gt; element(;radius=radius))\n    act!(blob, Action(1:Int(round(n_frames*0.25)), change(:radius, 1 =&gt; 75))) # scale up\n    act!(blob, Action(n_frames:(n_frames+50), change(:radius, 75 =&gt; 250))) # scale up further\n    act!(blob, Action(1:30, translate_anim, translate()))\n    act!(blob, Action(31:120, rotate_anim(i, n_colours), rotate_around(Point(-(size*radius_factor), 0))))\n    act!(blob, Action(121:150, translate_back_anim, translate()))\n    act!(blob, Action(1:150, color_anim(julia_colours[colour_order[i]]), sethue()))\n\n    # Quarto cross:\n    cross_h = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:horizontal))\n    cross_v = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:vertical))\nend\n\nrender(\n    video;\n    pathname = joinpath(www_path, \"intro.gif\"),\n)\n\n\n\n\n\nFigure¬†1: Julia and Quarto: a perfect match. Image by author (heavily borrowing from Javis.jl tutorial)"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/quarto.html#more-resources",
    "href": "content/talks/posts/2022-juliacon/quarto.html#more-resources",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nRelated blog post (hosted on a blog that itself is built with Quarto and involves lots of Julia content).\nExamples of Julia package documentation I‚Äôve built with Quarto + Documenter.jl:\n\nCounterfactualExplanations.jl\nLaplaceRedux.jl\n\nQuarto‚Äôs own guide to using Quarto with Julia.\n\n\n\n\n\n                   \n\n\n\n\n\n\n\n\nJulia and Quarto: a match made in heaven? üå§ ‚Äì JuliaCon 2022 ‚Äì Patrick Altmeyer"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/index.html",
    "href": "content/talks/posts/2022-juliacon/index.html",
    "title": "JuliaCon 2022",
    "section": "",
    "text": "In July, 2022, I gave three different talks at JuliaCon 2022."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/index.html#explaining-black-box-models-through-counterfactuals",
    "href": "content/talks/posts/2022-juliacon/index.html#explaining-black-box-models-through-counterfactuals",
    "title": "JuliaCon 2022",
    "section": "Explaining Black-Box Models through Counterfactuals",
    "text": "Explaining Black-Box Models through Counterfactuals\nYou can watch the video below. See here for the slides."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/index.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "href": "content/talks/posts/2022-juliacon/index.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "title": "JuliaCon 2022",
    "section": "Effortless Bayesian Deep Learning through Laplace Redux",
    "text": "Effortless Bayesian Deep Learning through Laplace Redux\nYou can watch the video below. See here for the slides."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/index.html#julia-and-quarto-a-match-made-in-heaven",
    "href": "content/talks/posts/2022-juliacon/index.html#julia-and-quarto-a-match-made-in-heaven",
    "title": "JuliaCon 2022",
    "section": "Julia and Quarto: a Match Made in Heaven? üå§Ô∏è",
    "text": "Julia and Quarto: a Match Made in Heaven? üå§Ô∏è\nSee here for the slides."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/index.html",
    "href": "content/talks/posts/2023-juliacon/index.html",
    "title": "Predictive Uncertainty Quantification in Machine Learning",
    "section": "",
    "text": "In July 2023, I gave a talk at JuliaCon 2023 on Predictive Uncertainty Quantification in Machine Learning using ConformalPrediction.jl. The conference was held in person at MIT in Cambridge, Massachusetts. You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/news.html",
    "href": "content/news.html",
    "title": "Patrick Altmeyer",
    "section": "",
    "text": "News\n\nOur work on Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals has been accepted at AAAI 2024 (main track). Details will follow soon!\nThe Taija package ecosystem for Trustworthy AI in Julia is slowly growing. If you‚Äôre interested in contributing, please get in touch!\nI recently gave a long presentation about faithful model explanations at the Dutch central bank (De Nederlandsche Bank). You can find the slides here.\nAs of September 15, 2023, I‚Äôm a third-year PhD student. I‚Äôm still loving the experience, although second year did get a bit rough at times. I‚Äôm looking forward to the next two years!\nIn one of my latest blog posts I put ConformalPrediction.jl to work and build a chatbot that can be used for Conformal Intent Recognition.\n\n\n\nFeatured Visual\n\n\n\nOne of my favorite animations from the blog: it shows how the posterior of a Bayesian neural network evolves as it observes new data."
  },
  {
    "objectID": "content/publications/posts/jcon-ce/index.html",
    "href": "content/publications/posts/jcon-ce/index.html",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "",
    "text": "We present CounterfactualExplanations.jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia. CE explain how inputs into a model need to change to yield specific model predictions. Explanations that involve realistic and actionable changes can be used to provide AR: a set of proposed actions for individuals to change an undesirable outcome for the better. In this article, we discuss the usefulness of CE for Explainable Artificial Intelligence and demonstrate the functionality of our package. The package is straightforward to use and designed with a focus on customization and extensibility. We envision it to one day be the go-to place for explaining arbitrary predictive models in Julia through a diverse suite of counterfactual generators.\nFull paper: please find all available versions here."
  },
  {
    "objectID": "content/publications/posts/jcon-ce/index.html#abstract",
    "href": "content/publications/posts/jcon-ce/index.html#abstract",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "",
    "text": "We present CounterfactualExplanations.jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia. CE explain how inputs into a model need to change to yield specific model predictions. Explanations that involve realistic and actionable changes can be used to provide AR: a set of proposed actions for individuals to change an undesirable outcome for the better. In this article, we discuss the usefulness of CE for Explainable Artificial Intelligence and demonstrate the functionality of our package. The package is straightforward to use and designed with a focus on customization and extensibility. We envision it to one day be the go-to place for explaining arbitrary predictive models in Julia through a diverse suite of counterfactual generators.\nFull paper: please find all available versions here."
  },
  {
    "objectID": "content/publications/posts/satml-2023/index.html",
    "href": "content/publications/posts/satml-2023/index.html",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "",
    "text": "Existing work on Counterfactual Explanations (CE) and Algorithmic Recourse (AR) has largely focused on single individuals in a static environment: given some estimated model, the goal is to find valid counterfactuals for an individual instance that fulfill various desiderata. The ability of such counterfactuals to handle dynamics like data and model drift remains a largely unexplored research challenge. There has also been surprisingly little work on the related question of how the actual implementation of recourse by one individual may affect other individuals. Through this work, we aim to close that gap. We first show that many of the existing methodologies can be collectively described by a generalized framework. We then argue that the existing framework does not account for a hidden external cost of recourse, that only reveals itself when studying the endogenous dynamics of recourse at the group level. Through simulation experiments involving various state-of-the-art counterfactual generators and several benchmark datasets, we generate large numbers of counterfactuals and study the resulting domain and model shifts. We find that the induced shifts are substantial enough to likely impede the applicability of Algorithmic Recourse in some situations. Fortunately, we find various strategies to mitigate these concerns. Our simulation framework for studying recourse dynamics is fast and open-sourced.\nFull paper: please find all available versions here.\n\n\n\nPhoto taken during poster session following my presentation at SaTML."
  },
  {
    "objectID": "content/publications/posts/satml-2023/index.html#abstract",
    "href": "content/publications/posts/satml-2023/index.html#abstract",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "",
    "text": "Existing work on Counterfactual Explanations (CE) and Algorithmic Recourse (AR) has largely focused on single individuals in a static environment: given some estimated model, the goal is to find valid counterfactuals for an individual instance that fulfill various desiderata. The ability of such counterfactuals to handle dynamics like data and model drift remains a largely unexplored research challenge. There has also been surprisingly little work on the related question of how the actual implementation of recourse by one individual may affect other individuals. Through this work, we aim to close that gap. We first show that many of the existing methodologies can be collectively described by a generalized framework. We then argue that the existing framework does not account for a hidden external cost of recourse, that only reveals itself when studying the endogenous dynamics of recourse at the group level. Through simulation experiments involving various state-of-the-art counterfactual generators and several benchmark datasets, we generate large numbers of counterfactuals and study the resulting domain and model shifts. We find that the induced shifts are substantial enough to likely impede the applicability of Algorithmic Recourse in some situations. Fortunately, we find various strategies to mitigate these concerns. Our simulation framework for studying recourse dynamics is fast and open-sourced.\nFull paper: please find all available versions here.\n\n\n\nPhoto taken during poster session following my presentation at SaTML."
  },
  {
    "objectID": "content/publications/posts/boe/index.html",
    "href": "content/publications/posts/boe/index.html",
    "title": "Yield curve sensitivity to investor positioning around economic shocks",
    "section": "",
    "text": "Speculative trading activity may either support efficient market functioning or introduce price distortions. Using granular, daily EMIR Trade Repository data on short sterling futures, we investigate the interaction of speculative trading and macroeconomic shocks on UK yield curve pricing over a 16-month sample period from 2018 to 2020. Our results are largely consistent with efficient market functioning throughout the period, although we find some evidence that short speculative positions amplified yield curve moves in response to Brexit shocks, while long speculative positions had a dampening effect.\nFull paper: please find all available versions here."
  },
  {
    "objectID": "content/publications/posts/boe/index.html#abstract",
    "href": "content/publications/posts/boe/index.html#abstract",
    "title": "Yield curve sensitivity to investor positioning around economic shocks",
    "section": "",
    "text": "Speculative trading activity may either support efficient market functioning or introduce price distortions. Using granular, daily EMIR Trade Repository data on short sterling futures, we investigate the interaction of speculative trading and macroeconomic shocks on UK yield curve pricing over a 16-month sample period from 2018 to 2020. Our results are largely consistent with efficient market functioning throughout the period, although we find some evidence that short speculative positions amplified yield curve moves in response to Brexit shocks, while long speculative positions had a dampening effect.\nFull paper: please find all available versions here."
  },
  {
    "objectID": "content/publications/posts/aaai-2024/index.html",
    "href": "content/publications/posts/aaai-2024/index.html",
    "title": "Faithful Model Explanations through Energy-Based Conformal Counterfactuals",
    "section": "",
    "text": "Counterfactual explanations offer an intuitive and straightforward way to explain black-box models and offer algorithmic recourse to individuals. To address the need for plausible explanations, existing work has primarily relied on surrogate models to learn how the input data is distributed. This effectively reallocates the task of learning realistic explanations for the data from the model itself to the surrogate. Consequently, the generated explanations may seem plausible to humans but need not necessarily describe the behaviour of the black-box model faithfully. We formalise this notion of faithfulness through the introduction of a tailored evaluation metric and propose a novel algorithmic framework for generating Energy-Constrained Conformal Counterfactuals that are only as plausible as the model permits. Through extensive empirical studies, we demonstrate that ECCCo reconciles the need for faithfulness and plausibility. In particular, we show that for models with gradient access, it is possible to achieve state-of-the-art performance without the need for surrogate models. To do so, our framework relies solely on properties defining the black-box model itself by leveraging recent advances in energy-based modelling and conformal prediction. To our knowledge, this is the first venture in this direction for generating faithful counterfactual explanations. Thus, we anticipate that ECCCo can serve as a baseline for future research. We believe that our work opens avenues for researchers and practitioners seeking tools to better distinguish trustworthy from unreliable models.\nFull paper: please find all available versions here (preprint)."
  },
  {
    "objectID": "content/publications/posts/aaai-2024/index.html#abstract",
    "href": "content/publications/posts/aaai-2024/index.html#abstract",
    "title": "Faithful Model Explanations through Energy-Based Conformal Counterfactuals",
    "section": "",
    "text": "Counterfactual explanations offer an intuitive and straightforward way to explain black-box models and offer algorithmic recourse to individuals. To address the need for plausible explanations, existing work has primarily relied on surrogate models to learn how the input data is distributed. This effectively reallocates the task of learning realistic explanations for the data from the model itself to the surrogate. Consequently, the generated explanations may seem plausible to humans but need not necessarily describe the behaviour of the black-box model faithfully. We formalise this notion of faithfulness through the introduction of a tailored evaluation metric and propose a novel algorithmic framework for generating Energy-Constrained Conformal Counterfactuals that are only as plausible as the model permits. Through extensive empirical studies, we demonstrate that ECCCo reconciles the need for faithfulness and plausibility. In particular, we show that for models with gradient access, it is possible to achieve state-of-the-art performance without the need for surrogate models. To do so, our framework relies solely on properties defining the black-box model itself by leveraging recent advances in energy-based modelling and conformal prediction. To our knowledge, this is the first venture in this direction for generating faithful counterfactual explanations. Thus, we anticipate that ECCCo can serve as a baseline for future research. We believe that our work opens avenues for researchers and practitioners seeking tools to better distinguish trustworthy from unreliable models.\nFull paper: please find all available versions here (preprint)."
  },
  {
    "objectID": "content/publications/index.html",
    "href": "content/publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "Below you may find a list of featured publications. For a full list, see my Google Scholar profile.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Year - Oldest\n        \n         \n          Year - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nYear\n\n\nVenue\n\n\nDescription\n\n\n\n\n\n\nFaithful Model Explanations through Energy-Based Conformal Counterfactuals\n\n\n2024\n\n\nThe 38th Annual AAAI Conference on Artificial Intelligence\n\n\nWe present a novel framework for generating faithful counterfactual explanations that solely on properties defining the black-box model itself by leveraging recent advances in energy-based modelling and conformal prediction.\n\n\n\n\nExplaining Black-Box Models through Counterfactuals\n\n\n2023\n\n\nJuliaCon Proceedings\n\n\nWe present CounterfactualExplanations.jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia.\n\n\n\n\nYield curve sensitivity to investor positioning around economic shocks\n\n\n2023\n\n\nBank of England Staff Working Paper\n\n\nUsing granular, daily EMIR Trade Repository data on short sterling futures, we investigate the interaction of speculative trading and macroeconomic shocks on UK yield curve pricing.\n\n\n\n\nEndogenous Macrodynamics in Algorithmic Recourse\n\n\n2023\n\n\nIEEE Conference on Secure and Trustworthy Machine Learning (SaTML)\n\n\nWe present evidence suggesting that state-of-the-art applications of Algorithmic Recourse to groups of individuals induce large domain and model shifts and propose ways to mitigate this.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#talk-agenda",
    "href": "content/talks/posts/2023-juliacon/presentation.html#talk-agenda",
    "title": "ConformalPrediction.jl",
    "section": "Talk Agenda1",
    "text": "Talk Agenda1\n\n\n\nIntroduction (5min)\nApplications (5min)\nInteractive demo of ConformalPrediction.jl (10min)\nUnder Construction (5min)\nQ&A\n\n\n\nCode along üíª tinyurl.com/cpjcon2023\n\n\n\n\nFeeling lucky? Use binder!\n\n\n\n\nLink to slides: tinyurl.com/cpjcon2023slides"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-prediction",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-prediction",
    "title": "ConformalPrediction.jl",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nConformal Prediction involves turning heuristic measures of Predictive Uncertainty into rigorous ones.\n\n\n\nA first crucial step towards building trustworthy AI systems is to be transparent about predictive uncertainty."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#example-split-cp",
    "href": "content/talks/posts/2023-juliacon/presentation.html#example-split-cp",
    "title": "ConformalPrediction.jl",
    "section": "Example: Split CP",
    "text": "Example: Split CP\n\nProper training set and separate calibration set: \\(\\mathcal{D}_n=\\mathcal{D}^{\\text{train}} \\cup \\mathcal{D}^{\\text{cali}}\\).\nTrain model on proper training set: \\(\\hat\\mu_{i \\in \\mathcal{D}^{\\text{train}}}(X_i,Y_i)\\).\nCompute nonconformity scores, \\(\\mathcal{S}\\), using calibration data \\(\\mathcal{D}^{\\text{cali}}\\) and fitted model \\(\\hat\\mu_{i \\in \\mathcal{D}^{\\text{train}}}\\).\nFor user-specified coverage ratio \\((1-\\alpha)\\) compute the corresponding quantile, \\(\\hat{q}\\), of \\(\\mathcal{S}\\).\nFor the given quantile and test sample \\(X_{\\text{test}}\\), form the corresponding conformal prediction set: \\(C(X_{\\text{test}})=\\{y:s(X_{\\text{test}},y) \\le \\hat{q}\\}\\).\n\n\n\n\n\n\n\nBlog posts\n\n\n\nConformal Classification ([blog], [TDS], [Forem])\nConformal Regression ([blog], [TDS], [Forem])"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#split-cp-illustrated",
    "href": "content/talks/posts/2023-juliacon/presentation.html#split-cp-illustrated",
    "title": "ConformalPrediction.jl",
    "section": "Split CP illustrated",
    "text": "Split CP illustrated\n\nFigure¬†1: Softmax output for class 1 (top left); non-conformity scores for calibration set (top right); (1-Œ±)-quantile (bottom left); non-conformity function applied to test point (bottom right). Solid bars make it into prediction set."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#cp-meets-sr",
    "href": "content/talks/posts/2023-juliacon/presentation.html#cp-meets-sr",
    "title": "ConformalPrediction.jl",
    "section": "CP meets SR",
    "text": "CP meets SR\nRemember SymbolicRegression.jl by Miles Cranmer?\n\n\n\n\n# Standard MLJ workflow:\nusing MLJ\nimport SymbolicRegression: SRRegressor\nmodel = SRRegressor(\n  niterations=50,\n  binary_operators=[+, -, *],\n  unary_operators=[sin],\n)\n\n# Conformalize:\nusing ConformalPrediction\nconf_model = conformal_model(model)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-chatbot",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-chatbot",
    "title": "ConformalPrediction.jl",
    "section": "Conformal Chatbot",
    "text": "Conformal Chatbot\n\nOverviewDemo\n\n\n\n\n\nFigure¬†2: High-level overview of Conformal Intent Classifier. Won 1st üèÜ at ING Global Experiment Week 2023.\n\n\n\n\n\n\n\n\n\nFigure¬†3: Demo of a REPL-based conformalized intent classifier.\n\n\n\nCICC substantially outperforms baseline approaches (e.g.¬†top-\\(K\\)).\n\n\n\n\n\n\nBlog post\n\n\nBuilding a Conformal Chatbot in Julia (blog, TDS)"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-image-classifier",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-image-classifier",
    "title": "ConformalPrediction.jl",
    "section": "Conformal Image Classifier",
    "text": "Conformal Image Classifier\n\n\nA simple MNIST classifier.\n# MLJFlux workflow:\nusing MLJFlux\nImageClassifier = @load ImageClassifier\n\n# Conformalize:\nusing ConformalPrediction\nconf_model = conformal_model(clf)\nmach = machine(conf_model, X, y)\nfit!(mach)\n\n\n\n\nFigure¬†4: Probably a 7 ü§î\n\n\n\n\n\n\n\n\n\n\nBlog post\n\n\nHow to Conformalize a Deep Image Classifier (blog, TDS, Forem)"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#time-series",
    "href": "content/talks/posts/2023-juliacon/presentation.html#time-series",
    "title": "ConformalPrediction.jl",
    "section": "Time Series",
    "text": "Time Series\n\n\nEnsemble Batch Prediction Intervals (Xu and Xie 2021) contributed by Mojtaba Farmanbar üì£.\n\n\n\n\n\n\nTutorial\n\n\nHow to Conformalize a Time Series Model (docs)\n\n\n\n\n\n\n\nFigure¬†5: EnbPI for Victoria electricity demand dataset."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-laplaceredux.jl",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-laplaceredux.jl",
    "title": "ConformalPrediction.jl",
    "section": "Conformal LaplaceRedux.jl",
    "text": "Conformal LaplaceRedux.jl\n\n\n\nPredictive posterior as heuristic (Angelopoulos and Bates 2022).\nImportance Sampling (Fong and Holmes 2021).\n\n\n\n\n\n\n\n\n\n\n\nContribute\n\n\nLaplaceRedux.jl interfaced to MLJFlux.jl. Planning to add both ideas [#64]."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-counterfactuals",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-counterfactuals",
    "title": "ConformalPrediction.jl",
    "section": "Conformal Counterfactuals",
    "text": "Conformal Counterfactuals\n\n\n\nStutz et al. (2022) introduce Conformal Training: conformal predictions (left), set size (centre) and smooth set size loss (right).\n\n\n\n\n\n\n\nConformal CounterfactualExplanations.jl.\n\n\n\n\n\n\n\n\n\nContribute\n\n\nCurrently working on full conformal training implementation [#62]."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#trustworthy-ai-in-julia",
    "href": "content/talks/posts/2023-juliacon/presentation.html#trustworthy-ai-in-julia",
    "title": "ConformalPrediction.jl",
    "section": "Trustworthy AI in Julia",
    "text": "Trustworthy AI in Julia\n\n\nTaija collects Julia packages geared towards Trustworthy AI:\n\nCounterfactualExplanations.jl\nConformalPrediction.jl\nLaplaceRedux.jl\nJointEnergyModels.jl\n‚Ä¶\n\n\nContributions welcome! üòä"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#references",
    "href": "content/talks/posts/2023-juliacon/presentation.html#references",
    "title": "ConformalPrediction.jl",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nAngelopoulos, Anastasios N., and Stephen Bates. 2022. ‚ÄúA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.‚Äù https://arxiv.org/abs/2107.07511.\n\n\nFong, Edwin, and Chris Holmes. 2021. ‚ÄúConformal Bayesian Computation.‚Äù arXiv. https://doi.org/10.48550/arXiv.2106.06137.\n\n\nStutz, David, Krishnamurthy, Dvijotham, Ali Taylan Cemgil, and Arnaud Doucet. 2022. ‚ÄúLearning Optimal Conformal Classifiers.‚Äù https://arxiv.org/abs/2110.09192.\n\n\nXu, Chen, and Yao Xie. 2021. ‚ÄúConformal Prediction Interval for Dynamic Time-Series.‚Äù In, 11559‚Äì69. PMLR. https://proceedings.mlr.press/v139/xu21h.html."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#overview",
    "href": "content/talks/posts/2022-juliacon/laplace.html#overview",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Overview",
    "text": "Overview\n\n\nThe Case for Bayesian Deep Learning\nLaplace Redux in Julia üì¶\n\nFrom Bayesian Logistic Regression ‚Ä¶\n‚Ä¶ to Bayesian Neural Networks.\n\nGoals and Ambitions üéØ"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#bayesian-model-averaging",
    "href": "content/talks/posts/2022-juliacon/laplace.html#bayesian-model-averaging",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Bayesian Model Averaging",
    "text": "Bayesian Model Averaging\n\nDon‚Äôt put all your ü•ö in one üß∫.\n\n\n\nIn Deep Learning we typically maximise highly non-convex functions full of local optima and saddle points.\nThere may be many \\(\\hat\\theta_1, ..., \\hat\\theta_m\\) that are slightly different, but yield similar performance.\n\n\n\n\n[‚Ä¶] parameters correspond to a diverse variety of compelling explanations for the data. (Wilson 2020)\n\n\n\n\\(\\theta\\) is a random variable. Shouldn‚Äôt we treat it that way?\n\\[\np(y|x,\\mathcal{D}) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D})d\\theta\n\\qquad(1)\\]\n\nIntractable!\n\n\n\nIn practice we typically rely on a plugin approximation (Murphy 2022).\n\\[\np(y|x,\\mathcal{D}) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D})d\\theta \\approx p(y|x,\\hat\\theta)\n\\qquad(2)\\]\n\nYes, ‚Äúplugin‚Äù is literal ‚Ä¶ can we do better?"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#enter-bayesian-deep-learning",
    "href": "content/talks/posts/2022-juliacon/laplace.html#enter-bayesian-deep-learning",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Enter: Bayesian Deep Learning üîÆ",
    "text": "Enter: Bayesian Deep Learning üîÆ\n\nYes, we can!\n\n\n\nPopular approaches include ‚Ä¶\n\n\nMCMC (see Turing)\n\n\nVariational Inference (Blundell et al. 2015)\n\n\nMonte Carlo Dropout (Gal and Ghahramani 2016)\n\n\nDeep Ensembles (Lakshminarayanan, Pritzel, and Blundell 2017)\n\n\n\nLaplace Redux (Immer, Korzepa, and Bauer (2020),Daxberger et al. (2021))\n\n. . .\n\n\n\nFigure¬†1: Pierre-Simon Laplace as chancellor of the Senate under the First French Empire. Source: Wikipedia\n\n\n\n\n\n\nFigure¬†2: Simulation of changing posteriour predictive distribution. Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#laplace-approximation",
    "href": "content/talks/posts/2022-juliacon/laplace.html#laplace-approximation",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Laplace Approximation",
    "text": "Laplace Approximation\n\nWe first need to estimate the weight posterior \\(p(\\theta|\\mathcal{D})\\) ‚Ä¶\n\n\nIdea üí°: Taylor approximation at the mode.\n\n\nGoing through the maths we find that this yields a Gaussian posteriour centered around the MAP estimate \\(\\hat\\theta\\) (see pp.¬†148/149 in Murphy (2022)).\nCovariance corresponds to inverse Hessian at the mode (in practice we may have to rely on approximations).\n\n\n\n\n\n\n\nUnnormalized log-posterior and corresponding Laplace Approximation. Source: Murphy (2022).\n\n\n\nNow we can rely on MC or Probit Approximation to compute posterior predictive (classification)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#laplaceredux.jl---a-small-package",
    "href": "content/talks/posts/2022-juliacon/laplace.html#laplaceredux.jl---a-small-package",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "LaplaceRedux.jl - a small package üì¶",
    "text": "LaplaceRedux.jl - a small package üì¶\n  \n\nWhat started out as my first coding project Julia ‚Ä¶\n\n\n\nBig fan of learning by coding so after reading the first chapters of Murphy (2022) I decided to code up Bayesian Logisitic Regression from scratch.\nI also wanted to learn Julia at the time, so tried to hit two birds with one stone.\nOutcome: 1. This blog post. 2. I have since been hooked on Julia.\n\n\n\n\n‚Ä¶ has turned into a small package üì¶ with great potential.\n\n\n\nWhen coming across the NeurIPS 2021 paper on Laplace Redux for deep learning (Daxberger et al. 2021), I figured I could step it up a notch.\nOutcome: LaplaceRedux.jl and another blog post.\n\n\n\n\nSo let‚Äôs add the package ‚Ä¶\nusing Pkg\nPkg.add(\"https://github.com/juliatrustworthyai/LaplaceRedux.jl\")\n‚Ä¶ and use it.\n\nusing LaplaceRedux"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#from-bayesian-logistic-regression",
    "href": "content/talks/posts/2022-juliacon/laplace.html#from-bayesian-logistic-regression",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "From Bayesian Logistic Regression ‚Ä¶",
    "text": "From Bayesian Logistic Regression ‚Ä¶\n\n\nFrom maths ‚Ä¶\n. . .\nWe assume a Gaussian prior for our weights ‚Ä¶ \\[\np(\\theta) \\sim \\mathcal{N} \\left( \\theta | \\mathbf{0}, \\lambda^{-1} \\mathbf{I} \\right)=\\mathcal{N} \\left( \\theta | \\mathbf{0}, \\mathbf{H}_0^{-1} \\right)\n\\qquad(3)\\]\n. . .\n‚Ä¶ which corresponds to logit binary crossentropy loss with weight decay:\n\\[\n\\ell(\\theta)= - \\sum_{n}^N [y_n \\log \\mu_n + (1-y_n)\\log (1-\\mu_n)] + \\\\ \\frac{1}{2} (\\theta-\\theta_0)^T\\mathbf{H}_0(\\theta-\\theta_0)\n\\qquad(4)\\]\n. . .\nFor Logistic Regression we have the Hessian in closed form (p.¬†338 in Murphy (2022)):\n\\[\n\\nabla_{\\theta}\\nabla_{\\theta}^\\mathsf{T}\\ell(\\theta) = \\frac{1}{N} \\sum_{n}^N(\\mu_n(1-\\mu_n)\\mathbf{x}_n)\\mathbf{x}_n^\\mathsf{T} + \\mathbf{H}_0\n\\qquad(5)\\]\n\n‚Ä¶ to code\n. . .\n# Hessian:\nfunction ‚àá‚àáùìÅ(Œ∏,Œ∏_0,H_0,X,y)\n    N = length(y)\n    Œº = sigmoid(Œ∏,X)\n    H = ‚àë(Œº[n] * (1-Œº[n]) * X[n,:] * X[n,:]' for n=1:N)\n    return H + H_0\nend\n\nGotta love Julia ‚ù§Ô∏èüíúüíö\n\n. . .\nLogistic Regression can be done in Flux ‚Ä¶\n\nusing Flux\n# Initializing weights as zeros only for illustrative purposes:\nnn = Chain(Dense(zeros(1,2),zeros(1))) \n\n. . .\n‚Ä¶ but now we autograd! Leveraged in LaplaceRedux.\n\nla = Laplace(nn, Œª=Œª)\nfit!(la, data)\n\n\n\n\nFigure¬†3: Posterior predictive distribution of Logistic regression in the 2D feature space using plugin estimator (left) and Laplace approximation (right). Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#to-bayesian-neural-networks",
    "href": "content/talks/posts/2022-juliacon/laplace.html#to-bayesian-neural-networks",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "‚Ä¶ to Bayesian Neural Networks",
    "text": "‚Ä¶ to Bayesian Neural Networks\n\n\nCode\n. . .\nAn actual MLP ‚Ä¶\n\n# Build MLP:\nn_hidden = 32\nD = size(X)[1]\nnn = Chain(\n    Dense(\n      randn(n_hidden,D)./10,\n      zeros(n_hidden), œÉ\n    ),\n    Dense(\n      randn(1,n_hidden)./10,\n      zeros(1)\n    )\n)  \n\n. . .\n‚Ä¶ same API call:\n\nla = Laplace(\n  nn, Œª=Œª, \n  subset_of_weights=:last_layer\n)\nfit!(la, data)\n\n. . .\n\nResults\n. . .\n\n\n\nFigure¬†4: Posterior predictive distribution of MLP in the 2D feature space using plugin estimator (left) and Laplace approximation (right). Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#a-quick-note-on-the-prior",
    "href": "content/talks/posts/2022-juliacon/laplace.html#a-quick-note-on-the-prior",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "A quick note on the prior",
    "text": "A quick note on the prior\nLow prior uncertainty \\(\\rightarrow\\) posterior dominated by prior. High prior uncertainty \\(\\rightarrow\\) posterior approaches MLE.\nLogistic Regression\n\n\n\nFigure¬†5: Prior uncertainty increases from left to right (Logsitic Regression). Image by author.\n\n\nMLP\n\n\n\nFigure¬†6: Prior uncertainty increases from left to right (MLP). Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#a-crucial-detail-i-skipped",
    "href": "content/talks/posts/2022-juliacon/laplace.html#a-crucial-detail-i-skipped",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "A crucial detail I skipped",
    "text": "A crucial detail I skipped\n\nWe‚Äôre really been using linearized neural networks ‚Ä¶\n\n\n\n\nMC fails\n\n\nCould do Monte Carlo for true BNN predictive, but this performs poorly when using approximations for the Hessian.\nInstead we rely on linear expansion of predictive around mode (Immer, Korzepa, and Bauer 2020).\nIntuition: Hessian approximation involves linearization, then so should the predictive.\n\n\n. . .\n\nApplying the GNN approximation [‚Ä¶] turns the underlying probabilistic model locally from a BNN into a GLM [‚Ä¶] Because we have effectively done inference in the GGN-linearized model, we should instead predict using these modified features. ‚Äî Immer, Korzepa, and Bauer (2020)\n\n\n\n\n\nFigure¬†7: MC samples from the Laplace posterior (Lawrence 2001)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#juliacon-2022-and-beyond",
    "href": "content/talks/posts/2022-juliacon/laplace.html#juliacon-2022-and-beyond",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "JuliaCon 2022 and beyond",
    "text": "JuliaCon 2022 and beyond\n\n\n\n\nTo JuliaCon ‚Ä¶\n\nLearn about Laplace Redux by implementing it in Julia.\n\n\nTurn code into a small package.\n\n\nSubmit to JuliaCon 2022 and share the idea.\n\n\n‚Ä¶ and beyond\n. . .\nPackage is bare-bones at this point and needs a lot of work.\n\n\nGoal: reach same level of maturity as Python counterpart. (Beautiful work btw!)\nProblem: limited capacity and fairly new to Julia.\nSolution: find contributors ü§ó.\n\n\n\n\n\n\nPhoto by Ivan Diaz on Unsplash"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#specific-goals",
    "href": "content/talks/posts/2022-juliacon/laplace.html#specific-goals",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Specific Goals",
    "text": "Specific Goals\n\n\nEasy\n\nStill missing support for multi-class and regression.\nDue diligence: peer review and unit testing.\n\nHarder\n\nHessian approximations still quadratically large: use factorizations.\nHyperparameter tuning: what about that prior?\nScaling things up: subnetwork inference.\nEarly stopping: do we really end up at the mode?\n‚Ä¶\n\n\n\n\n\nSource: Giphy"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#more-resources",
    "href": "content/talks/posts/2022-juliacon/laplace.html#more-resources",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nBlog post (1) ‚Äì Bayesian Logisitic Regression: [TDS, homepage].\nBlog post (2) ‚Äì Bayesian Deep Learning: [TDS, homepage].\nDetailed slide pack generously shared by Professor Jos√© Miguel Hern√°ndez-Lobato: [pdf]\nPackage docs.\n\n\n‚Ä¶ or even better: get involved! ü§ó"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#references",
    "href": "content/talks/posts/2022-juliacon/laplace.html#references",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "References",
    "text": "References\n\n\n\nEffortless Bayesian Deep Learning through Laplace Redux ‚Äì JuliaCon 2022 ‚Äì Patrick Altmeyer\n\n\n\nBlundell, Charles, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. 2015. ‚ÄúWeight Uncertainty in Neural Network.‚Äù In International Conference on Machine Learning, 1613‚Äì22. PMLR.\n\n\nDaxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. ‚ÄúLaplace Redux-Effortless Bayesian Deep Learning.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nGal, Yarin, and Zoubin Ghahramani. 2016. ‚ÄúDropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning.‚Äù In International Conference on Machine Learning, 1050‚Äì59. PMLR.\n\n\nImmer, Alexander, Maciej Korzepa, and Matthias Bauer. 2020. ‚ÄúImproving Predictions of Bayesian Neural Networks via Local Linearization.‚Äù https://arxiv.org/abs/2008.08400.\n\n\nLakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2017. ‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù Advances in Neural Information Processing Systems 30.\n\n\nLawrence, Neil David. 2001. ‚ÄúVariational Inference in Probabilistic Models.‚Äù PhD thesis, University of Cambridge.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nWilson, Andrew Gordon. 2020. ‚ÄúThe Case for Bayesian Deep Learning.‚Äù https://arxiv.org/abs/2001.10995."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#overview",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#overview",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Overview",
    "text": "Overview\n\n\nThe Problem with Black Boxes ‚¨õ\n\nWhat are black-box models? Why do we need explainability?\n\nEnter: Counterfactual Explanations üîÆ\n\nWhat are they? What are they not?\n\nCounterfactual Explanations in Julia (and beyond!) üì¶\n\nIntroducing: CounterfactualExplanations.jl\nPackage architecture\nUsage examples - what can it do?\n\nGoals and Ambitions üéØ\n\nFuture developments - where can it go?\nContributor‚Äôs guide"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#short-lists-pandas-and-gibbons",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#short-lists-pandas-and-gibbons",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Short Lists, Pandas and Gibbons",
    "text": "Short Lists, Pandas and Gibbons\n\nFrom human to data-driven decision-making ‚Ä¶\n\n\n\nBlack-box models like deep neural networks are being deployed virtually everywhere.\nIncludes safety-critical and public domains: health care, autonomous driving, finance, ‚Ä¶\nMore likely than not that your loan or employment application is handled by an algorithm.\n\n\n\n\n‚Ä¶ where black boxes are recipe for disaster.\n\n\n\nWe have no idea what exactly we‚Äôre cooking up ‚Ä¶\n\nHave you received an automated rejection email? Why didn‚Äôt you ‚ÄúmEet tHe sHoRtLisTiNg cRiTeRia‚Äù? üôÉ\n\n‚Ä¶ but we do know that some of it is junk.\n\n\n\n\n\n\n\nFigure¬†1: Adversarial attacks on deep neural networks. Source: Goodfellow, Shlens, and Szegedy (2014)"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#weapons-of-math-destruction",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#weapons-of-math-destruction",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "‚ÄúWeapons of Math Destruction‚Äù",
    "text": "‚ÄúWeapons of Math Destruction‚Äù\n\n\n\n‚ÄúYou cannot appeal to (algorithms). They do not listen. Nor do they bend.‚Äù\n‚Äî Cathy O‚ÄôNeil in Weapons of Math Destruction, 2016\n\n\n\n\nFigure¬†2: Cathy O‚ÄôNeil. Source: Cathy O‚ÄôNeil a.k.a. mathbabe.\n\n\n\n\n\nIf left unchallenged, these properties of black-box models can create undesirable dynamics in automated decision-making systems:\n\nHuman operators in charge of the system have to rely on it blindly.\nIndividuals subject to the decisions generally have no way to challenge their outcome."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-1",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-1",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nCurrent Standard in ML\nWe typically want to maximize the likelihood of observing \\(\\mathcal{D}_n\\) under given parameters (Murphy 2022):\n\\[\n\\theta^* = \\arg \\max_{\\theta} p(\\mathcal{D}_n|\\theta)\n\\qquad(1)\\]\nCompute an MLE (or MAP) point estimate \\(\\hat\\theta = \\mathbb{E} \\theta^*\\) and use plugin approximation for prediction:\n\\[\np(y|x,\\mathcal{D}_n) \\approx p(y|x,\\hat\\theta)\n\\qquad(2)\\]\n\nIn an ideal world we can just use parsimonious and interpretable models like GLM (Rudin 2019), for which in many cases we can rely on asymptotic properties of \\(\\theta\\) to quantify uncertainty.\nIn practice these models often have performance limitations.\nBlack-box models like deep neural networks are popular, but they are also the very opposite of parsimonious.\n\nObjective"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-2",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-2",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nObjective\n. . .\n\n[‚Ä¶] deep neural networks are typically very underspecified by the available data, and [‚Ä¶] parameters [therefore] correspond to a diverse variety of compelling explanations for the data. (Wilson 2020)\n\nIn this setting it is often crucial to treat models probabilistically!\n\\[\np(y|x,\\mathcal{D}_n) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D}_n)d\\theta\n\\qquad(3)\\]\n. . .\n\nProbabilistic models covered briefly today. More in my other talk on Laplace Redux ‚Ä¶"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-3",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-3",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\n\nWe can now make predictions ‚Äì great! But do we know how the predictions are actually being made?\n\n\nObjective\nWith the model trained for its task, we are interested in understanding how its predictions change in response to input changes.\n\\[\n\\nabla_x p(y|x,\\mathcal{D}_n;\\hat\\theta)\n\\qquad(4)\\]\n\n\nCounterfactual reasoning (in this context) boils down to simple questions: what if \\(x\\) (factual) \\(\\Rightarrow\\) \\(x\\prime\\) (counterfactual)?\nBy strategically perturbing features and checking the model output, we can (begin to) understand how the model makes its decisions.\nCounterfactual Explanations always have full fidelity by construction (as opposed to surrogate explanations, for example).\n\n\n. . .\n\nImportant to realize that we are keeping \\(\\hat\\theta\\) constant!"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#a-framework-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#a-framework-for-counterfactual-explanations",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "A Framework for Counterfactual Explanations",
    "text": "A Framework for Counterfactual Explanations\n\nEven though [‚Ä¶] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the ‚Äúblack box‚Äù. (Wachter, Mittelstadt, and Russell 2017)\n\n\n\nFramework\n. . .\nObjective originally proposed by Wachter, Mittelstadt, and Russell (2017) is as follows\n\\[\n\\min_{x\\prime \\in \\mathcal{X}} h(x\\prime) \\ \\ \\ \\mbox{s. t.} \\ \\ \\ M(x\\prime) = t\n\\qquad(5)\\]\nwhere \\(h\\) relates to the complexity of the counterfactual and \\(M\\) denotes the classifier.\n. . .\nTypically this is approximated through regularization:\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) + \\lambda h(x\\prime)\n\\qquad(6)\\]\n\nIntuition\n. . .\n\n\n\nFigure¬†3: A cat performing gradient descent in the feature space √† la Wachter, Mittelstadt, and Russell (2017)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#counterfactuals-as-in-adversarial-examples",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#counterfactuals-as-in-adversarial-examples",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Adversarial Examples?",
    "text": "Counterfactuals ‚Ä¶ as in Adversarial Examples?\n\n\nYes and no!\n\nWhile both are methodologically very similar, adversarial examples are meant to go undetected while CEs ought to be meaningful.\n\n\n\nEffective counterfactuals should meet certain criteria ‚úÖ\n\n\ncloseness: the average distance between factual and counterfactual features should be small (Wachter, Mittelstadt, and Russell (2017))\nactionability: the proposed feature perturbation should actually be actionable (Ustun, Spangher, and Liu (2019), Poyiadzi et al. (2020))\nplausibility: the counterfactual explanation should be plausible to a human (Joshi et al. (2019))\nunambiguity: a human should have no trouble assigning a label to the counterfactual (Schut et al. (2021))\nsparsity: the counterfactual explanation should involve as few individual feature changes as possible (Schut et al. (2021))\nrobustness: the counterfactual explanation should be robust to domain and model shifts (Upadhyay, Joshi, and Lakkaraju (2021))\ndiversity: ideally multiple diverse counterfactual explanations should be provided (Mothilal, Sharma, and Tan (2020))\ncausality: counterfactual explanations reflect the structural causal model underlying the data generating process (Karimi et al. (2020), Karimi, Sch√∂lkopf, and Valera (2021))"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#counterfactuals-as-in-causal-inference",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#counterfactuals-as-in-causal-inference",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Causal Inference?",
    "text": "Counterfactuals ‚Ä¶ as in Causal Inference?\n\nNO!\n\n\n\nCausal inference: counterfactuals are thought of as unobserved states of the world that we would like to observe in order to establish causality.\n\nThe only way to do this is by actually interfering with the state of the world: \\(p(y|do(x),\\theta)\\).\nIn practice we can only move some individuals to the counterfactual state of the world and compare their outcomes to a control group.\nProvided we have controlled for confounders, properly randomized, ‚Ä¶ we can estimate an average treatment effect: \\(\\hat\\theta\\).\n\nCounterfactual Explanations: involves perturbing features after some model has been trained.\n\nWe end up comparing modeled outcomes \\(p(y|x,\\hat\\phi)\\) and \\(p(y|x\\prime,\\hat\\phi)\\) for individuals.\nWe have not magically solved causality.\n\n\n\n\nThe number of ostensibly pro data scientists confusing themselves into believing that \"counterfactual explanations\" capture real-world causality is just staggeringü§¶‚Äç‚ôÄÔ∏è. Where do we go from here? How can a community that doesn't even understand what's already known make advances?\n\n‚Äî Zachary Lipton (@zacharylipton) June 20, 2022"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#probabilistic-methods-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#probabilistic-methods-for-counterfactual-explanations",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Probabilistic Methods for Counterfactual Explanations",
    "text": "Probabilistic Methods for Counterfactual Explanations\nWhen people say that counterfactuals should look realistic or plausible, they really mean that counterfactuals should be generated by the same Data Generating Process (DGP) as the factuals:\n\\[\nx\\prime \\sim p(x)\n\\]\nBut how do we estimate \\(p(x)\\)? Two probabilistic approaches ‚Ä¶\n\n\nAPPROACH 1: use the model itselfAPPROACH 2: use some generative model\n\n\n\n\nSchut et al. (2021) note that by maximizing predictive probabilities \\(\\sigma(M(x\\prime))\\) for probabilistic models \\(M\\in\\mathcal{\\widetilde{M}}\\) one implicitly minimizes epistemic and aleotoric uncertainty.\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) \\ \\ \\ , \\ \\ \\ M\\in\\mathcal{\\widetilde{M}}\n\\qquad(7)\\]\n\n\n\n\nFigure¬†4: A cat performing gradient descent in the feature space √† la Schut et al. (2021)\n\n\n\n\n\n\n\n\nInstead of perturbing samples directly, some have proposed to instead traverse a lower-dimensional latent embedding learned through a generative model (Joshi et al. 2019).\n\\[\nz\\prime = \\arg \\min_{z\\prime}  \\ell(M(dec(z\\prime)),t) + \\lambda h(x\\prime)\n\\qquad(8)\\]\nand\n\\[x\\prime = dec(z\\prime)\\]\nwhere \\(dec(\\cdot)\\) is the decoder function.\n\n\n\n\nFigure¬†5: Counterfactual (yellow) generated through latent space search (right panel) following Joshi et al. (2019). The corresponding counterfactual path in the feature space is shown in the left panel."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#limited-software-availability",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#limited-software-availability",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Limited Software Availability",
    "text": "Limited Software Availability\n\nWork currently scattered across different GitHub repositories ‚Ä¶\n\n\n\n\n\nOnly one unifying Python library: CARLA (Pawelczyk et al. 2021).\n\nComprehensive and (somewhat) extensible.\nBut not language-agnostic and some desirable functionality not supported.\nAlso not composable: each generator is treated as different class/entity.\n\nBoth R and Julia lacking any kind of implementation.\n\n\n\n\n\n\nPhoto by Volodymyr Hryshchenko on Unsplash."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#enter-counterfactualexplanations.jl",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#enter-counterfactualexplanations.jl",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Enter: CounterfactualExplanations.jl üì¶",
    "text": "Enter: CounterfactualExplanations.jl üì¶\n   \n\n‚Ä¶ until now!\n\n\n\n\n\nA unifying framework for generating Counterfactual Explanations.\nBuilt in Julia, but essentially language agnostic:\n\nCurrently supporting explanations for differentiable models built in Julia (e.g.¬†Flux) and torch (R and Python).\n\nDesigned to be easily extensible through dispatch.\nDesigned to be composable allowing users and developers to combine different counterfactual generators.\n\n\n\n\n\n\nPhoto by Denise Jans on Unsplash.\n\n\n\n\n\n\nJulia has an edge with respect to Trustworthy AI: it‚Äôs open-source, uniquely transparent and interoperable üî¥üü¢üü£"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#overview-1",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#overview-1",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Overview",
    "text": "Overview\n\nFigure¬†6: Overview of package architecture. Modules are shown in red, structs in green and functions in blue."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#generators",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#generators",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Generators",
    "text": "Generators\n\nusing CounterfactualExplanations, Plots, GraphRecipes\nplt = plot(AbstractGenerator, method=:tree, fontsize=10, nodeshape=:rect, size=(1000,700))\nsavefig(plt, joinpath(www_path,\"generators.png\"))\n\n\nFigure¬†7: Type tree for AbstractGenerator."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#models",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#models",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Models",
    "text": "Models\n\nplt = plot(AbstractFittedModel, method=:tree, fontsize=10, nodeshape=:rect, size=(1000,700))\nsavefig(plt, joinpath(www_path,\"models.png\"))\n\n\nFigure¬†8: Type tree for AbstractFittedModel."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#a-simple-example",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#a-simple-example",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "A simple example",
    "text": "A simple example\n\n\n\nLoad and prepare some toy data.\nSelect a random sample.\nGenerate counterfactuals using different approaches.\n\n\n# Data:\nusing Random\nRandom.seed!(123)\nN = 100\nusing CounterfactualExplanations\nxs, ys = toy_data_linear(N)\nX = hcat(xs...)\ncounterfactual_data = CounterfactualData(X,ys')\n\n# Randomly selected factual:\nx = select_factual(counterfactual_data,rand(1:size(X)[2]))\n\n\n\n\n\nFigure¬†9: Synthetic data."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#generic-generator",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#generic-generator",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Generic Generator",
    "text": "Generic Generator\n\n\nCode\n. . .\nWe begin by instantiating the fitted model ‚Ä¶\n\n# Model\nw = [1.0 1.0] # estimated coefficients\nb = 0 # estimated bias\nM = LogisticModel(w, [b])\n\n. . .\n‚Ä¶ then based on its prediction for \\(x\\) we choose the opposite label as our target ‚Ä¶\n\n# Select target class:\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target\n\n. . .\n‚Ä¶ and finally generate the counterfactual.\n\n# Counterfactual search:\ngenerator = GenericGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\nOutput\n. . .\n\n‚Ä¶ et voil√†!\n\n\n\n\nFigure¬†10: Counterfactual path (left) and predicted probability (right) for GenericGenerator. The contour (left) shows the predicted probabilities of the classifier (Logistic Regression)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#greedy-generator",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#greedy-generator",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Greedy Generator",
    "text": "Greedy Generator\n\n\nCode\n. . .\nThis time we use a Bayesian classifier ‚Ä¶\n\nusing LinearAlgebra\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.01 + UniformScaling(1)) # MAP covariance matrix\nŒº = hcat(b, w)\nM = BayesianLogisticModel(Œº, Œ£)\n\n. . .\n‚Ä¶ and once again choose our target label as before ‚Ä¶\n\n# Select target class:\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target\n\n. . .\n‚Ä¶ to then finally use greedy search to find a counterfactual.\n\n# Counterfactual search:\nparams = GreedyGeneratorParams(\n  Œ¥ = 0.5,\n  n = 10\n)\ngenerator = GreedyGenerator(;params=params)\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\nOutput\n. . .\n\nIn this case the Bayesian approach yields a similar outcome.\n\n\n\n\nFigure¬†11: Counterfactual path (left) and predicted probability (right) for GreedyGenerator. The contour (left) shows the predicted probabilities of the classifier (Bayesian Logistic Regression)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#revise-generator",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#revise-generator",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "REVISE Generator",
    "text": "REVISE Generator\n\n\nCode\nUsing the same classifier as before we can either use the specific REVISEGenerator ‚Ä¶\n\n# Counterfactual search:\ngenerator = REVISEGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n. . .\n‚Ä¶ or realize that that REVISE (Joshi et al. 2019) just boils down to generic search in a latent space:\n\n# Counterfactual search:\ngenerator = GenericGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator,\n  latent_space=true\n)\n\n\nOutput\n. . .\n\nWe have essentially combined latent search with a probabilistic classifier (as in Antor√°n et al. (2020)).\n\n\n\n\nFigure¬†12: Counterfactual path (left) and predicted probability (right) for REVISEGenerator."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#mnist---latent-space-search",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#mnist---latent-space-search",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "MNIST - Latent Space Search",
    "text": "MNIST - Latent Space Search\n\n\nGood VAE\n. . .\nLoading pre-trained classifiers and VAE ‚Ä¶\n\nX, ys = mnist_data() \nmodel = mnist_model() # simple MLP\n\n. . .\n‚Ä¶ instantiating model and attaching VAE.\n\nM = FluxModel(model, likelihood=:classification_multi)\ncounterfactual_data = CounterfactualData(X,ys)\nvae = mnist_vae()\ncounterfactual_data.generative_model = vae\n\n. . .\n\nThe results in Figure¬†13 look great!\n\n\n\n\nFigure¬†13: Turning a nine (9) into a four (4) using REVISE. It appears that the VAE is well-specified in this case.\n\n\n\nBad VAE\n. . .\n\nBut things can also go wrong ‚Ä¶\n\nThe VAE used to generate the counterfactual in Figure¬†14 is not expressive enough.\n\n\n\nFigure¬†14: Turning a seven (7) into a nine (9) using REVISE with a weak VAE.\n\n\n. . .\n\nThe counterfactual in Figure¬†15 is also valid ‚Ä¶ what to do?\n\n\n\n\nFigure¬†15: Turning a seven (7) into a nine (9) using generic search."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-models---deep-ensemble",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-models---deep-ensemble",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Custom Models - Deep Ensemble",
    "text": "Custom Models - Deep Ensemble\n\nLoading the pre-trained deep ensemble ‚Ä¶\n\nensemble = mnist_ensemble() # deep ensemble\n\n\n\nStep 1: add composite type as subtype of AbstractFittedModel.\n\nstruct FittedEnsemble &lt;: Models.AbstractFittedModel\n    ensemble::AbstractArray\nend\n\n\n\nStep 2: dispatch logits and probs methods for new model type.\n\nusing Statistics\nimport CounterfactualExplanations.Models: logits, probs\nlogits(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([nn(X) for nn in M.ensemble],3), dims=3)\nprobs(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([softmax(nn(X)) for nn in M.ensemble],3),dims=3)\nM = FittedEnsemble(ensemble)\n\n\n\n\nResults for a simple deep ensemble also look convincing!\n\n\n\n\nFigure¬†16: Turning a nine (9) into a four (4) using generic (Wachter) and greedy search for MLP and deep ensemble."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-models---interoperability",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-models---interoperability",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Custom Models - Interoperability",
    "text": "Custom Models - Interoperability\nAdding support for torch models was easy! Here‚Äôs how I implemented it for torch classifiers trained in R.\n\n\n\nSource code\n. . .\nStep 1: add composite type as subtype of AbstractFittedModel\n\nImplemented here.\n\nStep 2: dispatch logits and probs methods for new model type.\n\nImplemented here.\n\n. . .\nStep 3: add gradient access.\n\nImplemented here.\n\n\nUnchanged API\n. . .\n\nM = RTorchModel(model)\n# Select target class:\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target\n# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\n\n\nFigure¬†17: Counterfactual path (left) and predicted probability (right) for GenericGenerator and RTorchModel."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-generators",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-generators",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Custom Generators",
    "text": "Custom Generators\nIdea üí°: let‚Äôs implement a generic generator with dropout!\n\n\n\nDispatch\n. . .\nStep 1: create a subtype of AbstractGradientBasedGenerator (adhering to some basic rules).\n\n# Constructor:\nabstract type AbstractDropoutGenerator &lt;: AbstractGradientBasedGenerator end\nstruct DropoutGenerator &lt;: AbstractDropoutGenerator\n    loss::Symbol # loss function\n    complexity::Function # complexity function\n    mutability::Union{Nothing,Vector{Symbol}} # mutibility constraints \n    Œª::AbstractFloat # strength of penalty\n    œµ::AbstractFloat # step size\n    œÑ::AbstractFloat # tolerance for convergence\n    p_dropout::AbstractFloat # dropout rate\nend\n\n. . .\nStep 2: implement logic for generating perturbations.\n\nimport CounterfactualExplanations.Generators: generate_perturbations, ‚àá\nusing StatsBase\nfunction generate_perturbations(generator::AbstractDropoutGenerator, counterfactual_state::State)\n    ùê†‚Çú = ‚àá(generator, counterfactual_state.M, counterfactual_state) # gradient\n    # Dropout:\n    set_to_zero = sample(1:length(ùê†‚Çú),Int(round(generator.p_dropout*length(ùê†‚Çú))),replace=false)\n    ùê†‚Çú[set_to_zero] .= 0\n    Œîx‚Ä≤ = - (generator.œµ .* ùê†‚Çú) # gradient step\n    return Œîx‚Ä≤\nend\n\n\nUnchanged API\n. . .\n\n# Instantiate:\nusing LinearAlgebra\ngenerator = DropoutGenerator(\n    :logitbinarycrossentropy,\n    norm,\n    nothing,\n    0.1,\n    0.1,\n    1e-5,\n    0.5\n)\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\n\n\nFigure¬†18: Counterfactual path (left) and predicted probability (right) for custom DropoutGenerator and RTorchModel."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#juliacon-2022-and-beyond",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#juliacon-2022-and-beyond",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "JuliaCon 2022 and beyond",
    "text": "JuliaCon 2022 and beyond\n\n\n\n\nTo JuliaCon ‚Ä¶\n\nDevelop package, register and submit to JuliaCon 2022.\n\n\nNative support for deep learning models (Flux, torch).\n\n\nAdd latent space search.\n\n\n‚Ä¶ and beyond\n. . .\n\nAdd more generators:\n\nDiCE (Mothilal, Sharma, and Tan 2020)\nROAR (Upadhyay, Joshi, and Lakkaraju 2021)\nMINT (Karimi, Sch√∂lkopf, and Valera 2021)\n\n\n. . .\n\nAdd support for more models:\n\nMLJ, GLM, ‚Ä¶\nNon-differentiable\n\n\n. . .\n\nEnhance preprocessing functionality.\n\n. . .\n\nExtend functionality to regression problems.\n\n. . .\n\nUse Flux optimizers.\n\n. . .\n\n‚Ä¶\n\n\n\n\n\nPhoto by Ivan Diaz on Unsplash"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#more-resources",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#more-resources",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nBlog post introducing CE: [TDS, homepage].\nBlog post introducing package: [TDS, homepage].\nPackage docs with lots of examples.\n\n\n‚Ä¶ or get involved! ü§ó\n\n\nContributor‚Äôs Guide"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#references",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#references",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "References",
    "text": "References\n\n\n\nExplaining Black-Box Models through Counterfactuals ‚Äì JuliaCon 2022 ‚Äì Patrick Altmeyer\n\n\n\nAntor√°n, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and Jos√© Miguel Hern√°ndez-Lobato. 2020. ‚ÄúGetting a Clue: A Method for Explaining Uncertainty Estimates.‚Äù https://arxiv.org/abs/2006.06848.\n\n\nGoodfellow, Ian J, Jonathon Shlens, and Christian Szegedy. 2014. ‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù https://arxiv.org/abs/1412.6572.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKarimi, Amir-Hossein, Bernhard Sch√∂lkopf, and Isabel Valera. 2021. ‚ÄúAlgorithmic Recourse: From Counterfactual Explanations to Interventions.‚Äù In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 353‚Äì62.\n\n\nKarimi, Amir-Hossein, Julius Von K√ºgelgen, Bernhard Sch√∂lkopf, and Isabel Valera. 2020. ‚ÄúAlgorithmic Recourse Under Imperfect Causal Knowledge: A Probabilistic Approach.‚Äù https://arxiv.org/abs/2006.06831.\n\n\nKaur, Harmanpreet, Harsha Nori, Samuel Jenkins, Rich Caruana, Hanna Wallach, and Jennifer Wortman Vaughan. 2020. ‚ÄúInterpreting Interpretability: Understanding Data Scientists‚Äô Use of Interpretability Tools for Machine Learning.‚Äù In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1‚Äì14. https://doi.org/10.1145/3313831.3376219.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nPawelczyk, Martin, Sascha Bielawski, Johannes van den Heuvel, Tobias Richter, and Gjergji Kasneci. 2021. ‚ÄúCARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms.‚Äù https://arxiv.org/abs/2108.00783.\n\n\nPoyiadzi, Rafael, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, and Peter Flach. 2020. ‚ÄúFACE: Feasible and Actionable Counterfactual Explanations.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 344‚Äì50.\n\n\nRudin, Cynthia. 2019. ‚ÄúStop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.‚Äù Nature Machine Intelligence 1 (5): 206‚Äì15. https://doi.org/10.1038/s42256-019-0048-x.\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nSlack, Dylan, Sophie Hilgard, Emily Jia, Sameer Singh, and Himabindu Lakkaraju. 2020. ‚ÄúFooling Lime and Shap: Adversarial Attacks on Post Hoc Explanation Methods.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 180‚Äì86.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nUstun, Berk, Alexander Spangher, and Yang Liu. 2019. ‚ÄúActionable Recourse in Linear Classification.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 10‚Äì19. https://doi.org/10.1145/3287560.3287566.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nWilson, Andrew Gordon. 2020. ‚ÄúThe Case for Bayesian Deep Learning.‚Äù https://arxiv.org/abs/2001.10995."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#blurb",
    "href": "content/talks/posts/2022-boe/presentation.html#blurb",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Blurb",
    "text": "Blurb\nCounterfactual Explanations explain how inputs into a model need to change for it to produce different outputs. Explanations that involve realistic and actionable changes can be used for the purpose of Algorithmic Recourse: they offer human stakeholders a principled approach to not only understand the model they are seeking to explain, but also react to it or adjust it.\nThe general setup lends itself naturally to Bank datasets that revolve around counterparty risk, for example. In this seminar I will introduce the topic and place it into the broader context of Explainable AI. Using my Julia package I will go through a worked example involving a publicly available credit data set. Finally, I will also briefly present some of our recent research that points to potential pitfalls of current state-of-the-art approaches and proposes mitigation strategies.\nDISCLAIMER: Views presented in this presentation are my own."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#quick-intro",
    "href": "content/talks/posts/2022-boe/presentation.html#quick-intro",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Quick Intro",
    "text": "Quick Intro\n\n\n\nCurrently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nWorking on Counterfactual Explanations and Probabilistic Machine Learning with applications in Finance.\nPreviously, educational background in Economics and Finance and two years at the Bank of England (MPAT \\(\\subset\\) MIAD).\nEnthusiastic about free open-source software, in particular Julia and Quarto."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#the-problem-with-todays-ai",
    "href": "content/talks/posts/2022-boe/presentation.html#the-problem-with-todays-ai",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "The Problem with Today‚Äôs AI",
    "text": "The Problem with Today‚Äôs AI\n\nFrom human to data-driven decision-making ‚Ä¶\n\n\n\nBlack-box models like deep neural networks are being deployed virtually everywhere.\nIncludes safety-critical and public domains: health care, autonomous driving, finance, ‚Ä¶\nMore likely than not that your loan or employment application is handled by an algorithm.\n\n\n\n\n‚Ä¶ where black boxes are recipe for disaster.\n\n\n\nWe have no idea what exactly we‚Äôre cooking up ‚Ä¶\n\nHave you received an automated rejection email? Why didn‚Äôt you ‚ÄúmEet tHe sHoRtLisTiNg cRiTeRia‚Äù? üôÉ\n\n‚Ä¶ but we do know that some of it is junk.\n\n\n\n\n\n\n\nFigure¬†1: Adversarial attacks on deep neural networks. Source: Goodfellow, Shlens, and Szegedy (2014)"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai",
    "href": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-1",
    "href": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-1",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nCurrent Standard in ML\nWe typically want to maximize the likelihood of observing \\(\\mathcal{D}_n\\) under given parameters (Murphy 2022):\n\\[\n\\theta^* = \\arg \\max_{\\theta} p(\\mathcal{D}_n|\\theta)\n\\qquad(1)\\]\nCompute an MLE (or MAP) point estimate \\(\\hat\\theta = \\mathbb{E} \\theta^*\\) and use plugin approximation for prediction:\n\\[\np(y|x,\\mathcal{D}_n) \\approx p(y|x,\\hat\\theta)\n\\qquad(2)\\]\n\nIn an ideal world we can just use parsimonious and interpretable models like GLM (Rudin 2019), for which in many cases we can rely on asymptotic properties of \\(\\theta\\) to quantify uncertainty.\nIn practice these models often have performance limitations.\nBlack-box models like deep neural networks are popular, but they are also the very opposite of parsimonious.\n\nObjective"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-2",
    "href": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-2",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nObjective\n. . .\n\n[‚Ä¶] deep neural networks are typically very underspecified by the available data, and [‚Ä¶] parameters [therefore] correspond to a diverse variety of compelling explanations for the data. (Wilson 2020)\n\nIn this setting it is often crucial to treat models probabilistically!\n\\[\np(y|x,\\mathcal{D}_n) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D}_n)d\\theta\n\\qquad(3)\\]"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-3",
    "href": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-3",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\n\nWe can now make predictions ‚Äì great! But do we know how the predictions are actually being made?\n\n\nObjective\nWith the model trained for its task, we are interested in understanding how its predictions change in response to input changes.\n\\[\n\\nabla_x p(y|x,\\mathcal{D}_n;\\hat\\theta)\n\\qquad(4)\\]\n\n\nCounterfactual reasoning (in this context) boils down to simple questions: what if \\(x\\) (factual) \\(\\Rightarrow\\) \\(x\\prime\\) (counterfactual)?\nBy strategically perturbing features and checking the model output, we can (begin to) understand how the model makes its decisions.\nCounterfactual Explanations always have full fidelity by construction (as opposed to surrogate explanations, for example).\n\n\n. . .\n\nImportant to realize that we are keeping \\(\\hat\\theta\\) constant!"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#todays-talk",
    "href": "content/talks/posts/2022-boe/presentation.html#todays-talk",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Today‚Äôs talk",
    "text": "Today‚Äôs talk\n\nüîÆ Explaining Black-Box Models through Counterfactuals (\\(\\approx\\) 10min)\n\nWhat are they? What are they not?\nCounterfactual Explanations in the broader XAI landscape\nFrom Counterfactual Explanations to Algorithmic Recourse\n\nüõ†Ô∏è Hands-on examples ‚Äî CounterfactualExplanations.jl in Julia (\\(\\approx\\) 15min)\nüìä Endogenous Macrodynamics in Algorithmic Recourse (\\(\\approx\\) 10min)\n‚ùì Q&A (\\(\\approx\\) 10min)\nüöÄ Related Research Topics (\\(\\approx\\) 10min)\n\nPredictive Uncertainty Quantification"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#a-framework-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-boe/presentation.html#a-framework-for-counterfactual-explanations",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "A Framework for Counterfactual Explanations",
    "text": "A Framework for Counterfactual Explanations\n\nEven though [‚Ä¶] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the ‚Äúblack box‚Äù. (Wachter, Mittelstadt, and Russell 2017)\n\n\n\nFramework\n. . .\nObjective originally proposed by Wachter, Mittelstadt, and Russell (2017) is as follows\n\\[\n\\min_{x\\prime \\in \\mathcal{X}} h(x\\prime) \\ \\ \\ \\mbox{s. t.} \\ \\ \\ M(x\\prime) = t\n\\qquad(5)\\]\nwhere \\(h\\) relates to the complexity of the counterfactual and \\(M\\) denotes the classifier.\n. . .\nTypically this is approximated through regularization:\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) + \\lambda h(x\\prime)\n\\qquad(6)\\]\n\nIntuition\n. . .\n\n\n\nFigure¬†2: A cat performing gradient descent in the feature space √† la Wachter, Mittelstadt, and Russell (2017)."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#counterfactuals-as-in-adversarial-examples",
    "href": "content/talks/posts/2022-boe/presentation.html#counterfactuals-as-in-adversarial-examples",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Adversarial Examples?",
    "text": "Counterfactuals ‚Ä¶ as in Adversarial Examples?\n\n\n\nYes and no!\n\nWhile both are methodologically very similar, adversarial examples are meant to go undetected while CEs ought to be meaningful.\n\n\nDesiderata\n\n\ncloseness: the average distance between factual and counterfactual features should be small (Wachter, Mittelstadt, and Russell (2017))\nactionability: the proposed feature perturbation should actually be actionable (Ustun, Spangher, and Liu (2019), Poyiadzi et al. (2020))\nplausibility: the counterfactual explanation should be plausible to a human (Joshi et al. (2019))\nunambiguity: a human should have no trouble assigning a label to the counterfactual (Schut et al. (2021))\nsparsity: the counterfactual explanation should involve as few individual feature changes as possible (Schut et al. (2021))\nrobustness: the counterfactual explanation should be robust to domain and model shifts (Upadhyay, Joshi, and Lakkaraju (2021))\ndiversity: ideally multiple diverse counterfactual explanations should be provided (Mothilal, Sharma, and Tan (2020))\ncausality: counterfactual explanations reflect the structural causal model underlying the data generating process (Karimi et al. (2020), Karimi, Sch√∂lkopf, and Valera (2021))"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#counterfactuals-as-in-causal-inference",
    "href": "content/talks/posts/2022-boe/presentation.html#counterfactuals-as-in-causal-inference",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Causal Inference?",
    "text": "Counterfactuals ‚Ä¶ as in Causal Inference?\n\nNO!\n\n\n\nCausal inference: counterfactuals are thought of as unobserved states of the world that we would like to observe in order to establish causality.\n\nThe only way to do this is by actually interfering with the state of the world: \\(p(y|do(x),\\theta)\\).\nIn practice we can only move some individuals to the counterfactual state of the world and compare their outcomes to a control group.\nProvided we have controlled for confounders, properly randomized, ‚Ä¶ we can estimate an average treatment effect: \\(\\hat\\theta\\).\n\nCounterfactual Explanations: involves perturbing features after some model has been trained.\n\nWe end up comparing modeled outcomes \\(p(y|x,\\hat\\phi)\\) and \\(p(y|x\\prime,\\hat\\phi)\\) for individuals.\nWe have not magically solved causality.\n\n\n\n\nThe number of ostensibly pro data scientists confusing themselves into believing that \"counterfactual explanations\" capture real-world causality is just staggeringü§¶‚Äç‚ôÄÔ∏è. Where do we go from here? How can a community that doesn't even understand what's already known make advances?\n\n‚Äî Zachary Lipton (@zacharylipton) June 20, 2022"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#the-xai-landscape",
    "href": "content/talks/posts/2022-boe/presentation.html#the-xai-landscape",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "The XAI Landscape",
    "text": "The XAI Landscape\n\nOverviewLiterature\n\n\n\nA (highly) simplified and incomplete overview ‚Ä¶\n\n\n\n\n\n\n\n\nFigure¬†3: A (highly) simplified and incomplete overview of the XAI landscape loosly based on (molnar2020interpretable?).\n\n\n\n\n\n\nSurrogate Explainers\n\nLundberg and Lee (2017) propose SHAP as a provably unified approach to additive feature attribution methods (including LIME) with certain desiderata. Contrary to LIME, this approach involves permuting through the feature space and checking how different features impact model predictions when they are included in the permutations.\nRibeiro, Singh, and Guestrin (2016) propose Local Interpretable Model-Agnostic Explanations (LIME): the approach involves generating local perturbations in the input space, deriving predictions from the original classifier and than fitting a white box model (e.g.¬†linear regression) on this synthetic data set.\n\nCounterfactual Explanations\n\nWachter, Mittelstadt, and Russell (2017) were among the first to propose counterfactual explanations that do not require knowledge about the inner workings of a black-box model.\nJoshi et al. (2019) extend the framework of Ustun, Spangher, and Liu (2019). Their proposed REVISE method is applicable to a broader class of models including black box classifiers and structural causal models. For a summary see here and for a set of slides see here.\nSchut et al. (2021) introduce Bayesian modeling to the context of CE: their approach implicitly minimizes aleatoric and epistemic uncertainty to generate a CE that us unambiguous and realistic, respectively.\n\nCriticism (XAI)\n\n‚ÄúExplanatory models by definition do not produce 100% reliable explanations, because they are approximations. This means explanations can‚Äôt be fully trusted, and so neither can the original model.‚Äù ‚Äì causaLens, 2021\n\n\nMittelstadt, Russell, and Wachter (2019) points out that there is a gap in the understanding of what explanations are between computer scientists and explanation scientists (social scientists, cognitive scientists, pyschologists, ‚Ä¶). Current methods produce at best locally reliable explanations. There needs to be shift towards interactive explanations.\nRudin (2019) argues that instead of bothering with explanations for black box models we should focus on designing inherently interpretable models. In her view the trade-off between (intrinsic) explainability and performance is not as clear-cut as people claim.\nLakkaraju and Bastani (2020) show how misleading black box explanations can manipulate users into trusting an untrustworthy model.\nSlack et al. (2020) demonstrate that both LIME and SHAP are not reliable: their reliance on feature perturbations makes them susceptible to adversarial attacks.\nSlack et al. (2021) show that (gradient-based) Counterfactual Explanations that are also vulnerable to manipulation, but various simple mitigation strategies can be used to avoid this."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#from-counterfactual-explanations-to-algorithmic-recourse",
    "href": "content/talks/posts/2022-boe/presentation.html#from-counterfactual-explanations-to-algorithmic-recourse",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "From Counterfactual Explanations to Algorithmic Recourse",
    "text": "From Counterfactual Explanations to Algorithmic Recourse\n\n\n\n‚ÄúYou cannot appeal to (algorithms). They do not listen. Nor do they bend.‚Äù\n‚Äî Cathy O‚ÄôNeil in Weapons of Math Destruction, 2016\n\n\n\n\nFigure¬†4: Cathy O‚ÄôNeil. Source: Cathy O‚ÄôNeil a.k.a. mathbabe.\n\n\n\nAlgorithmic Recourse\n. . .\n\nO‚ÄôNeil (2016) points to various real-world involving black-box models and affected individuals facing adverse outcomes.\n\n. . .\n\nThese individuals generally have no way to challenge their outcome.\n\n. . .\n\nCounterfactual Explanations that involve actionable and realistic feature perturbations can be used for the purpose of Algorithmic Recourse."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#counterfactualexplanations.jl",
    "href": "content/talks/posts/2022-boe/presentation.html#counterfactualexplanations.jl",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "CounterfactualExplanations.jl üì¶",
    "text": "CounterfactualExplanations.jl üì¶\n     \n\n\n\n\nA unifying framework for generating Counterfactual Explanations.\nFast, extensible and composable allowing users and developers to add and combine different counterfactual generators.\nImplements a number of SOTA generators.\nBuilt in Julia, but can be used to explain models built in R and Python (still experimental).\nStatus üîÅ: ready for research, not production. Thought/challenge/contributions welcome!\n\n\n\n\n\n\nPhoto by Denise Jans on Unsplash.\n\n\n\n\n\n\nJulia has an edge with respect to Trustworthy AI: it‚Äôs open-source, uniquely transparent and interoperable üî¥üü¢üü£"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#a-simple-example",
    "href": "content/talks/posts/2022-boe/presentation.html#a-simple-example",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "A simple example",
    "text": "A simple example\n\n\n\nLoad and prepare some toy data.\nSelect a random sample.\nGenerate counterfactuals using different approaches."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#generic-generator",
    "href": "content/talks/posts/2022-boe/presentation.html#generic-generator",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Generic Generator",
    "text": "Generic Generator\n\n\nCode\n. . .\nWe begin by instantiating the fitted model ‚Ä¶\n. . .\n‚Ä¶ then based on its prediction for \\(x\\) we choose the opposite label as our target ‚Ä¶\n. . .\n‚Ä¶ and finally generate the counterfactual.\n\nOutput\n. . .\n\n‚Ä¶ et voil√†!"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#probabilistic-methods-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-boe/presentation.html#probabilistic-methods-for-counterfactual-explanations",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Probabilistic Methods for Counterfactual Explanations",
    "text": "Probabilistic Methods for Counterfactual Explanations\nWhen people say that counterfactuals should look realistic or plausible, they really mean that counterfactuals should be generated by the same Data Generating Process (DGP) as the factuals:\n\\[\nx\\prime \\sim p(x)\n\\]\nBut how do we estimate \\(p(x)\\)? Two probabilistic approaches ‚Ä¶\n\n\nAPPROACH 1: use the model itselfAPPROACH 2: use some generative model\n\n\n\n\nSchut et al. (2021) note that by maximizing predictive probabilities \\(\\sigma(M(x\\prime))\\) for probabilistic models \\(M\\in\\mathcal{\\widetilde{M}}\\) one implicitly minimizes epistemic and aleotoric uncertainty.\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) \\ \\ \\ , \\ \\ \\ M\\in\\mathcal{\\widetilde{M}}\n\\qquad(7)\\]\n\n\n\n\nFigure¬†5: A cat performing gradient descent in the feature space √† la Schut et al. (2021)\n\n\n\n\n\n\n\n\nInstead of perturbing samples directly, some have proposed to instead traverse a lower-dimensional latent embedding learned through a generative model (Joshi et al. 2019).\n\\[\nz\\prime = \\arg \\min_{z\\prime}  \\ell(M(dec(z\\prime)),t) + \\lambda h(x\\prime)\n\\qquad(8)\\]\nand\n\\[x\\prime = dec(z\\prime)\\]\nwhere \\(dec(\\cdot)\\) is the decoder function.\n\n\n\n\nFigure¬†6: Counterfactual (yellow) generated through latent space search (right panel) following Joshi et al. (2019). The corresponding counterfactual path in the feature space is shown in the left panel."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#greedy-generator",
    "href": "content/talks/posts/2022-boe/presentation.html#greedy-generator",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Greedy Generator",
    "text": "Greedy Generator\n\n\nCode\n. . .\nThis time we use a Bayesian classifier ‚Ä¶\n. . .\n‚Ä¶ and once again choose our target label as before ‚Ä¶\n. . .\n‚Ä¶ to then finally use greedy search to find a counterfactual.\n\nOutput\n. . .\n\nIn this case the Bayesian approach yields a similar outcome."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#latent-space-generator",
    "href": "content/talks/posts/2022-boe/presentation.html#latent-space-generator",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Latent Space Generator",
    "text": "Latent Space Generator\n\n\nCode\n. . .\nUsing the same classifier as before we can either use the specific REVISEGenerator ‚Ä¶\n. . .\n‚Ä¶ or realize that that REVISE (Joshi et al. 2019) just boils down to generic search in a latent space:\n\nOutput\n. . .\n\nWe have essentially combined latent search with a probabilistic classifier (as in Antor√°n et al. (2020))."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#diverse-counterfactuals",
    "href": "content/talks/posts/2022-boe/presentation.html#diverse-counterfactuals",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Diverse Counterfactuals",
    "text": "Diverse Counterfactuals\n\n\nCode\n. . .\nWe can use the DiCEGenerator to produce multiple diverse counterfactuals:\n\nOutput\n. . ."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#a-real-world-example---credit-default",
    "href": "content/talks/posts/2022-boe/presentation.html#a-real-world-example---credit-default",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "A Real-World Example - Credit Default",
    "text": "A Real-World Example - Credit Default\n\nThe Give Me Some Credit dataset is publicly available from Kaggle.\n\n\nImprove on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years.\n\n\nWe have \\(y \\in \\{0=\\text{no stress},1=\\text{stress}\\}\\) and a number of demographic and credit-related features \\(X\\)."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#ignoring-mutability",
    "href": "content/talks/posts/2022-boe/presentation.html#ignoring-mutability",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Ignoring Mutability",
    "text": "Ignoring Mutability\nUsing DiCE to generate counterfactuals for a single individual, ignoring actionability:"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#respecting-mutability",
    "href": "content/talks/posts/2022-boe/presentation.html#respecting-mutability",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Respecting Mutability",
    "text": "Respecting Mutability\nUsing the generic generator to generate counterfactuals for multiple individuals, respecting that age cannot be decreased (you might argue that age also cannot be easily increased ‚Ä¶):"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#motivation",
    "href": "content/talks/posts/2022-boe/presentation.html#motivation",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Motivation",
    "text": "Motivation\n\n\n\nTL;DR: We find that standard implementation of various SOTA approaches to AR can induce substantial domain and model shifts. We argue that these dynamics indicate that individual recourse generates hidden external costs and provide mitigation strategies.\n\nIn this work we investigate what happens if Algorithmic Recourse is actually implemented by a large number of individuals.\nFigure¬†7 illustrates what we mean by Endogenous Macrodynamics in Algorithmic Recourse:\n\nPanel (a): we have a simple linear classifier trained for binary classification where samples from the negative class (y=0) are marked in blue and samples of the positive class (y=1) are marked in orange\nPanel (b): the implementation of AR for a random subset of individuals leads to a noticable domain shift\nPanel (c): as the classifier is retrained we observe a corresponding model shift (Upadhyay, Joshi, and Lakkaraju 2021)\nPanel (d): as this process is repeated, the decision boundary moves away from the target class.\n\n\n\n\n\nFigure¬†7: Proof of concept: repeated implementation of AR leads to domain and model shifts.\n\n\n\nWe argue that these shifts should be considered as an expected external cost of individual recourse and call for a paradigm shift from individual to collective recourse in these types of situations."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#generalised-framework",
    "href": "content/talks/posts/2022-boe/presentation.html#generalised-framework",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Generalised Framework",
    "text": "Generalised Framework\nFrom individual recourse ‚Ä¶\nWe restate Equation¬†6 to encapsulate latent space search:\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\left\\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)}+ \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\right\\}\n\\end{aligned}\n\\qquad(9)\\]\n‚Ä¶ towards collective recourse\nWe borrow the notion of negative externalities from Economics, to formalise the idea that individual recourse fails to account for external costs:\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\{ {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)} \\\\ &+ \\lambda_1 {\\text{cost}(f(\\mathbf{s}^\\prime))} + \\lambda_2 {\\text{extcost}(f(\\mathbf{s}^\\prime))} \\}\n\\end{aligned}\n\\qquad(10)\\]"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#findings",
    "href": "content/talks/posts/2022-boe/presentation.html#findings",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Findings",
    "text": "Findings\n\n\n\n\n\nResults for synthetic data.\n\n\n\n\n\n\nResults for real-word data."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#mitigation-strategies",
    "href": "content/talks/posts/2022-boe/presentation.html#mitigation-strategies",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Mitigation Strategies",
    "text": "Mitigation Strategies\n\n\n\nChoose more conservative decision thresholds.\nClassifer Preserving ROAR (ClaPROAR): penalise classifier loss.\n\n\\[\n\\begin{aligned}\n\\text{extcost}(f(\\mathbf{s}^\\prime)) = l(M(f(\\mathbf{s}^\\prime)),y^\\prime)\n\\end{aligned}\n\\qquad(11)\\]\n\nGravitational Counterfactual Explanations: penalise distance to some sensible point in the target domain.\n\n\\[\n\\begin{aligned}\n\\text{extcost}(f(\\mathbf{s}^\\prime)) = \\text{dist}(f(\\mathbf{s}^\\prime),\\bar{x})  \n\\end{aligned}\n\\qquad(12)\\]\n\n\n\n\nFigure¬†8: Illustrative example demonstrating the properties of the various mitigation strategies. Samples from the negative class \\((y = 0)\\) are marked in blue while samples of the positive class \\((y = 1)\\) are marked in orange.\n\n\n\n\n\n\n\n\n\nMitigation strategies applied to synthetic data.\n\n\n\n\n\n\nMitigation strategies applied to real-world data."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "href": "content/talks/posts/2022-boe/presentation.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Effortless Bayesian Deep Learning through Laplace Redux",
    "text": "Effortless Bayesian Deep Learning through Laplace Redux\n   \n\n\nLaplaceRedux.jl (formerly BayesLaplace.jl) is a small package that can be used for effortless Bayesian Deep Learning and Logistic Regression trough Laplace Approximation. It is inspired by this Python library and its companion paper.\n\n\n\nPlugin Approximation (left) and Laplace Posterior (right) for simple artificial neural network.\n\n\n\n\n\n\nSimulation of changing posteriour predictive distribution. Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#conformalprediction.jl",
    "href": "content/talks/posts/2022-boe/presentation.html#conformalprediction.jl",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "ConformalPrediction.jl",
    "text": "ConformalPrediction.jl\n      \nConformalPrediction.jl is a package for Uncertainty Quantification (UQ) through Conformal Prediction (CP) in Julia. It is designed to work with supervised models trained in MLJ (Blaom et al. 2020). Conformal Prediction is distribution-free, easy-to-understand, easy-to-use and model-agnostic.\n\n\n\nConformal Prediction in action: Prediction sets for two different samples and changing coverage rates. As coverage grows, so does the size of the prediction sets."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#more-resources",
    "href": "content/talks/posts/2022-boe/presentation.html#more-resources",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nBlog post introducing CE: [TDS], [blog].\nBlog post on Laplace Redux: [TDS], [blog].\nBlog post on Conformal Prediction: [TDS], [blog].\n\n\n‚Ä¶ or get involved! ü§ó\n\n\nContributor‚Äôs Guide for CounterfactualExplanations.jl\nContributor‚Äôs Guide for ConformalPrediction.jl"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#image-sources",
    "href": "content/talks/posts/2022-boe/presentation.html#image-sources",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Image Sources",
    "text": "Image Sources\n\nCrystal ball on beach: Nicole Avagliano on Unsplash\nColour gradient: A.Z on Unsplash\nElephant herd: Sergi Ferrete on Unsplash\nBank of England logo: Bank of England here"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#references",
    "href": "content/talks/posts/2022-boe/presentation.html#references",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "References",
    "text": "References\n\n\n\nExplaining Machine Learning Models through Counterfactuals ‚Äî Patrick Altmeyer ‚Äî CC BY-NC\n\n\n\nAntor√°n, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and Jos√© Miguel Hern√°ndez-Lobato. 2020. ‚ÄúGetting a Clue: A Method for Explaining Uncertainty Estimates.‚Äù https://arxiv.org/abs/2006.06848.\n\n\nBlaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. ‚ÄúMLJ: A Julia Package for Composable Machine Learning.‚Äù Journal of Open Source Software 5 (55): 2704. https://doi.org/10.21105/joss.02704.\n\n\nGoodfellow, Ian J, Jonathon Shlens, and Christian Szegedy. 2014. ‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù https://arxiv.org/abs/1412.6572.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKarimi, Amir-Hossein, Bernhard Sch√∂lkopf, and Isabel Valera. 2021. ‚ÄúAlgorithmic Recourse: From Counterfactual Explanations to Interventions.‚Äù In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 353‚Äì62.\n\n\nKarimi, Amir-Hossein, Julius Von K√ºgelgen, Bernhard Sch√∂lkopf, and Isabel Valera. 2020. ‚ÄúAlgorithmic Recourse Under Imperfect Causal Knowledge: A Probabilistic Approach.‚Äù https://arxiv.org/abs/2006.06831.\n\n\nLakkaraju, Himabindu, and Osbert Bastani. 2020. ‚Äú\" How Do I Fool You?\" Manipulating User Trust via Misleading Black Box Explanations.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 79‚Äì85.\n\n\nLundberg, Scott M, and Su-In Lee. 2017. ‚ÄúA Unified Approach to Interpreting Model Predictions.‚Äù In Proceedings of the 31st International Conference on Neural Information Processing Systems, 4768‚Äì77.\n\n\nMittelstadt, Brent, Chris Russell, and Sandra Wachter. 2019. ‚ÄúExplaining Explanations in AI.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 279‚Äì88. https://doi.org/10.1145/3287560.3287574.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nO‚ÄôNeil, Cathy. 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown.\n\n\nPoyiadzi, Rafael, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, and Peter Flach. 2020. ‚ÄúFACE: Feasible and Actionable Counterfactual Explanations.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 344‚Äì50.\n\n\nRibeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. ‚Äú\"Why Should i Trust You?\" Explaining the Predictions of Any Classifier.‚Äù In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1135‚Äì44.\n\n\nRudin, Cynthia. 2019. ‚ÄúStop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.‚Äù Nature Machine Intelligence 1 (5): 206‚Äì15. https://doi.org/10.1038/s42256-019-0048-x.\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nSlack, Dylan, Anna Hilgard, Himabindu Lakkaraju, and Sameer Singh. 2021. ‚ÄúCounterfactual Explanations Can Be Manipulated.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nSlack, Dylan, Sophie Hilgard, Emily Jia, Sameer Singh, and Himabindu Lakkaraju. 2020. ‚ÄúFooling Lime and Shap: Adversarial Attacks on Post Hoc Explanation Methods.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 180‚Äì86.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nUstun, Berk, Alexander Spangher, and Yang Liu. 2019. ‚ÄúActionable Recourse in Linear Classification.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 10‚Äì19. https://doi.org/10.1145/3287560.3287566.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nWilson, Andrew Gordon. 2020. ‚ÄúThe Case for Bayesian Deep Learning.‚Äù https://arxiv.org/abs/2001.10995."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#quick-introduction",
    "href": "content/talks/posts/2023-dnb/presentation.html#quick-introduction",
    "title": "Faithful Model Explanations",
    "section": "Quick Introduction",
    "text": "Quick Introduction\n\n\nSlides on my website, scan this code!\n\n\n\n\n\n3rd year PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nPart of AI for FinTech Research Lab‚Äî5yr collaboration between TU Delft and ING.\nPreviously, educational background in Economics and Finance and two years in Monetary Policy at the Bank of England.\nResearch: Trustworthy AI for real-world problems, particularly finance.\nBlogger, Julia developer and founder of Taija."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#research",
    "href": "content/talks/posts/2023-dnb/presentation.html#research",
    "title": "Faithful Model Explanations",
    "section": "Research",
    "text": "Research\n\n\nTo give you a better idea of my research profile, I‚Äôve listed some of my publications below.\nThe focus today will be on Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals, which is still under review.\n\n\n\n\nTrustworthy AI\n\nFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals (under review).\nEndogenous Macrodynamics in Algorithmic Recourse (Altmeyer, Angela, et al. 2023).\nExplaining Black-Box Models Through Counterfactuals (Altmeyer, Deursen, et al. 2023).\n\n\nFinance and Economics\n\nYield curve sensitivity to investor positioning around economic shocks (Altmeyer, Boneva, et al. 2023) (BoE Staff Working Paper).\nDeep vector autoregression for macroeconomic data (Agustƒ±ÃÅ, Altmeyer, and Vidal-Quadras 2021) (NeurIPS MLECON 2021, DNB DS workshop and published through BIS)\nOption pricing in the Heston stochastic volatility model: an empirical evaluation (Altmeyer et al. 2018)"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#in-a-nutshell",
    "href": "content/talks/posts/2023-dnb/presentation.html#in-a-nutshell",
    "title": "Faithful Model Explanations",
    "section": "In A Nutshell",
    "text": "In A Nutshell\n\n‚Äú[‚Ä¶] unified front of our expertise in this area formed to help the financial industry solve the growingly complex challenges.‚Äù\n‚ÄîDelft FinTech Lab\n\n\n\nBackground\n\nFinance at the forefront of digitalization.\nOver 50 TU Delft researchers in FinTech.\nWith dozens of societal partners.\n\n\nObjective\n\nStrengthen societal and industrial impact.\nIncrease collaboration and visibility."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#core-pillars",
    "href": "content/talks/posts/2023-dnb/presentation.html#core-pillars",
    "title": "Faithful Model Explanations",
    "section": "Core Pillars",
    "text": "Core Pillars\n\n\n\nTrustworthy Financial Systems led by Stefan Buijsman.\nQuantitative Modelling led by Antonis Papapantoleon.\nFinancial Data Intelligence led by Asterios Katsifodimos.\nBlockchain led by J√©r√©mie Decouchant.\n\n\n\n\n\n\n\nReliable and trustworthy financial systems are explainable and transparent.\nModel development and validation, derivative pricing, and investment analysis.\nArtificial intelligence, data and software analytics.\nDevelopment of decentralized systems.\n\n\n\n\nWhat about topics specific to supervision?"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#natural-language-processing",
    "href": "content/talks/posts/2023-dnb/presentation.html#natural-language-processing",
    "title": "Faithful Model Explanations",
    "section": "Natural language processing",
    "text": "Natural language processing\n\n\nIn this context, this is usually about ‚Ä¶\nBut perhaps also other things like sentiment analysis as a proxy for uncertainty or risk.\n\n\n\nMine large volumes of text.\nRetrieve relevant information from large collections of text.\nLong document understanding and track/identify/predict anomaly patterns.\nExplainable AI for NLP (Arous et al. 2021).\nPredictive Uncertainty Quantification for LLMs (see blog post)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#privacy-enhancing-technologies-pet",
    "href": "content/talks/posts/2023-dnb/presentation.html#privacy-enhancing-technologies-pet",
    "title": "Faithful Model Explanations",
    "section": "Privacy Enhancing Technologies (PET)",
    "text": "Privacy Enhancing Technologies (PET)\n\n\nThis is not my area of expertise but, of course, it is very important to ensure that data is handled in a privacy-preserving manner.\nI attended a conference earlier this year that involved a competition to extract training data from a large language model and the results were quite shocking.\nThis is a huge concern especially in the context of highly sensitive financial data.\n\n\n\nSynthetic data generation by ML, algorithmic, probabilistic and statistical techniques (Porsius Martins 2023; Werf 2021).\nStatistics/econometrics under privacy constraints ex. differential privacy.\nMultiparty computations and homomorphic encryptions."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#human-ai-collaboration",
    "href": "content/talks/posts/2023-dnb/presentation.html#human-ai-collaboration",
    "title": "Faithful Model Explanations",
    "section": "Human-AI Collaboration",
    "text": "Human-AI Collaboration\n\n\nNext, we have human-AI collaboration and here we are getting a bit closer to my area of expertise.\nA term you may have heard a lot recently is ‚Äòhuman alignment‚Äô: we want to ensure that AI systems are aligned with human values.\nThat can be achieved by keeping humans in the loop.\n\n\n\nAugmenting human experts with AI.\n\n\nHybrid human-AI workflows: amplify human intelligence, reduce human costs, and improve precaution.\nCollaborative human-AI knowledge synthesis.\nExplainable AI (Anand et al. 2022; Leonhardt, Rudra, and Anand 2023), and human-in-the-loop continual learning (Yang et al. 2018)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#automated-compliance",
    "href": "content/talks/posts/2023-dnb/presentation.html#automated-compliance",
    "title": "Faithful Model Explanations",
    "section": "Automated Compliance",
    "text": "Automated Compliance\n\n\nAnd finally, another relevant topic is automated compliance.\nWe want to ensure, for example, that ‚Ä¶\n\n\n\nEnsure decisions made by banks‚Äô models are compliant by being explainable and robust:\n\n\nCounterfactual reasoning and contestability (Altmeyer, Angela, et al. 2023; Altmeyer, Deursen, et al. 2023)\n\n\nEthics assessment, AI governance\nPredictive uncertainty: How robust/uncertain predictions are (conformal predictions) in a model-agnostic manner."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2023-dnb/presentation.html#counterfactual-explanations",
    "title": "Faithful Model Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\nBorn out of the need for explanations ‚Ä¶\n\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs (Wachter, Mittelstadt, and Russell 2017).\n\nProvided the changes are realistic and actionable, they can be used for Algorithmic Recourse (AR) to help individuals who face adverse outcomes."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-consumer-credit",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-consumer-credit",
    "title": "Faithful Model Explanations",
    "section": "Example: Consumer Credit",
    "text": "Example: Consumer Credit\nFrom ‚Äòloan denied‚Äô to ‚Äòloan supplied‚Äô: CounterfactualExplanations.jl üì¶.\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search.\n\n\n\n\n\n\nFigure¬†2: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-insurance-premium",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-insurance-premium",
    "title": "Faithful Model Explanations",
    "section": "Example: Insurance Premium1",
    "text": "Example: Insurance Premium1\n\n\nInput \\(\\mathbf{X}\\): A dataset of individuals containing demographic and financial information.\nAdditional Input \\(\\mathbf{Z}\\): Individuals can opt-in to provide their personal Apple Health data to improve their chance of receiving a lower premium.\nBinary output \\(\\mathbf{Y}\\): based on the data, the individual is either eligible (\\(y=1\\)) or not eligible (\\(y=0\\)) for a lower premium.\nTo model \\(p(y=1|X)\\) the insurance provider can rely on an interpretable linear classifier.\nTo model \\(p(y=1|X,Z)\\) the insurance provider turns to a more accurate but less interpretable black-box model.\n\n\nFor simplicity, we‚Äôll stay in the classification setting. Work on counterfactual regression like Spooner et al. (2021) exists but it is scarce."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-insurance-premium-1",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-insurance-premium-1",
    "title": "Faithful Model Explanations",
    "section": "Example: Insurance Premium",
    "text": "Example: Insurance Premium\nIn the EU, individuals have the right ‚Äú[‚Ä¶] to obtain an explanation of the decision reached after such assessment and to challenge the decision.‚Äù (Recital 71 of the General Data Protection Regulation (GDPR))\n\n\nIn our example, who do you think is most likely to ask for an explanation?"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#gradient-based-counterfactual-search",
    "href": "content/talks/posts/2023-dnb/presentation.html#gradient-based-counterfactual-search",
    "title": "Faithful Model Explanations",
    "section": "Gradient-based Counterfactual Search",
    "text": "Gradient-based Counterfactual Search\nThe starting point for most counterfactual generators is as follows,\n\\[\n\\begin{aligned}\n\\mathbf{Z}^\\prime =& \\arg \\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} \\\\ &+ \\lambda {\\text{cost}(f(\\mathbf{Z}^\\prime)) }  \\}\n\\end{aligned}\n\\tag{1}\\]\nwhere \\(\\mathbf{Z}^\\prime\\) is a counterfactual, \\(M_{\\theta}\\) is the black-box model and \\(\\mathbf{y}^+\\) is the desired output."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#but-wait-a-second",
    "href": "content/talks/posts/2023-dnb/presentation.html#but-wait-a-second",
    "title": "Faithful Model Explanations",
    "section": "But wait a second ‚Ä¶",
    "text": "But wait a second ‚Ä¶\nEquation¬†1 looks a lot like an adversarial attack (Goodfellow, Shlens, and Szegedy 2014), doesn‚Äôt it?\n\nFigure¬†3: Adversarial attack on an Image Classifier.In both settings, we take gradients with respect to features \\(\\nabla_{\\mathbf{Z}^\\prime}\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)\\) in order to trigger changes in the model‚Äôs output."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#gradient-descend-visualized",
    "href": "content/talks/posts/2023-dnb/presentation.html#gradient-descend-visualized",
    "title": "Faithful Model Explanations",
    "section": "Gradient Descend Visualized",
    "text": "Gradient Descend Visualized\n\nFigure¬†4: Gradient-based counterfactual search."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#open-questions",
    "href": "content/talks/posts/2023-dnb/presentation.html#open-questions",
    "title": "Faithful Model Explanations",
    "section": "Open Questions",
    "text": "Open Questions\n\n\nWhat makes a counterfactual plausible?\nWhy do we need plausibility?\nIs plausibility all we need?\nWhat makes models more explainable?"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#plausibility",
    "href": "content/talks/posts/2023-dnb/presentation.html#plausibility",
    "title": "Faithful Model Explanations",
    "section": "Plausibility",
    "text": "Plausibility\nThere‚Äôs no consensus on the exact definition of plausibility but we think about it as follows:\n\nDefinition 1 (Plausible Counterfactuals) Let \\(\\mathcal{X}|\\mathbf{y}^+= p(\\mathbf{x}|\\mathbf{y}^+)\\) denote the true conditional distribution of samples in the target class \\(\\mathbf{y}^+\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a plausible counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}|\\mathbf{y}^+\\)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#counter-example",
    "href": "content/talks/posts/2023-dnb/presentation.html#counter-example",
    "title": "Faithful Model Explanations",
    "section": "Counter Example",
    "text": "Counter Example\n\n\n\nThe counterfactual in Figure¬†5 is valid: it has crossed the decision boundary.\nBut is it consistent with the data in the target class (blue)?\n\n\n\n\n\nFigure¬†5: A valid but implausible counterfactual. Source: Altmeyer, Deursen, et al. (2023)"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#why-plausibility",
    "href": "content/talks/posts/2023-dnb/presentation.html#why-plausibility",
    "title": "Faithful Model Explanations",
    "section": "Why Plausibility?",
    "text": "Why Plausibility?\n\nActionability: If a counterfactual is implausible, it is unlikely to be actionable.\nFairness: If a counterfactual is implausible, it is unlikely to be fair.\nRobustness: If a counterfactual is implausible, it is unlikely to be robust.\n\nBut: Higher plausibility seems to require larger changes and hence increase costs to individuals."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#recourse-dynamics",
    "href": "content/talks/posts/2023-dnb/presentation.html#recourse-dynamics",
    "title": "Faithful Model Explanations",
    "section": "Recourse Dynamics",
    "text": "Recourse Dynamics\nMoving just across the decision boundary may minimize costs to individuals but it may also generate external costs for other stakeholders (Altmeyer, Angela, et al. 2023)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#a-balancing-act",
    "href": "content/talks/posts/2023-dnb/presentation.html#a-balancing-act",
    "title": "Faithful Model Explanations",
    "section": "A Balancing Act",
    "text": "A Balancing Act\n\n\nMinimizing private costs generates external costs for other stakeholders.\nTo avoid this, counterfactuals need to be plausible, i.e.¬†comply with the data-generating process.\nIn practice, costs to various stakeholders need to be carefully balanced.\n\n\n\n\nIs plausibility really all we need?"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2023-dnb/presentation.html#pick-your-poison",
    "title": "Faithful Model Explanations",
    "section": "Pick your Poison?",
    "text": "Pick your Poison?\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction. Which one would you pick?\n\nFigure¬†6: Turning a 9 into a 7: Counterfactual Examplanations for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#what-do-models-learn",
    "href": "content/talks/posts/2023-dnb/presentation.html#what-do-models-learn",
    "title": "Faithful Model Explanations",
    "section": "What do Models Learn?",
    "text": "What do Models Learn?\nThese images are sampled from the posterior distribution learned by the model. Looks different, no?\n\nFigure¬†7: Conditional Generated Images from the Image Classifier"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#faithful-counterfactuals",
    "href": "content/talks/posts/2023-dnb/presentation.html#faithful-counterfactuals",
    "title": "Faithful Model Explanations",
    "section": "Faithful Counterfactuals",
    "text": "Faithful Counterfactuals\n\n\nWe propose a way to generate counterfactuals that are as plausible as the underlying model permits (under review).\n\nDefinition 2 (Faithful Counterfactuals) Let \\(\\mathcal{X}_{\\theta}|\\mathbf{y}^+ = p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\) denote the conditional distribution of \\(\\mathbf{x}\\) in the target class \\(\\mathbf{y}^+\\), where \\(\\theta\\) denotes the parameters of model \\(M_{\\theta}\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a faithful counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}_{\\theta}|\\mathbf{y}^+\\).\n\n\n\n\n\n\n\n\nFigure¬†8: Gradient fields and counterfactual paths for different generators."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#improving-models",
    "href": "content/talks/posts/2023-dnb/presentation.html#improving-models",
    "title": "Faithful Model Explanations",
    "section": "Improving Models",
    "text": "Improving Models\nNow that we have a tool to faithfully explain models we may ask: how do models learn plausible explanations? Initial evidence:\n\nIncorporating predictive uncertainty (e.g.¬†ensembling).\nAddressing robustness (e.g.¬†adversarial training in Schut et al. (2021)).\nBetter model architectures.\nHybrid modelling (i.e.¬†combining generative and discriminative models)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-architecture",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-architecture",
    "title": "Faithful Model Explanations",
    "section": "Example: Architecture",
    "text": "Example: Architecture\n\nFigure¬†9: Counterfactuals for LeNet-5 convolutional neural network (LeCun et al. 1998)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-jem-ensemble",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-jem-ensemble",
    "title": "Faithful Model Explanations",
    "section": "Example: JEM Ensemble",
    "text": "Example: JEM Ensemble\n\nFigure¬†10: Counterfactuals for an ensemble of Joint Energy Models (JEM) (Grathwohl et al. 2020)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#taija",
    "href": "content/talks/posts/2023-dnb/presentation.html#taija",
    "title": "Faithful Model Explanations",
    "section": "üê∂ Taija",
    "text": "üê∂ Taija\n\nResearch informs development, development informs research.\n\n\nTrustworthy Artificial Intelligence in Julia.Taija is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.\nOur work has been presented online for JuliaCon 2022, at MIT in Boston for JuliaCon 2023 and hopefully beyond."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#counterfactual-explanations-1",
    "href": "content/talks/posts/2023-dnb/presentation.html#counterfactual-explanations-1",
    "title": "Faithful Model Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\nAll the work presented today is powered by CounterfactualExplanations.jl üì¶.\nThere is also a corresponding paper, Explaining Black-Box Models through Counterfactuals, which has been published in JuliaCon Proceedings.\nIf you decide to use this package in your work, please consider citing the paper:"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#conformal-prediction",
    "href": "content/talks/posts/2023-dnb/presentation.html#conformal-prediction",
    "title": "Faithful Model Explanations",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nConformal Prediction is a model-agnostic, distribution-free approach to Predictive Uncertainty Quantification: ConformalPrediction.jl üì¶.\n\n\n\n\n\nFigure¬†11: Conformal Prediction intervals for regression.\n\n\n\n\n\n\nFigure¬†12: Conformal Prediction sets for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#laplace-redux",
    "href": "content/talks/posts/2023-dnb/presentation.html#laplace-redux",
    "title": "Faithful Model Explanations",
    "section": "Laplace Redux",
    "text": "Laplace Redux\n\n\nEffortless Bayesian Deep Learning through Laplace Approximation Daxberger et al. (2021): LaplaceRedux.jl üì¶.\n\n\n\n\nFigure¬†13: Predictive interval for neural network with Laplace Approximation."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#joint-energy-models",
    "href": "content/talks/posts/2023-dnb/presentation.html#joint-energy-models",
    "title": "Faithful Model Explanations",
    "section": "Joint Energy Models",
    "text": "Joint Energy Models\nJoint Energy Models (JEMs) are hybrid models trained to learn the conditional output and input distribution (Grathwohl et al. 2020): JointEnergyModels.jl üì¶.\n\nFigure¬†14: A JEM trained on Circles data."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#questions",
    "href": "content/talks/posts/2023-dnb/presentation.html#questions",
    "title": "Faithful Model Explanations",
    "section": "Questions?",
    "text": "Questions?\n\n\nIncludes joint work with Cynthia C. S. Liem, Arie van Deursen, Mojtaba Farmanbar, Aleksander Buszydlik, Karol Dobiczek, Giovan Angela and many other students at TU Delft.\nSlides power by Quarto."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#references",
    "href": "content/talks/posts/2023-dnb/presentation.html#references",
    "title": "Faithful Model Explanations",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nAgustƒ±ÃÅ, Marc, Patrick Altmeyer, and Ignacio Vidal-Quadras. 2021. ‚ÄúDeep Vector Autoregression for Macroeconomic Data.‚Äù\n\n\nAltmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia CS Liem. 2023. ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse.‚Äù In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 418‚Äì31. IEEE.\n\n\nAltmeyer, Patrick, Lena Boneva, Rafael Kinston, Shreyosi Saha, and Evarist Stoja. 2023. ‚ÄúYield Curve Sensitivity to Investor Positioning Around Economic Shocks.‚Äù\n\n\nAltmeyer, Patrick, Arie van Deursen, et al. 2023. ‚ÄúExplaining Black-Box Models Through Counterfactuals.‚Äù In Proceedings of the JuliaCon Conferences, 1:130. 1.\n\n\nAltmeyer, Patrick, Jacob Daniel Grapendal, Makar Pravosud, and Gand Derry Quintana. 2018. ‚ÄúOption Pricing in the Heston Stochastic Volatility Model: An Empirical Evaluation.‚Äù\n\n\nAnand, Avishek, Lijun Lyu, Maximilian Idahl, Yumeng Wang, Jonas Wallat, and Zijian Zhang. 2022. ‚ÄúExplainable Information Retrieval: A Survey.‚Äù arXiv Preprint arXiv:2211.02405.\n\n\nArous, Ines, Ljiljana Dolamic, Jie Yang, Akansha Bhardwaj, Giuseppe Cuccu, and Philippe Cudr√©-Mauroux. 2021. ‚ÄúMarta: Leveraging Human Rationales for Explainable Text Classification.‚Äù In Proceedings of the AAAI Conference on Artificial Intelligence, 35:5868‚Äì76. 7.\n\n\nDaxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. ‚ÄúLaplace Redux-Effortless Bayesian Deep Learning.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nGoodfellow, Ian J, Jonathon Shlens, and Christian Szegedy. 2014. ‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù https://arxiv.org/abs/1412.6572.\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nImmer, Alexander, Maciej Korzepa, and Matthias Bauer. 2020. ‚ÄúImproving Predictions of Bayesian Neural Networks via Local Linearization.‚Äù https://arxiv.org/abs/2008.08400.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit.\n\n\nLeCun, Yann, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. ‚ÄúGradient-Based Learning Applied to Document Recognition.‚Äù Proceedings of the IEEE 86 (11): 2278‚Äì2324.\n\n\nLeonhardt, Jurek, Koustav Rudra, and Avishek Anand. 2023. ‚ÄúExtractive Explanations for Interpretable Text Ranking.‚Äù ACM Transactions on Information Systems 41 (4): 1‚Äì31.\n\n\nPorsius Martins, C√©lio. 2023. ‚ÄúPrivate Cycle Detection in Financial Transactions.‚Äù\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nSpooner, Thomas, Danial Dervovic, Jason Long, Jon Shepard, Jiahao Chen, and Daniele Magazzeni. 2021. ‚ÄúCounterfactual Explanations for Arbitrary Regression Models.‚Äù https://arxiv.org/abs/2106.15212.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nWerf, Daan van der. 2021. ‚ÄúOne Step Ahead: A Weakly-Supervised Approach to Training Robust Machine Learning Models for Transaction Monitoring.‚Äù\n\n\nYang, Jie, Thomas Drake, Andreas Damianou, and Yoelle Maarek. 2018. ‚ÄúLeveraging Crowdsourcing Data for Deep Active Learning an Application: Learning Intents in Alexa.‚Äù In Proceedings of the 2018 World Wide Web Conference, 23‚Äì32."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#house-rules",
    "href": "content/talks/posts/2022-dscc/presentation.html#house-rules",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "House Rules",
    "text": "House Rules\n\nDISCLAIMER: Views presented in this presentation are my own."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#quick-intro",
    "href": "content/talks/posts/2022-dscc/presentation.html#quick-intro",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Quick Intro",
    "text": "Quick Intro\n\n\n\nCurrently 2nd year of PhD in Trustworthy Artificial Intelligence.\nWorking on Counterfactual Explanations and Probabilistic Machine Learning.\nPreviously, educational background in Economics and Finance and two years in monetary policy at the Bank of England.\nEnthusiastic about free open-source software, in particular Julia and Quarto."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#the-problem-with-todays-ai",
    "href": "content/talks/posts/2022-dscc/presentation.html#the-problem-with-todays-ai",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "The Problem with Today‚Äôs AI",
    "text": "The Problem with Today‚Äôs AI\n\nFrom human to data-driven decision-making ‚Ä¶\n\n\n\nBlack-box models like deep neural networks are being deployed virtually everywhere.\nIncludes safety-critical and public domains: health care, autonomous driving, finance, ‚Ä¶\nMore likely than not that your loan or employment application is handled by an algorithm.\n\n\n\n\n‚Ä¶ where black boxes are recipe for disaster.\n\n\n\nWe have no idea what exactly we‚Äôre cooking up ‚Ä¶\n\nHave you received an automated rejection email? Why didn‚Äôt you ‚ÄúmEet tHe sHoRtLisTiNg cRiTeRia‚Äù? üôÉ\n\n‚Ä¶ but we do know that some of it is junk.\n\n\n\n\n\n\n\nFigure¬†1: Adversarial attacks on deep neural networks. Source: Goodfellow, Shlens, and Szegedy (2014)"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#towards-trustworthy-ai",
    "href": "content/talks/posts/2022-dscc/presentation.html#towards-trustworthy-ai",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#towards-trustworthy-ai-1",
    "href": "content/talks/posts/2022-dscc/presentation.html#towards-trustworthy-ai-1",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nCurrent Standard in ML\nWe typically want to maximize the likelihood of observing \\(\\mathcal{D}_n\\) under given parameters (Murphy 2022):\n\\[\n\\theta^* = \\arg \\max_{\\theta} p(\\mathcal{D}_n|\\theta)\n\\qquad(1)\\]\nCompute an MLE (or MAP) point estimate \\(\\hat\\theta = \\mathbb{E} \\theta^*\\) and use plugin approximation for prediction:\n\\[\np(y|x,\\mathcal{D}_n) \\approx p(y|x,\\hat\\theta)\n\\qquad(2)\\]\n\nIn an ideal world we can just use parsimonious and interpretable models like GLM (Rudin 2019), for which in many cases we can rely on asymptotic properties of \\(\\theta\\) to quantify uncertainty.\nIn practice these models often have performance limitations.\nBlack-box models like deep neural networks are popular, but they are also the very opposite of parsimonious.\n\nObjective"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#towards-trustworthy-ai-2",
    "href": "content/talks/posts/2022-dscc/presentation.html#towards-trustworthy-ai-2",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nObjective\n. . .\n\n[‚Ä¶] deep neural networks are typically very underspecified by the available data, and [‚Ä¶] parameters [therefore] correspond to a diverse variety of compelling explanations for the data. (Wilson 2020)\n\nIn this setting it is often crucial to treat models probabilistically!\n\\[\np(y|x,\\mathcal{D}_n) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D}_n)d\\theta\n\\qquad(3)\\]"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#towards-trustworthy-ai-3",
    "href": "content/talks/posts/2022-dscc/presentation.html#towards-trustworthy-ai-3",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\n\nWe can now make predictions ‚Äì great! But do we know how the predictions are actually being made?\n\n\nObjective\nWith the model trained for its task, we are interested in understanding how its predictions change in response to input changes.\n\\[\n\\nabla_x p(y|x,\\mathcal{D}_n;\\hat\\theta)\n\\qquad(4)\\]\n\n\nCounterfactual reasoning (in this context) boils down to simple questions: what if \\(x\\) (factual) \\(\\Rightarrow\\) \\(x\\prime\\) (counterfactual)?\nBy strategically perturbing features and checking the model output, we can (begin to) understand how the model makes its decisions.\nCounterfactual Explanations always have full fidelity by construction (as opposed to surrogate explanations, for example).\n\n\n. . .\n\nImportant to realize that we are keeping \\(\\hat\\theta\\) constant!"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#todays-talk",
    "href": "content/talks/posts/2022-dscc/presentation.html#todays-talk",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Today‚Äôs talk",
    "text": "Today‚Äôs talk\n\nüîÆ Explaining Black-Box Models through Counterfactuals (\\(\\approx\\) 10min)\n\nWhat are they? What are they not?\nFrom Counterfactual Explanations to Algorithmic Recourse\n\nüõ†Ô∏è Hands-on examples ‚Äî CounterfactualExplanations.jl in Julia (\\(\\approx\\) 15min)\nüìä Endogenous Macrodynamics in Algorithmic Recourse (\\(\\approx\\) 10min)\nüöÄ The Road Ahead ‚Äî Related Research Topics (\\(\\approx\\) 10min)\n\nPredictive Uncertainty Quantification\n\n‚ùì Q&A (\\(\\approx\\) 10min)"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#a-framework-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-dscc/presentation.html#a-framework-for-counterfactual-explanations",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "A Framework for Counterfactual Explanations",
    "text": "A Framework for Counterfactual Explanations\n\nEven though [‚Ä¶] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the ‚Äúblack box‚Äù. (Wachter, Mittelstadt, and Russell 2017)\n\n\n\nFramework\n. . .\nObjective originally proposed by Wachter, Mittelstadt, and Russell (2017) is as follows\n\\[\n\\min_{x\\prime \\in \\mathcal{X}} h(x\\prime) \\ \\ \\ \\mbox{s. t.} \\ \\ \\ M(x\\prime) = t\n\\qquad(5)\\]\nwhere \\(h\\) relates to the complexity of the counterfactual and \\(M\\) denotes the classifier.\n. . .\nTypically this is approximated through regularization:\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) + \\lambda h(x\\prime)\n\\qquad(6)\\]\n\nIntuition\n. . .\n\n\n\nFigure¬†2: A cat performing gradient descent in the feature space √† la Wachter, Mittelstadt, and Russell (2017)."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#counterfactuals-as-in-adversarial-examples",
    "href": "content/talks/posts/2022-dscc/presentation.html#counterfactuals-as-in-adversarial-examples",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Adversarial Examples?",
    "text": "Counterfactuals ‚Ä¶ as in Adversarial Examples?\n\n\n\nYes and no!\n\nWhile both are methodologically very similar, adversarial examples are meant to go undetected while CEs ought to be meaningful.\n\n\nDesiderata\n\n\ncloseness: the average distance between factual and counterfactual features should be small (Wachter, Mittelstadt, and Russell (2017))\nactionability: the proposed feature perturbation should actually be actionable (Ustun, Spangher, and Liu (2019), Poyiadzi et al. (2020))\nplausibility: the counterfactual explanation should be plausible to a human (Joshi et al. (2019))\nunambiguity: a human should have no trouble assigning a label to the counterfactual (Schut et al. (2021))\nsparsity: the counterfactual explanation should involve as few individual feature changes as possible (Schut et al. (2021))\nrobustness: the counterfactual explanation should be robust to domain and model shifts (Upadhyay, Joshi, and Lakkaraju (2021))\ndiversity: ideally multiple diverse counterfactual explanations should be provided (Mothilal, Sharma, and Tan (2020))\ncausality: counterfactual explanations reflect the structural causal model underlying the data generating process (Karimi et al. (2020), Karimi, Sch√∂lkopf, and Valera (2021))"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#counterfactuals-as-in-causal-inference",
    "href": "content/talks/posts/2022-dscc/presentation.html#counterfactuals-as-in-causal-inference",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Causal Inference?",
    "text": "Counterfactuals ‚Ä¶ as in Causal Inference?\n\nNO!\n\n\n\nCausal inference: counterfactuals are thought of as unobserved states of the world that we would like to observe in order to establish causality.\n\nThe only way to do this is by actually interfering with the state of the world: \\(p(y|do(x),\\theta)\\).\nIn practice we can only move some individuals to the counterfactual state of the world and compare their outcomes to a control group.\nProvided we have controlled for confounders, properly randomized, ‚Ä¶ we can estimate an average treatment effect: \\(\\hat\\theta\\).\n\nCounterfactual Explanations: involves perturbing features after some model has been trained.\n\nWe end up comparing modeled outcomes \\(p(y|x,\\hat\\phi)\\) and \\(p(y|x\\prime,\\hat\\phi)\\) for individuals.\nWe have not magically solved causality.\n\n\n\n\nThe number of ostensibly pro data scientists confusing themselves into believing that \"counterfactual explanations\" capture real-world causality is just staggeringü§¶‚Äç‚ôÄÔ∏è. Where do we go from here? How can a community that doesn't even understand what's already known make advances?\n\n‚Äî Zachary Lipton (@zacharylipton) June 20, 2022"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#from-counterfactual-explanations-to-algorithmic-recourse",
    "href": "content/talks/posts/2022-dscc/presentation.html#from-counterfactual-explanations-to-algorithmic-recourse",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "From Counterfactual Explanations to Algorithmic Recourse",
    "text": "From Counterfactual Explanations to Algorithmic Recourse\n\n\n\n‚ÄúYou cannot appeal to (algorithms). They do not listen. Nor do they bend.‚Äù\n‚Äî Cathy O‚ÄôNeil in Weapons of Math Destruction, 2016\n\n\n\n\nFigure¬†3: Cathy O‚ÄôNeil. Source: Cathy O‚ÄôNeil a.k.a. mathbabe.\n\n\n\nAlgorithmic Recourse\n. . .\n\nO‚ÄôNeil (2016) points to various real-world involving black-box models and affected individuals facing adverse outcomes.\n\n. . .\n\nThese individuals generally have no way to challenge their outcome.\n\n. . .\n\nCounterfactual Explanations that involve actionable and realistic feature perturbations can be used for the purpose of Algorithmic Recourse."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#limited-software-availability",
    "href": "content/talks/posts/2022-dscc/presentation.html#limited-software-availability",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Limited Software Availability",
    "text": "Limited Software Availability\n\nWork currently scattered across different GitHub repositories ‚Ä¶\n\n\n\n\n\nOnly one unifying Python library: CARLA (Pawelczyk et al. 2021).\n\nComprehensive and (somewhat) extensible.\nNot composable: each generator is treated as different class/entity.\n\nBoth R and Julia lacking any kind of implementation.\nEnter: üëâ CounterfactualExplanations.jl Altmeyer (2022)\n\n\n\n\n\n\nPhoto by Volodymyr Hryshchenko on Unsplash."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#counterfactualexplanations.jl",
    "href": "content/talks/posts/2022-dscc/presentation.html#counterfactualexplanations.jl",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "CounterfactualExplanations.jl üì¶",
    "text": "CounterfactualExplanations.jl üì¶\n     \n\n\n\n\nA unifying framework for generating Counterfactual Explanations.\nFast, extensible and composable allowing users and developers to add and combine different counterfactual generators.\nImplements a number of SOTA generators.\nBuilt in Julia, but can be used to explain models built in R and Python (still experimental).\n\n\n\n\n\n\nPhoto by Denise Jans on Unsplash.\n\n\n\n\n\n\nJulia has an edge with respect to Trustworthy AI: it‚Äôs open-source, uniquely transparent and interoperable üî¥üü¢üü£"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#a-simple-example",
    "href": "content/talks/posts/2022-dscc/presentation.html#a-simple-example",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "A simple example",
    "text": "A simple example\n\n\n\nLoad and prepare some toy data.\nSelect a random sample.\nGenerate counterfactuals using different approaches.\n\n\n# Data:\nusing Random\nRandom.seed!(123)\nN = 100\nusing CounterfactualExplanations\nxs, ys = toy_data_linear(N)\nX = hcat(xs...)\ncounterfactual_data = CounterfactualData(X,ys')\n\n# Randomly selected factual:\nx = select_factual(counterfactual_data,rand(1:size(X)[2]))"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#generic-generator",
    "href": "content/talks/posts/2022-dscc/presentation.html#generic-generator",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Generic Generator",
    "text": "Generic Generator\n\n\nCode\n. . .\nWe begin by instantiating the fitted model ‚Ä¶\n\n# Model\nw = [1.0 1.0] # estimated coefficients\nb = 0 # estimated bias\nM = LogisticModel(w, [b])\n\n. . .\n‚Ä¶ then based on its prediction for \\(x\\) we choose the opposite label as our target ‚Ä¶\n\n# Select target class:\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target\n\n. . .\n‚Ä¶ and finally generate the counterfactual.\n\n# Counterfactual search:\ngenerator = GenericGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\nConvergence: ‚úÖ\n\n\n\n after 41 steps.\n\n\n\nOutput\n. . .\n\n‚Ä¶ et voil√†!\n\n\nanim = animate_path(counterfactual; plot_proba=true, colorbar=false, size=(800,300), alpha_=0.7)\ngif(anim, fps=5)\n\n\n\nFigure¬†4: Counterfactual path (left) and predicted probability (right) for GenericGenerator. The contour (left) shows the predicted probabilities of the classifier (Logistic Regression)."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#probabilistic-methods-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-dscc/presentation.html#probabilistic-methods-for-counterfactual-explanations",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Probabilistic Methods for Counterfactual Explanations",
    "text": "Probabilistic Methods for Counterfactual Explanations\nWhen people say that counterfactuals should look realistic or plausible, they really mean that counterfactuals should be generated by the same Data Generating Process (DGP) as the factuals:\n\\[\nx\\prime \\sim p(x)\n\\]\nBut how do we estimate \\(p(x)\\)? Two probabilistic approaches ‚Ä¶\n\n\nAPPROACH 1: use the model itselfAPPROACH 2: use some generative model\n\n\n\n\nSchut et al. (2021) note that by maximizing predictive probabilities \\(\\sigma(M(x\\prime))\\) for probabilistic models \\(M\\in\\mathcal{\\widetilde{M}}\\) one implicitly minimizes epistemic and aleotoric uncertainty.\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) \\ \\ \\ , \\ \\ \\ M\\in\\mathcal{\\widetilde{M}}\n\\qquad(7)\\]\n\n\n\n\nFigure¬†5: A cat performing gradient descent in the feature space √† la Schut et al. (2021)\n\n\n\n\n\n\n\n\nInstead of perturbing samples directly, some have proposed to instead traverse a lower-dimensional latent embedding learned through a generative model (Joshi et al. 2019).\n\\[\nz\\prime = \\arg \\min_{z\\prime}  \\ell(M(dec(z\\prime)),t) + \\lambda h(x\\prime)\n\\qquad(8)\\]\nand\n\\[x\\prime = dec(z\\prime)\\]\nwhere \\(dec(\\cdot)\\) is the decoder function.\n\n\n\n\nFigure¬†6: Counterfactual (yellow) generated through latent space search (right panel) following Joshi et al. (2019). The corresponding counterfactual path in the feature space is shown in the left panel."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#greedy-generator",
    "href": "content/talks/posts/2022-dscc/presentation.html#greedy-generator",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Greedy Generator",
    "text": "Greedy Generator\n\n\nCode\n. . .\nThis time we use a Bayesian classifier ‚Ä¶\n\nusing LinearAlgebra\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.01 + UniformScaling(1)) # MAP covariance matrix\nŒº = hcat(b, w)\nM = BayesianLogisticModel(Œº, Œ£)\n\n. . .\n‚Ä¶ and once again choose our target label as before ‚Ä¶\n\n# Select target class:\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target\n\n. . .\n‚Ä¶ to then finally use greedy search to find a counterfactual.\n\n# Counterfactual search:\ngenerator = GreedyGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\nConvergence: ‚úÖ\n\n\n\n after 62 steps.\n\n\n\nOutput\n. . .\n\nIn this case the Bayesian approach yields a similar outcome.\n\n\nanim = animate_path(counterfactual; plot_proba=true, colorbar=false, size=(800,300), alpha_=0.7)\ngif(anim, fps=15)\n\n\n\nFigure¬†7: Counterfactual path (left) and predicted probability (right) for GreedyGenerator. The contour (left) shows the predicted probabilities of the classifier (Bayesian Logistic Regression)."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#latent-space-generator",
    "href": "content/talks/posts/2022-dscc/presentation.html#latent-space-generator",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Latent Space Generator",
    "text": "Latent Space Generator\n\n\nCode\n. . .\nUsing the same classifier as before we can either use the specific REVISEGenerator ‚Ä¶\n\n# Counterfactual search:\ngenerator = REVISEGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n. . .\n‚Ä¶ or realize that that REVISE (Joshi et al. 2019) just boils down to generic search in a latent space:\n\n# Counterfactual search:\ngenerator = GenericGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator,\n  latent_space=true\n)\n\n\nConvergence: ‚úÖ\n\n\n\n after 8 steps.\n\n\n\nOutput\n. . .\n\nWe have essentially combined latent search with a probabilistic classifier (as in Antor√°n et al. (2020)).\n\n\nanim = animate_path(counterfactual; plot_proba=true, colorbar=false, size=(800,300), alpha_=0.7)\ngif(anim, fps=2)\n\n\n\nFigure¬†8: Counterfactual path (left) and predicted probability (right) for REVISEGenerator."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#diverse-counterfactuals",
    "href": "content/talks/posts/2022-dscc/presentation.html#diverse-counterfactuals",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Diverse Counterfactuals",
    "text": "Diverse Counterfactuals\n\n\nCode\n. . .\nWe can use the DiCEGenerator to produce multiple diverse counterfactuals:\n\n# Counterfactual search:\ngenerator = DiCEGenerator(Œª=[0.1, 5.0])\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator;\n  num_counterfactuals = 5\n)\n\n\nConvergence: ‚úÖ\n\n\n\n after 28 steps.\n\n\n\nOutput\n. . .\n\nanim = animate_path(counterfactual; plot_proba=true, colorbar=false, size=(800,300), alpha_=0.7)\ngif(anim, fps=20)\n\n\n\nFigure¬†9: Counterfactual path (left) and predicted probability (right) for DiCEGenerator."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#motivation",
    "href": "content/talks/posts/2022-dscc/presentation.html#motivation",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Motivation",
    "text": "Motivation\n\n\n\nTL;DR: We find that standard implementation of various SOTA approaches to AR can induce substantial domain and model shifts. We argue that these dynamics indicate that individual recourse generates hidden external costs and provide mitigation strategies.\n\nIn this work we investigate what happens if Algorithmic Recourse is actually implemented by a large number of individuals.\nFigure¬†10 illustrates what we mean by Endogenous Macrodynamics in Algorithmic Recourse:\n\nPanel (a): we have a simple linear classifier trained for binary classification where samples from the negative class (y=0) are marked in blue and samples of the positive class (y=1) are marked in orange\nPanel (b): the implementation of AR for a random subset of individuals leads to a noticable domain shift\nPanel (c): as the classifier is retrained we observe a corresponding model shift (Upadhyay, Joshi, and Lakkaraju 2021)\nPanel (d): as this process is repeated, the decision boundary moves away from the target class.\n\n\n\n\n\nFigure¬†10: Proof of concept: repeated implementation of AR leads to domain and model shifts.\n\n\n\nWe argue that these shifts should be considered as an expected external cost of individual recourse and call for a paradigm shift from individual to collective recourse in these types of situations."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#findings",
    "href": "content/talks/posts/2022-dscc/presentation.html#findings",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Findings",
    "text": "Findings\n\n\n\n\n\nResults for synthetic data.\n\n\n\n\n\n\nResults for real-word data."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#mitigation-strategies---intuition",
    "href": "content/talks/posts/2022-dscc/presentation.html#mitigation-strategies---intuition",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Mitigation Strategies - Intuition",
    "text": "Mitigation Strategies - Intuition\n\n\n\nChoose more conservative decision thresholds.\nClassifer Preserving ROAR (ClaPROAR): penalise classifier loss.\nGravitational Counterfactual Explanations: penalise distance to some sensible point in the target domain.\n\n\n\n\n\nFigure¬†11: Illustrative example demonstrating the properties of the various mitigation strategies. Samples from the negative class \\((y = 0)\\) are marked in blue while samples of the positive class \\((y = 1)\\) are marked in orange."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#mitigation-strategies---findings",
    "href": "content/talks/posts/2022-dscc/presentation.html#mitigation-strategies---findings",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Mitigation Strategies - Findings",
    "text": "Mitigation Strategies - Findings\n\n\n\n\n\nMitigation strategies applied to synthetic data.\n\n\n\n\n\n\nMitigation strategies applied to real-world data."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "href": "content/talks/posts/2022-dscc/presentation.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Effortless Bayesian Deep Learning through Laplace Redux",
    "text": "Effortless Bayesian Deep Learning through Laplace Redux\n   \n\n\nLaplaceRedux.jl (formerly BayesLaplace.jl) is a small package that can be used for effortless Bayesian Deep Learning and Logistic Regression trough Laplace Approximation. It is inspired by this Python library and its companion paper.\n\n\n\nPlugin Approximation (left) and Laplace Posterior (right) for simple artificial neural network.\n\n\n\n\n\n\nSimulation of changing posteriour predictive distribution. Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#conformalprediction.jl",
    "href": "content/talks/posts/2022-dscc/presentation.html#conformalprediction.jl",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "ConformalPrediction.jl",
    "text": "ConformalPrediction.jl\n      \nConformalPrediction.jl is a package for Uncertainty Quantification (UQ) through Conformal Prediction (CP) in Julia. It is designed to work with supervised models trained in MLJ (Blaom et al. 2020). Conformal Prediction is distribution-free, easy-to-understand, easy-to-use and model-agnostic.\n\n\n\nConformal Prediction in action: Prediction sets for two different samples and changing coverage rates. As coverage grows, so does the size of the prediction sets."
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#more-resources",
    "href": "content/talks/posts/2022-dscc/presentation.html#more-resources",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nBlog post introducing CE: [TDS], [blog].\nBlog post on Laplace Redux: [TDS], [blog].\nBlog post on Conformal Prediction: [TDS], [blog].\n\n\n‚Ä¶ or get involved! ü§ó\n\n\nContributor‚Äôs Guide for CounterfactualExplanations.jl\nContributor‚Äôs Guide for ConformalPrediction.jl"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#image-sources",
    "href": "content/talks/posts/2022-dscc/presentation.html#image-sources",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Image Sources",
    "text": "Image Sources\n\nCrystal ball on beach: Nicole Avagliano on Unsplash\nColour gradient: A.Z on Unsplash\nElephant herd: Sergi Ferrete on Unsplash\nDSCC 2022 logo: ING"
  },
  {
    "objectID": "content/talks/posts/2022-dscc/presentation.html#references",
    "href": "content/talks/posts/2022-dscc/presentation.html#references",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "References",
    "text": "References\n\n\n\nExplaining Black-Box Models through Counterfactuals ‚Äî Patrick Altmeyer ‚Äî CC BY-NC\n\n\n\nAltmeyer, Patrick. 2022. ‚ÄúCounterfactualExplanations.jl - a Julia Package for Counterfactual Explanations and Algorithmic Recourse.‚Äù https://github.com/pat-alt/CounterfactualExplanations.jl.\n\n\nAntor√°n, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and Jos√© Miguel Hern√°ndez-Lobato. 2020. ‚ÄúGetting a Clue: A Method for Explaining Uncertainty Estimates.‚Äù https://arxiv.org/abs/2006.06848.\n\n\nBlaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. ‚ÄúMLJ: A Julia Package for Composable Machine Learning.‚Äù Journal of Open Source Software 5 (55): 2704. https://doi.org/10.21105/joss.02704.\n\n\nGoodfellow, Ian J, Jonathon Shlens, and Christian Szegedy. 2014. ‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù https://arxiv.org/abs/1412.6572.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKarimi, Amir-Hossein, Bernhard Sch√∂lkopf, and Isabel Valera. 2021. ‚ÄúAlgorithmic Recourse: From Counterfactual Explanations to Interventions.‚Äù In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 353‚Äì62.\n\n\nKarimi, Amir-Hossein, Julius Von K√ºgelgen, Bernhard Sch√∂lkopf, and Isabel Valera. 2020. ‚ÄúAlgorithmic Recourse Under Imperfect Causal Knowledge: A Probabilistic Approach.‚Äù https://arxiv.org/abs/2006.06831.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nO‚ÄôNeil, Cathy. 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown.\n\n\nPawelczyk, Martin, Sascha Bielawski, Johannes van den Heuvel, Tobias Richter, and Gjergji Kasneci. 2021. ‚ÄúCARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms.‚Äù https://arxiv.org/abs/2108.00783.\n\n\nPoyiadzi, Rafael, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, and Peter Flach. 2020. ‚ÄúFACE: Feasible and Actionable Counterfactual Explanations.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 344‚Äì50.\n\n\nRudin, Cynthia. 2019. ‚ÄúStop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.‚Äù Nature Machine Intelligence 1 (5): 206‚Äì15. https://doi.org/10.1038/s42256-019-0048-x.\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nUstun, Berk, Alexander Spangher, and Yang Liu. 2019. ‚ÄúActionable Recourse in Linear Classification.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 10‚Äì19. https://doi.org/10.1145/3287560.3287566.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nWilson, Andrew Gordon. 2020. ‚ÄúThe Case for Bayesian Deep Learning.‚Äù https://arxiv.org/abs/2001.10995."
  },
  {
    "objectID": "content/talks/posts/2023-ictopen/presentation.html#taija",
    "href": "content/talks/posts/2023-ictopen/presentation.html#taija",
    "title": "Taija - Trustworthy AI in Julia",
    "section": "üê∂ Taija",
    "text": "üê∂ Taija\n\nResearch informs development, development informs research.\n\n\nTrustworthy Artificial Intelligence in Julia.Taija is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.\nOur work has been presented at JuliaCon 2022 and will be presented again at JuliaCon 2023 and hopefully beyond."
  },
  {
    "objectID": "content/talks/posts/2023-ictopen/presentation.html#current-state",
    "href": "content/talks/posts/2023-ictopen/presentation.html#current-state",
    "title": "Taija - Trustworthy AI in Julia",
    "section": "üõ†Ô∏è Current State",
    "text": "üõ†Ô∏è Current State\n\n\nTowards Trustworthy AI in Julia\n\nCounterfactualExplanations.jl (JuliaCon 2022)\nConformalPrediction.jl (JuliaCon 2023)\nLaplaceRedudx.jl (JuliaCon 2022)\nAlgorithmicRecourseDynamics.jl (IEEE SaTML 2023)\nJointEnergyModels.jl (JuliaCon 2024 ‚Ä¶ I hope?)\n\n‚Ä¶ contributions welcome! üòä"
  },
  {
    "objectID": "content/talks/posts/2023-ictopen/presentation.html#future-plans",
    "href": "content/talks/posts/2023-ictopen/presentation.html#future-plans",
    "title": "Taija - Trustworthy AI in Julia",
    "section": "üöÄ Future Plans",
    "text": "üöÄ Future Plans\n\nPatrick has been actively developing Taija since starting his PhD in 2021 and plans to continue doing so until he graduates in 2025 and beyond.\nTU Delft Student Software Project 2023: a total of 10 students will be working on Taija for the next 2-3 months.\nWe have managed to attract contributors from the Julia community and are looking for more."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#blurb",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#blurb",
    "title": "A year of using Quarto with Julia",
    "section": "Blurb",
    "text": "Blurb\n\nAs a Julia practitioner you may want to publish your work in various forms: notebooks, Markdown, HTML, PDF and more. What if you could produce all these different outputs from the same input? I will share how I‚Äôve been using Quarto with Julia, for package documentation, blogging and JuliaCon proceedings.\n\nDISCLAIMER: Views presented in this presentation are my own. I am not affiliated with either Quarto or Posit (RStudio)."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#quick-intro",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#quick-intro",
    "title": "A year of using Quarto with Julia",
    "section": "Quick Intro",
    "text": "Quick Intro\n\n\n\nCurrently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nWorking on Counterfactual Explanations and Probabilistic Machine Learning with applications in Finance.\nPreviously, educational background in Economics and Finance and two years at the Bank of England.\nEnthusiastic about free open-source software, in particular Julia and Quarto."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#from-r-markdown",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#from-r-markdown",
    "title": "A year of using Quarto with Julia",
    "section": "From R Markdown ‚Ä¶",
    "text": "From R Markdown ‚Ä¶\n\n\n\nR Markdown users have enjoyed many of the benefits highlighted in today‚Äôs for many years.\nFor me personally, the workflow enabled by R Markdown was for many years a key reason to rely on R whenever possible (see here).\nIn recent years Posit (formerly RStudio) has first embraced Python and then geared towards multi-language support.\n\n\n\n\nWe have some wonderful news: RStudio is now Posit! üéâWhile many things will stay the same, our rebrand will result in changes beyond a new name. To start, our new website https://t.co/vI56Gz7Yqf is now live. Please check out our new home and let us know what you think! pic.twitter.com/hzJGXsX0tj\n\n‚Äî Posit PBC (@posit_pbc) November 2, 2022"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#to-quarto",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#to-quarto",
    "title": "A year of using Quarto with Julia",
    "section": "‚Ä¶ to Quarto",
    "text": "‚Ä¶ to Quarto\n\n\n\nGenerate multiple different output formats with ease:\n\nThe old school: \\(\\LaTeX\\) and PDF (including Beamer); MS Office\nThe brave new world: beautiful, dynamic HTML content\n\nwebsites\ne-books\napps\n‚Ä¶\n\n\nAll of this starting from the same place ‚Ä¶\n\n\n\n\n\nQuarto at JuliaCon 2022.\n\n\n\n\n\nA plain Markdown document blended with your favorite programming language and a YAML header defining your output."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#effective-communication-and-reproducibility-in-science",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#effective-communication-and-reproducibility-in-science",
    "title": "A year of using Quarto with Julia",
    "section": "Effective Communication and Reproducibility in Science",
    "text": "Effective Communication and Reproducibility in Science\n\nMost science today involves code. Often code forms such an integral part of the science, that it deserves its place in the final publication.\nScientific Ideas can often be most effectively communicated through dynamic visualizations.\nRequirements and preferences vary.\nQuarto allows us to cater to those needs, while at the same time facilitating reproducibility by bridging the gap between computations and writing.\n\n\nQuarto enables effective communication and reproducibility without compromises."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#code-chunks",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#code-chunks",
    "title": "A year of using Quarto with Julia",
    "section": "Code chunks",
    "text": "Code chunks\nMost science today involves code.\n\nusing Markdown\nMarkdown.parse(\"\"\"\nOften code forms such an integral part of the science, that it deserves its place in the final publication.\n\"\"\")\n\nOften code forms such an integral part of the science, that it deserves its place in the final publication.\n\n\n\nUsing simple YAML options, we can specify how code is displayed. For example, we may want to use code folding to avoid unnecessary interruptions or hide large code chunks like this one that builds Figure¬†1.\n\n\nCode\nusing Javis, Animations, Colors\nwww_path = \"www/images\"\n\n_size = 600\nradius_factor = 0.33\n\nfunction ground(args...)\n    background(\"transparent\")\n    sethue(\"white\")\nend\n\nfunction rotate_anim(idx::Number, total::Number) \n    distance_circle = 0.875\n    steps = collect(range(distance_circle,1-distance_circle,length=total))\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [0, steps[idx]*2œÄ],\n        [sineio()],\n    )\nend\n\ntranslate_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(_size*radius_factor, 0)],\n    [sineio()],\n)\n\ntranslate_back_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(-(_size*radius_factor), 0)],\n    [sineio()],\n)\n\njulia_colours = Dict(\n    :blue =&gt; \"#4063D8\",\n    :green =&gt; \"#389826\",\n    :purple =&gt; \"#9558b2\",\n    :red =&gt; \"#CB3C33\"\n)\ncolour_order = [:red, :purple, :green, :blue]\nn_colours = length(julia_colours)\nfunction color_anim(start_colour::String, quarto_col::String=\"#4b95d0\")\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [Lab(color(start_colour)), Lab(color(quarto_col))],\n        [sineio()],\n    )\nend\n\nvideo = Video(_size, _size)\n\nframe_starts = 1:10:40\nn_total = 250\nn_frames = 150\nBackground(1:n_total, ground)\n\n# Blob:\nfunction element(; radius = 1)\n    circle(O, radius, :fill) # The 4 is to make the circle not so small\nend\n\n# Cross:\nfunction cross(color=\"black\";orientation=:horizontal)\n    sethue(color)\n    setline(10)\n    if orientation==:horizontal\n        out = line(Point(-_size,0),Point(_size,0), :stroke)\n    else\n        out = line(Point(0,-_size),Point(0,_size), :stroke)\n    end\n    return out\nend\n\nfor (i, frame_start) in enumerate(1:10:40)\n\n    # Julia circles:\n    blob = Object(frame_start:n_total, (args...;radius=1) -&gt; element(;radius=radius))\n    act!(blob, Action(1:Int(round(n_frames*0.25)), change(:radius, 1 =&gt; 75))) # scale up\n    act!(blob, Action(n_frames:(n_frames+50), change(:radius, 75 =&gt; 250))) # scale up further\n    act!(blob, Action(1:30, translate_anim, translate()))\n    act!(blob, Action(31:120, rotate_anim(i, n_colours), rotate_around(Point(-(_size*radius_factor), 0))))\n    act!(blob, Action(121:150, translate_back_anim, translate()))\n    act!(blob, Action(1:150, color_anim(julia_colours[colour_order[i]]), sethue()))\n\n    # Quarto cross:\n    cross_h = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:horizontal))\n    cross_v = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:vertical))\nend\n\nrender(\n    video;\n    pathname = joinpath(www_path, \"julia_quarto.gif\"),\n)\n\n\n\n\n\nFigure¬†1: A simple animation built with Javis.jl."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#dynamic-visualizations",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#dynamic-visualizations",
    "title": "A year of using Quarto with Julia",
    "section": "Dynamic Visualizations",
    "text": "Dynamic Visualizations\nScientific Ideas can often be most effectively communicated through dynamic visualizations.\n\nusing Plots\nusing StatsBase\n\nsteps = randn(1)\nT = 100\n\nanim = @animate for t in 2:T\n    append!(steps, randn(1))\n    random_walk = cumsum(steps)\n    p1 = plot(random_walk, color=1, label=\"\", title=\"A Gaussian random walk ...\", xlims=(0,T))\n    acf = autocor(random_walk)\n    p2 = bar(acf, color=1, label=\"\", title=\"... is non-stationary\", xlims=(0,10), ylims=(0,1))\n    plot(p1, p2, size=(800,300))\nend\ngif(anim, fps=5)"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#meeting-varying-requirements",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#meeting-varying-requirements",
    "title": "A year of using Quarto with Julia",
    "section": "Meeting Varying Requirements",
    "text": "Meeting Varying Requirements\n\nQuarto has fantastic support for traditional and modern scholarly writing.\n\n\n\nThe challenge ‚Ä¶\n. . .\nSome people still prefer to read paper or work with MS Office. Most scientific journals, for example, still work with PDF and \\(\\LaTeX\\).\n\n\n\nFigure¬†2: Source: Giphy\n\n\n\n‚Ä¶ and Quarto‚Äôs answer\n. . .\nEquations like Equation¬†1 (as well as Sections, Figures, Theorems, ‚Ä¶) can be cross-referenced in a standardized way.\n$$\n\\begin{aligned}\nZ &= \\sum_{t=0}^T X_t, && X_t \\sim N(\\mu, \\sigma)\n\\end{aligned}\n$$ {#eq-bm}\n\\[\n\\begin{aligned}\nZ &= \\sum_{t=0}^T X_t, && X_t \\sim N(\\mu, \\sigma)\n\\end{aligned}\n\\qquad(1)\\]"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#reproducible-and-dynamic-content",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#reproducible-and-dynamic-content",
    "title": "A year of using Quarto with Julia",
    "section": "Reproducible and Dynamic Content",
    "text": "Reproducible and Dynamic Content\nQuarto allows us to cater to different requirements, while at the same time facilitating reproducibility by bridging the gap between computations and writing.\n\nThe world and the data that describes it is not static üìà. Why should scientific outputs be?\n\n\n\n\nFrom dynamic inputs ‚Ä¶\n. . .\nThe code below depends on remote data that is continuously updated:\n\nusing MarketData\nsnp = yahoo(\"^GSPC\")\n\nusing Dates\nlast_trade_day = timestamp(snp[end])[1]\np_close = values(snp[end,:Close])[1]\nlast_trade_day_formatted = Dates.format(last_trade_day, \"U d, yyyy\")\n\nWe‚Äôd like any updates to the inputs to automatically affect our output (ideally, all the way through to the finished report or paper).\n\n‚Ä¶ to dynamic outputs\n. . .\n\nMarkdown.parse(\"\"\"\nWhen the S&P 500 last traded, on $(last_trade_day_formatted), it closed at $(p_close). \n\"\"\")\n\nWhen the S&P 500 last traded, on February 23, 2023, it closed at 4012.320068."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#in-this-section",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#in-this-section",
    "title": "A year of using Quarto with Julia",
    "section": "In this section ‚Ä¶",
    "text": "In this section ‚Ä¶\n\n\nPreferred setup: VSCode, Quarto and Julia\n\nUsing Julia and VSCode? There‚Äôs a Quarto extension for VSCode, so you can stick with your preferred IDE.\n\n\n\n\nBlogging\n\nQuarto makes it easy to build beautiful websites and blogs.\n\n\n\n\nJulia Packages\n\nDocumenter.jl and Quarto play nicely with each other (both Markdown based).\nTurning Julia packages into Quarto projects comes with a few advantages.\n\n\n\n\nJuliaCon Proceedings\n\nJuliaCon proceedings submissions currently work with a GitHub template that requires users to submit a .tex file.\nQuarto can be used to generate that file, but there are additional benefits we could tab into."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#vscode-quarto-and-julia",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#vscode-quarto-and-julia",
    "title": "A year of using Quarto with Julia",
    "section": "VSCode, Quarto and Julia",
    "text": "VSCode, Quarto and Julia\n\nTo get started, see here.\n\n\nSome tips to get started\n\n\n\nAdd IJulia to startup.jl\n\n\nIf you install a new Julia binary [‚Ä¶], you must update the IJulia installation [‚Ä¶] by running Pkg.build(\"IJulia\")\n‚Äî Source: IJulia docs\n\n\n\nUser snippets need to be explicitly enabled (see here)\n\n{\n  \"Two columns\": {\n    \"prefix\": \"cols\",\n    \"body\": [\n      \"::::{.columns}::::\",\n      \":::{.column width='$1%'}\",\n      \":::\",\n      \":::{.column width='$2%'}\",\n      \":::\",\n      \"::::\"\n    ]\n  }\n}\n\n\n. . .\nUsing .ipynb vs .qmd\n\nCan switch between Jupyter and .qmd with ease.\nWhen working with .qmd, code chunks connect to REPL.\nSet keep-ipynb: true to have interactive notebooks in repo."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#blogging-1",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#blogging-1",
    "title": "A year of using Quarto with Julia",
    "section": "Blogging",
    "text": "Blogging\n\nThese very slides are not only built using Quarto, but also hosted on a website that is also run on Quarto.\n\n\nOrganization ‚Äî Quarto uses something call document listings: an easy way to collect, arrange and navigate content like this one.\n---\ntitle: \"Talks\"\nlisting:\n  contents: \n    - \"posts/*/index.qmd\"\n  sort: \"date desc\"\n  type: default\n  categories: false\n  fields: [image, date, title, description, author, file-modified]\n  image-align: left\n---\n\n\nCode Execution ‚Äî You can specify YAML options such that changes to your underlying Julia code will trigger your blog post to be rerendered. This essentially allows you to easily test that the code you publish actually runs:\nexecute:\n  freeze: auto\n  eval: true\n  echo: true\n  output: false\n\n\nReproducibility ‚Äî The Julia version and environment can be managed globally or locally for individual blog posts:\njupyter: julia-1.8\nusing Pkg; Pkg.activate(\"&lt;path&gt;\")\n\n\nCommunity Engagement ‚Äî It is remarkably easy to engage the community through support for commenting, an RSS Feed, ‚Ä¶\ncomments:\n  utterances:\n    repo: quarto-dev/quarto-docs"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#julia-packages-1",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#julia-packages-1",
    "title": "A year of using Quarto with Julia",
    "section": "Julia Packages",
    "text": "Julia Packages\n\nDocumenter.jl and Quarto generally play nicely with each other (both Markdown based).\n\nformat: \n  commonmark:\n    variant: -raw_html\n    wrap: preserve\n\nYou get some stuff for free, e.g.¬†citation management. Unfortunately, still no support for cross-referencing ‚Ä¶\nThe use of jldoctest is not always straight-forward (see here). Letting docs run through the Quarto engine provides an additional layer of quality assurance.\nAdmonitions can be used as follows (see related discussion):\n\n| !!! note \\\"An optional title\\\"\n| &nbsp; &nbsp; Here is something that you should pay attention to.   \n\n\nAs an example, we will look at ‚Ä¶ ü•Å\n\n\n\nLaplaceRedux.jl\n      \nLaplaceRedux.jl is a library written in pure Julia that can be used for effortless Bayesian Deep Learning trough Laplace Approximation (LA)."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#juliacon-proceedings-1",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#juliacon-proceedings-1",
    "title": "A year of using Quarto with Julia",
    "section": "JuliaCon Proceedings",
    "text": "JuliaCon Proceedings\n\nQuarto supports \\(\\LaTeX\\) templates/classes, but I‚Äôve found that rticles still has an edge here.\nThe list of out-of-the-box templates for journal articles is growing.\n\n\n\nAs an example we will look at ‚Ä¶ ü•Å\n\n\n‚Ä¶ my pending JuliaCon Proceedings submission for my 2022 talk: Explaining Black-Box Models through Counterfactuals\n\n\n\n\n‚Ä¶ but why only publish proceedings in PDF form?\nQuarto opens the floodgates to more innovative forms of publishing (think distill, but more than that)"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#counterfactualexplanations.jl",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#counterfactualexplanations.jl",
    "title": "A year of using Quarto with Julia",
    "section": "CounterfactualExplanations.jl",
    "text": "CounterfactualExplanations.jl\n   \n\n\nCounterfactualExplanations.jl is a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box algorithms. Both CE and AR are related tools for explainable artificial intelligence (XAI). While the package is written purely in Julia, it can be used to explain machine learning algorithms developed and trained in other popular programming languages like Python and R. See below for short introduction and other resources or dive straight into the docs.\n\n\n\nTurning a nine (9) into a four (4).\n\n\n\n\n\n\nA sad üê± on its counterfactual path to its cool dog friends."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#laplaceredux.jl-1",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#laplaceredux.jl-1",
    "title": "A year of using Quarto with Julia",
    "section": "LaplaceRedux.jl",
    "text": "LaplaceRedux.jl\n   \nJuliaCon 22: Effortless Bayesian Deep Learning through Laplace Redux\n\n\nLaplaceRedux.jl is a small package that can be used for effortless Bayesian Deep Learning and Logistic Regression trough Laplace Approximation. It is inspired by this Python library and its companion paper.\n\n\n\nPlugin Approximation (left) and Laplace Posterior (right) for simple artificial neural network.\n\n\n\n\n\n\nSimulation of changing posteriour predictive distribution. Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#conformalprediction.jl",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#conformalprediction.jl",
    "title": "A year of using Quarto with Julia",
    "section": "ConformalPrediction.jl",
    "text": "ConformalPrediction.jl\n      \nConformalPrediction.jl is a package for Uncertainty Quantification (UQ) through Conformal Prediction (CP) in Julia. It is designed to work with supervised models trained in MLJ (Blaom et al. 2020). Conformal Prediction is distribution-free, easy-to-understand, easy-to-use and model-agnostic.\n\n\n\nConformal Prediction in action: Prediction sets for two different samples and changing coverage rates. As coverage grows, so does the size of the prediction sets."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#more-resources",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#more-resources",
    "title": "A year of using Quarto with Julia",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nRelated blog posts (hosted on this website that itself is built with Quarto and involves lots of Julia content): [1] and [2].\nBlog post introducing CE: [TDS], [blog].\nBlog post on Laplace Redux: [TDS], [blog].\nBlog post on Conformal Prediction: [TDS], [blog].\n\n\n‚Ä¶ or get involved! ü§ó\n\n\nContributor‚Äôs Guide for CounterfactualExplanations.jl\nContributor‚Äôs Guide for ConformalPrediction.jl"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#image-sources",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#image-sources",
    "title": "A year of using Quarto with Julia",
    "section": "Image Sources",
    "text": "Image Sources\n\nQuarto logo. Source: Quarto\nJulia to Quarto animation. Source: author (heavily borrowing from Javis.jl tutorial)"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#references",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#references",
    "title": "A year of using Quarto with Julia",
    "section": "References",
    "text": "References\n\n\n\nA year of using Quarto with Julia ‚Äî Patrick Altmeyer ‚Äî CC BY-NC\n\n\n\nBlaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. ‚ÄúMLJ: A Julia Package for Composable Machine Learning.‚Äù Journal of Open Source Software 5 (55): 2704. https://doi.org/10.21105/joss.02704."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#quick-introduction",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#quick-introduction",
    "title": "Faithful Model Explanations",
    "section": "Quick Introduction",
    "text": "Quick Introduction\n\n\n\nRecently entered the 3rd year of my PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nPreviously, educational background in Economics and Finance and two years in Monetary Policy at the Bank of England.\nInterested in applying Trustworthy AI to real-world problems, particularly in the financial sector."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#counterfactual-explanations",
    "title": "Faithful Model Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\nBorn out of the need for explanations ‚Ä¶\n\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs (Wachter, Mittelstadt, and Russell 2017).\n\nProvided the changes are realistic and actionable, they can be used for Algorithmic Recourse (AR) to help individuals who face adverse outcomes."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-consumer-credit",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-consumer-credit",
    "title": "Faithful Model Explanations",
    "section": "Example: Consumer Credit",
    "text": "Example: Consumer Credit\nFrom ‚Äòloan denied‚Äô to ‚Äòloan supplied‚Äô: CounterfactualExplanations.jl üì¶.\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search.\n\n\n\n\n\n\nFigure¬†2: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-insurance-premium",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-insurance-premium",
    "title": "Faithful Model Explanations",
    "section": "Example: Insurance Premium1",
    "text": "Example: Insurance Premium1\n\n\nInput \\(\\mathbf{X}\\): A dataset of individuals containing demographic and financial information.\nAdditional Input \\(\\mathbf{Z}\\): Individuals can opt-in to provide their personal Apple Health data to improve their chance of receiving a lower premium.\nBinary output \\(\\mathbf{Y}\\): based on the data, the individual is either eligible (\\(y=1\\)) or not eligible (\\(y=0\\)) for a lower premium.\nTo model \\(p(y=1|X)\\) the insurance provider can rely on an interpretable linear classifier.\nTo model \\(p(y=1|X,Z)\\) the insurance provider turns to a more accurate but less interpretable black-box model.\n\n\nFor simplicity, we‚Äôll stay in the classification setting. Work on counterfactual regression like Spooner et al. (2021) exists but it is scarce."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-insurance-premium-1",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-insurance-premium-1",
    "title": "Faithful Model Explanations",
    "section": "Example: Insurance Premium",
    "text": "Example: Insurance Premium\nIn the EU, individuals have the right ‚Äú[‚Ä¶] to obtain an explanation of the decision reached after such assessment and to challenge the decision.‚Äù (Recital 71 of the General Data Protection Regulation (GDPR))\n\n\nIn our example, who do you think is most likely to ask for an explanation?"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#gradient-based-counterfactual-search",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#gradient-based-counterfactual-search",
    "title": "Faithful Model Explanations",
    "section": "Gradient-based Counterfactual Search",
    "text": "Gradient-based Counterfactual Search\nThe starting point for most counterfactual generators is as follows,\n\\[\n\\begin{aligned}\n\\mathbf{Z}^\\prime =& \\arg \\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} \\\\ &+ \\lambda {\\text{cost}(f(\\mathbf{Z}^\\prime)) }  \\}\n\\end{aligned}\n\\tag{1}\\]\nwhere \\(\\mathbf{Z}^\\prime\\) is a counterfactual, \\(M_{\\theta}\\) is the black-box model and \\(\\mathbf{y}^+\\) is the desired output."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#but-wait-a-second",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#but-wait-a-second",
    "title": "Faithful Model Explanations",
    "section": "But wait a second ‚Ä¶",
    "text": "But wait a second ‚Ä¶\nEquation¬†1 looks a lot like an adversarial attack (Goodfellow, Shlens, and Szegedy 2014), doesn‚Äôt it?\n\nFigure¬†3: Adversarial attack on an Image Classifier.In both settings, we take gradients with respect to features \\(\\nabla_{\\mathbf{Z}^\\prime}\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)\\) in order to trigger changes in the model‚Äôs output."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#gradient-descend-visualized",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#gradient-descend-visualized",
    "title": "Faithful Model Explanations",
    "section": "Gradient Descend Visualized",
    "text": "Gradient Descend Visualized\n\nFigure¬†4: Gradient-based counterfactual search."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#open-questions",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#open-questions",
    "title": "Faithful Model Explanations",
    "section": "Open Questions",
    "text": "Open Questions\n\n\nWhat makes a counterfactual plausible?\nWhy do we need plausibility?\nIs plausibility all we need?\nWhat makes models more explainable?"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#plausibility",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#plausibility",
    "title": "Faithful Model Explanations",
    "section": "Plausibility",
    "text": "Plausibility\nThere‚Äôs no consensus on the exact definition of plausibility but we think about it as follows:\n\nDefinition 1 (Plausible Counterfactuals) Let \\(\\mathcal{X}|\\mathbf{y}^+= p(\\mathbf{x}|\\mathbf{y}^+)\\) denote the true conditional distribution of samples in the target class \\(\\mathbf{y}^+\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a plausible counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}|\\mathbf{y}^+\\)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#counter-example",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#counter-example",
    "title": "Faithful Model Explanations",
    "section": "Counter Example",
    "text": "Counter Example\n\n\n\nThe counterfactual in Figure¬†5 is valid: it has crossed the decision boundary.\nBut is it consistent with the data in the target class (blue)?\n\n\n\n\n\nFigure¬†5: A valid but implausible counterfactual. Source: Altmeyer, Deursen, et al. (2023)"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#why-plausibility",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#why-plausibility",
    "title": "Faithful Model Explanations",
    "section": "Why Plausibility?",
    "text": "Why Plausibility?\n\nActionability: If a counterfactual is implausible, it is unlikely to be actionable.\nFairness: If a counterfactual is implausible, it is unlikely to be fair.\nRobustness: If a counterfactual is implausible, it is unlikely to be robust.\n\nBut: Higher plausibility seems to require larger changes and hence increase costs to individuals."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#recourse-dynamics",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#recourse-dynamics",
    "title": "Faithful Model Explanations",
    "section": "Recourse Dynamics",
    "text": "Recourse Dynamics\nMoving just across the decision boundary may minimize costs to individuals but it may also generate external costs for other stakeholders (Altmeyer et al. 2023)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#a-balancing-act",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#a-balancing-act",
    "title": "Faithful Model Explanations",
    "section": "A Balancing Act",
    "text": "A Balancing Act\n\n\nMinimizing private costs generates external costs for other stakeholders.\nTo avoid this, counterfactuals need to be plausible, i.e.¬†comply with the data-generating process.\nIn practice, costs to various stakeholders need to be carefully balanced.\n\n\n\n\nIs plausibility really all we need?"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#pick-your-poison",
    "title": "Faithful Model Explanations",
    "section": "Pick your Poison?",
    "text": "Pick your Poison?\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction. Which one would you pick?\n\nFigure¬†6: Turning a 9 into a 7: Counterfactual Examplanations for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#what-do-models-learn",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#what-do-models-learn",
    "title": "Faithful Model Explanations",
    "section": "What do Models Learn?",
    "text": "What do Models Learn?\nThese images are sampled from the posterior distribution learned by the model. Looks different, no?\n\nFigure¬†7: Conditional Generated Images from the Image Classifier"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#faithful-counterfactuals",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#faithful-counterfactuals",
    "title": "Faithful Model Explanations",
    "section": "Faithful Counterfactuals",
    "text": "Faithful Counterfactuals\n\n\nWe propose a way to generate counterfactuals that are as plausible as the underlying model permits (under review).\n\nDefinition 2 (Faithful Counterfactuals) Let \\(\\mathcal{X}_{\\theta}|\\mathbf{y}^+ = p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\) denote the conditional distribution of \\(\\mathbf{x}\\) in the target class \\(\\mathbf{y}^+\\), where \\(\\theta\\) denotes the parameters of model \\(M_{\\theta}\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a faithful counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}_{\\theta}|\\mathbf{y}^+\\).\n\n\n\n\n\n\n\n\nFigure¬†8: Gradient fields and counterfactual paths for different generators."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#improving-models",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#improving-models",
    "title": "Faithful Model Explanations",
    "section": "Improving Models",
    "text": "Improving Models\nNow that we have a tool to faithfully explain models we may ask: how do models learn plausible explanations? Initial evidence:\n\nIncorporating predictive uncertainty (e.g.¬†ensembling).\nAddressing robustness (e.g.¬†adversarial training in Schut et al. (2021)).\nBetter model architectures.\nHybrid modelling (i.e.¬†combining generative and discriminative models)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-architecture",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-architecture",
    "title": "Faithful Model Explanations",
    "section": "Example: Architecture",
    "text": "Example: Architecture\n\nFigure¬†9: Counterfactuals for LeNet-5 convolutional neural network (LeCun et al. 1998)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-jem-ensemble",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-jem-ensemble",
    "title": "Faithful Model Explanations",
    "section": "Example: JEM Ensemble",
    "text": "Example: JEM Ensemble\n\nFigure¬†10: Counterfactuals for an ensemble of Joint Energy Models (JEM) (Grathwohl et al. 2020)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#taija",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#taija",
    "title": "Faithful Model Explanations",
    "section": "üê∂ Taija",
    "text": "üê∂ Taija\n\nResearch informs development, development informs research.\n\n\nTrustworthy Artificial Intelligence in Julia.Taija is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.\nOur work has been presented online for JuliaCon 2022, at MIT in Boston for JuliaCon 2023 and hopefully beyond."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#counterfactual-explanations-1",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#counterfactual-explanations-1",
    "title": "Faithful Model Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\nAll the work presented today is powered by CounterfactualExplanations.jl üì¶.\nThere is also a corresponding paper, Explaining Black-Box Models through Counterfactuals, which has been published in JuliaCon Proceedings.\nIf you decide to use this package in your work, please consider citing the paper:"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#conformal-prediction",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#conformal-prediction",
    "title": "Faithful Model Explanations",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nConformal Prediction is a model-agnostic, distribution-free approach to Predictive Uncertainty Quantification: ConformalPrediction.jl üì¶.\n\n\n\n\n\nFigure¬†11: Conformal Prediction intervals for regression.\n\n\n\n\n\n\nFigure¬†12: Conformal Prediction sets for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#laplace-redux",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#laplace-redux",
    "title": "Faithful Model Explanations",
    "section": "Laplace Redux",
    "text": "Laplace Redux\n\n\nEffortless Bayesian Deep Learning through Laplace Approximation Daxberger et al. (2021): LaplaceRedux.jl üì¶.\n\n\n\n\nFigure¬†13: Predictive interval for neural network with Laplace Approximation."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#joint-energy-models",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#joint-energy-models",
    "title": "Faithful Model Explanations",
    "section": "Joint Energy Models",
    "text": "Joint Energy Models\nJoint Energy Models (JEMs) are hybrid models trained to learn the conditional output and input distribution (Grathwohl et al. 2020): JointEnergyModels.jl üì¶.\n\nFigure¬†14: A JEM trained on Circles data."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#questions",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#questions",
    "title": "Faithful Model Explanations",
    "section": "Questions?",
    "text": "Questions?\n\n\nIncludes joint work with Cynthia C. S. Liem, Arie van Deursen, Mojtaba Farmanbar, Aleksander Buszydlik, Karol Dobiczek, Giovan Angela and many other students at TU Delft.\nSlides power by Quarto."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#references",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#references",
    "title": "Faithful Model Explanations",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nAltmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia CS Liem. 2023. ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse.‚Äù In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 418‚Äì31. IEEE.\n\n\nAltmeyer, Patrick, Arie van Deursen, et al. 2023. ‚ÄúExplaining Black-Box Models Through Counterfactuals.‚Äù In Proceedings of the JuliaCon Conferences, 1:130. 1.\n\n\nDaxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. ‚ÄúLaplace Redux-Effortless Bayesian Deep Learning.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nGoodfellow, Ian J, Jonathon Shlens, and Christian Szegedy. 2014. ‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù https://arxiv.org/abs/1412.6572.\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nImmer, Alexander, Maciej Korzepa, and Matthias Bauer. 2020. ‚ÄúImproving Predictions of Bayesian Neural Networks via Local Linearization.‚Äù https://arxiv.org/abs/2008.08400.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit.\n\n\nLeCun, Yann, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. ‚ÄúGradient-Based Learning Applied to Document Recognition.‚Äù Proceedings of the IEEE 86 (11): 2278‚Äì2324.\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nSpooner, Thomas, Danial Dervovic, Jason Long, Jon Shepard, Jiahao Chen, and Daniele Magazzeni. 2021. ‚ÄúCounterfactual Explanations for Arbitrary Regression Models.‚Äù https://arxiv.org/abs/2106.15212.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2024-aaai/presentation.html#pick-your-poison",
    "title": "ECCCos from the Black Box",
    "section": "Pick your Poison",
    "text": "Pick your Poison\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction.\n\nWhich one would you pick?\n\n\nFigure¬†1: Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using Wachter (Wachter, Mittelstadt, and Russell 2017), Schut (Schut et al. 2021) and REVISE (Joshi et al. 2019)."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#summary",
    "href": "content/talks/posts/2024-aaai/presentation.html#summary",
    "title": "ECCCos from the Black Box",
    "section": "Summary",
    "text": "Summary\n\n\nIdea: generate counterfactuals that are consistent with what the model has learned about the data.\nMethod: constrain the model‚Äôs energy and predictive uncertainty for the counterfactual.\nResult: faithful counterfactuals that are as plausible as the model permits.\nBenefits: enable us to distinguish trustworthy from unreliable models."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2024-aaai/presentation.html#counterfactual-explanations",
    "title": "ECCCos from the Black Box",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\\[\n\\begin{aligned}\n\\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} + \\lambda {\\text{cost}(f(\\mathbf{Z}^\\prime)) }  \\}\n\\end{aligned}\n\\]\n\n\nCounterfactual Explanations (CE) explain how inputs into a model need to change for it to produce different outputs.\n\n\n\n\nFigure¬†2: Gradient-based counterfactual search."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#plausibility",
    "href": "content/talks/posts/2024-aaai/presentation.html#plausibility",
    "title": "ECCCos from the Black Box",
    "section": "Plausibility",
    "text": "Plausibility\n\n\n\nDefinition 1 (Plausible Counterfactuals) Let \\(\\mathcal{X}|\\mathbf{y}^+= p(\\mathbf{x}|\\mathbf{y}^+)\\) denote the true conditional distribution of samples in the target class \\(\\mathbf{y}^+\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a plausible counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}|\\mathbf{y}^+\\).\n\n\n\n\nWhy Plausibility?\n\n\nPlausibility is positively associated with actionability, robustness (Artelt et al. 2021) and causal validity (Mahajan, Tan, and Sharma 2020).\n\n\n\n\n\n\n\nFigure¬†3: Kernel density estimate (KDE) for the conditional distribution, \\(p(\\mathbf{x}|\\mathbf{y}^+)\\), based on observed data. Counterfactual path as in Figure¬†2."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#faithfulness",
    "href": "content/talks/posts/2024-aaai/presentation.html#faithfulness",
    "title": "ECCCos from the Black Box",
    "section": "Faithfulness",
    "text": "Faithfulness\n\n\n\nDefinition 2 (Faithful Counterfactuals) Let \\(\\mathcal{X}_{\\theta}|\\mathbf{y}^+ = p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\) denote the conditional distribution of \\(\\mathbf{x}\\) in the target class \\(\\mathbf{y}^+\\), where \\(\\theta\\) denotes the parameters of model \\(M_{\\theta}\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a faithful counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}_{\\theta}|\\mathbf{y}^+\\).\n\n\n\n\nTrustworthy Models\n\n\nIf the model posterior approximates the true posterior (\\(p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+) \\rightarrow p(\\mathbf{x}|\\mathbf{y}^+)\\)), faithful counterfactuals are also plausible.\n\n\n\n\n\n\n\nFigure¬†4: KDE for learned conditional distribution, \\(p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\). Yellow stars indicate conditional samples generated through SGLD for a joint energy model (JEM)."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#eccco",
    "href": "content/talks/posts/2024-aaai/presentation.html#eccco",
    "title": "ECCCos from the Black Box",
    "section": "ECCCo",
    "text": "ECCCo\n\n\n\n\n\nKey Idea\n\n\nUse the hybrid objective of joint energy models (JEM) and a model-agnostic penalty for predictive uncertainty: Energy-Constrained (\\(\\mathcal{E}_{\\theta}\\)) Conformal (\\(\\Omega\\)) Counterfactuals (ECCCo).\n\n\n\n\nECCCo objective1:\n\\[\n\\begin{aligned}\n& \\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {L_{\\text{clf}}(f(\\mathbf{Z}^\\prime);M_{\\theta},\\mathbf{y}^+)}+ \\lambda_1 {\\text{cost}(f(\\mathbf{Z}^\\prime)) } \\\\\n&+ \\lambda_2 \\mathcal{E}_{\\theta}(f(\\mathbf{Z}^\\prime)|\\mathbf{y}^+) + \\lambda_3 \\Omega(C_{\\theta}(f(\\mathbf{Z}^\\prime);\\alpha)) \\}\n\\end{aligned}\n\\]\n\n\n\nFigure¬†5: Gradient fields and counterfactual paths for different generators.\n\n\n\n\nWe leverage ideas from Grathwohl et al. (2020) and Stutz et al. (2022). See the paper and appendix for a derivation of the objective from first principles."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#visual-evidence",
    "href": "content/talks/posts/2024-aaai/presentation.html#visual-evidence",
    "title": "ECCCos from the Black Box",
    "section": "Visual Evidence",
    "text": "Visual Evidence\n\n\n\n\n\nFigure¬†6: Turning a 9 into a 7. ECCCo applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).\n\n\n\nECCCo generates counterfactuals that\n\nfaithfully represent model quality (Figure¬†6).\nachieve state-of-the-art plausibility (Figure¬†7).\n\n\n\n\nFigure¬†7: Results for different generators (from 3 to 5)."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#the-numbers",
    "href": "content/talks/posts/2024-aaai/presentation.html#the-numbers",
    "title": "ECCCos from the Black Box",
    "section": "The Numbers",
    "text": "The Numbers\n\nLarge benchmarks on a variety of models and datasets from various domains.\nECCCo achieves state-of-the-art faithfulness across models and datasets and approaches state-of-the-art plausibility for more trustworthy models."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#code",
    "href": "content/talks/posts/2024-aaai/presentation.html#code",
    "title": "ECCCos from the Black Box",
    "section": "Code",
    "text": "Code\nThe code used to run the analysis for this work is built on top of CounterfactualExplanations.jl.\nThere is also a corresponding paper, Explaining Black-Box Models through Counterfactuals, which has been published in JuliaCon Proceedings.\n\nTrustworthy AI in Julia: github.com/JuliaTrustworthyAI"
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#references",
    "href": "content/talks/posts/2024-aaai/presentation.html#references",
    "title": "ECCCos from the Black Box",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nArtelt, Andr√©, Valerie Vaquet, Riza Velioglu, Fabian Hinder, Johannes Brinkrolf, Malte Schilling, and Barbara Hammer. 2021. ‚ÄúEvaluating Robustness of Counterfactual Explanations.‚Äù In 2021 IEEE Symposium Series on Computational Intelligence (SSCI), 01‚Äì09. IEEE.\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nMahajan, Divyat, Chenhao Tan, and Amit Sharma. 2020. ‚ÄúPreserving Causal Constraints in Counterfactual Explanations for Machine Learning Classifiers.‚Äù https://arxiv.org/abs/1912.03277.\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nStutz, David, Krishnamurthy, Dvijotham, Ali Taylan Cemgil, and Arnaud Doucet. 2022. ‚ÄúLearning Optimal Conformal Classifiers.‚Äù https://arxiv.org/abs/2110.09192.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#quick-introduction",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#quick-introduction",
    "title": "Echos from the Black Box",
    "section": "Quick Introduction",
    "text": "Quick Introduction\n\n\n\nCurrently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nPreviously, educational background in Economics and Finance and two years in Monetary Policy at the Bank of England.\nInterested in applying Trustworthy AI to real-world problems, particularly in the financial sector."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#counterfactual-explanations",
    "title": "Echos from the Black Box",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs.\n\nProvided the changes are realistic and actionable, they can be used for Algorithmic Recourse (AR) to help individuals who face adverse outcomes."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#example-consumer-credit",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#example-consumer-credit",
    "title": "Echos from the Black Box",
    "section": "Example: Consumer Credit",
    "text": "Example: Consumer Credit\nFrom ‚Äòloan denied‚Äô to ‚Äòloan supplied‚Äô: CounterfactualExplanations.jl üì¶.\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search.\n\n\n\n\n\n\nFigure¬†2: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#conformal-prediction",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#conformal-prediction",
    "title": "Echos from the Black Box",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nConformal Prediction is a model-agnostic, distribution-free approach to Predictive Uncertainty Quantification: ConformalPrediction.jl üì¶.\n\n\n\n\n\nFigure¬†3: Conformal Prediction intervals for regression.\n\n\n\n\n\n\nFigure¬†4: Conformal Prediction sets for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#joint-energy-models",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#joint-energy-models",
    "title": "Echos from the Black Box",
    "section": "Joint Energy Models",
    "text": "Joint Energy Models\nJoint Energy Models (JEMs) are hybrid models trained to learn the conditional output and input distribution (Grathwohl et al. 2020): JointEnergyModels.jl üì¶.\n\nFigure¬†5: A JEM trained on Circles data."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#recourse-dynamics",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#recourse-dynamics",
    "title": "Echos from the Black Box",
    "section": "Recourse Dynamics",
    "text": "Recourse Dynamics\nWe present evidence suggesting that state-of-the-art applications of Algorithmic Recourse to groups of individuals induce large domain and model shifts and propose ways to mitigate this (IEEE SaTML paper).\nJoint work with Giovan Angela, Karol Dobiczek, Aleksander Buszydlik, Arie van Deursen and Cynthia C. S. Liem (all TU Delft)."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#a-balancing-act",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#a-balancing-act",
    "title": "Echos from the Black Box",
    "section": "A Balancing Act",
    "text": "A Balancing Act\n\n\nMinimizing private costs generates external costs for other stakeholders.\nTo avoid this, counterfactuals need to be plausible, i.e.¬†comply with the data-generating process.\nIn practice, costs to various stakeholders need to be carefully balanced.\n\n\n\n\nIs plausibility really all we need?"
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#pick-your-poison",
    "title": "Echos from the Black Box",
    "section": "Pick your Poison?",
    "text": "Pick your Poison?\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction. Which one would you pick?\n\nFigure¬†6: Turning a 9 into a 7: Counterfactual Examplanations for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#what-do-models-learn",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#what-do-models-learn",
    "title": "Echos from the Black Box",
    "section": "What do Models Learn?",
    "text": "What do Models Learn?\nThese images are sampled from the posterior distribution learned by the model. Looks different, no?\n\nFigure¬†7: Conditional Generated Images from the Image Classifier"
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#ecccos-from-the-black-box",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#ecccos-from-the-black-box",
    "title": "Echos from the Black Box",
    "section": "ECCCos from the Black Box",
    "text": "ECCCos from the Black Box\n\n\nWe propose a framework for generating Energy-Constrained Conformal Counterfactuals (ECCCos) which explain black-box models faithfully.\nJoint work with Mojtaba Framanbar (ING), Arie van Deursen (TU Delft) and Cynthia C. S. Liem (TU Delft).\n\n\n\n\n\n\n\nFigure¬†8: Gradient fields and counterfactual paths for different generators."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#taija",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#taija",
    "title": "Echos from the Black Box",
    "section": "üê∂ Taija",
    "text": "üê∂ Taija\n\nResearch informs development, development informs research.\n\n\nTrustworthy Artificial Intelligence in Julia.Taija is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.\nOur work has been presented at JuliaCon 2022 and will be presented again at JuliaCon 2023 and hopefully beyond."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#questions",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#questions",
    "title": "Echos from the Black Box",
    "section": "Questions?",
    "text": "Questions?"
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#references",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#references",
    "title": "Echos from the Black Box",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#background",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#background",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Background",
    "text": "Background\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs.\n\nProvided the changes are realistic and actionable, they can be used for Algorithmic Recourse (AR) to help individuals who face adverse outcomes."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#example-consumer-credit",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#example-consumer-credit",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Example: Consumer Credit",
    "text": "Example: Consumer Credit\nIn Figure¬†1, arrows indicate changes from factuals (loan denied) to counterfactuals (loan supplied).\n\nFigure¬†1: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#our-work-in-a-nutshell",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#our-work-in-a-nutshell",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Our work in a nutshell ‚Ä¶",
    "text": "Our work in a nutshell ‚Ä¶\n\nFigure¬†2: Dynamics in Algorithmic Recourse.\nWe show that counterfactuals can induce substantial domain and model shifts like in Figure¬†2.\n\n\n\nWe propose a novel perspective on AR that explicitly addresses this issue.\n\n\n\n\nWe open-source a Julia package to study the dynamics we point to."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#proof-of-concept",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#proof-of-concept",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Proof-of-Concept",
    "text": "Proof-of-Concept\n\n\n\n\n\nFigure¬†3: A bank has trained a model to evaluate credit applicants. Credit risk is highest in bottom-right corner.\n\n\n\n\n\n\n\nFigure¬†4: The bank has provided recourse to unsuccessful applicants: endogenous domain shift.\n\n\n\n\n\n\n\nFigure¬†5: The bank has retrained the classifier: endogenous model shift.\n\n\n\n\n\n\n\nFigure¬†6: The outcome after the process has been repeated a few times. Average default risk has increased."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#questions",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#questions",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Questions ‚Ä¶",
    "text": "Questions ‚Ä¶\n\n\n\n\nWho should bear the cost?\nAre the counterfactuals genuinely valid in practice?\nWhat about fairness and privacy concerns?\n\n\n\n\n\n\nFigure¬†7: Indiviudals who received recourse are clearly distinguishable."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#empirical-setup",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#empirical-setup",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Empirical Setup",
    "text": "Empirical Setup\n\nEvaluation: we propose metrics to measure domain shifts and model shifts.\n\n\nModels: we use linear classifiers, deep neural networks and deep ensembles.\n\n\nData:\n\n\nSynthetic\n\nOverlapping, Linearly Separable, Circles, Moons.\n\n\n\nReal-World\n\nGive Me Some Credit (Kaggle 2011), UCI defaultCredit (Yeh and Lien 2009), California Housing\n\n\n\n\n\nGenerators: Wachter (Wachter, Mittelstadt, and Russell 2017), REVISE (Joshi et al. 2019), DiCE (Mothilal, Sharma, and Tan 2020), Greedy (Schut et al. 2021)"
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#principal-findings-synthetic",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#principal-findings-synthetic",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Principal Findings ‚Äî Synthetic",
    "text": "Principal Findings ‚Äî Synthetic\n\n\n\n\n\nDomain shifts for overlapping synthetic data using deep ensemble.\n\n\n\n\n\n\nPerformance deterioration for overlapping synthetic data using deep ensemble."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#principal-findings-real-world",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#principal-findings-real-world",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Principal Findings ‚Äî Real-World",
    "text": "Principal Findings ‚Äî Real-World\n\n\n\n\n\nModel shifts for Credit Default data using deep ensemble.\n\n\n\n\n\n\nPerformance deterioration for Credit Default data using deep ensemble."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#method-general",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#method-general",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "From Individual Recourse ‚Ä¶",
    "text": "From Individual Recourse ‚Ä¶\nMany existing approaches to CE and AR work with the following baseline:\n\\[\n\\begin{aligned}\n\\color{lightgrey} \\mathbf{s}^\\prime &\\color{lightgrey}= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)} \\\\&\\color{black} + \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\color{lightgrey} \\}\n\\end{aligned}\n\\tag{1}\\]\nTypically concern has centred around minimizing costs to a single individual."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#method-collective",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#method-collective",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "‚Ä¶ towards collective recourse",
    "text": "‚Ä¶ towards collective recourse\nWe propose to extend Equation¬†1 as follows:\n\\[\n\\begin{aligned}\n\\color{lightgrey}\\mathbf{s}^\\prime &\\color{lightgrey}= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\{ {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)} \\\\ &\\color{lightgrey}+ \\lambda_1 {\\text{cost}(f(\\mathbf{s}^\\prime))} + \\color{black}\\lambda_2 {\\text{extcost}(f(\\mathbf{s}^\\prime))} \\color{lightgrey}\\}  \n\\end{aligned}\n\\tag{2}\\]\nThe newly introduced term \\(\\text{extcost}(f(\\mathbf{s}^\\prime))\\) is meant to explicitly capture external costs generated by changes to \\(\\mathbf{s}^\\prime\\)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#background-externalities",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#background-externalities",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Background: Externalities",
    "text": "Background: Externalities\nWe borrow the concept of private vs.¬†external costs from Economics.\n\nFigure¬†8: Illustration of a negative externality. Source: Investopedia."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#externalities-in-our-context",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#externalities-in-our-context",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Externalities in our Context",
    "text": "Externalities in our Context\nRelating this bank to our opening example, the external cost is carried by the retail bank.\n\nFigure¬†9: External cost is carried by bank."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#mitigation-strategies",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#mitigation-strategies",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Mitigation Strategies",
    "text": "Mitigation Strategies\n\nMore Conservative Decision Thresholds\nClassifier Preserving ROAR (ClaPROAR)1\nGravitational Counterfactual Explanations\n\n\n\n\nFigure¬†10: Mitigation strategies.\n\n\nLoosely inspired by ROAR (Upadhyay, Joshi, and Lakkaraju 2021)"
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#secondary-findings",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#secondary-findings",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Secondary Findings",
    "text": "Secondary Findings\n\n\n\n\n\nDomain shifts for overlapping synthetic data using deep ensemble.\n\n\n\n\n\n\nPerformance deterioration for overlapping synthetic data using deep ensemble."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#key-takeaways",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#key-takeaways",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Key Takeaways üîë",
    "text": "Key Takeaways üîë\n\n\nState-of-the-art approaches to AR induce substantial domain and model shifts.\n\n\n\n\nExternal costs of Individual Recourse should be shared across stakeholders.\n\n\n\n\nAd-hoc solution: penalize external costs in the counterfactual search objective function (Equation¬†2).\n\n\n\n\nThis gives rise to interesting cross-disciplinary research ideas (e.g.¬†Pareto-optimal AR)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#counterfactual-explanations-and-probabilistic-machine-learning",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#counterfactual-explanations-and-probabilistic-machine-learning",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Counterfactual Explanations and Probabilistic Machine Learning",
    "text": "Counterfactual Explanations and Probabilistic Machine Learning\n\nMethodologies and open-source tools that help researchers and practitioners assess the trustworthiness of predictive models.\n\n\n\nTowards Trustworthy AI in Julia\n\nCounterfactualExplanations.jl (JuliaCon 2022)\nConformalPrediction.jl (JuliaCon 2023 ‚Äî I hope!)\nLaplaceRedudx.jl (JuliaCon 2022)\nAlgorithmicRecourseDynamics.jl\n\n‚Ä¶ contributions welcome! üòä"
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#more-reading",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#more-reading",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "üìö More Reading",
    "text": "üìö More Reading\n\nGranular results for all of our experiments can be found in this online companion: https://www.paltmeyer.com/endogenous-macrodynamics-in-algorithmic-recourse/.\nMany other related posts on my blog."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#image-sources",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#image-sources",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Image Sources",
    "text": "Image Sources\n\nCopyright for stock images belongs to TU Delft.\nAll other images, graphics or animations were created by us."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#references",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#references",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nYeh, I-Cheng, and Che-hui Lien. 2009. ‚ÄúThe Comparisons of Data Mining Techniques for the Predictive Accuracy of Probability of Default of Credit Card Clients.‚Äù Expert Systems with Applications 36 (2): 2473‚Äì80. https://doi.org/10.1016/j.eswa.2007.12.020."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#quick-intro",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#quick-intro",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Quick Intro",
    "text": "Quick Intro\n\n\n\nCurrently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nWorking on Counterfactual Explanations and Probabilistic Machine Learning with applications in Finance.\nPreviously, educational background in Economics and Finance and two years at the Bank of England.\nEnthusiastic about free open-source software, in particular Julia and Quarto."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#in-a-nutshell",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#in-a-nutshell",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "In a nutshell ‚Ä¶",
    "text": "In a nutshell ‚Ä¶\n\n[‚Ä¶] we run experiments that simulate the application of recourse in practice using various state-of-the-art counterfactual generators and find that all of them induce substantial domain and model shifts.\n\n\n\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs.\nCounterfactual Explanations that involve realistic and actionable changes can be used for the purpose of Algorithmic Recourse (AR) to help individuals who face adverse outcomes.\n\n\n\n\n\n\nüéØ Key Contributions\n\n\n\nWe find that the induced shifts are substantial enough to likely impede the applicability of Algorithmic Recourse in some situations.\nFortunately, we find various strategies to mitigate these concerns.\nOur simulation framework for studying recourse dynamics is fast and open-sourced."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#proof-of-concept",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#proof-of-concept",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Proof-of-Concept",
    "text": "Proof-of-Concept\n\n\n\nExample 1 (Consumer Credit) ¬†\n\nSuppose Figure¬†1 relates to an automated decision-making system used by a retail bank to evaluate credit applicants.\nCreditworthiness decreases in the South-East direction.\nOutcome: bank supplies credit to more borrowers (orange), but these borrowers are riskier on average, which represents a cost to the retail bank.\n\n\n\nExample 2 (Student Admission) ¬†\n\nSuppose Figure¬†1 relates to an automated decision-making system used by a university in its student admission process.\nLikelihood of students completing their degree decreases in the South-East direction.\nOutcome: more students are admitted to university (orange), but they are more likely to fail their degree; the university suspends its efforts to offer AR, which represents a cost to future applicants.\n\n\n\n\n\n\nFigure¬†1: Dynamics in Algorithmic Recourse: (a) we have a simple linear classifier trained for binary classification where samples from the negative class (\\(y=0\\)) are marked in orange and samples of the positive class (\\(y=1\\)) are marked in blue; (b) the implementation of AR for a random subset of individuals leads to a noticeable domain shift; (c) as the classifier is retrained we observe a corresponding model shift; (d) as this process is repeated, the decision boundary moves away from the target class."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#algorithmic-recourse",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#algorithmic-recourse",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Algorithmic Recourse",
    "text": "Algorithmic Recourse\n\nEven though [‚Ä¶] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the ‚Äúblack box‚Äù. (Wachter, Mittelstadt, and Russell 2017)\n\n\n\nFramework\n. . .\nObjective originally proposed by Wachter, Mittelstadt, and Russell (2017) is as follows\n\\[\n\\min_{x^\\prime \\in \\mathcal{X}} \\text{cost}(x^\\prime) \\ \\ \\ \\mbox{s. t.} \\ \\ \\ M(x^\\prime) = y^*\n\\qquad(1)\\]\nTypically this is approximated through regularization:\n\\[\nx^\\prime = \\arg \\min_{x^\\prime}  \\text{yloss}(M(x^\\prime),y^*) + \\lambda \\text{cost}(x^\\prime)\n\\qquad(2)\\]\n\nIntuition\n. . .\n\n\n\nFigure¬†2: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#method-general",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#method-general",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "From individual recourse ‚Ä¶",
    "text": "From individual recourse ‚Ä¶\n\nWe include the following generators in our simulation experiments below: REVISE (Joshi et al. 2019), CLUE (Antor√°n et al. 2020), DiCE (Mothilal, Sharma, and Tan 2020) and a Greedy approach that relies on probabilistic models (Schut et al. 2021).\n\n\n\nAll of them can be described by the following generalized form of Equation¬†2:\n\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\left\\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)}+ \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\right\\}\n\\end{aligned}\n\\qquad(3)\\]\n\n\n\nHere \\(\\mathbf{s}^\\prime=\\left\\{s_k^\\prime\\right\\}_K\\) is a \\(K\\)-dimensional array of counterfactual states and \\(f: \\mathcal{S} \\mapsto \\mathcal{X}\\) maps from the counterfactual state space to the feature space.\n\n\n\n\n\n\nFigure¬†3: Feature space (left) and counterfactual state space (right)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#method-collective",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#method-collective",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "‚Ä¶ towards collective recourse",
    "text": "‚Ä¶ towards collective recourse\n\nAll of the different approaches introduced above tackle the problem of Algorithmic Recourse from the perspective of one single individual.\n\n\n\nWe propose to extend Equation¬†3 as follows:\n\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\{ {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)} \\\\ &+ \\lambda_1 {\\text{cost}(f(\\mathbf{s}^\\prime))} + \\lambda_2 {\\text{extcost}(f(\\mathbf{s}^\\prime))} \\}  \n\\end{aligned}\n\\qquad(4)\\]\n\n\n\nHere \\(\\text{cost}(f(\\mathbf{s}^\\prime))\\) denotes the proxy for private costs faced by the individual; the newly introduced term \\(\\text{extcost}(f(\\mathbf{s}^\\prime))\\) is meant to capture external costs generated by changes to \\(\\mathbf{s}^\\prime\\).\n\n\n\n\n\n\nüéì Negative Externalities\n\n\nThe underlying concept of private and external costs is borrowed from Economics and well-established in that field: when the decisions or actions by some individual market participant generate external costs, then the market is said to suffer from negative externalities and is considered inefficient (Pindyck and Rubinfeld 2014)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#research-questions",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#research-questions",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Research Questions",
    "text": "Research Questions\nPrincipal Concerns\n\nRQ 1 (Endogenous Shifts) Does the repeated implementation of recourse provided by state-of-the-art generators lead to shifts in the domain and model?\n\n\nRQ 2 (Costs) If so, are these dynamics substantial enough to be considered costly to stakeholders involved in real-world automated decision-making processes?\n\n\nRQ 3 (Heterogeneity) Do different counterfactual generators yield significantly different outcomes in this context? Furthermore, is there any heterogeneity concerning the chosen classifier and dataset?\n\n\nRQ 4 (Drivers) What are the drivers of endogenous dynamics in Algorithmic Recourse?\n\nSecondary Concerns\n\nRQ 5 (Mitigation Strategies) What are potential mitigation strategies with respect to endogenous macrodynamics in AR?"
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#empirical-setup",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#empirical-setup",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Empirical Setup",
    "text": "Empirical Setup\n\nEvaluation MetricsModelsDataGenerators\n\n\n\n\nDomain Shifts\n\nMaximum Mean Discrepancy (MMD): a measure of the distance between the kernel mean embeddings of two samples; in our context, large values indicate that a domain shift indeed seems to have occurred.\n\n\nModel Shifts\n\nPerturbations: following Upadhyay, Joshi, and Lakkaraju (2021) we define \\(\\Delta=||\\theta_{t+1}-\\theta_{t}||^2\\), that is the euclidean distance between the vectors of parameters before and after retraining the model \\(M\\).\nPredicted Probability MMD (PP MMD): instead of applying MMD to features directly, we apply it to the predicted probabilities assigned to a set of samples by the model \\(M\\).\nDisagreement Coefficient: this metric was introduced in Hanneke (2007) and estimates \\(p(M(x) \\neq M^\\prime(x))\\), that is the probability that two classifiers disagree on the predicted outcome for a randomly chosen sample.\nDecisiveness: we define the metric simply as \\({\\frac{1}{N}}\\sum_{i=0}^N(\\sigma(M(x)) - 0.5)^2\\) where \\(M(x)\\) are predicted logits from a binary classifier and \\(\\sigma\\) denotes the sigmoid function; it quantifies the likelihood that a model assigns a high probability to its classification of any given sample.\nPerformance: we compute the classifier‚Äôs F-score on a test sample that we leave untouched throughout the experiment.\n\n\n\n\n\nClassifiers\n\nSimple linear classifier‚ÄîLogistic Regression.\nMultilayer perceptron‚ÄîMLP.\nDeep Ensemble composed of five MLPs following Lakshminarayanan, Pritzel, and Blundell (2017).\n\nGenerative Models\nDifferent specifications of a plain-vanilla Variational Autoencoder (VAE)\n\n\n\n\nTable¬†1: Model parameters.\n\n\nModel\nData\nHidden Dim.\nLatent Dim.\nHidden Layers\nBatch\nDropout\nEpochs\n\n\n\n\nMLP\nSynthetic\n32\n-\n1\n-\n-\n100\n\n\nMLP\nReal-World\n64\n-\n2\n500\n0.1\n100\n\n\nVAE\nSynthetic\n32\n2\n1\n-\n-\n100\n\n\nVAE\nReal-World\n32\n8\n1\n-\n-\n250\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Data\nFour synthetic binary classification datasets consisting of 1000 samples each: Overlapping, Linearly Separable, Circles and Moons (Figure¬†4).\n\n\n\nFigure¬†4: Synthetic classification datasets used in our experiments. Samples from the negative class (\\(y=0\\)) are marked in orange while samples of the positive class (\\(y=1\\)) are marked in blue.\n\n\n\nReal-World Data\nThree real-world datasets from the Finance and Economics domain: all tabular and can be used for binary classification.\n\nThe Give Me Some Credit dataset: predict whether a borrower is likely to experience financial difficulties in the next two years (Kaggle 2011).\nThe UCI defaultCredit dataset (Yeh and Lien 2009): a benchmark dataset that can be used to train binary classifiers to predict the whether credit card clients default on their payment.\nThe California Housing dataset Pace and Barry (1997): continuous outcome variable binarized as \\(\\tilde{y}=\\mathbb{I}_{y&gt;\\text{median}(Y)}\\) indicating if the median house price of a given district is above the median of all districts.\n\n\n\n\n\n\n\nPrincipal Concerns\n\nWachter (Wachter, Mittelstadt, and Russell 2017)\nREVISE (Joshi et al. 2019)\nCLUE (Antor√°n et al. 2020)\nDiCE (Mothilal, Sharma, and Tan 2020)\nGreedy (Schut et al. 2021)\n\n\nSecondary Concerns\n\nMore Conservative Decision Thresholds\nClassifier Preserving ROAR (ClaPROAR):\n\n\\[\n\\begin{aligned}\n\\text{extcost}(f(\\mathbf{s}^\\prime)) = l(M(f(\\mathbf{s}^\\prime)),y^\\prime)\n\\end{aligned}\n\\qquad(5)\\]\n\nGravitational Counterfactual Explanations:\n\n\\[\n\\begin{aligned}\n\\text{extcost}(f(\\mathbf{s}^\\prime)) = \\text{dist}(f(\\mathbf{s}^\\prime),\\bar{x}^*)\n\\end{aligned}\n\\qquad(6)\\]\n\n\n\nMitigation strategies."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#principal-findings",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#principal-findings",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Principal Findings",
    "text": "Principal Findings\n\n\n\n\n\nResults for synthetic data.\n\n\n\n\n\n\nResults for real-world data."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#secondary-findings",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#secondary-findings",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Secondary Findings",
    "text": "Secondary Findings\n\n\n\n\n\nResults for synthetic data.\n\n\n\n\n\n\nResults for real-world data."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#summary-of-findings",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#summary-of-findings",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Summary of Findings",
    "text": "Summary of Findings\nPrincipal Concerns\n\nFirstly, endogenous dynamics do emerge in our experiments (Proposition¬†1) and we find them substantial enough to be considered costly (Proposition¬†2)\nSecondly, the choice of the counterfactual generator matters, with Latent Space search generally having a dampening effect (Proposition¬†3).\nThe observed dynamics, therefore, seem to be driven by a discrepancy between counterfactual outcomes that minimize costs to individuals and outcomes that comply with the data-generating process (Proposition¬†4).\n\nSecondary Concerns\n\nOur findings indicate that all three proposed mitigation strategies are at least at par with LS generators (Proposition¬†5)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#key-takeaways",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#key-takeaways",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Key Takeaways üîë",
    "text": "Key Takeaways üîë\n\n\nOur findings indicate that state-of-the-art approaches to Algorithmic Recourse induce substantial domain and model shifts.\n\n\n\n\nWe would argue that the expected external costs of individual recourse should be shared by all stakeholders.\n\n\n\n\nA straightforward way to achieve this is to penalize external costs in the counterfactual search objective function (Equation¬†4).\n\n\n\n\nVarious simple strategies based on this notion can be effectively used to mitigate shifts."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#limitations",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#limitations",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Limitations",
    "text": "Limitations\n\nPrivate vs.¬†External Costs\n\nWe fall short of providing any definitive answers as to how to trade off private vs.¬†external costs.\nProposed strategies are a good starting point, but they are ad-hoc.\n\n. . .\nExperimental Setup\n\nExperimental design is a vast over-simplification of potential real-world scenarios.\n\n. . .\nCausal Modelling\n\nHave focused on popular counterfactual generators that do not incorporate any causal knowledge.\nPerturbations therefore may involve changes to variables that affect the outcome predicted by the black-box model, but not the true, causal outcome.\nFuture work would likely benefit from including recent approaches to AR that incorporate causal knowledge such Karimi, Sch√∂lkopf, and Valera (2021).\n\n. . .\nClassifiers\n\nWe have limited our analysis to differentiable linear and non-linear classifiers; empirical evidence suggests that other models such as boosted decision trees outperform DL on tabular data ((borisov2021deep?), Grinsztajn, Oyallon, and Varoquaux (2022))."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#more-resources",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#more-resources",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nGranular results for all of our experiments can be found in this online companion: https://www.paltmeyer.com/endogenous-macrodynamics-in-algorithmic-recourse/.\nBlog post introducing Counterfactual Explanations: [TDS, homepage].\n\n\n‚Ä¶ or get busy üñ•Ô∏è\n\n\nCounterfactualExplanations.jl (Altmeyer 2022) provides an extensible, fast and language-agnostic implementation in Julia.\nWe have built a framework that extends the functionality from static benchmarks to simulation experiments: AlgorithmicRecourseDynamics.jl.\nThe Github repository containing all the code used to produce the results in this paper can be found here."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#image-sources",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#image-sources",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Image Sources",
    "text": "Image Sources\n\nCopyright for stock images belongs to TU Delft.\nAll other images, graphics or animations were created by us."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#references",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#references",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "References",
    "text": "References\n\n\nIEEE Conference on Secure and Trustworthy Machine Learning ‚Äô23 ‚Äî Patrick Altmeyer ‚Äî CC BY-NC\n\n\n\nAltmeyer, Patrick. 2022. ‚ÄúCounterfactualExplanations.jl - a Julia Package for Counterfactual Explanations and Algorithmic Recourse.‚Äù https://github.com/pat-alt/CounterfactualExplanations.jl.\n\n\nAntor√°n, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and Jos√© Miguel Hern√°ndez-Lobato. 2020. ‚ÄúGetting a Clue: A Method for Explaining Uncertainty Estimates.‚Äù https://arxiv.org/abs/2006.06848.\n\n\nGrinsztajn, L√©o, Edouard Oyallon, and Ga√´l Varoquaux. 2022. ‚ÄúWhy Do Tree-Based Models Still Outperform Deep Learning on Tabular Data?‚Äù https://arxiv.org/abs/2207.08815.\n\n\nHanneke, Steve. 2007. ‚ÄúA Bound on the Label Complexity of Agnostic Active Learning.‚Äù In Proceedings of the 24th International Conference on Machine Learning, 353‚Äì60. https://doi.org/10.1145/1273496.1273541.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit.\n\n\nKarimi, Amir-Hossein, Bernhard Sch√∂lkopf, and Isabel Valera. 2021. ‚ÄúAlgorithmic Recourse: From Counterfactual Explanations to Interventions.‚Äù In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 353‚Äì62.\n\n\nLakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2017. ‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù Advances in Neural Information Processing Systems 30.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nPace, R Kelley, and Ronald Barry. 1997. ‚ÄúSparse Spatial Autoregressions.‚Äù Statistics & Probability Letters 33 (3): 291‚Äì97. https://doi.org/10.1016/s0167-7152(96)00140-x.\n\n\nPedregosa, Fabian, Ga√´l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2011. ‚ÄúScikit-Learn: Machine Learning in Python.‚Äù The Journal of Machine Learning Research 12: 2825‚Äì30.\n\n\nPindyck, Robert S, and Daniel L Rubinfeld. 2014. Microeconomics. Pearson Education.\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nYeh, I-Cheng, and Che-hui Lien. 2009. ‚ÄúThe Comparisons of Data Mining Techniques for the Predictive Accuracy of Probability of Default of Credit Card Clients.‚Äù Expert Systems with Applications 36 (2): 2473‚Äì80. https://doi.org/10.1016/j.eswa.2007.12.020."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#agenda",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#agenda",
    "title": "Julia on HPC",
    "section": "Agenda",
    "text": "Agenda\n\n\nIntroduction to Parallel Computing (15 min).\n\nWhat is parallel computing?\nParallel computing in Julia.\nDifferent forms of parallelization offered by CounterfactualExplanations.jl.\n\nFirst interactive session: local parallelization (15 min).\nJulia on DelftBlue (25 min).\n\nWhat is DelftBlue?\nHow to use Julia on DelftBlue?\nChallenges and solutions.\n\nSecond interactive session: remote parallelization (25 min)."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#what-is-parallel-computing",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#what-is-parallel-computing",
    "title": "Julia on HPC",
    "section": "What is Parallel Computing?",
    "text": "What is Parallel Computing?\n\nParallel computing is a type of computation in which many calculations or processes are carried out simultaneously. ‚Äî Wikipedia\n\n\nImage by Kay Jan Wong."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#parallel-computing-in-julia",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#parallel-computing-in-julia",
    "title": "Julia on HPC",
    "section": "Parallel Computing in Julia",
    "text": "Parallel Computing in Julia\nJulia has strong native and external support for parallel computing.\n\n\nMulti-Threading\nCommand line:\njulia --threads 4\nJulia:\nThreads.@threads for i = 1:10\n    a[i] = Threads.threadid()\nend\n\nMulti-Processing\n\nDistributed standard library (not covered here).\nMPI.jl wrapper for MPI (our focus)."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#parallelization-in-counterfactualexplanations.jl",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#parallelization-in-counterfactualexplanations.jl",
    "title": "Julia on HPC",
    "section": "Parallelization in CounterfactualExplanations.jl",
    "text": "Parallelization in CounterfactualExplanations.jl\n\n\n\n\nMotivation: often required to generate many explanations.\nGoal: native support for both forms of parallelization.\nDesiteratum: minimize the burden on users.\n\n\n\n\n\n\nUsage example."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#tasks-15-min",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#tasks-15-min",
    "title": "Julia on HPC",
    "section": "Tasks (15 min)",
    "text": "Tasks (15 min)\n\nIf not already done, either fork or clone the repo.\nOpen the notebook docs/src/tutorials/parallelization.qmd.\nUsing the @time macro, check if multi-threading speeds up computations."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#what-is-delftblue",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#what-is-delftblue",
    "title": "Julia on HPC",
    "section": "What is DelftBlue?",
    "text": "What is DelftBlue?\n\nDelftBlue is [one of two] supercomputer[s] at TU Delft [that] will offer 20,000 CPU cores in over 400 compute nodes. ‚Äî DelftBlue\n\n\nRich documentation including a small section on Julia.\nShould be accessible to all of you.\nYou will be among the first to use Julia on DelftBlue.\nAlternative: DAIC."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#how-to-use-julia-on-delftblue",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#how-to-use-julia-on-delftblue",
    "title": "Julia on HPC",
    "section": "How to Use Julia on DelftBlue?",
    "text": "How to Use Julia on DelftBlue?\n\n\n\n\nUse Julia from the software stack (see docs).\nRecommended: install your own Julia version.\nGet help on Mattermost.\n\n\n\n\n\n\nSelf-install\n\n\nSee julia-hpc-for-dummies for additional details.\n\nSym-link the Julia installation to your home directory.\n\nmkdir -p /scratch/${USER}/.julia\nln -s /scratch/${USER}/.julia $HOME/.julia\n\nSym-link juliaup to your home directory.\n\nmkdir -p /scratch/${USER}/.juliaup\nln -s /scratch/${USER}/.juliaup $HOME/.juliaup\n\nInstall juliaup as follows: curl -fsSL https://install.julialang.org | sh. Customize location to /scratch/${USER}/.juliaup."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#challenges-and-solutions",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#challenges-and-solutions",
    "title": "Julia on HPC",
    "section": "Challenges and Solutions",
    "text": "Challenges and Solutions\n\n\nJulia version shipped with software stack is outdated. Solution: install your own Julia version.\nLogin nodes are not meant for computations. Compiling Julia takes a long time. Solution: do as much as possible on your local machine. For anything else, rely mostly on the compute nodes.\nSelf-installed Julia uses ‚Äúall the resources!‚Äù üßê Solution: use this header for your scripts.\n\n\n\n\n\n\nWhoopsie!"
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#tasks-25-min",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#tasks-25-min",
    "title": "Julia on HPC",
    "section": "Tasks (25 min)",
    "text": "Tasks (25 min)\n\nInstall your own Julia version on DelftBlue.\nFork and/or clone the julia-hpc-for-dummies repo.\nSend a job to DelftBlue."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/presentation.html#wat-is-kunstmatige-intelligentie",
    "href": "content/talks/posts/2023-goethe/presentation.html#wat-is-kunstmatige-intelligentie",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "Wat is Kunstmatige Intelligentie?",
    "text": "Wat is Kunstmatige Intelligentie?\n\n\n\nKI is niet alleen ‚Äòmachinaal leren‚Äô (ML), hoewel mensen vandaag meestal ML bedoelen als ze KI zeggen.\nML: je geeft de computer aleen een objectief en data en hij leert (bijna) vanzelf.\n\n\n\n\n\nEen algoritme leert van data.\n\n\n\n\n\n\nIn de tijden van ChatGPT heeft iederen een idee van KI maar het is niet heel klar wat het eigenlijk betekent.\nVolgens mij bedoelen mensen meestal ‚Äúmachinaal leren‚Äù als ze ‚ÄòKI‚Äô zeggen.\n‚ÄúMachinaal leren‚Äù, of koort ‚ÄúML‚Äù, is niet hetzelfde als ‚ÄúKI‚Äù maar het is wel een belangrijk onderdeel van KI.\n‚ÄúML‚Äù is een manier om een computer te trainen om een taak te doen zonder dat je de computer precies vertelt hoe hij het moet doen.\nJe geeft de computer alleen een objectief en een hoop voorbeelden. Dan lat je de computer zelf een manier vinden om het objectief te bereiken en ten slotte hoop je dat de computer goed geleerd heeft.\nBijvoorbeeld, je zie hier aan de rechte kant een algoritme dat leert tussen twee klassen te onderscheiden. Hoe meer data het heeft gezien, hoe beter het zijn werk doet."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/presentation.html#diep-leren---de-huidige-standaard",
    "href": "content/talks/posts/2023-goethe/presentation.html#diep-leren---de-huidige-standaard",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "‚ÄúDiep Leren‚Äù - de huidige standaard",
    "text": "‚ÄúDiep Leren‚Äù - de huidige standaard\n\n\nDe kerntechniek van de sterkste KI systemen van vandaag is ‚Äúdiep leren‚Äù.\n\n‚ÄúSchaal is alles wat je nodig hebt‚Äù‚Äîiemand van OpenAI\n\n\n\n\n\nEen (niet zo) diep kunstmatiges neuraal netwerk.\n\n\n\n\n\n\nDe kerntechniek van de sterkste KI systemen van vandaag is ‚Äúdiep leren‚Äù, of ‚Äúdeep learning‚Äù in het Engels.\nIn het kort, bij diep leren gebruiken we grote modellen met veel instellingen. Deze waarden worden geleerd en verbeterd via optimalisatie.\nOpenAI‚Äôs ChatGPT heeft zoveel succes gehad omdat het een heel groot model is. Eigenlijk is het inoffici√´le motto van OpenAI: ‚ÄúScale is all you need‚Äù, dus ‚ÄúSchaal is alles wat je nodig hebt‚Äù.\nAan de rechte kant zien jullie een voorbeeld van een diep neuraal netwerk. Die groene punten zijn de instellingen van het model. Kan iemand tellen hoeveel instellingen dit model heeft?\nDus er zijn 32 plus 6 plus 32 plus 12 groene punten. Dat is 82 instellingen.\nMaar dit is erg niet diep. Ter vergelijking: ChatGPT heeft ongeveer 15 miljard instellingen.\nSommige mensen geloven dat deze sort modellen de toekomst van KI zijn en ons zullen helpen om de meest complexe problemen op te lossen."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/presentation.html#klinkt-goed-maar",
    "href": "content/talks/posts/2023-goethe/presentation.html#klinkt-goed-maar",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "Klinkt goed, maar ‚Ä¶",
    "text": "Klinkt goed, maar ‚Ä¶\n\n\nDeze modellen hebben ook nadele. Ze zijn:\n\nkwetsbaar\nniet transparant\n‚Ä¶\n\n\n\n\n\nAfbeelding¬†1: Stopbord of bloempod? Bron: Wu et al.¬†(2020)\n\n\n\n\n\n\nDit klinkt allemaal goed, maar deze modellen hebben ook nadele.\nBijvoorbeeld, ze zijn kwetsbaar. Ze kunnen makkelijk misleid worden.\nIn de afbeelding aan de rechte kant zien jullie aan de linke kant een stopbord: eerst erkent het model het stopbord als een stopbord. Maar als de foto een beetje veranderen, dan ziet het model een bloempot. Dit zie je aan de rechte kant.\nEen van de grootste problemen met diep leren is dat de modellen zo groot zijn dat niemand ze echt begrijpt.\nJe kan niet het model zomaar openen en zien hoe het werkt. Als een model niet transparant is, noemen we het een ‚Äòblack box‚Äô.\nDit is heel problematisch voor de betrouwbaarheid van KI systemen, vooral als ze gebruikt worden in kritische toepassingen zoals medische diagnoses of autonome voertuigen.\nMaar ook en mer aldagelijkse toepassingen: heeft iemand hier eermaal een lening aangevraagd? Of een sollicitatie gedaan? Of een verzekering afgesloten? Dan is de kans groot dat een KI systeem een rol heeft gespeld in de beslissing."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/presentation.html#verklaarbaarheid",
    "href": "content/talks/posts/2023-goethe/presentation.html#verklaarbaarheid",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "Verklaarbaarheid",
    "text": "Verklaarbaarheid\n\n\nBetrouwbaarheid door Verklaarbaarheid:\n\nWat moeten we veranderen aan de modelinputs om de outputs te veranderen?\n\n\n\n\n\nAfbeelding¬†2: Kan je het katje helpen om een lieve hondje te worden?\n\n\n\n\n\n\nEen van de belangrijkste manieren om de betrouwbaarheid van KI systemen te verbeteren is door ze verklaarbaar te maken.\nDit is de focus van mijn onderzoek.\nIk richt mij in het bijzonder op een methode die ‚Äúcounterfactual explanations‚Äù heet.\nIntu√Øtief vragen we wat we moeten veranderen aan de modelinputs om de outputs te veranderen.\nBijvorbeeld zien jullie hier aan de rechte kant en model dat tussen katjes and hondjes kan onderscheiden.\nOm te begrijpen waarom het model een katje ziet, kunnen we de characteristieken van het katje veranderen en kijken hoe het model reageert.\nHier zie je hoe het katje van links oven naar rechts beneden wandelt.\nDit betekent in dit geval dat het katje zijn staartje moet inkorten en iets groter moet worden.\nEn dit is dan de verklaring."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#agenda",
    "href": "content/talks/posts/2023-progress/presentation.html#agenda",
    "title": "2nd Year Progress Meeting",
    "section": "Agenda",
    "text": "Agenda\n\nStocktaking\nReflection on the past year\nNext steps"
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#papers",
    "href": "content/talks/posts/2023-progress/presentation.html#papers",
    "title": "2nd Year Progress Meeting",
    "section": "Papers",
    "text": "Papers\nSolid progress on chapter 1 to 3 of the thesis:\n\n1 paper published and presented (SaTML: [Ch2]), 1 published in proceedings (JuliaCon: [Ch1.1]).\n1 paper submitted (ECCCo: [Ch3]).\n1 paper in preparation (LaplaceRedux.jl: [Ch1.2]), 1 about to start (ConformalPrediction.jl [Ch1.3]).\n1 paper co-authored (Conformal Intent Recognition)."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#open-source-and-science",
    "href": "content/talks/posts/2023-progress/presentation.html#open-source-and-science",
    "title": "2nd Year Progress Meeting",
    "section": "Open Source and Science",
    "text": "Open Source and Science\n\n2 new Julia packages published: ConformalPrediction.jl and JointEnergyModels.jl.\nMajor updates to CounterfactualExplanations.jl and LaplaceRedux.jl.\nFirst steps towards a unified ecosystem for Trustworthy AI in Julia: Taija.jl.\nPublished 7 blog posts.\nSome work on Quarto extensions."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#talks",
    "href": "content/talks/posts/2023-progress/presentation.html#talks",
    "title": "2nd Year Progress Meeting",
    "section": "Talks",
    "text": "Talks\nA total of 8 talks:\n\nCompanies (3): DSCC (ING), Bank of England, Verbond van Verzekeraars.\nSoftware community (2): Julia Eindhoven, JuliaCon.\nAcademia (3): SaTML, ICT.Open (demo), Mondai."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#graduate-school",
    "href": "content/talks/posts/2023-progress/presentation.html#graduate-school",
    "title": "2nd Year Progress Meeting",
    "section": "Graduate School",
    "text": "Graduate School\n\nSummer School in Barcelona (5 ECTS: discipline).\nDeep Learning in Julia study group.\nSoftware project (2nd year BSc): CounterfactualExplanations.jl (2 ECTS: research).\nSoftware project (2nd year BSc): LaplaceRedux.jl (2 ECTS: research).\nSaTML and JuliaCon (4 ECTS: research).\n\nTotal (missing): research (-2.5), discipline (5), transferable (8)"
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#other-accomplishments",
    "href": "content/talks/posts/2023-progress/presentation.html#other-accomplishments",
    "title": "2nd Year Progress Meeting",
    "section": "Other Accomplishments",
    "text": "Other Accomplishments\n\n1st Price at ING Experiment Week.\n2nd Price at JuliaCon 2023 Pluto Notebook Competition.\nFirst person at TU Delft to do serious work in Julia on a HPC cluster (as far as I know)."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#what-went-well",
    "href": "content/talks/posts/2023-progress/presentation.html#what-went-well",
    "title": "2nd Year Progress Meeting",
    "section": "What went well?",
    "text": "What went well?\n\n\nVery happy with the progress on the open-source projects.\nGenerally also happy with the progress on papers.\n\nResearch ideas are becoming more refined and interesting.\n\nI am enjoying the work and the people I am working with."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#what-could-have-gone-better",
    "href": "content/talks/posts/2023-progress/presentation.html#what-could-have-gone-better",
    "title": "2nd Year Progress Meeting",
    "section": "What could have gone better?",
    "text": "What could have gone better?\n\n\nI am struggling with the balance between research and open-source.\nI have come to realise that writing truly solid technical papers takes more time than I thought.\n\nCamera-ready version of SaTML paper took about 1 month.\nECCCo took about 2-3 additional months of work after initial submission.\n\nAt times, seriously overwhelmed, to the extent that I was genuinely concerned about my mental health for the first time in my life.\n\nNobody‚Äôs fault if not my own, but not going back to that place again."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#what-did-i-learn",
    "href": "content/talks/posts/2023-progress/presentation.html#what-did-i-learn",
    "title": "2nd Year Progress Meeting",
    "section": "What did I learn?",
    "text": "What did I learn?\n\n\nYou can‚Äôt have it all: open-source, research, outreach, teaching, physical and mental health, social life, ‚Ä¶\nI need to be more selective about what I work on.\nI need to be more realistic about what I can achieve."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#ongoing-papers",
    "href": "content/talks/posts/2023-progress/presentation.html#ongoing-papers",
    "title": "2nd Year Progress Meeting",
    "section": "Ongoing Papers",
    "text": "Ongoing Papers\n\n\nECCCo [Ch3]: only minor revisions left.\n\nEven if AAAI fails, I am finally fully confident about the results and proud of this paper.\n\nConformal Prediction [Ch1.3]: start writing.\nLaplaceRedux [Ch1.2]: turn into full paper."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#planned-papers",
    "href": "content/talks/posts/2023-progress/presentation.html#planned-papers",
    "title": "2nd Year Progress Meeting",
    "section": "Planned Papers",
    "text": "Planned Papers\n\n3rd research paper [Ch4]: What makes models explainable?\n\nInvolve students (ECCCo for trees and model-agnostic).\nCandidate venues: NeuRIPS Datasets and Benchmarks (2024/2025), journal.\n‚ñ∂Ô∏è Difficulty: relatively safe bet, but computationally expensive.\n\n4th research paper [Ch5]:\n\nThe Cost of Unfaithful Model Explanations: agent-based simulation of the impact of unfaithful model explanations on human decision-making.\nCausal ECCCo: combining ECCCo with Causal Abstraction.\n\n\n‚ñ∂Ô∏è Difficulty: both high risk, high reward."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#open-source",
    "href": "content/talks/posts/2023-progress/presentation.html#open-source",
    "title": "2nd Year Progress Meeting",
    "section": "Open Source",
    "text": "Open Source\n\nMaybe: Lightening talk on JointEnergyModels.jl at JuliaCon 2024 [Ch1.4].\nThen: ‚ÄúTaija.jl 4 years later‚Äù at JuliaCon 2025."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#time-management",
    "href": "content/talks/posts/2023-progress/presentation.html#time-management",
    "title": "2nd Year Progress Meeting",
    "section": "Time Management",
    "text": "Time Management\n\nI think it is feasible to have the following papers in (near-) final form by the end of year 3: ECCCo [Ch3], LaplaceRedux [Ch1.2], Conformal Prediction [Ch1.3], 3rd research paper [Ch4].\nAt that point, we are looking at a comprehensive thesis: 3 software papers forming the extended introduction and 3 research papers forming the core.\n4th year can then be used to:\n\nCollate chapters (thesis).\nWrite paper on JointEnergyModels.jl [potentially Ch1.4].\nTackle 4th research paper w/o pressure to publish in time [potentially Ch5].\nEnsure Taija.jl is in a good state.\nEnsure Graduate School credits are in order.\nCareer Planning.\nGoogle Summer of Code? Teaching? Research Visit? Internship? Other?"
  },
  {
    "objectID": "content/talks/index.html",
    "href": "content/talks/index.html",
    "title": "Talks",
    "section": "",
    "text": "Order By\n       Default\n         \n          Year - Oldest\n        \n         \n          Year - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nYear\n\n\nVenue\n\n\nDescription\n\n\n\n\n\n\nFaithful Model Explanations through Energy-Based Conformal Counterfactuals\n\n\n2024\n\n\nAAAI 2024, Vancouver, Canada\n\n\nSlides and poster for our AAAI 2024 paper, Faithful Model Explanations through Energy-Based Conformal Counterfactuals.\n\n\n\n\nFaithful Model Explanations\n\n\n2023\n\n\nDe Nederlandsche Bank\n\n\nSlides for my presentation at the Dutch Central Bank, De Nederlandsche Bank.\n\n\n\n\nBetrouwbare Kunstmatige Intelligentie\n\n\n2023\n\n\nGoethe Instituut, Amsterdam\n\n\nMijn eerste presentatie in het Nederlands.\n\n\n\n\nJulia on HPC\n\n\n2023\n\n\nTU Delft\n\n\nSlides for a tutorial on using Julia on the DelftBlue supercomputer.\n\n\n\n\nFaithful Model Explanations\n\n\n2023\n\n\nVerbond van Verzekeraars\n\n\nSlides for my presentation at the Delft FinTech Lab Launch.\n\n\n\n\nPredictive Uncertainty Quantification in Machine Learning\n\n\n2023\n\n\nJuliaCon 2023, MIT, Cambridge, Massachusetts\n\n\nSlides for my presentation at JuliaCon 2023.\n\n\n\n\nEchos from the Black Box\n\n\n2023\n\n\nMondai House of AI, Delft\n\n\nSlides for my presentation at the Delft FinTech Lab Launch.\n\n\n\n\nTaija - Trustworthy AI in Julia\n\n\n2023\n\n\nNWO ICT.Open 2023\n\n\nSlides for my demo at the NWO ICT.Open in April, 2023.\n\n\n\n\nEndogenous Macrodynamics in Algorithmic Recourse\n\n\n2023\n\n\nFirst IEEE Conference on Secure and Trustworthy Machine Learning\n\n\nSlides for my presentation at the first IEEE SaTML conference in February, 2023.\n\n\n\n\nA year of using Quarto with Julia\n\n\n2022\n\n\nJulia Eindhoven Meetup\n\n\nSlides for my presentation at the Julia Eindhoven Meetup in November, 2022.\n\n\n\n\nExplaining Black-Box Models through Counterfactuals\n\n\n2022\n\n\nBank of England\n\n\nSlides for my presentation at the Bank of England in November 2022.\n\n\n\n\nExplaining Black-Box Models through Counterfactuals\n\n\n2022\n\n\nING Data Science Community Conference 2022\n\n\nSlides for my presentation at the ING Data Science Community Conference 2022.\n\n\n\n\nJuliaCon 2022\n\n\n2022\n\n\nJuliaCon 2022 (online)\n\n\nI gave three different talks at JuliaCon 2022.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/about/index.html",
    "href": "content/about/index.html",
    "title": "Patrick Altmeyer",
    "section": "",
    "text": "Researching Trustworthy Artificial Intelligence (AI) for Finance and Economics. I am an economist by background with an interest in cross-disciplinary research on the intersection of Trustworthy AI and Financial Economics. For my PhD in Trustworthy AI, I currently focus on Counterfactual Explanations and Probabilisitic Machine Learning under supervision of Cynthia Liem and Arie van Deursen at Delft University of Technology. I am also a member of the AI for Fintech Research Lab.\nPreviously, I worked as an economist for Bank of England where I was involved in research, monetary policy briefings and market intelligence. I hold two masters degrees from Barcelona School of Economics, one in Data Science and one in Finance. I also hold an undergraduate degree in Economics from the University of Edinburgh.\nüìÑ Resume: printable pdf or right here on this website.\n\nContact\nYou can best reach me via my work email or you can set up a chat."
  },
  {
    "objectID": "content/software.html",
    "href": "content/software.html",
    "title": "Software",
    "section": "",
    "text": "I code in Julia üî¥üü£üü¢ and write in Quarto. Occasionally I also use R, Python and C++. After years of consuming open-source software, I‚Äôve recently started contributing free open-source software myself:"
  },
  {
    "objectID": "content/software.html#activity",
    "href": "content/software.html#activity",
    "title": "Software",
    "section": "Activity",
    "text": "Activity"
  },
  {
    "objectID": "www/cv/cv.html#contact",
    "href": "www/cv/cv.html#contact",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Contact Info",
    "text": "Contact Info\n\n p.altmeyer@tudelft.nl\n www.paltmeyer.com\n github.com/pat-alt\n +49 176 48726927\nFor more information, please contact me via email."
  },
  {
    "objectID": "www/cv/cv.html#skills",
    "href": "www/cv/cv.html#skills",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Skills",
    "text": "Skills\n\nExperienced in Machine Learning, Finance, Economics and Monetary Policy.\nHighly skilled in Julia, R, Python and Quarto.\nWell-informed about the field of Explainable Artificial Intelligence."
  },
  {
    "objectID": "www/cv/cv.html#disclaimer",
    "href": "www/cv/cv.html#disclaimer",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Disclaimer",
    "text": "Disclaimer\n\nLast updated on 2024-02-07."
  },
  {
    "objectID": "www/cv/cv.html#title",
    "href": "www/cv/cv.html#title",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Patrick Altmeyer",
    "text": "Patrick Altmeyer\n\nResearching Trustworthy Artificial Intelligence (AI) for Finance and Economics\nI am an economist by background with an interest in cross-disciplinary research on the intersection of Trustworthy AI and Financial Economics. For my PhD in Trustworthy AI, I currently focus on Counterfactual Explanations and Probabilisitic Machine Learning under supervision of Cynthia Liem at Delft University of Technology."
  },
  {
    "objectID": "www/cv/cv.html#education",
    "href": "www/cv/cv.html#education",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Education",
    "text": "Education\n\nPhD in Computer Science\nDelft University of Technology\nDelft, Netherlands\n2025 - 2021\nThesis topic: Counterfactual Reasoning and Probabilistic Methods for Trustworthy AI with Applications in Finance\n\n\nMaster in Data Science\nBarcelona School of Economics\nBarcelona, Spain\n2021\nThesis: Deep Vector Autoregression for Macroeconomic Data\n\n\nMaster in Finance\nBarcelona School of Economics\nBarcelona, Spain\n2018\nThesis: Option Pricing in the Heston Stochastic Volatility Model\n\n\nMaster of Arts with Honours in Economics\nUniversity of Edinburgh\nEdinburgh, United Kingdom\n2017\nThesis: Can misguided monetary policy explain the European housing bubble?"
  },
  {
    "objectID": "www/cv/cv.html#professional-experience",
    "href": "www/cv/cv.html#professional-experience",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nEconomist\nBank of England\nLondon, United Kingdom\n2021 - 2018\n\n\nCo-author of two staff working papers (upcoming).\nCo-initiated and led app development.\nBriefing work for policy committees.\n\n\n\n\nPostgraduate Intern\nBank of England\nLondon, United Kingdom\n2017\n\n\nEconometric analysis of transaction data set in R.\nInternal presentation of project results."
  },
  {
    "objectID": "www/cv/cv.html#teaching-experience",
    "href": "www/cv/cv.html#teaching-experience",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Teaching Experience",
    "text": "Teaching Experience\n\nMaster‚Äôs Thesis Supervision\nResearch co-supervisor of various Master‚Äôs students\nDelft, Netherlands\n2024 - 2023\n\n\nSoftware Project Supervision\nProject supervisor for two groups of students\nDelft, Netherlands\n2023\n\n\nProposal of two software projects related to Trustworthy AI in Julia.\nSupervision of two groups of five undergraduate students working on the project.\n\n\n\n\nBachelor‚Äôs Thesis Supervision\nResearch supervisor for group of students\nDelft, Netherlands\n2022\n\n\nProposal of final-year research project on Endogenous Dynamics in Algorithmic Recourse.\nSupervision of group of three undergraduate students working on the project.\n\n\n\n\nFoundations of Data Science Summer School\nTeaching Assistant at Barcelona School of Economics\nBarcelona, Spain\n2021\n\n\nIntroduction course to R and Git\nLead Trainer at Analytics Enablement Hub, Bank of England.\nLondon, United Kingdom\n2020 - 2019\n\n\nHonours Modules in Econometrics\nTeaching assistant at School of Economics, University of Edinburgh\nEdinburgh, United Kingdom\n2017 - 2016"
  },
  {
    "objectID": "www/cv/cv.html#selected-publications",
    "href": "www/cv/cv.html#selected-publications",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Selected Publications",
    "text": "Selected Publications\n\nFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals\nThe 38th Annual AAAI Conference on Artificial Intelligence (upcoming): [pre-print]\nDelft, Netherlands\n2023\n\n\nExplaining Black-Box Model through Counterfactuals\nThe Proceedings of the JuliaCon Conferences: [PDF]\nDelft, Netherlands\n2023\n\n\nEndogenous Macrodynamics in Algorithmic Recourse\nFirst IEEE Conference on Secure and Trustworthy Machine Learning: [PDF]\nDelft, Netherlands\n2023\nAltmeyer P., Angela G., Buszydlik A., Dobiczek K., van Deursen A., Liem C.C.S.\n\n\nYield Curve Sensitivity to Investor Positioning Around Economic Shocks\nBank of England Staff Working Paper: [PDF]\nLondon, United Kingdom\n2023\nAltmeyer P., Boneva L., Kinston R., Saha S., Stoja E.\n\n\nDeep Vector Autoregression for Macroeconomic Data\nMasters Thesis (selected for publication): [PDF], [GitHub]\nBarcelona, Spain\n2021\nAgust√≠ M., Altmeyer P., Vidal-Quadras Costa I.\n\n\nOption Pricing in the Heston Stochastic Volatility Model: an Empirical Evaluation\nMasters Thesis (selected for publication): [PDF]\nBarcelona, Spain\n2018\nAltmeyer P., Grapendal J., Pravosud M., Quintana G."
  },
  {
    "objectID": "www/cv/cv.html#selected-conferences-workshops-and-posters",
    "href": "www/cv/cv.html#selected-conferences-workshops-and-posters",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Selected Conferences, Workshops and Posters",
    "text": "Selected Conferences, Workshops and Posters\n\nNavigating the Interplay of Explainability and Privacy in AI\nPresentation: Preview of Faithful Model Explanations through Energy-Based Conformal Counterfactuals\nDelft, Netherlands\n2024\n\n\nJuliaCon 2023\nPresentation: Predictive Uncertainty Quantification in Machine Learning\nMIT in Boston, USA\n2023\n\n\nFirst IEEE Conference on Secure and Trustworthy Machine Learning\nPresentation: Endogenous Macrodynamics in Algorithmic Recourse\nRaleigh, North Carolina\n2023\n\n\nNew Methods Seminar at the Bank of England\nPresentation: Explaining Black-Box Models through Counterfactuals\nLondon, United Kingdom\n2022\n\n\nING Data Science Community Conference 2022\nPresentation: Explaining Black-Box Models through Counterfactuals\nAmsterdam, Netherlands\n2022\n\n\nJuliaCon 2022\nPresented Julia packages I developed\nVirtual\n2022\n\n\nExplaining Black-Box Models through Counterfactuals (main talk)\nEffortless Bayesian Deep Learning through Laplace Redux (lightening talk)\nJulia and Quarto: A Match Made in Heaven? (experience talk)\n\n\n\n\nProbAI 2022 Summer School\nPoster presentation ‚ÄúExplainable AI: Probabilistic Methods for Counterfactual Explanations‚Äù: [poster]\nHelsinki, Finland\n2022\n\n\nTU Delft EEMCS PhD event\nPoster presentation ‚ÄúCounterfactual Explanations and Algorithmic Recourse‚Äù: [poster]\nDelft, Netherlands\n2022\n\n\nDe Nederlandse Bank Conference ‚ÄúCentral Bankers Go Data Driven: Applications of AI and ML for Policy and Prudential Supervision‚Äù\nPoster presentation of Altmeyer, Agusti, and Vidal-Quadras Costa (2021).\nAmsterdam, Netherlands\n2022\n\n\nIFC and Bank of Italy workshop on ‚ÄúData science in central banking‚Äù\nPresentation of Altmeyer, Agusti, and Vidal-Quadras Costa (2021): [event link], [YouTube]\nVirtual\n2022\n\n\nNeurIPS 2021 MLECON Workshop\nPoster presentation of Altmeyer, Agusti, and Vidal-Quadras Costa (2021): [event link]\nVirtual\n2021\n\n\nIFABS 2021 Oxford\nPresented our upcoming BoE Staff Working Paper on yield curve pricing [event link]\nVirtual\n2021\n\n\nMoney markets and Central Bank Balance Sheets\nPresented research on demand for central bank reserves at ECB: [event link]\nFrankfurt, Germany\n2019"
  },
  {
    "objectID": "www/cv/cv.html#selected-open-source-software",
    "href": "www/cv/cv.html#selected-open-source-software",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Selected Open-Source Software",
    "text": "Selected Open-Source Software\n\nConformalPrediction.jl\nJulia package for Conformal Prediction: [docs], [GitHub]\nN/A\n2022-2024\n\n\nCounterfactualExplanations.jl\nJulia package for Counterfactual Explanations: [docs], [GitHub]\nN/A\n2021-2024\n\n\nLaplaceRedux.jl\nJulia package for effortless Bayesian Deep Learning: [docs], [GitHub]\nN/A\n2021-2024\n\n\ndeepvars\nR package implementing Deep Vector Autoregression (Altmeyer, Agusti, and Vidal-Quadras Costa 2021): [GitHub]\nN/A\n2021-2022"
  },
  {
    "objectID": "www/cv/cv.html#outreach-and-volunteering",
    "href": "www/cv/cv.html#outreach-and-volunteering",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Outreach and Volunteering",
    "text": "Outreach and Volunteering\n\nPersonal blog\nCommunication AI in an accessible, visual manner: [url]\nN/A\n2022 - 2021\n\n\nClass representative\nMasters in Data Science\nBarcelona, Spain\n2020\n\n\nTEDx talk\nHeld a TEDx talk about European Integration: [YouTube]\nEdinburgh, United Kingdom\n2016"
  },
  {
    "objectID": "www/cv/cv.html#scholarships-and-awards",
    "href": "www/cv/cv.html#scholarships-and-awards",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Scholarships and awards",
    "text": "Scholarships and awards\n\nPluto Notebook Competition for JuliaCon2023\n2nd Price Winner\nMIT in Boston, USA\n2023\n\n\nNovartis Datathon\n3rd Price Winner of Datathon\nBarcelona, Spain\n2020\n\n\nFee Waiver and Funding for Masters\nFull funding for Masters in Data Science through BSE and Bank of England\nBarcelona, Spain\n2020\n\n\nFee waiver for Masters\nTotal tuition fee waiver for Master in Finance through BSE\nBarcelona, Spain\n2017\n\n\nSchool of Economics Prize\nEdinburgh University School of Economics Joint Prize for the best performance in Economics\nEdinburgh, United Kingdom\n2017\n\n\nSchool of Economics Prize\nSchool of Economics Prize for academic excellence in Economics\nEdinburgh, United Kingdom\n2015"
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html",
    "title": "How I‚Äôm building this website in R",
    "section": "",
    "text": "Note\n\n\n\nUpdate on Feb 20, 2022\nThe post below was written when I still used blogdown in combination with Hugo to build this blog. I have recently migrated the blog (along pretty much everything else I do) to quarto.\n\nQuarto¬Æ is an open-source scientific and technical publishing system built on Pandoc.\n\nBased on my first few experiences I would go further and say that quarto is the only open-source scientific and technical publishing system you‚Äôll ever need. The project is supported by RStudio and (unsurprisingly) Yihui Xie is one of the contributors. Go check it out!"
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#getting-started",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#getting-started",
    "title": "How I‚Äôm building this website in R",
    "section": "Getting started",
    "text": "Getting started\nIt turns out building a static website in R is remarkably easy, as long as you know your way around R Markdown. Knowledge of HTML and CSS helps, but is not strictly necessary and can be acquired along the way. My package of choice for this website is blogdown by Yihui Xie who has had a major impact on the R community through his many package contributions (knitr, bookdown, pagedown, ‚Ä¶) and certainly made my life a lot easier on many occasions.\nTo get started just follow the instructions on blogdown‚Äôs GitHub repository or keep reading here for a high-level overview. Setting up a basic website in R requires exactly two steps:\n\nSet up a local directory for the website. Let‚Äôs suppose you create it here ~/Documents/myAwesomeWebsite.\nIn R, navigate to the directory and simply run blogdown::newsite().\n\nThis will set up a basic template which you can develop. Changing the theme and playing with the basic structure of the website is relatively straight-forward. Personally I have so far managed to work things out based on a working knowledge of HTML and CSS that I‚Äôve developed in the past through my work with R Shiny."
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#deploying-your-website",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#deploying-your-website",
    "title": "How I‚Äôm building this website in R",
    "section": "Deploying your website",
    "text": "Deploying your website\nThere are various ways to deploy your website, i.e.¬†make it accessible to the public. This website is deployed through GitHub pages. Detailed instructions on how to do this can be found here. Since I already had an existing local clone of my pat-alt.github.io repo, I just dropped it in the source directory of the website:\nsource/\n‚îÇ\n‚îú‚îÄ‚îÄ config.yaml\n‚îú‚îÄ‚îÄ content/\n‚îú‚îÄ‚îÄ themes/\n‚îî‚îÄ‚îÄ ...\n\npatalt.github.io/\n‚îÇ\n‚îú‚îÄ‚îÄ .git/\n‚îú‚îÄ‚îÄ .nojekyll\n‚îú‚îÄ‚îÄ index.html\n‚îú‚îÄ‚îÄ about/\n‚îî‚îÄ‚îÄ ...\nAfter adding publishDir: pat-alt.github.io to my config.yaml and then running blogdown::hugo_build() the website was built inside the clone. All that was left to do was to commit changes from the local clone to the pat-alt.github.io remote repo. A few moments later the website was already up and running."
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#why-all-the-trouble",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#why-all-the-trouble",
    "title": "How I‚Äôm building this website in R",
    "section": "Why all the trouble?",
    "text": "Why all the trouble?\nThere are certainly easier ways to build a website. But if like me you do pretty much all your work in R Markdown and want to share some of it, then you will love blogdown. The beauty of it is that once the basic infrastructure is set up, adding content is as simple as running the following wrapper function\n\n\nCode\nblogdown::new_post(\"Your new post\", ext = \".Rmd\")\n\n\nwhere the first argument is just the title of your post and the ext argument can be used to specify that you want to create an R Markdown document that can include code chucks. The wrapper function will automatically set up a directory for your post under /post/. R Studio will redirect you to the relevant .Rmd file that you can then fill with content. By default that folder will look roughly like this:\n‚îú‚îÄ‚îÄ index.Rmd\n‚îú‚îÄ‚îÄ index.html\n‚îî‚îÄ‚îÄ index_files\n    ‚îî‚îÄ‚îÄ header-attrs\n        ‚îî‚îÄ‚îÄ header-attrs.js"
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#a-simple-coding-example",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#a-simple-coding-example",
    "title": "How I‚Äôm building this website in R",
    "section": "A simple coding example",
    "text": "A simple coding example\nAs you can probably tell from the code chunks above this post was created just in the way I described. So I thought I might as well go ahead with a simple coding example to add some flavour. Suppose you have built some function that you think is worth sharing with the world or simply learned something new and interesting. As a case in point, I recently had a look at the Rcpp package and wrote a small program in C++ to be used in R. Since R Markdown supports Rcpp code chunks (along with Python, bash, SQL, ‚Ä¶) it is straight-forward to show-case that code on this website.\nThe program can be used to simulate data from a categorical distribution. This distribution describes the possible results of a random variable that can take on one of \\(K\\) possible categories with different probabilities. In base R we could use rmultinom(n=1000,1,p=c(0.5,0.1,0.4)) to simulate draws from one such distribution with three different categories. Alternatively, we could write the program in C++ as follows:\n\n\nCode\n#include &lt;Rcpp.h&gt;\nusing namespace Rcpp;\n\n// [[Rcpp::export]]\nNumericMatrix simCategorical(int n, NumericVector p) {\n  int k = p.size();\n  NumericMatrix mat(k, n);\n  // Normalise prob if necessary:\n  if (sum(p)!=1) {\n    p = p/sum(p);\n  }\n  NumericVector emp_cdf = cumsum(p);\n  NumericVector u = Rcpp::runif(n, 0, 1);\n  // Matrix for 1-hot-encoding:\n  for (int j = 0; j &lt; n; j++) {\n    // Perform binary search:\n    int l = 0;\n    int r = k;\n    double target = u[j];\n    while (l &lt; r) {\n      int m = floor((l+r)/2);\n      if (emp_cdf[m] &gt; target) {\n        r = m;\n      } else {\n        l = m+1;\n      }\n    }\n    mat(r,j) = 1;\n  }\n  return mat;\n}\n\n\nIn terms of performance it turns out that the simple C++ program actually does somewhat better than the base R alternative:\n\n\nCode\nlibrary(microbenchmark)\nlibrary(ggplot2)\nn &lt;- 1000\np &lt;- c(0.5,0.1,0.4)\nmb &lt;- microbenchmark(\n    \"rmultinom\" = {rmultinom(n, 1, p)},\n    \"Rcpp\" = {simCategorical(n, p)}\n)\nautoplot(mb)"
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#embedding-existing-work",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#embedding-existing-work",
    "title": "How I‚Äôm building this website in R",
    "section": "Embedding existing work",
    "text": "Embedding existing work\nIf you have some existing work that you would like to share you can just use it to overwrite the index.Rmd file. blogdown supports any kind of R Markdown documents so you can use all of your favourite markdown packages (bookdown, pagedown, ‚Ä¶). Just make sure to specify HTML output in the YAML header."
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#resources",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#resources",
    "title": "How I‚Äôm building this website in R",
    "section": "Resources",
    "text": "Resources\nFor more information about blogdown see here. To inspect the code that builds this website check out my GitHub repository."
  },
  {
    "objectID": "blog/posts/trillion-dollar-words/index.html",
    "href": "blog/posts/trillion-dollar-words/index.html",
    "title": "TrillionDollarWords.jl",
    "section": "",
    "text": "Photo by Kenny Eliason on Unsplash\nIn a recent post, I questioned the idea that finding patterns in latent embeddings of models is indicative of AGI or even surprising. One of the models we investigate in our related paper (Altmeyer et al. 2024) is the FOMC-RoBERTa model trained on the Trillion Dollar Words dataset, both of which were published by Shah, Paturi, and Chava (2023) in a recent ACL 2023 paper: Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis (Shah, Paturi, and Chava 2023). To run our experiments and facilitate working with the data and model in Julia, I have developed a small package: TrillionDollarWords.jl. This short post introduces the package and its basic functionality."
  },
  {
    "objectID": "blog/posts/trillion-dollar-words/index.html#trilliondollarwords.jl",
    "href": "blog/posts/trillion-dollar-words/index.html#trilliondollarwords.jl",
    "title": "TrillionDollarWords.jl",
    "section": "TrillionDollarWords.jl",
    "text": "TrillionDollarWords.jl\n    \nTrillionDollarWords.jl is a light-weight package that provides Julia useres easy access to the Trillion Dollar Words dataset and model (Shah, Paturi, and Chava 2023).\n\n\n\n\n\n\nDisclaimer\n\n\n\nPlease note that I am not the author of the Trillion Dollar Words paper nor am I affiliated with the authors. The package was developed as a by-product of our research and is not officially endorsed by the authors of the paper.\n\n\nThe package is currently pending registration on Julia‚Äôs general registry. In the meantime, you can install the development version from GitHub:\nusing Pkg\nPkg.add(url=\"https://github.com/pat-alt/TrillionDollarWords.jl\")\n\nBasic Functionality\nThe package provides the following functionality:\n\nLoad pre-processed data.\nLoad the model proposed in the paper.\nBasic model inference: compute forward passes and layer-wise activations.\nDownload pre-computed activations for probing the model.\n\nThe latter two are particularly useful for downstream tasks related to mechanistic interpretability. In times of increasing scrutiny of AI models, it is important to understand how they work and what they have learned. Mechanistic interpretability is a promising approach to this end, as it aims to understand the model‚Äôs internal representations and how they relate to the task at hand. As we make abundantly clear in our own paper (Altmeyer et al. 2024), interpretability is not a silver bullet, but merely a step towards understanding, monitoring and improving AI models.\n\n\nLoading the Data\nThe Trillion Dollar Words dataset is a collection of preprocessed sentences around 40,000 time-stamped sentences from meeting minutes, press conferences and speeches by members of the Federal Open Market Committee (FOMC) (Shah, Paturi, and Chava 2023). The total sample period spans from January, 1996, to October, 2022. In order to train various rule-based models and large language models (LLM) to classify sentences as either ‚Äòhawkish‚Äô, ‚Äòdovish‚Äô or ‚Äòneutral‚Äô, they have manually annotated a subset of around 2,500 sentences. The best-performing model, a large BERT model with around 355 million parameters, was open-sourced on HuggingFace. The authors also link the sentences to market data, which makes it possible to study the relationship between language and financial markets. While the authors of the paper did publish their data, much of it is unfortunately scattered across CSV and Excel files stored in a public GitHub repo. I have collected and merged that data, yielding a combined dataset with indexed sentences and additional metadata that may be useful for downstream tasks.\nThe entire dataset of all available sentences used in the paper can be loaded as follows:\n\n\nCode\nusing TrillionDollarWords\nload_all_sentences() |&gt; show\n\n\n38358√ó8 DataFrame\n   Row ‚îÇ sentence_id  doc_id  date        event_type        label    sentence  ‚ãØ\n       ‚îÇ Int64        Int64   Date        String31          String7  String    ‚ãØ\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n     1 ‚îÇ           1       1  1996-01-30  meeting minutes   neutral  The Commi ‚ãØ\n     2 ‚îÇ           2       1  1996-01-30  meeting minutes   neutral  Consumer\n     3 ‚îÇ           3       1  1996-01-30  meeting minutes   dovish   Slower gr\n     4 ‚îÇ           4       1  1996-01-30  meeting minutes   hawkish  The deman\n     5 ‚îÇ           5       1  1996-01-30  meeting minutes   neutral  The recen ‚ãØ\n     6 ‚îÇ           6       1  1996-01-30  meeting minutes   neutral  Nonfarm p\n     7 ‚îÇ           7       1  1996-01-30  meeting minutes   hawkish  Job growt\n     8 ‚îÇ           8       1  1996-01-30  meeting minutes   hawkish  Elsewhere\n     9 ‚îÇ           9       1  1996-01-30  meeting minutes   neutral  The outpu ‚ãØ\n    10 ‚îÇ          10       1  1996-01-30  meeting minutes   neutral  Recent in\n    11 ‚îÇ          11       1  1996-01-30  meeting minutes   hawkish  Incoming\n   ‚ãÆ   ‚îÇ      ‚ãÆ         ‚ãÆ         ‚ãÆ              ‚ãÆ             ‚ãÆ               ‚ã±\n 38349 ‚îÇ       38349      63  2015-09-17  press conference  dovish   monetary\n 38350 ‚îÇ       38350      63  2015-09-17  press conference  neutral  When we‚Äîw ‚ãØ\n 38351 ‚îÇ       38351      63  2015-09-17  press conference  neutral  It‚Äôs one\n 38352 ‚îÇ       38352      63  2015-09-17  press conference  neutral  1 Chair Y\n 38353 ‚îÇ       38353      63  2015-09-17  press conference  neutral  It remain\n 38354 ‚îÇ       38354      63  2015-09-17  press conference  neutral  And, reme ‚ãØ\n 38355 ‚îÇ       38355      63  2015-09-17  press conference  neutral  It is tru\n 38356 ‚îÇ       38356      63  2015-09-17  press conference  dovish   To me, th\n 38357 ‚îÇ       38357      63  2015-09-17  press conference  hawkish  And since\n 38358 ‚îÇ       38358      63  2015-09-17  press conference  neutral  There hav ‚ãØ\n                                                3 columns and 38337 rows omitted\n\n\nThe combined dataset is also available as a DataFrame and can be loaded as follows:\n\n\nCode\nload_all_data() |&gt; show\n\n\n524395√ó11 DataFrame\n    Row ‚îÇ sentence_id  doc_id  date        event_type       label    sentence  ‚ãØ\n        ‚îÇ Int64        Int64   Date        String31         String7  String    ‚ãØ\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n      1 ‚îÇ           1       1  1996-01-30  meeting minutes  neutral  The Commi ‚ãØ\n      2 ‚îÇ           2       1  1996-01-30  meeting minutes  neutral  Consumer\n      3 ‚îÇ           3       1  1996-01-30  meeting minutes  dovish   Slower gr\n      4 ‚îÇ           4       1  1996-01-30  meeting minutes  hawkish  The deman\n      5 ‚îÇ           5       1  1996-01-30  meeting minutes  neutral  The recen ‚ãØ\n      6 ‚îÇ           6       1  1996-01-30  meeting minutes  neutral  Nonfarm p\n      7 ‚îÇ           7       1  1996-01-30  meeting minutes  hawkish  Job growt\n      8 ‚îÇ           8       1  1996-01-30  meeting minutes  hawkish  Elsewhere\n      9 ‚îÇ           9       1  1996-01-30  meeting minutes  neutral  The outpu ‚ãØ\n     10 ‚îÇ          10       1  1996-01-30  meeting minutes  neutral  Recent in\n     11 ‚îÇ          11       1  1996-01-30  meeting minutes  hawkish  Incoming\n   ‚ãÆ    ‚îÇ      ‚ãÆ         ‚ãÆ         ‚ãÆ              ‚ãÆ            ‚ãÆ               ‚ã±\n 524386 ‚îÇ       29435     125  2022-10-12  speech           hawkish  However,\n 524387 ‚îÇ       29436     125  2022-10-12  speech           hawkish  My genera ‚ãØ\n 524388 ‚îÇ       29429     125  2022-10-12  speech           neutral  I will fo\n 524389 ‚îÇ       29430     125  2022-10-12  speech           hawkish  Inflation\n 524390 ‚îÇ       29431     125  2022-10-12  speech           neutral  At this p\n 524391 ‚îÇ       29432     125  2022-10-12  speech           hawkish  If we do  ‚ãØ\n 524392 ‚îÇ       29433     125  2022-10-12  speech           hawkish  However,\n 524393 ‚îÇ       29434     125  2022-10-12  speech           hawkish  To bring\n 524394 ‚îÇ       29435     125  2022-10-12  speech           hawkish  However,\n 524395 ‚îÇ       29436     125  2022-10-12  speech           hawkish  My genera ‚ãØ\n                                               6 columns and 524374 rows omitted\n\n\nAdditional functionality for data loading is available (see docs).\n\n\nLoading the Model\nThe model can be loaded with or without the classifier head (below without the head). Under the hood, this function uses Transformers.jl to retrieve the model from HuggingFace. Any keyword arguments accepted by Transformers.HuggingFace.HGFConfig can also be passed. For example, to load the model without the classifier head and enable access to layer-wise activations, the following command can be used:\n\n\nCode\nload_model(; load_head=false, output_hidden_states=true) |&gt; show\n\n\nBaselineModel(GPT2TextEncoder(\n‚îú‚îÄ TextTokenizer(MatchTokenization(CodeNormalizer(BPETokenization(GPT2Tokenization, bpe = CachedBPE(BPE(50000 merges))), codemap = CodeMap{UInt8 =&gt; UInt16}(3 code-ranges)), 5 patterns)),\n‚îú‚îÄ vocab = Vocab{String, SizedArray}(size = 50265, unk = &lt;unk&gt;, unki = 4),\n‚îú‚îÄ codemap = CodeMap{UInt8 =&gt; UInt16}(3 code-ranges),\n‚îú‚îÄ startsym = &lt;s&gt;,\n‚îú‚îÄ endsym = &lt;/s&gt;,\n‚îú‚îÄ padsym = &lt;pad&gt;,\n‚îú‚îÄ trunc = 256,\n‚îî‚îÄ process = Pipelines:\n  ‚ï∞‚îÄ target[token] := TextEncodeBase.nestedcall(string_getvalue, source)\n  ‚ï∞‚îÄ target[token] := Transformers.TextEncoders.grouping_sentence(target.token)\n  ‚ï∞‚îÄ target[(token, segment)] := SequenceTemplate{String}(&lt;s&gt;:&lt;type=1&gt; Input:&lt;type=1&gt; &lt;/s&gt;:&lt;type=1&gt; (&lt;/s&gt;:&lt;type=1&gt; Input:&lt;type=1&gt; &lt;/s&gt;:&lt;type=1&gt;)...)(target.token)\n  ‚ï∞‚îÄ target[attention_mask] := (NeuralAttentionlib.LengthMask ‚àò Transformers.TextEncoders.getlengths(256))(target.token)\n  ‚ï∞‚îÄ target[token] := TextEncodeBase.trunc_or_pad(256, &lt;pad&gt;, tail, tail)(target.token)\n  ‚ï∞‚îÄ target[token] := TextEncodeBase.nested2batch(target.token)\n  ‚ï∞‚îÄ target := (target.token, target.attention_mask)\n), HGFRobertaModel(Chain(CompositeEmbedding(token = Embed(1024, 50265), position = ApplyEmbed(.+, FixedLenPositionEmbed(1024, 514), Transformers.HuggingFace.roberta_pe_indices(1,)), segment = ApplyEmbed(.+, Embed(1024, 1), Transformers.HuggingFace.bert_ones_like)), DropoutLayer&lt;nothing&gt;(LayerNorm(1024, œµ = 1.0e-5))), Transformer&lt;24&gt;(PostNormTransformerBlock(DropoutLayer&lt;nothing&gt;(SelfAttention(MultiheadQKVAttenOp(head = 16, p = nothing), Fork&lt;3&gt;(Dense(W = (1024, 1024), b = true)), Dense(W = (1024, 1024), b = true))), LayerNorm(1024, œµ = 1.0e-5), DropoutLayer&lt;nothing&gt;(Chain(Dense(œÉ = NNlib.gelu, W = (1024, 4096), b = true), Dense(W = (4096, 1024), b = true))), LayerNorm(1024, œµ = 1.0e-5))), Branch{(:pooled,) = (:hidden_state,)}(BertPooler(Dense(œÉ = NNlib.tanh_fast, W = (1024, 1024), b = true)))), Transformers.HuggingFace.HGFConfig{:roberta, JSON3.Object{Vector{UInt8}, Vector{UInt64}}, Dict{Symbol, Any}}(:use_cache =&gt; true, :torch_dtype =&gt; \"float32\", :vocab_size =&gt; 50265, :output_hidden_states =&gt; true, :hidden_act =&gt; \"gelu\", :num_hidden_layers =&gt; 24, :num_attention_heads =&gt; 16, :classifier_dropout =&gt; nothing, :type_vocab_size =&gt; 1, :intermediate_size =&gt; 4096, :max_position_embeddings =&gt; 514, :model_type =&gt; \"roberta\", :layer_norm_eps =&gt; 1.0e-5, :id2label =&gt; Dict(0 =&gt; \"LABEL_0\", 2 =&gt; \"LABEL_2\", 1 =&gt; \"LABEL_1\"), :_name_or_path =&gt; \"roberta-large\", :hidden_size =&gt; 1024, :transformers_version =&gt; \"4.21.2\", :attention_probs_dropout_prob =&gt; 0.1, :bos_token_id =&gt; 0, :problem_type =&gt; \"single_label_classification\", :eos_token_id =&gt; 2, :initializer_range =&gt; 0.02, :hidden_dropout_prob =&gt; 0.1, :label2id =&gt; Dict(\"LABEL_1\" =&gt; 1, \"LABEL_2\" =&gt; 2, \"LABEL_0\" =&gt; 0), :pad_token_id =&gt; 1, :position_embedding_type =&gt; \"absolute\", :architectures =&gt; [\"RobertaForSequenceClassification\"]))\n\n\n\n\nBasic Model Inference\nUsing the model and data, layer-wise activations can be computed as below (here for the first 5 sentences). When called on a DataFrame, the layerwise_activations returns a data frame that links activations to sentence identifiers. This makes it possible to relate activations to market data by using the sentence_id key. Alternatively, layerwise_activations also accepts a vector of sentences.\n\n\nCode\ndf = load_all_sentences()\nmod = load_model(; load_head=false, output_hidden_states=true)\nn = 5\nqueries = df[1:n, :]\nlayerwise_activations(mod, queries) |&gt; show\n\n\n122880√ó4 DataFrame\n    Row ‚îÇ sentence_id  activations  layer  activation_id \n        ‚îÇ Int64        Float32      Int64  Int64         \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n      1 ‚îÇ           1   0.202931        1              1\n      2 ‚îÇ           1  -0.00693996      1              2\n      3 ‚îÇ           1   0.12731         1              3\n      4 ‚îÇ           1  -0.0129803       1              4\n      5 ‚îÇ           1   0.122843        1              5\n      6 ‚îÇ           1   0.258675        1              6\n      7 ‚îÇ           1   0.0466324       1              7\n      8 ‚îÇ           1   0.0318548       1              8\n      9 ‚îÇ           1   1.18888         1              9\n     10 ‚îÇ           1  -0.0386651       1             10\n     11 ‚îÇ           1  -0.116031        1             11\n   ‚ãÆ    ‚îÇ      ‚ãÆ            ‚ãÆ         ‚ãÆ          ‚ãÆ\n 122871 ‚îÇ           5  -0.769513       24           1015\n 122872 ‚îÇ           5   0.834678       24           1016\n 122873 ‚îÇ           5   0.212098       24           1017\n 122874 ‚îÇ           5  -0.556661       24           1018\n 122875 ‚îÇ           5   0.0957697      24           1019\n 122876 ‚îÇ           5   1.04358        24           1020\n 122877 ‚îÇ           5   1.71445        24           1021\n 122878 ‚îÇ           5   1.162          24           1022\n 122879 ‚îÇ           5  -1.58513        24           1023\n 122880 ‚îÇ           5  -1.01479        24           1024\n                                      122859 rows omitted\n\n\n\n\nProbe Findings\nFor our own research (Altmeyer et al. 2024), we have been interested in probing the model. This involves using linear models to estimate the relationship between layer-wise transformer embeddings and some outcome variable of interest (Alain and Bengio 2018). To do this, we first had to run a single forward pass for each sentence through the RoBERTa model and store the layerwise emeddings. As we have seen above, the package ships with functionality for doing just that, but to save others valuable GPU hours we have archived activations of the hidden state on the first entity token for each layer as artifacts. To download the last-layer activations in an interactive Julia session, for example, users can proceed as follows:\nusing LazyArtifacts\n\njulia&gt; artifact\"activations_layer_24\"\nWe have found that despite the small sample size, the FOMC-RoBERTa model appears to have distilled useful representations for downstream tasks that it was not explicitly trained for. Figure¬†1 below shows the average out-of-sample root mean squared error for predicting various market indicators from layer activations. Consistent with findings in related work (Alain and Bengio 2018), we find that performance typically improves for layers closer to the final output layer of the transformer model. The measured performance is at least on par with baseline autoregressive models. For more information on this, see also my other recent post.\n\n\n\nFigure¬†1: Out-of-sample root mean squared error (RMSE) for the linear probe plotted against FOMC-RoBERTa‚Äôs \\(n\\)-th layer for different indicators. The values correspond to averages computed across cross-validation folds, where we have used an expanding window approach to split the time series."
  },
  {
    "objectID": "blog/posts/trillion-dollar-words/index.html#intended-purpose-and-goals",
    "href": "blog/posts/trillion-dollar-words/index.html#intended-purpose-and-goals",
    "title": "TrillionDollarWords.jl",
    "section": "Intended Purpose and Goals",
    "text": "Intended Purpose and Goals\nI hope that this small package may be useful to members of the Julia community who are interested in the interplay between Economics, Finance and Artificial Intelligence. It should serve as a good starting point for the following ideas:\n\nFine-tune additional models on the classification task or other tasks of interest.\nFurther model probing, e.g.¬†using other market indicators not discussed in the original paper.\nImprove and extend the label annotations.\n\nAny contributions are very much welcome."
  },
  {
    "objectID": "blog/posts/conformal-image-classifier/index.html",
    "href": "blog/posts/conformal-image-classifier/index.html",
    "title": "How to Conformalize a Deep Image Classifier",
    "section": "",
    "text": "Conformalized prediction sets for asimple Deep Image Classifier.\nDeep Learning is popular and ‚Äî for some tasks like image classification ‚Äî remarkably powerful. But it is also well-known that Deep Neural Networks (DNN) can be unstable (Goodfellow, Shlens, and Szegedy 2014) and poorly calibrated. Conformal Prediction can be used to mitigate these pitfalls.\nIn the first part of this series of posts on Conformal Prediction, we looked at the basic underlying methodology and how CP can be implemented in Julia using ConformalPrediction.jl. This second part of the series is a more goal-oriented how-to guide: it demonstrates how you can conformalize a deep learning image classifier built in Flux.jl in just a few lines of code.\nSince this is meant to be more of a hands-on article, we will avoid diving too deeply into methodological concepts. If you need more colour on this, be sure to check out the first article on this topic and also A. N. Angelopoulos and Bates (2022). For a more formal treatment of Conformal Prediction see also A. Angelopoulos et al. (2022)."
  },
  {
    "objectID": "blog/posts/conformal-image-classifier/index.html#the-task-at-hand",
    "href": "blog/posts/conformal-image-classifier/index.html#the-task-at-hand",
    "title": "How to Conformalize a Deep Image Classifier",
    "section": "üéØ The Task at Hand",
    "text": "üéØ The Task at Hand\nThe task at hand is to predict the labels of handwritten images of digits using the famous MNIST dataset (LeCun 1998). Importing this popular machine learning dataset in Julia is made remarkably easy through MLDatasets.jl:\n\n\nCode\nusing MLDatasets\nN = 1000\nXraw, yraw = MNIST(split=:train)[:]\nXraw = Xraw[:,:,1:N]\nyraw = yraw[1:N]\n\n\nFigure¬†1 below shows a few random samples from the training data:\n\n\nCode\nusing MLJ\nusing Images\nX = map(x -&gt; convert2image(MNIST, x), eachslice(Xraw, dims=3))\ny = coerce(yraw, Multiclass)\n\nn_samples = 10\nmosaic(rand(X, n_samples)..., ncol=n_samples)\n\n\n\n\nFigure¬†1: Random samples from the MNIST dataset."
  },
  {
    "objectID": "blog/posts/conformal-image-classifier/index.html#building-the-network",
    "href": "blog/posts/conformal-image-classifier/index.html#building-the-network",
    "title": "How to Conformalize a Deep Image Classifier",
    "section": "üöß Building the Network",
    "text": "üöß Building the Network\nTo model the mapping from image inputs to labels will rely on a simple Multi-Layer Perceptron (MLP). A great Julia library for Deep Learning is Flux.jl. But wait ‚Ä¶ doesn‚Äôt ConformalPrediction.jl work with models trained in MLJ.jl? That‚Äôs right, but fortunately there exists a Flux.jl interface to MLJ.jl, namely MLJFlux.jl. The interface is still in its early stages, but already very powerful and easily accessible for anyone (like myself) who is used to building Neural Networks in Flux.jl.\nIn Flux.jl, you could build an MLP for this task as follows,\n\n\nCode\nusing Flux\n\nmlp = Chain(\n    Flux.flatten,\n    Dense(prod((28,28)), 32, relu),\n    Dense(32, 10)\n)\n\n\nwhere (28,28) is just the input dimension (28x28 pixel images). Since we have ten digits, our output dimension is ten.1\nWe can do the exact same thing in MLJFlux.jl as follows,\n\n\nCode\nusing MLJFlux\n\nbuilder = MLJFlux.@builder Chain(\n    Flux.flatten,\n    Dense(prod(n_in), 32, relu),\n    Dense(32, n_out)\n)\n\n\nwhere here we rely on the @builder macro to make the transition from Flux.jl to MLJ.jl as seamless as possible. Finally, MLJFlux.jl already comes with a number of helper functions to define plain-vanilla networks. In this case, we will use the ImageClassifier with our custom builder and cross-entropy loss:\n\n\nCode\nImageClassifier = @load ImageClassifier\nclf = ImageClassifier(\n    builder=builder,\n    epochs=10,\n    loss=Flux.crossentropy\n)\n\n\nThe generated instance clf is a model (in the MLJ.jl sense) so from this point on we can rely on standard MLJ.jl workflows. For example, we can wrap our model in data to create a machine and then evaluate it on a holdout set as follows:\n\n\nCode\nmach = machine(clf, X, y)\n\nevaluate!(\n    mach,\n    resampling=Holdout(rng=123, fraction_train=0.8),\n    operation=predict_mode,\n    measure=[accuracy]\n)\n\n\nThe accuracy of our very simple model is not amazing, but good enough for the purpose of this tutorial. For each image, our MLP returns a softmax output for each possible digit: 0,1,2,3,‚Ä¶,9. Since each individual softmax output is valued between zero and one, \\(y_k\\in(0,1)\\), this is commonly interpreted as a probability: \\(y_k \\coloneqq p(y=k|X)\\). Edge cases ‚Äì that is values close to either zero or one ‚Äì indicate high predictive certainty. But this is only a heuristic notion of predictive uncertainty (A. N. Angelopoulos and Bates 2022). Next, we will turn this heuristic notion of uncertainty into a rigorous one using Conformal Prediction."
  },
  {
    "objectID": "blog/posts/conformal-image-classifier/index.html#conformalizing-the-network",
    "href": "blog/posts/conformal-image-classifier/index.html#conformalizing-the-network",
    "title": "How to Conformalize a Deep Image Classifier",
    "section": "üî• Conformalizing the Network",
    "text": "üî• Conformalizing the Network\nSince clf is a model, it is also compatible with our package: ConformalPrediction.jl. To conformalize our MLP, we therefore only need to call conformal_model(clf). Since the generated instance conf_model is also just a model, we can still rely on standard MLJ.jl workflows. Below we first wrap it in data and then fit it. Aaaand ‚Ä¶ we‚Äôre done! Let‚Äôs look at the results in the next section.\n\n\nCode\nusing ConformalPrediction\nconf_model = conformal_model(clf; method=:simple_inductive, coverage=.95)\nmach = machine(conf_model, X, y)\nfit!(mach)"
  },
  {
    "objectID": "blog/posts/conformal-image-classifier/index.html#results",
    "href": "blog/posts/conformal-image-classifier/index.html#results",
    "title": "How to Conformalize a Deep Image Classifier",
    "section": "üìä Results",
    "text": "üìä Results\nFigure¬†2 below presents the results. Figure¬†2 (a) displays highly certain predictions, now defined in the rigorous sense of Conformal Prediction: in each case, the conformal set (just beneath the image) includes only one label.\nFigure¬†2 (b) and Figure¬†2 (c) display increasingly uncertain predictions of set size two and three, respectively. They demonstrate that CP is well equipped to deal with samples characterized by high aleatoric uncertainty: digits four (4), seven (7) and nine (9) share certain similarities. So do digits five (5) and six (6) as well as three (3) and eight (8). These may be hard to distinguish from each other even after seeing many examples (and even for a human). It is therefore unsurprising to see that these digits often end up together in conformal sets.\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n(a) Randomly selected prediction sets of size \\(|C|=1\\).\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n(b) Randomly selected prediction sets of size \\(|C|=2\\).\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n(c) Randomly selected prediction sets of size \\(|C|=3\\).\n\n\n\nFigure¬†2: Conformalized predictions from an image classifier."
  },
  {
    "objectID": "blog/posts/conformal-image-classifier/index.html#evaluation",
    "href": "blog/posts/conformal-image-classifier/index.html#evaluation",
    "title": "How to Conformalize a Deep Image Classifier",
    "section": "üßê Evaluation",
    "text": "üßê Evaluation\nTo evaluate the performance of conformal models, specific performance measures can be used to assess if the model is correctly specified and well-calibrated (A. N. Angelopoulos and Bates 2022). We will look at this in some more detail in another post in the future. For now, just be aware that these measures are already available in ConformalPrediction.jl and we will briefly showcase them here.\nAs for many other things, ConformalPrediction.jl taps into the existing functionality of MLJ.jl for model evaluation. In particular, we will see below how we can use the generic evaluate! method on our machine. To assess the correctness of our conformal predictor, we can compute the empirical coverage rate using the custom performance measure emp_coverage. With respect to model calibration we will look at the model‚Äôs conditional coverage. For adaptive, well-calibrated conformal models, conditional coverage is high. One general go-to measure for assessing conditional coverage is size-stratified coverage. The custom measure for this purpose is just called size_stratified_coverage, aliased by ssc.\nThe code below implements the model evaluation using cross-validation. The Simple Inductive Classifier that we used above is not adaptive and hence the attained conditional coverage is low compared to the overall empirical coverage, which is close to \\(0.95\\), so in line with the desired coverage rate specified above.\n\n\nCode\n_eval = evaluate!(\n    mach,\n    resampling=CV(),\n    operation=predict,\n    measure=[emp_coverage, ssc]\n)\ndisplay(_eval)\nprintln(\"Empirical coverage: $(round(_eval.measurement[1], digits=3))\")\nprintln(\"SSC: $(round(_eval.measurement[2], digits=3))\")\n\n\n\nPerformanceEvaluation object with these fields:\n  measure, operation, measurement, per_fold,\n  per_observation, fitted_params_per_fold,\n  report_per_fold, train_test_rows\nExtract:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ measure                                      ‚îÇ operation ‚îÇ measurement ‚îÇ 1.9 ‚ãØ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ ConformalPrediction.emp_coverage             ‚îÇ predict   ‚îÇ 0.95        ‚îÇ 0.0 ‚ãØ\n‚îÇ ConformalPrediction.size_stratified_coverage ‚îÇ predict   ‚îÇ 0.867       ‚îÇ 0.0 ‚ãØ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                                                               2 columns omitted\n\n\n\n\nEmpirical coverage: 0.95\nSSC: 0.867\n\n\nWe can attain higher adaptivity (SSC) when using adaptive prediction sets:\n\n\nCode\nconf_model = conformal_model(clf; method=:adaptive_inductive, coverage=.95)\nmach = machine(conf_model, X, y)\nfit!(mach)\n_eval = evaluate!(\n    mach,\n    resampling=CV(),\n    operation=predict,\n    measure=[emp_coverage, ssc]\n)\nresults[:adaptive_inductive] = mach\ndisplay(_eval)\nprintln(\"Empirical coverage: $(round(_eval.measurement[1], digits=3))\")\nprintln(\"SSC: $(round(_eval.measurement[2], digits=3))\")\n\n\n\nPerformanceEvaluation object with these fields:\n  measure, operation, measurement, per_fold,\n  per_observation, fitted_params_per_fold,\n  report_per_fold, train_test_rows\nExtract:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ measure                                      ‚îÇ operation ‚îÇ measurement ‚îÇ 1.9 ‚ãØ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÇ ConformalPrediction.emp_coverage             ‚îÇ predict   ‚îÇ 0.994       ‚îÇ 0.0 ‚ãØ\n‚îÇ ConformalPrediction.size_stratified_coverage ‚îÇ predict   ‚îÇ 0.97        ‚îÇ 0.0 ‚ãØ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n                                                               2 columns omitted\n\n\n\n\nEmpirical coverage: 0.994\nSSC: 0.97\n\n\nWe can also have a look at the resulting set size for both approaches using a custom Plots.jl recipe (fig-setsize). In line with the above, the spread is wider for the adaptive approach, which reflects that ‚Äúthe procedure is effectively distinguishing between easy and hard inputs‚Äù (A. N. Angelopoulos and Bates 2022).\n\n\nCode\nplt_list = []\nfor (_mod, mach) in results\n    push!(plt_list, bar(mach.model, mach.fitresult, X; title=String(_mod)))\nend\nplot(plt_list..., size=(800,300))\nplot(plt_list..., size=(800,300),bg_colour=:transparent)\n\n\n\n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3: Distribution of set sizes for both approaches."
  },
  {
    "objectID": "blog/posts/conformal-image-classifier/index.html#recap",
    "href": "blog/posts/conformal-image-classifier/index.html#recap",
    "title": "How to Conformalize a Deep Image Classifier",
    "section": "üîÅ Recap",
    "text": "üîÅ Recap\nIn this short guide, we have seen how easy it is to conformalize a deep learning image classifier in Julia using ConformalPrediction.jl. Almost any deep neural network trained in Flux.jl is compatible with MLJ.jl and can therefore be conformalized in just a few lines of code. This makes it remarkably easy to move uncertainty heuristics to rigorous predictive uncertainty estimates. We have also seen a sneak peek at the performance evaluation of conformal predictors. Stay tuned for more!"
  },
  {
    "objectID": "blog/posts/conformal-image-classifier/index.html#footnotes",
    "href": "blog/posts/conformal-image-classifier/index.html#footnotes",
    "title": "How to Conformalize a Deep Image Classifier",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor a full tutorial on how to build an MNIST image classifier relying solely on Flux.jl, check out this tutorial.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/welcome/index.html",
    "href": "blog/posts/welcome/index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to my blog!\nHaving worked with R Markdown and some of Yihui Xie‚Äôs amazing packages for years, I have only now come across his blogdown package. For a while I have been thinking about a good way to share some of my work and actually started collecting snippets in a Gitbook through bookdown quite some time ago. While the book is a work-in-progress that I aim to finish eventually, I will use this website to regularly share content related to my work, research and other things.\n\n\n\n\n\n\nNote\n\n\n\nUpdate on Feb 20, 2022\nI have recently migrated this blog and pretty much everything else I do to quarto.\n\nQuarto¬Æ is an open-source scientific and technical publishing system built on Pandoc.\n\nBased on my first few experiences I would go further and say that quarto is the only open-source scientific and technical publishing system you‚Äôll ever need. The project is supported by RStudio and (unsurprisingly) Yihui Xie is one of the contributors. Go check it out!\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{altmeyer2021,\n  author = {Altmeyer, Patrick and Altmeyer, Patrick},\n  title = {Welcome},\n  date = {2021-02-01},\n  url = {https://www.paltmeyer.com/blog//blog/posts/welcome},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAltmeyer, Patrick, and Patrick Altmeyer. 2021. ‚ÄúWelcome.‚Äù\nFebruary 1, 2021. https://www.paltmeyer.com/blog//blog/posts/welcome."
  },
  {
    "objectID": "blog/posts/a-new-tool-for-explainable-ai/index.html",
    "href": "blog/posts/a-new-tool-for-explainable-ai/index.html",
    "title": "A new tool for explainable AI",
    "section": "",
    "text": "Turning a 9 (nine) into a 4 (four).\nCounterfactual explanations, which I introduced in one of my previous posts1, offer a simple and intuitive way to explain black-box models without opening them. Still, as of today there exists only one open-source library that provides a unifying approach to generate and benchmark counterfactual explanations for models built and trained in Python (Pawelczyk et al. 2021). This is great, but of limited use to users of other programming languages ü•≤.\nEnter CounterfactualExplanations.jl: a Julia package that can be used to explain machine learning algorithms developed and trained in Julia, Python and R. Counterfactual explanations fall into the broader category of explainable artificial intelligence (XAI).\nExplainable AI typically involves models that are not inherently interpretable but require additional tools to be explainable to humans. Examples of the latter include ensembles, support vector machines and deep neural networks. This is not to be confused with interpretable AI, which involves models that are inherently interpretable and transparent such as general additive models (GAM), decision trees and rule-based models.\nSome would argue that we best avoid explaining black-box models altogether (Rudin 2019) and instead focus solely on interpretable AI. While I agree that initial efforts should always be geared towards interpretable models, stopping there would entail missed opportunities and anyway is probably not very realistic in times of DALL\\(\\cdot\\)E and Co.\nThis post introduces the main functionality of the new Julia package. Following a motivating example using a model trained in Julia, we will see how easy the package can be adapted to work with models trained in Python and R. Since the motivation for this post is also to hopefully attract contributors, the final section outlines some of the exciting developments we have planned."
  },
  {
    "objectID": "blog/posts/a-new-tool-for-explainable-ai/index.html#counterfactuals-for-image-data",
    "href": "blog/posts/a-new-tool-for-explainable-ai/index.html#counterfactuals-for-image-data",
    "title": "A new tool for explainable AI",
    "section": "Counterfactuals for image data üñº",
    "text": "Counterfactuals for image data üñº\nTo introduce counterfactual explanations I used a simple binary classification problem in my previous post. It involved a linear classifier and a linearly separable, synthetic data set with just two features. This time we are going to step it up a notch: we will generate counterfactual explanations MNIST data. The MNIST dataset contains 60,000 training samples of handwritten digits in the form of 28x28 pixel grey-scale images (LeCun 1998). Each image is associated with a label indicating the digit (0-9) that the image represents.\nThe CounterfactualExplanations.jl package ships with two black-box models that were trained to predict labels for this data: firstly, a simple multi-layer perceptron (MLP) and, secondly, a corresponding deep ensemble. Originally proposed by Lakshminarayanan, Pritzel, and Blundell (2017), deep ensembles are really just ensembles of deep neural networks. They are still among the most popular approaches to Bayesian deep learning.2\n\nBlack-box models\nThe code below loads relevant packages along with the MNIST data and pre-trained models.\n\n\nCode\n# Load package, models and data:\nusing CounterfactualExplanations, Flux\nusing CounterfactualExplanations.Data: mnist_data, mnist_model, mnist_ensemble\ndata, X, ys = mnist_data()\nmodel = mnist_model()\nensemble = mnist_ensemble()\ncounterfactual_data = CounterfactualData(X,ys;domain=(0,1))\n\n\nWhile the package can currently handle a few simple classification models natively, it is designed to be easily extensible through users and contributors. Extending the package to deal with custom models typically involves only two simple steps:\n\nSubtyping: the custom model needs to be declared as a subtype of the package-internal type AbstractFittedModel.\nMultiple dispatch: the package-internal functions logits and probs need to be extended through custom methods for the new model type.\n\nThe following code implements these two steps first for the MLP and then for the deep ensemble.\n\n\nCode\nusing CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs\n# MLP:\n# Step 1)\nstruct NeuralNetwork &lt;: Models.AbstractFittedModel\n    model::Any\nend\n# Step 2)\nlogits(M::NeuralNetwork, X::AbstractArray) = M.model(X)\nprobs(M::NeuralNetwork, X::AbstractArray)= softmax(logits(M, X))\nM = NeuralNetwork(model)\n\n# Deep ensemble:\nusing Flux: stack\n# Step 1)\nstruct FittedEnsemble &lt;: Models.AbstractFittedModel\n    ensemble::AbstractArray\nend\n# Step 2)\nusing Statistics\nlogits(M::FittedEnsemble, X::AbstractArray) = mean(stack([m(X) for m in M.ensemble],3),dims=3)\nprobs(M::FittedEnsemble, X::AbstractArray) = mean(stack([softmax(m(X)) for m in M.ensemble],3),dims=3)\nM_ensemble = FittedEnsemble(ensemble)\n\n\n\n\nCounterfactual generators\nNext, we need to specify the counterfactual generators we want to use. The package currently ships with two default generators that both need gradient access: firstly, the generic generator introduced by Wachter, Mittelstadt, and Russell (2017) and, secondly, a greedy generator introduced by Schut et al. (2021).\nThe greedy generator is designed to be used with models that incorporate uncertainty in their predictions such as the deep ensemble introduced above. It works for probabilistic (Bayesian) models, because they only produce high-confidence predictions in regions of the feature domain that are populated by training samples. As long as the model is expressive enough and well-specified, counterfactuals in these regions will always be realistic and unambiguous since by construction they should look very similar to training samples. Other popular approaches to counterfactual explanations like REVISE (Joshi et al. 2019) and CLUE (Antor√°n et al. 2020) also play with this simple idea.\nThe following code instantiates the two generators for the problem at hand.\n\n\nCode\ngeneric = GenericGenerator(;loss=:logitcrossentropy)\ngreedy = GreedyGenerator(;loss=:logitcrossentropy)\n\n\n\n\nExplanations\nOnce the model and counterfactual generator are specified, running counterfactual search is very easy using the package. For a given factual (x), target class (target) and data set (counterfactual_data), simply running\n\ngenerate_counterfactual(x, target, counterfactual_data, M, generic)\n\nwill generate the results, in this case using the generic generator (generic) for the MLP (M). Since we have specified two different black-box models and two different counterfactual generators, we have four combinations of a model and a generator in total. For each of these combinations I have used the generate_counterfactual function to produce the results in Figure¬†1.\nIn every case the desired label switch is in fact achieved, but arguably from a human perspective only the counterfactuals for the deep ensemble look like a four. The generic generator produces mild perturbations in regions that seem irrelevant from a human perspective, but nonetheless yields a counterfactual that can pass as a four. The greedy approach clearly targets pixels at the top of the handwritten nine and yields the best result overall. For the non-Bayesian MLP, both the generic and the greedy approach generate counterfactuals that look much like adversarial examples: they perturb pixels in seemingly random regions on the image.\n\n\n\nFigure¬†1: Counterfactual explanations for MNIST: turning a nine (9) into a four (4)."
  },
  {
    "objectID": "blog/posts/a-new-tool-for-explainable-ai/index.html#language-interoperability",
    "href": "blog/posts/a-new-tool-for-explainable-ai/index.html#language-interoperability",
    "title": "A new tool for explainable AI",
    "section": "Language interoperability üë•",
    "text": "Language interoperability üë•\nThe Julia language offers unique support for programming language interoperability. For example, calling R or Python is made remarkably easy through RCall.jl and PyCall.jl, respectively. This functionality can be leveraged to use CounterfactualExplanations.jl to generate explanations for models that were developed in other programming languages. At this time there is no native support for foreign programming languages, but the following example involving a torch neural network trained in R demonstrates how versatile the package is.3\n\nExplaining a torch model\nWe will consider a simple MLP trained for a binary classification task. As before we first need to adapt this custom model for use with our package. The code below the two necessary steps - sub-typing and method extension. Logits are returned by the torch model and copied from the R environment into the Julia scope. Probabilities are then computed inside the Julia scope by passing the logits through the sigmoid function.\n\n\nCode\nusing Flux\nusing CounterfactualExplanations, CounterfactualExplanations.Models\nimport CounterfactualExplanations.Models: logits, probs # import functions in order to extend\n\n# Step 1)\nstruct TorchNetwork &lt;: Models.AbstractFittedModel\n    nn::Any\nend\n\n# Step 2)\nfunction logits(M::TorchNetwork, X::AbstractArray)\n  nn = M.nn\n  y = rcopy(R\"as_array($nn(torch_tensor(t($X))))\")\n  y = isa(y, AbstractArray) ? y : [y]\n  return y'\nend\nfunction probs(M::TorchNetwork, X::AbstractArray)\n  return œÉ.(logits(M, X))\nend\nM = TorchNetwork(R\"model\")\n\n\nCompared to models trained in Julia, we need to do a little more work at this point. Since our counterfactual generators need gradient access, we essentially need to allow our package to communicate with the R torch library. While this may sound daunting, it turns out to be quite manageable: all we have to do is respecify the function that computes the gradient with respect to the counterfactual loss function so that it can deal with the TorchNetwork type we defined above. That is all the adjustment needed to use CounterfactualExplanations.jl for our custom R model. Figure¬†2 shows a counterfactual path for a randomly chosen sample with respect to the MLP trained in R.\n\n\n\n\n\n\nExperimental functionality\n\n\n\nYou may have stumbled across the term respecify above: does it really seem like a good idea to just replace an existing function from our package? Surely not! There are certainly better ways to go about this, which we will consider when adding native support for Python and R models in future package releases. Which brings us to our final section ‚Ä¶\n\n\n\n\nCode\nimport CounterfactualExplanations.Generators: ‚àÇ‚Ñì\nusing LinearAlgebra\n\n# Countefactual loss:\nfunction ‚àÇ‚Ñì(\n    generator::AbstractGradientBasedGenerator, \n    counterfactual_state::CounterfactualState) \n  M = counterfactual_state.M\n  nn = M.nn\n  x‚Ä≤ = counterfactual_state.x‚Ä≤\n  t = counterfactual_state.target_encoded\n  R\"\"\"\n  x &lt;- torch_tensor($x‚Ä≤, requires_grad=TRUE)\n  output &lt;- $nn(x)\n  loss_fun &lt;- nnf_binary_cross_entropy_with_logits\n  obj_loss &lt;- loss_fun(output,$t)\n  obj_loss$backward()\n  \"\"\"\n  grad = rcopy(R\"as_array(x$grad)\")\n  return grad\nend\n\n\n\n\n\nFigure¬†2: Counterfactual path using the generic counterfactual generator for a model trained in R."
  },
  {
    "objectID": "blog/posts/a-new-tool-for-explainable-ai/index.html#we-need-you",
    "href": "blog/posts/a-new-tool-for-explainable-ai/index.html#we-need-you",
    "title": "A new tool for explainable AI",
    "section": "We need you! ü´µ",
    "text": "We need you! ü´µ\nThe ambition for CounterfactualExplanations.jl is to provide a go-to place for counterfactual explanations to the Julia community and beyond. This is a grand ambition, especially for a package that has so far been built by a single developer who has little prior experience with Julia. We would therefore very much like to invite community contributions. If you have an interest in trustworthy AI, the open-source community and Julia, please do get involved! This package is still in its early stages of development, so any kind of contribution is welcome: advice on the core package architecture, pull requests, issues, discussions and even just comments below would be much appreciated.\nTo give you a flavor of what type of future developments we envision, here is a non-exhaustive list:\n\nNative support for additional counterfactual generators and predictive models including those built and trained in Python or R.\nAdditional datasets for testing, evaluation and benchmarking.\nImproved preprocessing including native support for categorical features.\nSupport for regression models.\n\nFinally, if you like this project but don‚Äôt have much time, then simply sharing this article or starring the repo on GitHub would also go a long way."
  },
  {
    "objectID": "blog/posts/a-new-tool-for-explainable-ai/index.html#further-reading",
    "href": "blog/posts/a-new-tool-for-explainable-ai/index.html#further-reading",
    "title": "A new tool for explainable AI",
    "section": "Further reading üìö",
    "text": "Further reading üìö\nIf you‚Äôre interested in learning more about this development, feel free to check out the following resources:\n\nPackage docs: [stable], [dev].\nContributor‚Äôs guide.\nGitHub repo."
  },
  {
    "objectID": "blog/posts/a-new-tool-for-explainable-ai/index.html#footnotes",
    "href": "blog/posts/a-new-tool-for-explainable-ai/index.html#footnotes",
    "title": "A new tool for explainable AI",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee: [TDS], [blog]‚Ü©Ô∏é\nFor more information on Bayesian deep learning see my previous post: [TDS], [blog].‚Ü©Ô∏é\nThe corresponding example involving PyTorch is analogous and therefore not included here. You may find it here.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html",
    "href": "blog/posts/quarto-extensions/index.html",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "",
    "text": "A TU Delft Theme for Quarto.\nI‚Äôve said it before and I‚Äôll say it again: Quarto is amazing! Since the beginning of my PhD I haven‚Äôt used any other tool for prototyping, writing and publishing any of my work.1 That work has included: this website, presentations, academic articles, notebooks and more. By highlighting useful features of Quarto in articles like this one, I hope to encourage more people to try it out.\nWhile I‚Äôm convinced that Quarto can be useful in almost any context including industry, I realize that certain obstacles may have so far prevented some of you from using it. One such obstacle concerns custom formats: the standard Quarto formats for HTML, PDF, Revealjs, etc. are slick but minimalistic. For many formats, there are various themes to choose from, but they too lack personal touch (or corporate identity in the industry setting).\nAt first sight, traditional publishing tools like MS Office seem to have an edge here: customization is made easy through GUIs and standardization through templates is possible to a certain degree. I understand the appeal but still would encourage you to look beyond MS Word, Powerpoint and Beamer presentations. To this end, I‚Äôve put together this short tutorial that explains how I have built and contributed a TU Delft theme for Revealjs. If nothing else, this theme can be used by my colleagues at Delft University of Technology to create beautiful, Delft-styled presentations with ease."
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html#background",
    "href": "blog/posts/quarto-extensions/index.html#background",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "üìñ Background",
    "text": "üìñ Background\nAdvanced and reproducible customization in Quarto is done through Quarto Extensions:\n\n‚ÄúQuarto Extensions are a powerful way to modify or extend the behavior of Quarto, and can be created and distributed by anyone.‚Äù\n‚Äî Quarto team\n\nUsers can already utilize several open-sourced extensions that add filters, journal article formats and other custom formats. As we will see, it is very straightforward to contribute extensions, so the list of available extensions is growing quickly."
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html#contributing-quarto-extensions",
    "href": "blog/posts/quarto-extensions/index.html#contributing-quarto-extensions",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "ü´¥ Contributing Quarto Extensions",
    "text": "ü´¥ Contributing Quarto Extensions\nNormally, I would start by explaining how to use Quarto Extensions, but in this particular case the user and developer experience is so close that I‚Äôll jump straight into development.\n\nSetup\nTo get started with building the TU Delft Custom Format I followed the official Quarto docs. I first used the appropriate Quarto command, which initiates an interactive process in the command line:\n$ quarto create extension format:revealjs\n ? Extension Name ‚Ä∫ lexdoc\nOnce done, the basic folder structure for my extension was set up and ready to be pushed to a remote Github repository for distribution: https://github.com/pat-alt/quarto-tudelft. Even though I had not yet added any custom formatting rules, anyone would now be able to use this empty extension for their work.\n\n\nAdding Rules\nTo actually add some custom formatting rules to the extension I started working on the files contained in _extensions/tudelft/. Using my institution‚Äôs PowerPoint template as a reference, I previewed the template.qmd file and simply made appropriate adjustments to the _extensions/tudelft/custom.scss and _extensions/tudelft/_extension.yml files until I was satisfied. To help me in that process, I took inspiration from various existing Revealjs extensions all listed in the awesome-quarto repository.\nI am no expert in CSS (far from it!), so this was very much trial-and-error based, but I got there eventually. One feature I am particularly happy about is the custom transition slides: by default all slides at level 1, so slides that initiate a new section,\n# Transition Slide\nwill be formatted in a standardized way. The relevant CSS rule can be found here\n\n\nAdding Assets\nThe Reavealjs template also includes a few images, which I have lifted from my institution‚Äôs PowerPoint template. To make sure that these images are also available locally when users install the template, any resources need to be stored inside the theme directory _extensions/tudelft/. I have had some issues pointing to the right location of these images in the _extensions/tudelft/custom.scss and _extensions/tudelft/_extension.yml file. At the time of writing this, the image URLs are pointing to their remote location on Github (see here). This works, but probably isn‚Äôt ideal, so any suggestions are welcome."
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html#example-presentation---using-quarto-extensions",
    "href": "blog/posts/quarto-extensions/index.html#example-presentation---using-quarto-extensions",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "üìã Example Presentation - Using Quarto Extensions",
    "text": "üìã Example Presentation - Using Quarto Extensions\nIn February, 2023, I will present a research paper on Algorithmic Recourse at the first IEEE Conference on Secure and Trustworthy Machine Learning: SaTML 2023. This was a good incentive for me to build a TU Delft Theme once for this occasion and then be able to reuse it again in the future.\n\nWith the template built and distributed, how do you actually use it?\n\nThis part is truly a walk in the park. As outlined in the README users can either work directly with the template,\nquarto use template pat-alt/quarto-tudelft\nor add the template to an existing Quarto project:\nquarto add pat-alt/quarto-tudelft\nThe first option will get you started with a working document straight away. For my paper presentation, I worked with the second option. At the time of writing, I am building and hosting all of my presentations in my website repository (the repo that also builds this very article you‚Äôre reading): https://github.com/pat-alt/pat-alt.github.io.\nWith the extension added to the project, I can now use it anywhere within that project by simply specifying,\nformat: tudelft-revealjs\nin the YAML header of my Quarto document where tudelft-revealjs is just the name of the custom format.\nIt gets better ‚Ä¶ The extension can be extended further by providing yet another custom style sheet, as I have done for my paper presentation:\nformat: \n  tudelft-revealjs:\n    theme: custom.scss\nCheck out the final presentation here or see the embedded version below:"
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html#footnotes",
    "href": "blog/posts/quarto-extensions/index.html#footnotes",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNot entirely true: I‚Äôve also used Pluto.jl üéà and had to resort to .Rmd in one particular case.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html",
    "href": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "",
    "text": "Julia and Quarto: a perfect match.\nDoes your work involve research, coding, writing and publishing? If so, then chances are that you often find yourself bouncing back and forth between different open-source text editors, IDEs, programming languages and platforms depending on your current needs. Using a diverse set of tools is reasonable, because there typically is no single perfect approach that solves all our problems. For example, interactive notebooks like Jupyter are useful for working with code and communicating it to others, but they are probably not anyone‚Äôs first choice for producing a scientific article. Similarly, Beamer presentations can be useful for presenting science in a standardized fashion, but they are the very opposite of interactive and look incredibly boring.\nAs much as the great variety of free tools deserves being celebrated, all this bouncing back and forth can be really tiring. What if there was a single tool, an engine that can turn your work into all kinds of different outputs? I mean literally any output you can think of: Markdown, HTML, PDF, LateX, ePub, entire websites, presentations (yes, also Beamer if you have to), MS Word, OpenOffice, ‚Ä¶ the list goes on. All of that starting from the same place: a plain Markdown document blended with essentially any programming language of your choice and a YAML header defining your output. This tool now exists and it goes by the name Quarto.\nIn this short blog post I hope to convince you that Quarto is the only publishing engine you will ever need. What I am definitely not going to tell you is which IDE, text editor or programming language you should be using to actually produce your work. Quarto does not care about that. Quarto is here to make your life a bit easier (and by ‚Äòa bit‚Äô I mean a whole lot). Quarto is nothing less but a revolution for scientific publishing.\nTo put this all in some context (well, my context), I will now tell you a bit about what has led me to making such bold claims about yet another open-source tool.\nYes! But it‚Äôs worth noting that a lot of the benefits that Quarto brings have been available to R users for many years, thanks to the amazing work of many great open-source contributors like @xieyihui. Julia was the main reason for me to branch out of this comfortable R bubble as I describe below. That said, if you are a Julia user who really couldn‚Äôt care less about my previous experiences with R Markdown, this is a good time to skip straight ahead to Section¬†2. By the way, if you haven‚Äôt clicked on that link, here‚Äôs a small showcase demonstrating how it was generated. It shows easy it is to have everything well organised and connected with Quarto."
  },
  {
    "objectID": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#sec-bubble",
    "href": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#sec-bubble",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "A comfortable bubble üéà",
    "text": "A comfortable bubble üéà\nFor many years I have used R Markdown for essentially anything work-related. As an undergraduate economics student facing the unfortunate reality that people still teach Stata, I was drawn to R. This was partially because R has a great open-source community and also partially because Stata. Once I realised that I would be able to use R Markdown to write up all of my future homework assignments and even my thesis, I never looked back. MS Word was now officially dead to me. Overleaf was nothing more than a last resort if everyone else in my team insisted on using it for a group project. Being able to write my undergraduate dissertation in R Markdown was a first truly triumphant moment. Soon after that I would also try myself at Shiny, produce outputs in HTML and build entire websites through blogdown. And all of that from within R Studio involving R and Markdown and really not much else. During my first professional job at the Bank of England I was reluctant to use anything other than R Markdown to produce all of my output. Luckily for me, the Bank was very much heading in that same direction at the time and my reluctance was not perceived as stubbornness, but actually welcome (at least I hoped so).\n\nCracks in the bubble üß®\nSoon though, part of me felt a little boxed in. For any work that required me to look outside of the R bubble, I knew I might also have to give up a very, very comfortable work environment and my productivity would surely take a hit. During my master‚Äôs in Data Science, for example, the mantra was very much ‚ÄúPython + Jupyter or die‚Äù. Through reticulate and R Studio‚Äôs growing support for Python I managed to get by without having to leave my bubble too often. But reticulate always felt a little clunky (sorry!) and some professors were reluctant to accept anything other than Jupyter notebooks. Even if others had not perceived it that way in the past, I certainly started to feel that I might just be a little too attached the beautiful bubble that R Studio had created around me.\n\n\nEnter: Julia üí£\nThen there was Julia: elegant, fast, pure, scientific and - oh my REPL! - those beautiful colors and unicode symbols. The stuff of dreams, really! Geeky dreams, but dreams nonetheless. I had once before given Julia a shot when working with high-frequency trade data for a course in market microstructure. This was the first time R really revealed its limitations to me and my bubble nearly burst, but thanks to data.table and Rcpp I managed to escape with only minor bruises. Still, Julia kept popping up, teasing me whenever I would work on some Frakenstein-style C++ code snippets that would hopefully resolve my R bottlenecks. I actually enjoyed mixing some C++ into my R code like I did here, but the process was just a little painful and slow. But wouldn‚Äôt learning all of Julia take even more time and patience? And what about my dependence on R Markdown?\n\n\nJulia bursts my bubble üí•\nAs I started my PhD in September 2021, I eventually gave in. New beginnings - time to suck it up! If it meant that I‚Äôd have to use Jupyter notebooks with Julia, so be it! And so I was off to a somewhat bumpy start that would have me bouncing back and forth between trying to make Julia work in R Studio (meh), setting up Jupyter Lab (meeeh), just using the Julia REPL because ‚Äúthe REPL is all you need‚Äù (nope) and even struggling with Vim and Emacs. Then there was also Pluto.jl, of course, which admittedly looks amazing! But it also looks very much tailored to Julia and (I believe) the number of different output formats you can produce is still very limited. Eventually, I settled for VSCode in combination with Jupyter notebooks. As much as I dreaded the latter, Jupyter is popular, arguably versatile and supports both R and Julia. This setup worked well enough for me, but it still definitely fell short of the breeze that R Studio had always provided. One thing that really bugged me, for example, was the fact that the IJulia kernel was not accessible from the Julia REPL. Each notebook would have its own environment, which could only be accessed through the notebook. In R Studio the interaction between R Markdown and the console is seamless, as both have access to the same environment variables.\n\n\nEnter: Quarto ‚ù§Ô∏è‚Äçü©π\nAround the same time that I started using Julia, I read about Quarto for the first time. It looked ‚Ä¶ great! Like a timely little miracle really! But also ‚Ä¶ unfinished? Definitely experimental at the time. I loved the idea though and in a footnote somewhere on their website it said that the project was supported by R Studio which I took as a very good sign. So I decided to at least give it a quick try and built a small (tiny) website summarising some of the literature I had read for my PhD:\n\n\nJust had my first go #quarto and I absolutely love the concept! Open-source and language agnostic - truly amazing work from &#64rstudio https://t.co/veCg7ywQ8v\n\n‚Äî Patrick Altmeyer (&#64paltmey) October 29, 2021\n\n\nThis was a first very pleasant encounter with Quarto, arguable even smoother than building websites in blogdown. As for working with Julia though, I had made up my mind that VSCode was the way to go and at the time there was no Quarto extension (there is now). There was also little in terms of communication about the project by R Studio, probably because things were really still in the early development stages. I was hopeful that eventually Quarto would enable me to emulate the R Studio experience in VS Code, but for now things were not quite there yet.\n\n\nQuarto keeps growing ü§û\nSince I was now working with VSCode + Jupyter and since Quarto supports Jupyter as well as all of my old R Markdown work, my next little Quarto project involved turning my old blogdown-powered blog into a Quarto-powered blog. This was not strictly necessary, as I could always export my new Jupyter notebooks to HTML and let blogdown do the rest. But it did streamline things a little bit and the default Quarto blog theme - you are staring at it - is actually üî•. I also did not have to feel guilty towards @xieyihui about leaving blogdown, because unsurprisingly he is on the Quarto team. As I was working on this little project I started noticing that the Quarto website was updated regularly and responses to issues I opened like this one were answered very swiftly. Clearly, things were moving and they were moving fast. More recently, the news about Quarto has been spreading and it‚Äôs left some folks as confused and amazed as I was, when I first heard about it:\n\n\n#RStats can someone explain to me what's the difference between {Quarto} and {RMarkdown}? I saw a tweet about Quarto and now I'm all confused ‚Ä¶ What gap is it supposed to fill?\n\n‚Äî Erwin Lares (&#64lasrubieras) March 30, 2022\n\n\nThis is why finally I‚Äôve decided I should write a brief post about how and why I use Quarto. Since I have been working mostly with Julia for the past couple of months, I‚Äôve chosen to focus on the interaction between Quarto and Julia. Coincidentally, yesterday was also the first time I saw a guide dedicated to Julia on the Quarto website, so evidently I am not the only one interested in that marriage. This also means that there really is not too much left for me to talk about now, since Quarto‚Äôs documentation is state-of-the-art. But a few bits and pieces I mention below might hopefully still be useful or at least some food for thought."
  },
  {
    "objectID": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#sec-match",
    "href": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#sec-match",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "Quarto and Julia: a perfect match üíôüíúüíö",
    "text": "Quarto and Julia: a perfect match üíôüíúüíö\nWhile what follows may be relevant to other programming languages, my main goal for this last section is to flag Quarto to the Julia community. In any case, #rstats folks have been using R and Python in R Markdown documents for a while now and won‚Äôt need much of an introduction to Quarto. As for Python aficionados, I can only recommend to give Quarto a shot (you will still be able to use Jupyter notebooks).\n\nWorking with VSCode, Quarto and Julia\nThe very article you are reading right now was composed in a Quarto document. These documents feel and look very much like standard Julia Markdown documents, but you can do a lot more with them. You can find the source code for this and other documents presented in this blog here.\nTo get you started, here is my current setup combining VSCode, Quarto and Julia:\n\nVSCode extensions: in addition to the Julia extension you will need the Quarto extension. In addition, the YAML extension and some extension to preview Markdown docs would be helpful. I am not sure if Markdown Julia and Jupyter are strictly necessary, but it won‚Äôt hurt.\nI do most of my work in Quarto documents .qmd.\nIf you choose to also do that, make sure that the .qmd document has access to a Pkg.jl environment that has IJulia added.\n\nJulia code cells can be added anywhere along with your plain text Markdown. They look like this:\n```{julia}\nusing Pkg\nPkg.add(\"CounterfactualExplanations\")\n```\nContrary to Jupyter notebooks, executing this code cells will start a Julia REPL in VSCode. I find this very helpful, because it lets me fiddle with anything I have created inside the Quarto notebook without having to click into cells all the time. Quarto comes with great support for specifying code executing options. For example, for the code below I have specified #| echo: true in order for the code to be rendered. The code itself is the code I actually used to build the animation above (heavily borrowed from this Javis.jl tutorial).\n#| echo: true\nusing Javis, Animations, Colors\n\nsize = 600\nradius_factor = 0.33\n\nfunction ground(args...)\n    background(\"transparent\")\n    sethue(\"white\")\nend\n\nfunction rotate_anim(idx::Number, total::Number) \n    distance_circle = 0.875\n    steps = collect(range(distance_circle,1-distance_circle,length=total))\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [0, steps[idx]*2œÄ],\n        [sineio()],\n    )\nend\n\ntranslate_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(size*radius_factor, 0)],\n    [sineio()],\n)\n\ntranslate_back_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(-(size*radius_factor), 0)],\n    [sineio()],\n)\n\njulia_colours = Dict(\n    :blue =&gt; \"#4063D8\",\n    :green =&gt; \"#389826\",\n    :purple =&gt; \"#9558b2\",\n    :red =&gt; \"#CB3C33\"\n)\ncolour_order = [:red, :purple, :green, :blue]\nn_colours = length(julia_colours)\nfunction color_anim(start_colour::String, quarto_col::String=\"#4b95d0\")\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [Lab(color(start_colour)), Lab(color(quarto_col))],\n        [sineio()],\n    )\nend\n\nvideo = Video(size, size)\n\nframe_starts = 1:10:40\nn_total = 250\nn_frames = 150\nBackground(1:n_total, ground)\n\n# Blob:\nfunction element(; radius = 1)\n    circle(O, radius, :fill) # The 4 is to make the circle not so small\nend\n\n# Cross:\nfunction cross(color=\"black\";orientation=:horizontal)\n    sethue(color)\n    setline(10)\n    if orientation==:horizontal\n        out = line(Point(-size,0),Point(size,0), :stroke)\n    else\n        out = line(Point(0,-size),Point(0,size), :stroke)\n    end\n    return out\nend\n\nfor (i, frame_start) in enumerate(1:10:40)\n\n    # Julia circles:\n    blob = Object(frame_start:n_total, (args...;radius=1) -&gt; element(;radius=radius))\n    act!(blob, Action(1:Int(round(n_frames*0.25)), change(:radius, 1 =&gt; 75))) # scale up\n    act!(blob, Action(n_frames:(n_frames+50), change(:radius, 75 =&gt; 250))) # scale up further\n    act!(blob, Action(1:30, translate_anim, translate()))\n    act!(blob, Action(31:120, rotate_anim(i, n_colours), rotate_around(Point(-(size*radius_factor), 0))))\n    act!(blob, Action(121:150, translate_back_anim, translate()))\n    act!(blob, Action(1:150, color_anim(julia_colours[colour_order[i]]), sethue()))\n\n    # Quarto cross:\n    cross_h = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:horizontal))\n    cross_v = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:vertical))\nend\n\nrender(\n    video;\n    pathname = joinpath(www_path, \"intro.gif\"),\n)\n\n\nWorking with Documenter.jl and Quarto\nAn interesting application of Quarto in the Julia ecosystem is package documentation. This is of course best done using Documenter.jl and fortunately the two play nicely with each other, since both share a common ground (Markdown). Their interaction is perhaps best demonstrated through this Julia library I recently developed: CounterfactualExplanatinos.jl. On there you will find lot of Julia scripts *.jl under src/ and test/, as well as many Markdown .md and Quarto documents .qmd under docs. I wrote the package documentation in the Quarto documents, rendered documents individually through quarto render [doc].qmd and then fed the resulting Markdown documents to Documenter.jl as always.\nBelow is my standard YAML header for those Quarto documents:\nformat: \n  commonmark:\n    variant: -raw_html\n    wrap: none\n    self-contained: true\ncrossref:\n  fig-prefix: Figure\n  tbl-prefix: Table\nbibliography: https://raw.githubusercontent.com/pat-alt/bib/main/bib.bib\noutput: asis\nexecute: \n  echo: true\n  eval: false\njupyter: julia-1.7\nYou can see that it points to Bibtex file I host on another Github repository. This makes it very easy to generate citations and references for the rendered Markdown documents, that also show up in the docs (e.g.¬†here). Unfortunately, cross-referencing only partially works, because it relies on auto-generated HTML and Documenter.jl expects this to be passed in blocks. Choosing variant: -raw_html is only a workaround as I have discussed here. Ideally, Documenter.jl would just accept HTML documents rendered from Quarto, but currently only Markdown documents are accepted by make_docs. Still, if anything this workaround is a nice gimmick that extends the default Documenter.jl functionality, without any hassle involved. Hopefully, this can be improved in the future.\n\n\nUsing Quarto for JuliaCon Proceedings\nAnother very good use-case for Quarto involves actual scientific publications in journals such as JuliaCon Proceedings. The existing submission process is tailored towards reproducibility and actually involves reviews directly on GitHub, which is fantastic. But currently only submissions in TeX format are accepted, which is not so great. Using Quarto would not only streamline this process further, but also open the JuliaCon Proceedings Journal up to publishing content in different output formats. Quarto docs could be used to still render the traditional PDF. But those same documents could also be used to create interactive versions in HTML. Arguably, the entire journal could probably be built through Quarto."
  },
  {
    "objectID": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#wrapping-up",
    "href": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#wrapping-up",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "Wrapping up üéó",
    "text": "Wrapping up üéó\nIn this post I wanted to demonstrate that Quarto might just be the next revolution in scientific publishing. In particular, I hope I have managed to demonstrate its appeal to the Julia community, which I am proud to be part of now that I have managed to branch out of my old R bubble. Please let me hear your thoughts and comments below!"
  },
  {
    "objectID": "blog/posts/conformal-regression/index.html",
    "href": "blog/posts/conformal-regression/index.html",
    "title": "Prediction Intervals for any Regression Model",
    "section": "",
    "text": "Conformal Prediction intervals for differentcoverage rates. As coverage grows, so doesthe width of the prediction interval.\nThis is the third (and for now final) part of a series of posts that introduce Conformal Prediction in Julia using ConformalPrediction.jl. The first post introduced Conformal Prediction for supervised classification tasks: we learned that conformal classifiers produce set-valued predictions that are guaranteed to include the true label of a new sample with a certain probability. In the second post we applied these ideas to a more hands-on example: we saw how easy it is to use ConformalPrediction.jl to conformalize a Deep Learning image classifier.\nIn this post, we will look at regression models instead, that is supervised learning tasks involving a continuous outcome variable. Regression tasks are as ubiquitous as classification tasks. For example, we might be interested in using a machine learning model to predict house prices or the inflation rate of the Euro or the parameter size of the next large language model. In fact, many readers may be more familiar with regression models than classification, in which case it may also be easier for you to understand Conformal Prediction (CP) in this context."
  },
  {
    "objectID": "blog/posts/conformal-regression/index.html#background",
    "href": "blog/posts/conformal-regression/index.html#background",
    "title": "Prediction Intervals for any Regression Model",
    "section": "üìñ Background",
    "text": "üìñ Background\nBefore we start, let‚Äôs briefly recap what CP is all about. Don‚Äôt worry, we‚Äôre not about to deep-dive into methodology. But just to give you a high-level description upfront:\n\nConformal prediction (a.k.a. conformal inference) is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions.\n‚Äî Angelopoulos and Bates (2022) (arXiv)\n\nIntuitively, CP works under the premise of turning heuristic notions of uncertainty into rigorous uncertainty estimates through repeated sampling or the use of dedicated calibration data.\nIn what follows we will explore what CP can do by going through a standard machine learning workflow using MLJ.jl and ConformalPrediction.jl. There will be less focus on how exactly CP works, but references will point you to additional resources.\n\n\n\n\n\n\nInteractive Version\n\n\n\nThis post is also available as a fully interactive Pluto.jl üéà notebook hosted on binder: \nIn my own experience, this may take some time to load, certainly long enough to get yourself a hot beverage ‚òï or first read on here. But I promise you that the wait is worth it!"
  },
  {
    "objectID": "blog/posts/conformal-regression/index.html#data",
    "href": "blog/posts/conformal-regression/index.html#data",
    "title": "Prediction Intervals for any Regression Model",
    "section": "üìà Data",
    "text": "üìà Data\nMost machine learning workflows start with data. For illustrative purposes we will work with synthetic data. The helper function below can be used to generate some regression data.\n\n\nCode\nfunction get_data(;N=1000, xmax=3.0, noise=0.5, fun::Function=fun(X) = X * sin(X))\n    # Inputs:\n    d = Distributions.Uniform(-xmax, xmax)\n    X = rand(d, N)\n    X = MLJBase.table(reshape(X, :, 1))\n\n    # Outputs:\n    Œµ = randn(N) .* noise\n    y = @.(fun(X.x1)) + Œµ\n    y = vec(y)\n    return X, y\nend\n\n\nFigure¬†1 illustrates our observations (dots) along with the ground-truth mapping from inputs to outputs (line). We have defined that mapping \\(f: \\mathcal{X} \\mapsto \\mathcal{Y}\\) as follows:\n\n\nCode\nf(X) = X * cos(X)\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Some synthetic regression data. Observations are shown as dots. The ground-truth mapping from inputs to outputs is shown as a dashed line."
  },
  {
    "objectID": "blog/posts/conformal-regression/index.html#model-training-using-mlj",
    "href": "blog/posts/conformal-regression/index.html#model-training-using-mlj",
    "title": "Prediction Intervals for any Regression Model",
    "section": "üèãÔ∏è Model Training using MLJ",
    "text": "üèãÔ∏è Model Training using MLJ\nConformalPrediction.jl is interfaced to MLJ.jl (Blaom et al. 2020): a comprehensive Machine Learning Framework for Julia. MLJ.jl provides a large and growing suite of popular machine learning models that can be used for supervised and unsupervised tasks. Conformal Prediction is a model-agnostic approach to uncertainty quantification, so it can be applied to any common supervised machine learning model.\nThe interface to MLJ.jl therefore seems natural: any (supervised) MLJ.jl model can now be conformalized using ConformalPrediction.jl. By leveraging existing MLJ.jl functionality for common tasks like training, prediction and model evaluation, this package is light-weight and scalable. Now let‚Äôs see how all of that works ‚Ä¶\nTo start with, let‚Äôs split our data into a training and test set:\n\n\nCode\ntrain, test = partition(eachindex(y), 0.4, 0.4, shuffle=true)\n\n\nNow let‚Äôs define a model for our regression task:\n\n\nCode\nModel = @load KNNRegressor pkg = NearestNeighborModels\nmodel = Model()\n\n\n\n\n\n\n\n\nHave it your way!\n\n\n\nThink this dataset is too simple? Wondering why on earth I‚Äôm not using XGBoost for this task? In the interactive version of this post you have full control over the data and the model. Try it out!\n\n\nUsing standard MLJ.jl workflows let us now first train the unconformalized model. We first wrap our model in data:\n\n\nCode\nmach_raw = machine(model, X, y)\n\n\nThen we fit the machine to the training data:\n\n\nCode\nMLJBase.fit!(mach_raw, rows=train, verbosity=0)\n\n\nFigure¬†2 below shows the resulting point predictions for the test data set:\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: Point predictions for our machine learning model.\n\n\n\nHow is our model doing? It‚Äôs never quite right, of course, since predictions are estimates and therefore uncertain. Let‚Äôs see how we can use Conformal Prediction to express that uncertainty."
  },
  {
    "objectID": "blog/posts/conformal-regression/index.html#conformalizing-the-model",
    "href": "blog/posts/conformal-regression/index.html#conformalizing-the-model",
    "title": "Prediction Intervals for any Regression Model",
    "section": "üî• Conformalizing the Model",
    "text": "üî• Conformalizing the Model\nWe can turn our model into a conformalized model in just one line of code:\n\n\nCode\nconf_model = conformal_model(model)\n\n\nBy default conformal_model creates an Inductive Conformal Regressor (more on this below) when called on a &lt;:Deterministic model. This behaviour can be changed by using the optional method key argument.\nTo train our conformal model we can once again rely on standard MLJ.jl workflows. We first wrap our model in data:\n\n\nCode\nmach = machine(conf_model, X, y)\n\n\nThen we fit the machine to the data:\n\n\nCode\nMLJBase.fit!(mach, rows=train, verbosity=0)\n\n\nNow let us look at the predictions for our test data again. The chart below shows the results for our conformalized model. Predictions from conformal regressors are range-valued: for each new sample the model returns an interval \\((y_{\\text{lb}},y_{\\text{ub}})\\in\\mathcal{Y}\\) that covers the test sample with a user-specified probability \\((1-\\alpha)\\), where \\(\\alpha\\) is the expected error rate. This is known as the marginal coverage guarantee and it is proven to hold under the assumption that training and test data are exchangeable.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3: Prediction intervals for our conformalized machine learning model.\n\n\n\nIntuitively, a higher coverage rate leads to larger prediction intervals: since a larger interval covers a larger subspace of \\(\\mathcal{Y}\\), it is more likely to cover the true value.\nI don‚Äôt expect you to believe me that the marginal coverage property really holds. In fact, I couldn‚Äôt believe it myself when I first learned about it. If you like mathematical proofs, you can find one in this tutorial, for example. If you like convincing yourself through empirical observations, read on below ‚Ä¶"
  },
  {
    "objectID": "blog/posts/conformal-regression/index.html#evaluation",
    "href": "blog/posts/conformal-regression/index.html#evaluation",
    "title": "Prediction Intervals for any Regression Model",
    "section": "üßê Evaluation",
    "text": "üßê Evaluation\nTo verify the marginal coverage property empirically we can look at the empirical coverage rate of our conformal predictor (see Section 3 of the tutorial for details). To this end our package provides a custom performance measure emp_coverage that is compatible with MLJ.jl model evaluation workflows. In particular, we will call evaluate! on our conformal model using emp_coverage as our performance metric. The resulting empirical coverage rate should then be close to the desired level of coverage.\n\n\nCode\nmodel_evaluation =\n    evaluate!(_mach, operation=MLJBase.predict, measure=emp_coverage, verbosity=0)\nprintln(\"Empirical coverage: $(round(model_evaluation.measurement[1], digits=3))\")\nprintln(\"Coverage per fold: $(round.(model_evaluation.per_fold[1], digits=3))\")\n\n\nEmpirical coverage: 0.902\nCoverage per fold: [0.94, 0.904, 0.874, 0.874, 0.898, 0.922]\n\n\n\n\n\n‚úÖ ‚úÖ ‚úÖ Great! We got an empirical coverage rate that is slightly higher than desired üòÅ ‚Ä¶ but why isn‚Äôt it exactly the same?\n\nIn most cases it will be slightly higher than desired, since \\((1-\\alpha)\\) is a lower bound. But note that it can also be slightly lower than desired. That is because the coverage property is ‚Äúmarginal‚Äù in the sense that the probability is averaged over the randomness in the data. For most purposes a large enough calibration set size (\\(n&gt;1000\\)) mitigates that randomness enough. Depending on your choices above, the calibration set may be quite small (set to 500), which can lead to coverage slack (see Section 3 in the tutorial).\n\n\n\nSo what‚Äôs happening under the hood?\nInductive Conformal Prediction (also referred to as Split Conformal Prediction) broadly speaking works as follows:\n\nPartition the training into a proper training set and a separate calibration set\nTrain the machine learning model on the proper training set.\nUsing some heuristic notion of uncertainty (e.g., absolute error in the regression case), compute nonconformity scores using the calibration data and the fitted model.\nFor the given coverage ratio compute the corresponding quantile of the empirical distribution of nonconformity scores.\nFor the given quantile and test sample \\(X_{\\text{test}}\\), form the corresponding conformal prediction set like so: \\(C(X_{\\text{test}})=\\{y:s(X_{\\text{test}},y) \\le \\hat{q}\\}\\)"
  },
  {
    "objectID": "blog/posts/conformal-regression/index.html#recap",
    "href": "blog/posts/conformal-regression/index.html#recap",
    "title": "Prediction Intervals for any Regression Model",
    "section": "üîÉ Recap",
    "text": "üîÉ Recap\nThis has been a super quick tour of ConformalPrediction.jl. We have seen how the package naturally integrates with MLJ.jl, allowing users to generate rigorous predictive uncertainty estimates for any supervised machine learning model.\n\nAre we done?\nQuite cool, right? Using a single API call we are able to generate rigorous prediction intervals for all kinds of different regression models. Have we just solved predictive uncertainty quantification once and for all? Do we even need to bother with anything else? Conformal Prediction is a very useful tool, but like so many other things, it is not the final answer to all our problems. In fact, let‚Äôs see if we can take CP to its limits.\nThe helper function to generate data from above takes an optional argument xmax. By increasing that value, we effectively expand the domain of our input. Let‚Äôs do that and see how our conformal model does on this new out-of-domain data.\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†4: Prediction intervals for our conformalized machine learning model applied to out-of-domain data.\n\n\n\n\nWhooooops ü§ï ‚Ä¶ looks like we‚Äôre in trouble: in Figure¬†4 the prediction intervals do not cover out-of-domain test samples well. What happened here?\n\nBy expanding the domain of out inputs, we have violated the exchangeability assumption. When that assumption is violated, the marginal coverage property does not hold. But do not despair! There are ways to deal with this."
  },
  {
    "objectID": "blog/posts/conformal-regression/index.html#read-on",
    "href": "blog/posts/conformal-regression/index.html#read-on",
    "title": "Prediction Intervals for any Regression Model",
    "section": "üìö Read on",
    "text": "üìö Read on\nIf you are curious to find out more, be sure to read on in the docs. There are also a number of useful resources to learn more about Conformal Prediction, a few of which I have listed below:\n\nA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification by Angelopoulos and Bates (2022).\nAwesome Conformal Prediction repository by Manokhin (2022)\nMAPIE: a comprehensive Python library for conformal prediction.\nMy previous two blog posts.\n\nEnjoy!"
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html",
    "href": "blog/posts/spurious-sparks/index.html",
    "title": "Spurious Sparks of AGI",
    "section": "",
    "text": "Photo by Jake Oates on Unsplash\nWe humans are prone to seek patterns everywhere. Meaningful patterns have often proven to help us make sense of our past, navigate our presence and predict the future. Our society is so invested in finding patterns that today it seems we are more willing than ever to outsource this task to an Artificial Intelligence (AI): an omniscient oracle that leads us down the right path.\nUnfortunately, history has shown time and again that patterns are double-edged swords: if we attribute the wrong meaning to them, they may lead us nowhere at all, or worse, they may lead us down dark roads. I think that the current debate around large language models (LLMs) is a prime example of this."
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#models-are-tools-treat-them-as-such",
    "href": "blog/posts/spurious-sparks/index.html#models-are-tools-treat-them-as-such",
    "title": "Spurious Sparks of AGI",
    "section": "Models are Tools, Treat Them as Such",
    "text": "Models are Tools, Treat Them as Such\nIn statistics, misleading patterns are referred to as spurious relationships: purely associational relationships between two or more variables that are not causally related to each other at all. The world is full of these and as good as we as species may be at recognizing patterns, we typically have a much harder time discerning spurious relationships from causal ones. Despite new and increased momentum in scientific fields concerned with causal inference and discovery, I am also willing to go out on a limb and claim that we are not about to finally reach the top of Judea Pearl‚Äôs Causal Ladder through the means of Causal AI (although I do think it is a step in the right direction).\nI agree with the premise that in a world full of spurious relationships, causal reasoning is our only remedy. But I am very skeptical of claims that AI will magically provide that remedy. This leads me to the title and topic of this post: spurious sparks of AGI‚Äîpatterns exhibited by AI that may hint at Artificial General Intelligence (AGI) but are really just reflections of the associational patterns found in the data used to train them. The article is written in response to a recent paper that finds a ‚Äòworld model‚Äô from Llama-2‚Äîa popular open-source large language model (LLM)‚Äîusing mechanistic interpretability (Gurnee and Tegmark 2023). In light of these findings, one of the authors, Max Tegmark, was quick to claim on social media that ‚ÄúNo, LLM‚Äôs aren‚Äôt mere stochastic parrots [‚Ä¶]‚Äù.\nSince this is an opinionated post, I feel that I should start by laying out my position on the paper and related claims.\n\n\n\n\n\n\nPosition\n\n\n\n\nI take no issue with the methodological ideas that form the foundation of the article in question. On the contrary, I think that mechanistic interpretability is an interesting and important toolkit that can help us better understand the intrinsics and behavior of opaque artificial intelligence.\nLinear probes are straightforward, the visualizations in Gurnee and Tegmark (2023) are intriguing, the code is open-sourced and the findings are interesting.\nI am surprised that people are surprised by the findings: if we agree that LLMs exhibit strong capabilities that can only be connected to the patterns observed in the data they were trained on, then where exactly should we expect this information to be stored if not in the parameters of the model?1\nI therefore do take issue with the way that these findings are being overblown by people with clout. Perhaps the parrot metaphor should not be taken too literally either, but if anything the paper‚Äôs findings seem to support the notion that LLMs are remarkably capable of memorizing and regurgitating explicit and implicit knowledge contained in text.\nI want to point out that linear probes were proposed in the context of monitoring models and diagnosing potential problems Alain and Bengio (2018). Favorable outcomes from probes merely indicate that the model in question ‚Äúhas learned information relevant for the property [of interest]‚Äù (Belinkov 2021). This is useful but not the same as demonstrating that the model has attained a true ‚Äúunderstanding‚Äù of the world.\n\n\n\nIn summary, I wish people used mechanistic interpretability to better understand the behavior and shortcomings of AI models, rather than chasing pipe dreams of AGI. Models are tools that need to be monitored and diagnosed, not anthropomorphized. This post should not be understood as a bash on the paper that originally inspired it, but rather as a call for more responsible and realistic interpretations of the findings in particular on social media."
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#patterns-in-latent-spaces-and-how-to-find-them",
    "href": "blog/posts/spurious-sparks/index.html#patterns-in-latent-spaces-and-how-to-find-them",
    "title": "Spurious Sparks of AGI",
    "section": "Patterns in Latent Spaces and How to Find Them",
    "text": "Patterns in Latent Spaces and How to Find Them\nTo support my claim that observing patterns in latent spaces should not generally surprise us, we will now go through a couple of simple examples. To illustrate further that this phenomenon is neither surprising nor unique to the field of Computer Science, I will draw on my background in Economics and Finance in this section. We will start with very simple examples to demonstrate that even small and simple models can learn meaningful representations of the data. The final example in Section¬†2.4 is a bit more involved and closer in spirit to the experiments conducted by Gurnee and Tegmark (2023). As we go along, we will try to discuss both the benefits and potential pitfalls of finding patterns in latent spaces.\n\nAre Neural Networks Born with World Models?\nBefore diving into the world of Economics, let‚Äôs start with a somewhat contrived and yet very illustrative example underpinning my point that patterns in latent spaces should not surprise us.\nGurnee and Tegmark (2023) extract and visualize the alleged geographical world model by training linear regression probes on internal activations in LLMs (including Llama-2) for the names of places, to predict geographical coordinates associated with these places. Now, the Llama-2 model has ingested huge amounts of publicly available data from the internet, including Wikipedia dumps from the June-August 2022 period (Touvron et al. 2023). It is therefore highly likely that the training data contains geographical coordinates, either directly or indirectly. At the very least, we should expect that the model has seen features during training that are highly correlated with geographical coordinates. The model itself is essentially a very large latent space to which all features are randomly projected in the very first instance before being passed through a series of layers which are gradually trained for its downstream task (next token prediction).\nIn our first example, we simulate this scenario, stopping short of training the model. In particular, we take the world_place.csv that was used in Gurnee and Tegmark (2023), which maps locations/areas to their latitude and longitude. For each place, it also indicates the corresponding country. From this, we take the subset that contains countries that are currently part of the top 10 FIFA world ranking, and assign the current rank to each country (i.e., Argentina gets 1, France gets 2, ‚Ä¶). To ensure that the training data only involves a noisy version of the coordinates, we transform the longitude and latitude data as follows: \\(\\rho \\cdot \\text{coord} + (1-\\rho) \\cdot \\epsilon\\) where \\(\\rho=0.5\\) and \\(\\epsilon \\sim \\mathcal{N}(0, 5)\\).\n\n\n\n\n\n\nCode\n\n\n\nIn the process of writing the paper, most of the code has been moved into scripts in a designated repository to ensure reproducibility. The code for this example can be found here.\n\n\nNext, we encode all features except the FIFA world rank indicator as continuous variables: \\(X^{(n \\times m)}\\) where \\(n\\) is the number of samples and \\(m\\) is the number of resulting features. Additionally, we add a large number of random features to \\(X\\) to simulate the fact that not all features ingested by Llama-2 are necessarily correlated with geographical coordinates. Let \\(d\\) denote the final number of features, i.e.~\\(d=m+k\\) where \\(k\\) is the number of random features.\nWe then initialize a small neural network, considered a projector, mapping from \\(X\\) to a single hidden layer with \\(h&lt;d\\) hidden units and sigmoid activation, and from there, to a lower-dimensional output space. Without performing any training on the projector, we simply compute a forward pass of \\(X\\) and retrieve activations \\(\\mathbf{Z}^{(n\\times h)}\\). Next, we perform the linear probe on a subset of \\(\\mathbf{Z}\\) through Ridge regression: \\(\\mathbf{W} = (\\mathbf{Z}_{\\text{train}}'\\mathbf{Z}_{\\text{train}} + \\lambda \\mathbf{I}) (\\mathbf{Z}_{\\text{train}}'\\textbf{coord})^{-1}\\), where \\(\\textbf{coord}\\) is the \\((n \\times 2)\\) matrix containing the longitude and latitude for each sample. A hold-out set is reserved for testing, on which we compute predicted coordinates for each sample as \\(\\widehat{\\textbf{coord}}=\\mathbf{Z}_{\\text{test}}\\mathbf{W}\\) and plot these on a world map (Figure¬†1).\n\nIf we can expect even random projections to contain useful representations, then should we really be surprised that a large language model, trained on a diverse set of data, contains representations that are useful for a wide range of tasks? ü§î\n\nWhile the fit certainly is not perfect, the results do indicate that the random projection contains representations that are useful for the task at hand. Thus, this simple example illustrates that meaningful target representations should be recoverable from a sufficiently large latent space, given the random projection of a small number of highly correlated features. Similarly, Alain and Bengio (2018) observe that even before training a convolutional neural network on MNIST data, the layer-wise activations can already be used to perform binary classification. In fact, it is well-known that random projections can be used for prediction tasks (Dasgupta 2013).\n\n\n\nFigure¬†1: Predicted coordinate values (out-of-sample) from a linear probe on final-layer activations of an untrained neural network.\n\n\n\n\nPCA as a Yield Curve Interpreter\nIn response to the claims made by Tegmark, numerous commentators on social media have pointed out that even the simplest of models can exhibit structure in their latent spaces. One of the most popular and illustrative examples I remember from my time at the Bank of England is yield curve decomposition through PCA. The yield curve is a popular tool for investors and economists to gauge the health of the economy. It plots the yields of bonds against their maturities. The slope of the yield curve is often used as a predictor of future economic activity: a steep yield curve is associated with a growing economy, while a flat or inverted yield curve is associated with a contracting economy.\nTo understand this better, let us go on a quick detour into economics and look at actual yield curves observed in the US during the Global Financial Crisis (GFC). Figure¬†2 (a) shows the yield curve of US Treasury bonds on 27 February 2007, which according to CNN was a ‚Äúbrutal day on Wall Street‚Äù.2 This followed reports on the previous day of former Federal Reserve Chairman Alan Greenspan‚Äôs warning that the US economy was at risk of a recession. The yield curve was inverted with a sharp negative spread between the 10-year and 3-month yields, indicative of the market‚Äôs expectation of a recession.\nFigure¬†2 (b) shows the corresponding yield curve during the aftermath of the GFC on 20 April 2009. On that day the influential Time Magazine reported that the ‚ÄúBanking Crisis is Over‚Äù. The yield curve was steeply sloped with a positive spread between the 10-year and 3-month yields, indicative of the market‚Äôs expectation of a recovery. The overall level of the yield curve was still very low though, indicative of the fact that US economy had not fully recovered at that point.\n\n\nCode\ndf = CSV.read(joinpath(BLOG_DIR, \"data/ust_yields.csv\"), DataFrame) |&gt;\n    x -&gt; @pivot_longer(x, -Date) |&gt;\n    x -&gt; @mutate(x, variable=to_year(variable)) |&gt;\n    x -&gt; @mutate(x, year=Dates.year(Date)) |&gt;\n    x -&gt; @mutate(x, quarter=Dates.quarter(Date)) |&gt;\n    x -&gt; @mutate(x, Date=Dates.format(Date, \"yyyy-mm-dd\")) |&gt;\n    x -&gt; @arrange(x, Date) |&gt;\n    x -&gt; @fill_missing(x, \"down\")\nylims = extrema(skipmissing(df.value))\n\n# Peak-crisis:\nonset_date = \"2007-02-27\"\nplt_df = df[df.Date .== onset_date, :]\nplt = plot(\n    plt_df.variable, plt_df.value;\n    label=\"\", color=:blue,\n    xlabel=\"Maturity (years)\", ylabel=\"Yield (%)\",\n    size=(380, 350)\n)\nscatter!(\n    plt_df.variable, plt_df.value;\n    label=\"\", color=:blue, alpha=0.5,\n    ylims=(0,6)\n)\ndisplay(plt)\n\n# Post-crisis:\naftermath_date = \"2009-04-20\"\nplt_df = df[df.Date .== aftermath_date, :]\nplt = plot(\n    plt_df.variable, plt_df.value;\n    label=\"\", color=:blue,\n    xlabel=\"Maturity (years)\", ylabel=\"Yield (%)\",\n    size=(380, 350)\n)\nscatter!(\n    plt_df.variable, plt_df.value;\n    label=\"\", color=:blue, alpha=0.5,\n    ylims=(0,6)\n)\ndisplay(plt)\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Onset of GFC: 27 February 2007.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Aftermath of GFC: 20 April 2009.\n\n\n\nFigure¬†2: Yield curve of US Treasury bonds.\n\n\n\nOf course, US Treasuries are not the only bonds that are traded in the market. To get a more complete picture of the economy, analysts might therefore be interested in looking at the yield curves of other bonds as well. In particular, we might be interested in predicting economic growth based on the yield curves of many different bonds. The problem with that idea is that it is cursed by high dimensionality: we would end up modelling a single variable of interest (economic growth) with a large number of predictors (the yields of many different bonds). To deal with the curse of high dimensionality it can be useful to decompose the yield curves into sets of principal components.\nTo compute the principal components we can decompose the matrix of yields \\(\\mathbf{Y}\\) into a product of its singular vectors and values: \\(\\mathbf{Y}=\\mathbf{U}\\Sigma\\mathbf{V}^{\\prime}\\). I will not go into the details here, because Professor Gilbert Strang has already done a much better job than I ever could in his Linear Algebra lectures. To put this into the broader context of the article, however, let us simply refer to \\(\\mathbf{U}\\), \\(\\Sigma\\) and \\(\\mathbf{V}^{\\prime}\\) as latent embeddings of the yield curve (they are latent because they are not directly observable).\nThe top panel in Figure¬†3 shows the first two principal components of the yield curves of US Treasury bonds over time. Vertical stalks indicate the key dates during the onset and aftermath of the crisis, which we discussed above. For both components, we can observe some marked shifts between the two dates - but can we attribute any meaning to these shifts? It turns out we can: for comparison, the bottom panel in Figure¬†3 shows the average level and spread of the yield curves over time. The first principal component is strongly correlated with the level of the yield curve, while the second principal component is strongly correlated with the spread of the yield curve.\n\n\nCode\n# PCA:\ndf_wide = @select(df, Date, variable, value) |&gt;\n    x -&gt; @pivot_wider(x, names_from = variable, values_from = value) |&gt;\n    x -&gt; dropmissing(x)\nX = @select(df_wide, -Date) |&gt; Matrix\nU, Œ£, V = svd(X)\n\n\n\n\n\nFigure¬†3: Comparison of latent embeddings and observed data of the US Treasury yield curve.\n\n\nNot convinced? Let us use \\(\\mathbf{Y}=\\mathbf{U}\\Sigma\\mathbf{V}^{\\prime}\\) in true autoencoder fashion to reconstruct yield curves from principal components. Let \\(z_1\\) denote the first principal component and consider the following: we keep all other \\(M-1\\) principal components fixed at zero where \\(M\\) denotes the total number of maturities; next we traverse the latent space by varying the value of \\(z_1\\) over a fixed grid of length \\(K\\) each time storing the full vector \\(\\mathbf{z}\\); finally, we vertically concatenate the vectors and end up with a matrix \\(\\mathbf{Z}\\) of dimension \\((K \\times M)\\). To reconstruct yields, we simply multiply \\(Z\\) by the singular values and right singular vectors: \\(\\mathbf{Y}=\\mathbf{Z}\\Sigma\\mathbf{V}^{\\prime}\\).\nFigure¬†4 shows the result of this exercise in the left panel. As we can see, our generated yield curves shift vertically as we traverse the latent space. The right panel of Figure¬†4 shows the result of a similar exercise, but this time we keep the first principal component fixed at zero and vary the second principal component. This time the slope of our generated yield curves shifts as we traverse the latent space.\n\n\nCode\nn_vals = 50\npc1_range = range(extrema(U[:,1])..., length=n_vals)\npc2_range = range(extrema(U[:,2])..., length=n_vals)\nZ_1 = [[pc1, 0, zeros(size(U, 2)-2)...] for pc1 in pc1_range] |&gt; x -&gt; reduce(vcat, x')\nY_1 = Z_1 * diagm(Œ£) * V'\nZ_2 = [[0, pc2, zeros(size(U, 2)-2)...] for pc2 in pc2_range] |&gt; x -&gt; reduce(vcat, x')\nY_2 = Z_2 * diagm(Œ£) * V'\nanim = @animate for i in 1:n_vals\n    # Level shifts:\n    y = Y_1[i,:]\n    p1 = plot(\n        unique(df.variable), y;\n        label=\"\", color=:blue,\n        xlabel=\"Maturity (years)\", ylabel=\"Yield (%)\",\n        title=\"PC1: $(round(collect(pc1_range)[i], digits=5))\",\n        ylims=extrema(Y_1)\n    )\n    scatter!(\n        unique(df.variable), y;\n        label=\"\", color=:blue, alpha=0.5,\n    )\n    # Spread shifts:\n    y = Y_2[i,:]\n    p2 = plot(\n        unique(df.variable), y;\n        label=\"\", color=:blue,\n        xlabel=\"Maturity (years)\", ylabel=\"Yield (%)\",\n        title=\"PC2: $(round(collect(pc2_range)[i], digits=5))\",\n        ylims=extrema(Y_2)\n    )\n    scatter!(\n        unique(df.variable), y;\n        label=\"\", color=:blue, alpha=0.5,\n    )\n    plot(p1, p2, layout=(1,2), size=(1000, 400), left_margin=5mm, bottom_margin=5mm)\nend\ngif(anim, joinpath(BLOG_DIR, \"results/figures/pc_anim.gif\"), fps=5)\n\n\n\n\n\nFigure¬†4: Yield curve decomposition through PCA.\n\n\n\n\nAutoencoders as Economic Growth Predictors\nSo far we have considered simple matrix decomposition. You might argue that principal components are not really latent embeddings in the traditional sense of deep learning. To address this, let us now consider a simple deep-learning example. Our goal will be to not only predict economic growth from the yield curve but also extract meaningful features at the same time. In particular, we will use a neural network architecture that allows us to recover a compressed latent representation of the yield curve.\n\nData\nTo estimate economic growth we will rely on a quarterly series of the real gross domestic product (GDP) provided by the Federal Reserve Bank of St.¬†Louis. The data arrives in terms of levels of real GDP. In order to estimate growth, we will transform the data into log differences. Since our yield curve data is daily, we will need to aggregate it to the quarterly frequency. To do this, we will simply take the average of the daily yields for each maturity. We will also standardize yields since deep learning models tend to perform better with standardized data. Since COVID-19 was a huge structural break, we will also filter out all observations after 2018. Figure¬†5 shows the pre-processed data.\n\n\nCode\ndf_gdp_full = CSV.read(joinpath(BLOG_DIR, \"data/gdp.csv\"), DataFrame) |&gt;\n    x -&gt; @rename(x, Date=DATE, gdp=GDPC1) |&gt;\n    x -&gt; @mutate(x, gdp_l1=lag(gdp)) |&gt;\n    x -&gt; @mutate(x, growth=log(gdp)-log(gdp_l1)) |&gt;\n    x -&gt; @select(x, Date, growth) |&gt;\n    x -&gt; @mutate(x, year=Dates.year(Date)) |&gt;\n    x -&gt; @mutate(x, quarter=Dates.quarter(Date)) \ndf_gdp = df_gdp_full |&gt;\n    x -&gt; @filter(x, year &lt;= 2018)\n\ndf_yields_qtr = @group_by(df, year, quarter, variable) |&gt;\n    x -&gt; @mutate(x, value=mean(value)) |&gt;\n    x -&gt; @ungroup(x) |&gt;\n    x -&gt; @select(x, -Date) |&gt;\n    unique\n\ndf_all = @inner_join(df_gdp, df_yields_qtr, (year, quarter)) |&gt; \n    x -&gt; @pivot_wider(x, names_from=variable, values_from=value) |&gt;\n    dropmissing\n\ny = df_all.growth |&gt; \n    x -&gt; Float32.(x)\nX = @select(df_all, -(Date:quarter)) |&gt; \n    Matrix |&gt;\n    x -&gt; Float32.(x) |&gt;\n    x -&gt; Flux.normalise(x; dims=1)\n\n# Plot:\np_gdp = plot(\n    df_all.Date, y;\n    label=\"\", color=:blue,\n    size=(800,200),\n    ylabel=\"GDP Growth (log difference)\"\n)\np_yields = plot(\n    df_all.Date, X;\n    label=\"\", color=:blue,\n    ylabel=\"Yield (standardized))\",\n    legend=:bottomright,\n    alpha=0.5,\n    size=(800,400)\n)\nplot(p_gdp, p_yields, layout=(2,1), size=(800, 600), left_margin=5mm)\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†5: GDP growth and yield curve data.\n\n\n\n\n\nModel\nUsing a simple autoencoder architecture (Figure¬†6), we let our model \\(g_t\\) denote growth and our conditional \\(\\mathbf{r}_t\\) the matrix of aggregated Treasury yield rates at time \\(t\\). Finally, we let \\(\\theta\\) denote our model parameters. Formally, we are interested in maximizing the likelihood \\(p_{\\theta}(g_t|\\mathbf{r}_t)\\).\nThe encoder consists of a single fully connected hidden layer with 32 neurons and a hyperbolic tangent activation function. The bottleneck layer connecting the encoder to the decoder, is a fully connected layer with 6 neurons. The decoder consists of two fully connected layers, each with a hyperbolic tangent activation function: the first layer consists of 32 neurons and the second layer will have the same dimension as the input data. The output layer consists of a single neuron for our output variable, \\(g_t\\). We train the model over 1,000 epochs to minimize mean squared error loss using the Adam optimizer~.\n\n\nCode\ndl = Flux.MLUtils.DataLoader((permutedims(X), permutedims(y)), batchsize=24, shuffle=true) \ninput_dim = size(X,2)\nn_pc = 6\nn_hidden = 32\nepochs = 1000\nactivation = tanh_fast\nencoder = Flux.Chain(\n    Dense(input_dim =&gt; n_hidden, activation),\n    Dense(n_hidden =&gt; n_pc, activation),\n) \ndecoder = Flux.Chain(\n    Dense(n_pc =&gt; n_hidden, activation),\n    Dense(n_hidden =&gt; input_dim, activation),\n) \nmodel = Flux.Chain(\n    encoder.layers...,\n    decoder.layers...,\n    Dense(input_dim, 1),\n) \nplt = plot(model, rand(input_dim))\ndisplay(plt)\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninput\n\n\nDense(12 =&gt; 32, tanh_fast)\n\n\nDense(32 =&gt; 6, tanh_fast)\n\n\nDense(6 =&gt; 32, tanh_fast)\n\n\nDense(32 =&gt; 12, tanh_fast)\n\n\nDense(12 =&gt; 1)\n\n\nFigure¬†6: Model architecture.\n\n\n\nThe in-sample fit of the model is shown in the left chart of Figure¬†7, which shows actual GDP growth and fitted values from the autoencoder model. The model has a large number of free parameters and captures the relationship between economic growth and the yield curve reasonably well, as expected. Since our primary goal is not out-of-sample prediction accuracy but feature extraction for inference, we use all of the available data instead of reserving a hold-out set. As discussed above, we also know that the relationship between economic growth and the yield curve is characterized by two main factors: the level and the spread. Since the model itself is fully characterized by its parameters, we would expect that these two important factors are reflected somewhere in the latent parameter space.\n\n\nLinear Probe\nWhile the loss function applies most direct pressure on layers near the final output layer, any information useful for the downstream task first needs to pass through the bottleneck layer (Alain and Bengio 2018). On a per-neuron basis, the pressure to distill useful representation is therefore likely maximized there. Consequently, the bottleneck layer activations seem like a natural place to start looking for compact, meaningful representations of distilled information. I compute and extract these activations \\(A_t\\) for all time periods \\(t=1,...,T\\). Next, we use a linear probe to regress the observed yield curve factors on the latent embeddings. Let \\(Y_t\\) denote the vector containing the two factors of interest in time \\(t\\): \\(y_{t,l}\\) and \\(y_{t,s}\\) for the level and spread, respectively. Formally, we are interested in the following regression model: \\(p_{w}(Y_t|A_t)\\) where \\(w\\) denotes the regression parameters. I use Ridge regression with \\(\\lambda\\) set to \\(0.1\\). Using the estimated regression parameters \\(\\hat{w}\\), we then predict the yield curve factors from the latent embeddings: \\(\\hat{Y}_t=\\hat{w}^{\\prime}A_t\\).\nThe in-sample predictions of the probe are shown in the right chart of Figure¬†7. Solid lines show the observed yield curve factors over time, while dashed lines show predicted values. We can observe that the latent embeddings predict the two yield curve factors reasonably well, in particular the spread.\n\n\n\nFigure¬†7: The left chart shows the actual GDP growth and fitted values from the autoencoder model. The right chart shows the observed average level and spread of the yield curve (solid) along with the predicted values (in-sample) from the linear probe based on the latent embeddings (dashed).\n\n\nDid the neural network now learn an intrinsic understanding of the economic relationship between growth and the yield curve? To me, that would be too big of a statement. Still, the current form of information distillation can be useful, even beyond its intended use for monitoring models.\n\n\nFor example, an interesting idea could be to use the latent embeddings as features in a more traditional and interpretable econometric model. To demonstrate this, let us consider a simple linear regression model for GDP growth. We might be interested in understanding to what degree economic growth in the past is associated with economic growth today. As we might expect, linearly regressing economic growth on lagged growth, as in column (1) of the table below, yields a statistically significant coefficient. However, this coefficient suffers from confounding bias since there are many other confounding variables at play, of which some may be readily observable and measurable, but others may not.\nI already mentioned the relationship between interest rates and economic growth. To account for that, while keeping our regression model as parsimonious as possible, we could include the level and the spread of the US Treasury yield curve as additional regressors. While this slightly changes the estimated magnitude of the coefficient on lagged growth, the coefficients on the observed level and spread are statistically insignificant (column (2) in the table). This indicates that these measures may be too crude to capture valuable information about the relationship between yields and economic growth. Because we have included two additional regressors with little to no predictive power, the model fit as measured by the Bayes Information Criterium (BIC) has actually deteriorated.\nColumn (3) of the table shows the effect of instead including one of the latent embeddings that we recovered above in the regression model. In particular, we pick the one latent embedding that we have found to exhibit the most significant effect on the output variable in a separate regression of growth on all latent embeddings. The estimated coefficient on this latent factor is small in magnitude, but statistically significant. The overall model fit, as measured by the BIC has improved and the magnitude of the coefficient on lagged growth has changed quite a bit. While this is still a very incomplete toy model of economic growth, it appears that the compact latent representation we recovered can be used in order to mitigate confounding bias.\n\n\n\nLLMs for Economic Sentiment Prediction\nTo round up this section, we will jump back on the hype train and consider an example involving an LLM. In particular, we will closely follow the approach in Gurnee and Tegmark (2023) and apply it to a novel financial dataset: the Trillion Dollar Words dataset introduced by Shah, Paturi, and Chava (2023). The dataset contains a curated selection of sentences formulated by central bankers of the US Federal Reserve and communicated to the public in speeches, meeting minutes and press conferences. The authors of the paper use this dataset to train LLMs to classify sentences as either ‚Äòdovish‚Äô, ‚Äòhawkish‚Äô or ‚Äòneutral‚Äô. To this end, they first manually annotate a subsample of the available data and then fine-tune various foundation models. Their model of choice, FOMC-RoBERTa (a fine-tuned version of RoBERTa (Liu et al. 2019)), achieves an \\(F_1\\) score of around \\(&gt;0.7\\) for the classification task. To illustrate the potential usefulness of the learned classifier, they use predicted labels for the entire dataset to compute an ad-hoc, count-based measure of ‚Äòhawkishness‚Äô. They then go on to show that this measure correlates with key economic indicators in the expected direction: when inflationary pressures rise, the measured level of ‚Äòhawkishness‚Äô increases as central bankers need to raise interest rates to bring inflation back to target.\n\nLinear Probes\nInstead of computing a measure based on predicted labels, we can use linear probes to assess if the fine-tuned model has learned associative patterns between central bank communications and key economic indicators. To this end, I have further pre-processed the data provided by Shah, Paturi, and Chava (2023) and used their proposed model to compute layer-wise embeddings for all available sentences. I have made these available and easily accessible through a small Julia package: TrillionDollarWords.jl. For each layer, I have then computed linear probes on two inflation indicators‚Äîthe Consumer Price Index (CPI) and the Producer Price Index (PPI)‚Äîas well as US Treasury yields at different levels of maturity. To mitigate issues related to over-parameterization, I follow the recommendation in Alain and Bengio (2018) to first reduce the dimensionality of the embeddings each time. In particular, linear probes are restricted to the first 128 principal components of the embeddings of each layer.\nFigure¬†8 shows the out-of-sample root mean squared error (RMSE) for the linear probe, plotted against FOMC-RoBERTa‚Äôs \\(n\\)-th layer. The values correspond to averages across cross-validation folds where I have used an expanding window scheme. Consistent with related work Gurnee and Tegmark (2023), we can observe that model performance tends to be higher for layers near the end of the transformer model. Curiously, for yields at longer maturities, we see that performance eventually deteriorates for the very final layers. This is not the case for the training data, so I would attribute this to overfitting. A detailed discussion of all our results including a benchmark of these probes against baseline autoregressive models can be found in the paper.\n\n\n\nFigure¬†8: Out-of-sample root mean squared error (RMSE) for the linear probe plotted against FOMC-RoBERTa‚Äôs \\(n\\)-th layer for different indicators. The values correspond to averages computed across cross-validation folds, where we have used an expanding window approach to split the time series.\n\n\n\n\nStochastic Parrots After All?\nThese results from the linear probe shown in Figure¬†8 are certainly not unimpressive: even though FOMC-RoBERTa was not explicitly trained to uncover associations between central bank communications and prices, it appears that the model has distilled representations that can be used to predict inflation and yields. It is worth pointing out here that this model is substantially smaller than the models tested in Gurnee and Tegmark (2023). This begs the following question:\n\nHave we uncovered further evidence that LLMs ‚Äúaren‚Äôt mere stochastic parrots‚Äù? Has FOMC-RoBERTa developed an intrinsic understanding of the economy just by ‚Äòreading‚Äô central bank communications?\n\nPersonally, I am having a very hard time believing this. To argue my case, I will now produce a counter-example demonstrating that, if anything, these findings are very much in line with the parrot metaphor. The counter-example is based on the following premise: if the results from the linear probe truly were indicative of some intrinsic understanding of the economy, then the probe should not be sensitive to random sentences that are most definitely not related to consumer prices.\nTo test this, I select the best-performing probe trained on the final-layer activations to predict changes in the CPI. I then make up sentences that fall into one of these four categories: Inflation/Prices (IP)‚Äîsentences about price inflation, Deflation/Prices (DP)‚Äîsentences about price deflation, Inflation/Birds (IB)‚Äîsentences about inflation in the number of birds and Deflation/Birds (DB)‚Äîsentences about deflation in the number of birds. A sensible sentence for category DP, for example, could be: ‚ÄúIt is essential to bring inflation back to target to avoid drifting into deflation territory.‚Äù. Analogically, we could construct the following sentence for the DB category: ‚ÄúIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.‚Äù.\nIn light of the encouraging results for the probe in Figure¬†8, we should expect the probe to predict higher levels of inflation for activations for sentences in the IP category than for sentences in the DP category. If this was indicative of true intrinsic understanding, we would not expect to see any significant difference in predicted inflation levels for sentences about birds, independent of whether or not their numbers are increasing. More specifically, we would not expect the probe to predict values for sentences about birds that are substantially different from the values it can be expected to predict when using actual white noise as inputs.\nTo get to this last point, I also generate many probe predictions for samples of noise. Let \\(f: \\mathcal{A}^k \\mapsto \\mathcal{Y}\\) denote the linear probe that maps from the \\(k\\)-dimensional space spanned by \\(k\\) first principal components of the final-layer activations to the output variable of interest (CPI growth in this case). Then I sample \\(\\varepsilon_i \\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}^{(k \\times k)})\\) for \\(i \\in [1,1000]\\) and compute the sample average. I repeat this process \\(10000\\) times and compute the median-of-means to get an estimate for \\(\\mathbb{E}[f(\\varepsilon)]=\\mathbb{E}[y|\\varepsilon]\\), that is the predicted value of the probe conditional on white noise.\nNext, I propose the following hypothesis test as a minimum viable testing framework to assess if the probe results (may) provide evidence for an actual understanding of key economic relationships learned purely from text:\n\nProposition 1 (Parrot Test) ¬†\n\nH0 (Null): The probe never predicts values that are statistically significantly different from \\(\\mathbb{E}[f(\\varepsilon)]\\).\nH1 (Stochastic Parrots): The probe predicts values that are statistically significantly different from \\(\\mathbb{E}[f(\\varepsilon)]\\) for sentences related to the outcome of interest and those that are independent (i.e.¬†sentences in all categories).\nH2 (More than Mere Stochastic Parrots): The probe predicts values that are statistically significantly different from \\(\\mathbb{E} [f(\\varepsilon)]\\) for sentences that are related to the outcome variable (IP and DP), but not for sentences that are independent of the outcome (IB and DB).\n\n\nTo be clear, if in such a test we did find substantial evidence in favour of rejecting both HO and H1, this would not automatically imply that H2 is true. But to even continue investigating if based on having learned meaningful representation the underlying LLM is more than just a parrot, it should be able to pass this simple test.\nIn this particular case, Figure¬†9 demonstrates that we find some evidence to reject H0 but not H1 for FOMC-RoBERTa. The median linear probe predictions for sentences about inflation and deflation are indeed substantially higher and lower, respectively than for random noise. Unfortunately, the same is true for sentences about the inflation and deflation in the number of birds, albeit to a somewhat lower degree.\nI should note that the number of sentences in each category is very small here (10), so the results in Figure¬†9 cannot be used to establish statistical significance. That being said, even a handful of convincing counter-examples should be enough for us to seriously question the claim that results from linear probes provide evidence against the parrot metaphor. In fact, even a handful of sentences for which any human annotator would easily arrive at the conclusion of independence, a prediction by the probe in either direction casts doubt.\n\n\n\nFigure¬†9: Probe predictions for sentences about inflation of prices (IP), deflation of prices (DP), inflation of birds (IB) and deflation of birds (DB). The vertical axis shows predicted inflation levels subtracted by the average predicted value of the probe for random noise."
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#conclusion",
    "href": "blog/posts/spurious-sparks/index.html#conclusion",
    "title": "Spurious Sparks of AGI",
    "section": "Conclusion",
    "text": "Conclusion\nLinear probes and related tools from mechanistic interpretability were proposed in the context of monitoring models and diagnosing potential problems Alain and Bengio (2018). Favorable outcomes from probes merely indicate that the model ‚Äúhas learned information relevant for the property [of interest]‚Äù Belinkov (2021). The examples shown here demonstrate that this is achievable even for small models, while these have certainly not developed an intrinsic ‚Äúunderstanding‚Äù of the world. Thus, my co-authors and I argue that more conservative and rigorous tests for emerging capabilities of AI model are needed.\nI want to conclude this blog post just as we conclude in our paper:\n\n‚ÄúWe as academic researchers carry great responsibility for how the narrative will unfold, and what claims are believed. We call upon our colleagues to be explicitly mindful of this. As attractive as it may be to beat the state-of-the-art with a grander claim, let us return to the Mertonian norms, and thus safeguard our academic legitimacy in a world that only will be eager to run with made claims.‚Äù\n‚Äî Altmeyer et al. (2024)"
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#acknowledgements",
    "href": "blog/posts/spurious-sparks/index.html#acknowledgements",
    "title": "Spurious Sparks of AGI",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nA huge thank you to my co-authors Andrew M. Demetriou, Antony Bartlett and Cynthia C. S. Liem who are also my colleagues at TU Delft and (in the case of Cynthia) my supervisor. It‚Äôs been a real pleasure working with you on this project."
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#footnotes",
    "href": "blog/posts/spurious-sparks/index.html#footnotes",
    "title": "Spurious Sparks of AGI",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI would be very surprised‚Äîconcerned even‚Äîif our search for patterns in latent spaces of capable LLMs revealed nothing at all.‚Ü©Ô∏é\nThe data is taken from the US Department of the Treasury.‚Ü©Ô∏é"
  }
]