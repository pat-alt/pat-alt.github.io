[
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#motivation",
    "href": "content/talks/posts/2024-econdat/presentation.html#motivation",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Motivation",
    "text": "Motivation\n\n\n\n\\(A_1\\): â€It is essential to bring inflation back to target to avoid drifting into deflation territory.â€œ\n\\(A_2\\): â€It is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.â€œ\n\n\nâ€œTheyâ€™re exactly the same.â€\nâ€” Linear probe \\(\\widehat{cpi}=f(A)\\)"
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#position",
    "href": "content/talks/posts/2024-econdat/presentation.html#position",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Position",
    "text": "Position\n\nCurrent LLMs embed knowledge. They donâ€˜t â€understandâ€œ anything. They are useful tools, but tools nonetheless.\n\n\n\nMeaningful patterns in embeddings are like doves in the sky.\nHumans are prone to seek patterns and anthropomorphize.\nObserved â€˜sparksâ€™ of Artificial General Intelligence are spurious.\nThe academic community should exercise extra caution.\nPublishing incentives need to be adjusted."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#outline",
    "href": "content/talks/posts/2024-econdat/presentation.html#outline",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Outline",
    "text": "Outline\n\n\nExperiments: We probe models of varying complexity including random projections, matrix decompositions, deep autoencoders and transformers.\n\nAll of them successfully distill knowledge and yet none of them develop true understanding.\n\nSocial sciences review: Humans are prone to seek patterns and anthropomorphize.\nConclusion and outlook: More caution at the individual level, and different incentives at the institutional level."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#the-holy-grail",
    "href": "content/talks/posts/2024-econdat/presentation.html#the-holy-grail",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "The Holy Grail",
    "text": "The Holy Grail\nAchievement of Artificial General Intelligence (AGI) has become a grand challenge, and in some cases, an explicit business goal.\n\n\nDefinition\nThe definition of AGI itself is not as clear-cut or consistent:\n\n(loosely) a phenomenon contrasting with â€˜narrow AIâ€™ systems, that were trained for specific tasks (Goertzel 2014).\n\n\nPractice\nResearchers have sought to show that AI models generalize to different (and possibly unseen) tasks or show performance considered â€˜surprisingâ€™ to humans.\n\nFor example, Google DeepMind claimed their AlphaGeometry model (Trinh et al. 2024) reached a â€˜milestoneâ€™ towards AGI."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#a-perfect-storm",
    "href": "content/talks/posts/2024-econdat/presentation.html#a-perfect-storm",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "A Perfect Storm",
    "text": "A Perfect Storm\nRecent developments in the field have created a â€˜perfect stormâ€™ for inflated claims:\n\n\nEarly sharing of preprints and code.\nVolume of publishable work has exploded.\nSocial media influencers start playing a role in article discovery and citeability (Weissburg et al. 2024).\nComplexity is increasing because it is incentivized (Birhane et al. 2022)."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#not-mere-stochastic-parrots",
    "href": "content/talks/posts/2024-econdat/presentation.html#not-mere-stochastic-parrots",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "â€œNot Mere Stochastic Parrotsâ€",
    "text": "â€œNot Mere Stochastic Parrotsâ€\n\nWe consider a recently viral work (Gurnee and Tegmark 2023a), in which claims about the learning of world models by LLMs were made.\n\nLinear probes (ridge regression) were successfully used to predict geographical locations from LLM embeddings.\n\nClaims on X that this indicates that LLMs are not mere â€˜stochastic parrotsâ€™ (Bender et al. 2021).\nReactions on X seemed to largely exhibit excitement and surprise at the authorsâ€™ findings."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#are-neural-networks-born-with-world-models",
    "href": "content/talks/posts/2024-econdat/presentation.html#are-neural-networks-born-with-world-models",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Are Neural Networks Born with World Models?",
    "text": "Are Neural Networks Born with World Models?\n\n\n\nLlama-2 model tested in Gurnee and Tegmark (2023b) has ingested huge amounts of publicly available data (Touvron et al. 2023).\n\nGeographical locations are literally in the training data: e.g.Â Wikipedia article for â€œLondonâ€.\nWhere would this information be encoded if not in the embedding space \\(\\mathcal{A}\\)? Is it surprising that \\(A_{\\text{LDN}}=enc(\\text{\"London\"}) \\not\\!\\perp\\!\\!\\!\\perp (\\text{lat}_{\\text{LDN}},\\text{long}_{\\text{LDN}})\\)?\n\nFigureÂ 1 shows the predicted coordinates of a linear probe on the final-layer activations of an untrained neural network.\n\n\n\n\n\n\n\n\nFigureÂ 1: Predicted coordinate values (out-of-sample) from a linear probe on final-layer activations of an untrained neural network.\n\n\n\n\nModel has seen noisy coordinates plus \\(d\\) random features.\nSingle hidden layer with \\(h &lt; d\\) hidden units."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#pca-as-a-yield-curve-interpreter",
    "href": "content/talks/posts/2024-econdat/presentation.html#pca-as-a-yield-curve-interpreter",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "PCA as a Yield Curve Interpreter",
    "text": "PCA as a Yield Curve Interpreter\nWhat are principal components if not model embeddings?\n\n\n\n\n\n\nFigureÂ 2: Top chart: The first two principal components of US Treasury yields over time at daily frequency. Bottom chart: Observed average level and 10yr-3mo spread of the yield curve. Vertical stalks roughly indicate the onset (|GFC) and the beginning of the aftermath (GFC|) of the Global Financial Crisis."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#embedding-fomc-comms",
    "href": "content/talks/posts/2024-econdat/presentation.html#embedding-fomc-comms",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Embedding FOMC comms",
    "text": "Embedding FOMC comms\n\nBERT-based model trained on FOMC minutes, speeches and press conferences to classify statements as hawkish or dovish (or neutral) (Shah, Paturi, and Chava 2023).\nWe linearly probe all layers to predict unseen economic indicators (CPI, PPI, UST yields).\nPredictive power increases with layer depth and probes outperform simple AR(\\(p\\)) models.\n\n\n\n\n\n\n\nFigureÂ 3: Out-of-sample root mean squared error (RMSE) for the linear probe plotted against FOMC-RoBERTaâ€™s n-th layer for different indicators."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#sparks-of-economic-understanding",
    "href": "content/talks/posts/2024-econdat/presentation.html#sparks-of-economic-understanding",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Sparks of Economic Understanding?",
    "text": "Sparks of Economic Understanding?\nPremise: If probe results were indicative of some intrinsic â€˜understandingâ€™ of the economy, then the probe should not be sensitive to random sentences unrelated to economics.\nParrot Test\n\nSelect the best-performing probe for each economic indicator.\nPredict inflation levels for real (related) and perturbed (unrelated) sentences.\n\n\n\n\n\n\n\nFigureÂ 4: Probe predictions for sentences about inflation of prices (IP), deflation of prices (DP), inflation of birds (IB) and deflation of birds (DB). The vertical axis shows predicted inflation levels subtracted by the average predicted value of the probe for random noise.\n\n\n\nAs evidenced by FigureÂ 4, the probe is easily fooled."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#spurious-relationships",
    "href": "content/talks/posts/2024-econdat/presentation.html#spurious-relationships",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Spurious Relationships",
    "text": "Spurious Relationships\nDefiniton: Varies somewhat (Haig 2003) but distinctly implies that the observation of correlations does not imply causation.\n\nHumans struggle to tell the difference between random and non-random sequences (Falk and Konold 1997).\nLack of expectation that randomness that hints towards a causal relationship will still appear at random.\nEven experts perceive correlations of inflated magnitude (Nickerson 1998) and causal relationships where none exist (Zgraggen et al. 2018)."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#antropomorphism",
    "href": "content/talks/posts/2024-econdat/presentation.html#antropomorphism",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Antropomorphism",
    "text": "Antropomorphism\nDefinition: Human tendency to attribute human-like characteristics to non-human agents and/or objects.\n\nExperience as humans is an always-readily-available template to interpret the world (Epley, Waytz, and Cacioppo 2007).\nMotivation to avoid loneliness may lead us to anthropomorphize inanimate objects Waytz, Epley, and Cacioppo (2010).\nMotivation to be competent may lead us anthropomorphize opaque technologies like LLMs Waytz, Epley, and Cacioppo (2010)"
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#confirmation-bias",
    "href": "content/talks/posts/2024-econdat/presentation.html#confirmation-bias",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Confirmation Bias",
    "text": "Confirmation Bias\nDefinition: Favoring interpretations of evidence that support existing beliefs or hypotheses (Nickerson 1998).\n\nHypotheses in present-day AI research are often implicit, often framed simply as a system being more accurate or efficient, compared to other systems.\n\nFailing to articulate a sufficiently strong null hypothesis leading to a â€˜weakâ€™ experiment (Claesen et al. 2022).\n\nIndividuals may place greater emphasis on evidence in support of their hypothesis, and lesser emphasis on evidence that opposes it (Nickerson 1998)."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#conclusion-and-outlook",
    "href": "content/talks/posts/2024-econdat/presentation.html#conclusion-and-outlook",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Conclusion and Outlook",
    "text": "Conclusion and Outlook\n\nWe call for the community to create explicit room for organized skepticism\n\nWelcome negative results\nEncouraging replication studies.\nMove from authorship to contribution-based credit (see e.g.Â Liem and Demetriou, 2023 and Smith, 1997).\n\nReturn to the Mertonian norms (communism, universalism, disinterestedness, organized skepticism) (Merton et al. 1942)."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#references",
    "href": "content/talks/posts/2024-econdat/presentation.html#references",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "References",
    "text": "References\n\n\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. â€œOn the dangers of stochastic parrots: Can language models be too big? .â€ In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 610â€“23.\n\n\nBirhane, Abeba, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit Dotan, and Michelle Bao. 2022. â€œThe Values Encoded in Machine Learning Research.â€ In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT â€™22).\n\n\nClaesen, Aline, Daniel Lakens, Noah van Dongen, et al. 2022. â€œSeverity and Crises in Science: Are We Getting It Right When Weâ€™re Right and Wrong When Weâ€™re Wrong?â€\n\n\nEpley, Nicholas, Adam Waytz, and John T Cacioppo. 2007. â€œOn seeing human: a three-factor theory of anthropomorphism.â€ Psychological Review 114 (4): 864.\n\n\nFalk, Ruma, and Clifford Konold. 1997. â€œMaking sense of randomness: Implicit encoding as a basis for judgment.â€ Psychological Review 104 (2): 301.\n\n\nGoertzel, Ben. 2014. â€œArtificial general intelligence: concept, state of the art, and future prospects.â€ Journal of Artificial General Intelligence 5 (1): 1.\n\n\nGurnee, Wes, and Max Tegmark. 2023b. â€œLanguage Models Represent Space and Time.â€ arXiv Preprint arXiv:2310.02207v2.\n\n\nâ€”â€”â€”. 2023a. â€œLanguage Models Represent Space and Time.â€ arXiv Preprint arXiv:2310.02207v1.\n\n\nHaig, Brian D. 2003. â€œWhat is a spurious correlation?â€ Understanding Statistics: Statistical Issues in Psychology, Education, and the Social Sciences 2 (2): 125â€“32.\n\n\nMerton, Robert K et al. 1942. â€œScience and technology in a democratic order.â€ Journal of Legal and Political Sociology 1 (1): 115â€“26.\n\n\nNickerson, Raymond S. 1998. â€œConfirmation bias: A ubiquitous phenomenon in many guises.â€ Review of General Psychology 2 (2): 175â€“220.\n\n\nShah, Agam, Suvan Paturi, and Sudheer Chava. 2023. â€œTrillion Dollar Words: A New Financial Dataset, Task & Market Analysis.â€ arXiv Preprint arXiv:2310.02207v1. https://arxiv.org/abs/2305.07972.\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, et al. 2023. â€œLLaMA: Open and Efficient Foundation Language Models.â€ https://arxiv.org/abs/2302.13971.\n\n\nTrinh, T. H., Wu, Y., Le, and Q. V. et al. 2024. â€œSolving olympiad geometry without human demonstrations.â€ Nature 625, 476â€“82. https://doi.org/https://doi.org/10.1038/s41586-023-06747-5.\n\n\nWaytz, Adam, Nicholas Epley, and John T Cacioppo. 2010. â€œSocial cognition unbound: Insights into anthropomorphism and dehumanization.â€ Current Directions in Psychological Science 19 (1): 58â€“62.\n\n\nWeissburg, Iain Xie, Mehir Arora, Liangming Pan, and William Yang Wang. 2024. â€œTweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility.â€ arXiv Preprint arXiv:2401.13782.\n\n\nZgraggen, Emanuel, Zheguang Zhao, Robert Zeleznik, and Tim Kraska. 2018. â€œInvestigating the effect of the multiple comparisons problem in visual analysis.â€ In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, 1â€“12."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#image-sources",
    "href": "content/talks/posts/2024-econdat/presentation.html#image-sources",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Image sources",
    "text": "Image sources\n\nLeonardo DiCaprio: Meme template by user on Reddit\nTarot cards: Photo by Viva Luna Studios on Unsplash\nWall-E: Photo by ray rui on Unsplash"
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#autoencoders-as-economic-growth-predictors",
    "href": "content/talks/posts/2024-econdat/presentation.html#autoencoders-as-economic-growth-predictors",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Autoencoders as Economic Growth Predictors",
    "text": "Autoencoders as Economic Growth Predictors\n\nWe train a neural network with a bottleneck layer to predict GDP growth from the yield curve.\nThis can be used for feature extraction and forecasting.\n\nBottle-neck layer embeddings predict spread and level of the yield curve.\n\n\n\n\n\n\n\n\nFigureÂ 5: The left chart shows the actual GDP growth and fitted values from the autoencoder model. The right chart shows the observed average level and spread of the yield curve (solid) along with the predicted values (in-sample) from the linear probe based on the latent embeddings (dashed)"
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#quote-sources",
    "href": "content/talks/posts/2024-econdat/presentation.html#quote-sources",
    "title": "Against Spurious Sparks âˆ’ Dovelating Inflated AI Claims ğŸ•Šï¸",
    "section": "Quote sources",
    "text": "Quote sources\n\nâ€œThere! Itâ€™s sentientâ€â€”that engineer at Google (probably!)\nâ€œThe human mind is a pattern-seeking deviceâ€â€”Daniel Kahneman\nâ€œWeâ€™re fascinated with robots because they are reflections of ourselves.â€â€”Ken Goldberg"
  }
]