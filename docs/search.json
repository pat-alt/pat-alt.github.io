[
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Welcome to my blog",
    "section": "",
    "text": "Below you can find a list of all my blog posts. I mostly blog about my research and open source projects."
  },
  {
    "objectID": "blog/index.html#posts",
    "href": "blog/index.html#posts",
    "title": "Welcome to my blog",
    "section": "Posts",
    "text": "Posts"
  },
  {
    "objectID": "blog/posts/meta-programming/index.html",
    "href": "blog/posts/meta-programming/index.html",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "",
    "text": "A leap of faith into Julia‚Äôs metaverse.\nOn this blog, I typically talk about things that I have some understanding of. In this post, I want to try something a little different and instead cover a topic that I am utterly clueless about. There‚Äôs an interesting aspect about Julia, which I know embarrassingly little about at this point: Metaprogramming.\nHaving worked with Julia for about 1.5 years now, I have so far employed a successful strategy of occasionally taking a glimpse at that part of the Julia documentation and then deciding to go back to pretending it never existed. Meanwhile, Karandeep Singh has stepped on the Julia scence around 5 minutes ago and already developed a package that literally oozes macro: Tidier.jl. The package API is such a joy to work with that I have felt inspired to finally take a serious look at what metaprogramming is all about.\nMy goal for this post is to get to the point where I can confidently write my first macro for CounterfactualExplanations.jl - more on this below! If you are as clueless and curious about the topic as I am, then follow along on a journey into the metaverse. Buckle in though, it‚Äôs going to be a bumpy ride! You have been warned."
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#all-right-where-to-start",
    "href": "blog/posts/meta-programming/index.html#all-right-where-to-start",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "ü§î All right, where to start?",
    "text": "ü§î All right, where to start?\nYou guessed it, we‚Äôll start with the official Julia documentation on the topic:\n\nLike Lisp, Julia represents its own code as a data structure of the language itself.\n\nHmmm ‚Ä¶ I know nothing about Lisp and this is already beyond me. Code as a data structure?\nLet‚Äôs first try to understand what exactly metaprogramming is, outside of Julia and Lisp. We‚Äôll take a quick detour before we‚Äôre back. Wikipedia has the following to say on the topic:\n\nMetaprogramming is a programming technique in which computer programs have the ability to treat other programs as their data.\n\nRight ‚Ä¶ What about ChatGPT? I wanted to try out ReplGPT anyway so here goes1:\njulia&gt; using ReplGPT\nChatGPT&gt; Hey hey, can you please explain metaprogramming to me (I have no computer science background, but am experienced with programming and data science)\n  Metaprogramming is a programming technique where a program is capable of creating or manipulating code at\n  runtime. It involves writing computer programs that create, modify, or analyze other computer programs or data\n  about those programs.\nSo, in layman‚Äôs terms, metaprogramming involves code that generates code - I guess we really have entered the metaverse!"
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#julia-docs",
    "href": "blog/posts/meta-programming/index.html#julia-docs",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "üìñ Julia docs",
    "text": "üìñ Julia docs\nLet‚Äôs head back to the Julia documentation (v1.8) and look at the first couple of examples.\n\nCode as Data Structures\nSkipping the details here, it turns out that when I write 1 + 1 in the REPL, Julia first parses this program as a string \"1 + 1 into an expression ex=:(1 + 1)::Expr, which is then evaluated eval(ex) (Figure¬†1). I‚Äôve used a quote here to generate the expression because I‚Äôve used quoting before for use with Documenter.jl.\n\n\n\n\n\n\nFigure¬†1: Key concept: code as a data structure.\n\n\n\nAnd if I understand this correctly, the expression ex::Expr is literally code as a data structure:\n\n\nCode\nex = :(sum([1,2,3]))\ndump(ex)\n\n\nExpr\n  head: Symbol call\n  args: Array{Any}((2,))\n    1: Symbol sum\n    2: Expr\n      head: Symbol vect\n      args: Array{Any}((3,))\n        1: Int64 1\n        2: Int64 2\n        3: Int64 3\n\n\nThat data structure can be ‚Äúmanipulated from within the language‚Äù.\nLet‚Äôs try that! Currently, evaluating this expression yields the sum of the Array:\n\n\nCode\neval(ex)\n\n\n6\n\n\nUpon manipulation (that sounds weird!), we have:\n\n\nCode\nex.args[1] = :maximum\neval(ex)\n\n\n3\n\n\nOk ok, things are starting to make sense now!\n\n\nInterpolation\nBack to the Julia documentation and next on the agenda we have Interpolation. Skipping the details again, it seems like I can interpolate an expression much like strings. Using interpolation I can recreate the expression from above as follows:\n\n\nCode\nfun = maximum\nx = [1,2,3]\nex_from_ex_interpoliation = :($fun($x))\na = eval(ex_from_ex_interpoliation)\n\n\nUsing string interpolation is quite similar:\n\n\nCode\nfun = maximum\nx = [1,2,3]\nex_from_string_interpolation = Meta.parse(\"$fun($x)\")\neval(ex_from_string_interpolation) == a\n\n\ntrue\n\n\nAnd much like with function arguments, we can also use splatting:\n\n\nCode\neval(:(zeros($x...)))\n\n\n1√ó2√ó3 Array{Float64, 3}:\n[:, :, 1] =\n 0.0  0.0\n\n[:, :, 2] =\n 0.0  0.0\n\n[:, :, 3] =\n 0.0  0.0\n\n\nNext off, we have nested quotes. I can‚Äôt see myself using these anytime soon but anyway it seems that for each $ sign that we prepend to x, an evaluation is trigged:\n\n\nCode\neval(quote quote $$:(x) end end)\n\n\nquote\n    #= /Users/paltmeyer/code/pat-alt.github.io/blog/posts/meta-programming/index.qmd:167 =#\n    [1, 2, 3]\nend\n\n\nMoving on, we have QuoteNodes, which I will steer clear of because I probably won‚Äôt be doing any super advanced metaprogramming anytime soon. The next two sections on evaluating expressions and functions on Expressions also look somewhat more involved than what I need right now, but I expect I‚Äôll find myself back here when I write that first macro for CounterfactualExplanations.jl.\n\n\nMacros\nAhhh, I see we‚Äôve finally arrived in Macroland!\n\nA macro maps a tuple of arguments to a returned expression, and the resulting expression is compiled directly rather than requiring a runtime eval call.\n\n\n\n\nArrived in Macroland.\n\n\nLet‚Äôs see if we can make sense of this as we move on. The Hello, world! example makes the concept quite clear:\n\n\nCode\nmacro sayhello(name)\n    return :( println(\"Hello, \", $name) )   # return the expression ...\nend\n@sayhello \"reader\"                          # ... to be immediately compiled.\n\n\nHello, reader\n\n\nIt seems that a macro is a way to build and return expressions inside a block (a bit like a function) but on call that expression is immediately evaluated. In other words, we can use macros to write code that generates code that is then evaluated.\nTo fully grasp the next part, I should have not skipped the part on functions on Expressions. We‚Äôll leave that little nugget for Future Me. That same guy will also have to suffer the consequences of Present Me merely skimming the details in the next section on macro invocation. Present Me is impatient and overly confident in the level of knowledge that we have just acquired about metaprogramming.\nLet‚Äôs get ahead of ourselves and meet the final boss of the metaverse: an Advanced Macro."
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#build-an-advanced-macro",
    "href": "blog/posts/meta-programming/index.html#build-an-advanced-macro",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "üî• BUILD AN ADVANCED MACRO",
    "text": "üî• BUILD AN ADVANCED MACRO\nI‚Äôll leave it to you to thoroughly read that section in the Julia docs. Here, we‚Äôll jump straight into building the macro I want to have for CounterfactualExplanations.jl. I now think it‚Äôll be less involved than I thought ‚Äî optimism in the face of uncertainty!\n\n\n\nAdvanced Macro: the final boss.\n\n\n\nFrom Off-the-Shelf Counterfactual Generators ‚Ä¶\nCounterfactualExplanations.jl is a package for generating Counterfactual Explanations for predictive models \\(f: \\mathcal{X} \\mapsto \\mathcal{Y}\\). This is a relatively recent approach to Explainable AI that I am (probably a little too) excited about and won‚Äôt dwell on here. For what follows, it suffices to say that generating Counterfactual Explanations can be seen as a generative modelling task because it involves generating samples in the input space: \\(x \\sim \\mathcal{X}\\). To this end, the package has previously shipped with a number of Generators: composite types that contain information about how counterfactuals ought to be generated.\nThis has allowed users to specify the type of generator they want to use by instantiating it. For example, the DiCE generator by Mothilal, Sharma, and Tan (2020) could (and still can) be instantiated as follows:\n\n\nCode\ngenerator = DiCEGenerator()\n\n\nThis has been a straightforward way for users to use off-the-shelf counterfactual generators. But relying on separate composite types for this task may have been an overkill. In fact, all this time there was some untapped potential here, as we will see next.\n\n\n‚Ä¶ To Composable Generators\nOne of my key objectives for the package has always been composability. It turns out that many of the various counterfactual generators that have been proposed in the literature, essentially do the same thing: they optimize an objective function. In Altmeyer et al. (2023), we denote that objective formally as follows,\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\left\\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)}+ \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\right\\}\n\\end{aligned}\n\\tag{1}\\]\nwhere \\(\\text{yloss}\\) denotes the main loss function and \\(\\text{cost}\\) is a penalty term. I won‚Äôt cover this in any more detail here, but you can read about it in the package docs. The important thing is that Equation¬†1 very closely describes how counterfactual search is actually implemented in the package.\nIn other words, all generators currently implemented share a common starting point. They largely just vary in the exact way the objective function is specified. This gives rise to an interesting idea:\n\nWhy not compose generators that combine ideas from different off-the-shelf generators?\n\nI want to give users an easy way to do that, without having to build custom Generator types from scratch. This (I think) is a good use case for metaprogramming.\nLet‚Äôs try and see if we can make that work. We‚Äôll simply extend CounterfactualExplanations right here in this repo hosting the blog (easily done in Julia) and provided everything works out well create a pull request. I already have a GitHub issue for this with a linked branch, so that‚Äôs the one I‚Äôll use in my environment:\n(metaprogramming) pkg&gt; add https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl#118-add-losses-and-penalties-modules-or-group-under-objectives-module\njulia&gt; using CounterfactualExplanations\nBy the time you‚Äôre reading this, all changes to that branch will have hopefully already been committed and merged.\nLet‚Äôs start by instantiating a generic generator:\n\n\nCode\ngenerator = GenericGenerator()\n\n\nOur goal is to create macros that build expressions that, when evaluated, mutate the generator instance.\n\n\nDefine your @objective\nOur first and most important macro shall define the counterfactual search objective. In particular, the @objective macro should accept an expression that looks much like the right-hand-side of Equation¬†1, which is essentially just a weighted sum.\n\n\n\nSketch of the envisioned @objective macro.\n\n\nLet‚Äôs start with that part. Naively, we could begin by writing it out very literally:\nex = :(yloss + Œª*cost)\neval(ex)\nOf course, evaluating this expression throws an error because none of the variables are actually defined. Let‚Äôs work on that ‚Ä¶\nFor the loss and penalty functions, we will use methods available from the CounterfactualExplanations.Objectives module, while for \\(\\lambda\\) we will use a literal:\n\n\nCode\nex = :(logitbinarycrossentropy + 0.1 * distance_l2)\n\n\nLet‚Äôs try to make sense of the data structure we have created:\n\n\nCode\nex.args\n\n\n3-element Vector{Any}:\n :+\n :logitbinarycrossentropy\n :(0.1distance_l2)\n\n\nMy first naive approach is shown below. It errors because I forgot to interpolate the variables inside the quote.\nmacro objective(generator, ex)\n    loss = ex.args[2]\n    ex_penalty = ex.args[3]\n    Œª = ex_penalty.args[2]\n    cost = ex_penalty.args[3]\n    ex_generator = quote \n        generator.loss = loss\n        generator.cost = cost\n        generator.Œª = Œª\n    end\n    return ex_generator\nend\nHaving fixed that below, I still get an error because loss and cost functions are not part of the global scope. I am pretty sure that this error would have occurred anyway and has nothing to do with the fact that I‚Äôm writing a macro.\nmacro objective(generator, ex)\n    loss = ex.args[2]\n    ex_penalty = ex.args[3]\n    Œª = ex_penalty.args[2]\n    cost = ex_penalty.args[3]\n    ex_generator = quote \n        $generator.loss = $loss\n        $generator.cost = $cost\n        $generator.Œª = $Œª\n    end\n    return ex_generator\nend\nInstead of importing the functions, I just get them explicitly from the Objectives module,\n\n\nCode\nmacro objective(generator, ex)\n    loss = getfield(CounterfactualExplanations.Objectives, ex.args[2])\n    ex_penalty = ex.args[3]\n    Œª = ex_penalty.args[2]\n    cost = getfield(CounterfactualExplanations.Objectives, ex_penalty.args[3])\n    ex_generator = quote \n        $generator.loss = $loss\n        $generator.penalty = $cost\n        $generator.Œª = $Œª\n        generator\n    end\n    return ex_generator\nend\n\n\nand, finally, this works:\n\n\nCode\n@objective(generator, logitbinarycrossentropy + 0.1distance_l2)\n\n\nCounterfactualExplanations.Generators.GradientBasedGenerator(Flux.Losses.logitbinarycrossentropy, CounterfactualExplanations.Objectives.distance_l2, 0.1, false, false, Flux.Optimise.Descent(0.1), NamedTuple())\n\n\nBut what about adding multiple penalties? The DiCE generator, for example, also takes into account how diverse the counterfactual explanations are (Mothilal, Sharma, and Tan 2020). The corresponding penalty is called ddp_diversity. Let‚Äôs start with the expression again:\n\n\nCode\nex = :(logitbinarycrossentropy + 0.1distance_l2 + 1.0ddp_diversity)\nex.args\n\n\n4-element Vector{Any}:\n :+\n :logitbinarycrossentropy\n :(0.1distance_l2)\n :(1.0ddp_diversity)\n\n\n\n\nThis time there's a second nested Expression among the arguments: :(1.0ddp_diversity).\n\n\n\n\n\nCode\nmacro objective(generator, ex)\n    loss = getfield(CounterfactualExplanations.Objectives, ex.args[2])\n    Œõ = Vector{AbstractFloat}()\n    costs = Vector{Function}()\n    for i in 3:length(ex.args)\n        ex_penalty = ex.args[i]\n        Œª = ex_penalty.args[2]\n        push!(Œõ, Œª)\n        cost = getfield(CounterfactualExplanations.Objectives, ex_penalty.args[3])\n        push!(costs, cost)\n    end\n    ex_generator = quote \n        $generator.loss = $loss\n        $generator.penalty = $costs\n        $generator.Œª = $Œõ\n        generator\n    end\n    return ex_generator\nend\n\n\nThat works well,\n\n\nCode\n@objective(generator, logitbinarycrossentropy + 0.05distance_l2 + 1.0ddp_diversity)\n\n\nCounterfactualExplanations.Generators.GradientBasedGenerator(Flux.Losses.logitbinarycrossentropy, Function[CounterfactualExplanations.Objectives.distance_l2, CounterfactualExplanations.Objectives.ddp_diversity], AbstractFloat[0.05, 1.0], false, false, Flux.Optimise.Descent(0.1), NamedTuple())\n\n\nbut we should still make sure that this generator is also compatible with our package. Below we go through some of the typical workflows associated with Counterfactual Explanations. Firstly, we load some synthetic data and fit a black-box model to it.\n\n\nCode\nusing CounterfactualExplanations.Models: fit_model\nn_dim = 2\nn_classes = 4\nn_samples = 400\nmodel_name = :MLP\ncounterfactual_data = TaijaData.load_blobs(n_samples; k=n_dim, centers=n_classes) |&gt;\n    data -&gt; CounterfactualData(data...)\nM = fit_model(counterfactual_data, model_name)\nplot(M, counterfactual_data)\n\n\nNext, we begin by specifying our target and factual label. We then draw a random sample from the non-target (factual) class.\n\n\nCode\n# Factual and target:\ntarget = 2\nfactual = 4\nchosen = rand(findall(predict_label(M, counterfactual_data) .== factual))\nx = select_factual(counterfactual_data,chosen)\n\n\nFinally, we use our generator to generate counterfactuals:\n\n\nCode\nusing CounterfactualExplanations.Convergence\nce = generate_counterfactual(\n    x, target, counterfactual_data, M, generator;\n    num_counterfactuals = 5,\n    convergence = GeneratorConditionsConvergence()\n)\n\n\nIt worked! üéâ The resulting counterfactual search is illustrated in Figure¬†2. I may have overspecified the size of the ddp_diversity penalty a little bit here, but it sure makes for a cool chart!\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: Counterfactual search using our composed generator.\n\n\n\n\nTime for me to add this all to CounterfactualExplanations.jl ‚Ä¶ ‚è≥"
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#hygiene",
    "href": "blog/posts/meta-programming/index.html#hygiene",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "üßº Hygiene",
    "text": "üßº Hygiene\n‚Ä¶ aaand I‚Äôm back. There was one thing I had ignored that ended up causing a minor complication: macro hygiene.\nAgain, I‚Äôll leave it to you to read up on the details, but the bottom line is that when writing macros, we need to keep variable scopes in mind. CounterfactualExplanations.jl is composed of various (sub)modules, and when I initially added the macro to the CounterfactualExplanations.Generators module, it errored.\nThe problem was (I believe) that the generator variable existed in the global scope (Main) but it was not accessible for the @objective macro that at runtime lives in Main.Generators. Fortunately, it is easy to make the variable accessible by wrapping it inside an esc() call:\n\nThis escaping mechanism can be used to ‚Äúviolate‚Äù hygiene when necessary, in order to introduce or manipulate user variables.\n\nThis may not be the ideal way to do this, and as always, if you have any suggestions I‚Äôd be happy to hear about them.\nIf you want to find out more about how macros can now be used to easily compose counterfactual generators, check out the new section in the package documentation."
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#wrapping-up",
    "href": "blog/posts/meta-programming/index.html#wrapping-up",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "üåØ Wrapping Up",
    "text": "üåØ Wrapping Up\nIn this blog post, I‚Äôve done something I usually try to avoid: talk about things I don‚Äôt know. Metaprogramming is an exciting topic and if you‚Äôre still here, you just got to experience it through the lens of an absolute novice. During our leap of faith into Julia‚Äôs metaverse we‚Äôve learned the following things:\n\nCode in Julia is internally represented as a mutable data structure.\nMacros are a way to take such data structures and transform them before they get evaluated at runtime.\nAn important thing to keep in mind when writing macros is variable scopes.\n\nThroughout this post, I have skipped various important details that (I think) were not immediately relevant to the goal I had in mind: adding my first macro to CounterfactualExplanations.jl. In the future, I may write about this topic again and cover some of these missing details (hopefully with a bit more insight at that point!)."
  },
  {
    "objectID": "blog/posts/meta-programming/index.html#footnotes",
    "href": "blog/posts/meta-programming/index.html#footnotes",
    "title": "A Leap of Faith into Julia‚Äôs Metaverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA very cool package! Funny story, though, I somehow managed to commit my OpenAI API key to GitHub on the first go (developing)‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/eccco/index.html",
    "href": "blog/posts/eccco/index.html",
    "title": "ECCCos from the Black Box",
    "section": "",
    "text": "Counterfactual explanations offer an intuitive and straightforward way to explain opaque machine learning (ML) models. They work under the premise of perturbing inputs to achieve a desired change in the predicted output. There are typically many ways to achieve this, in other words, many different counterfactuals may yield the same desired outcome. A key challenge for researchers has therefore been to, firstly, define certain desirable characteristics of counterfactual explanations and, secondly, come up with efficient ways to achieve them.\nOne of the most important and studied characteristics of counterfactual explanations is ‚Äòplausibility‚Äô: explanations should look realistic to humans. Plausibility is positively associated with actionability, robustness (Artelt et al. 2021) and causal validity (Mahajan, Tan, and Sharma 2020). To achieve plausibility, many existing approaches rely on surrogate models. This is straightforward but it also convolutes things further: it essentially reallocates the task of learning plausible explanations for the data from the model itself to the surrogate.\nIn our AAAI 2024 paper, Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals (ECCCo), we propose that we should not only look for explanations that please us but rather focus on generating counterfactuals that faithfully explain model behavior. It turns out that we can achieve both faithfulness and plausibility by relying solely on the model itself, leveraging recent advances in energy-based modelling and conformal prediction. We support this claim through extensive empirical studies and believe that ECCCo opens avenues for researchers and practitioners seeking tools to better distinguish trustworthy from unreliable models."
  },
  {
    "objectID": "blog/posts/eccco/index.html#sec-poison",
    "href": "blog/posts/eccco/index.html#sec-poison",
    "title": "ECCCos from the Black Box",
    "section": "Pick your Poison",
    "text": "Pick your Poison\nThere are two main philosophical debates in the field of Explainable AI (XAI). The first one centers around the role of explainability in AI: do we even need explanations and if so, why? Some have argued that we need not care about explaining models as long as they produce reliable outcomes (Robbins 2019). Humans have not shied away from this in other domains either: doctors, for example, have prescribed aspirin for decades without understanding why it is a reliable drug for pain relief (London 2019). While this reasoning may rightfully apply in some cases, experiments conducted by my colleagues at TU Delft have shown that humans do not make better decisions if aided by a reliable and yet opaque model (He, Buijsman, and Gadiraju 2023). In these studies, subjects tended to ignore the AI model indicating that they did not trust its decisions. Beyond this, explainability comes with numerous advantages such as accountability, control, contestability and the potential for uncovering causal relationships.\n\n\n\n\n\n\nIntermezzo: Why Bother?\n\n\n\nIf we can blindly rely on the decisions made by an AI, why should we even bother to come up with explanations? I must confess I had never even seriously considered this as an option until attending Stefan Buijsman‚Äôs recent talk at a Delft Design for Values workshop, which inspired the previous paragraph. As a philosopher and AI ethicist at TU Delft, some of Stefan‚Äôs most recent research investigates causal human-in-the-loop explanations for AI models (Biswas et al. 2022). I do not think that he adheres to the view that we should simply trust AI models blindly. In fact, he and his colleagues have shown that most humans do not tend to simply trust AI models even if they have been assured about their reliability (He, Buijsman, and Gadiraju 2023).\nStill, the question of why we even bother is an interesting challenge, especially considering that the field of XAI has so far struggled to produce satisfactory and robust results with meaningful real-world impact. Numerous studies related to He, Buijsman, and Gadiraju (2023) have shown that explanations for AI models either fail to help users or even mislead them (Mittelstadt, Russell, and Wachter 2019; Alufaisan et al. 2021; Lakkaraju and Bastani 2020). It seems that neither blind trust nor explanations are a silver bullet.\nSo, have our efforts toward explainable AI been in vain? Should we simply stop explaining black-box models altogether as proposed by Rudin (2019)? Having worked in this field for a little over 2 years now, I have personally grown more and more skeptical of certain trends I have observed. In particular, I think that the community has focused too much on finding explanations that please us independent of the model itself (ideally model-agnostic, really!). This is a bit like applying a band-aid to a wound without first cleaning it. At best, plausible explanations for untrustworthy models provide a false sense of security. At worst, they can be used to manipulate and deceive. The AAAI paper presented in this post is very much born out of skepticism about this trend.\nNonetheless, I do not think all hope is lost for XAI. I strongly believe that there is a need for algorithmic recourse as long as we continue to deploy black-box models for automated decision-making. While I am fully supportive of the idea that we should always strive to use models that are as interpretable as possible (Rudin 2019), I also think that there are cases where this is not feasible or it is simply too convenient to use a black-box model instead. The aspirin example mentioned above is a striking example of this. But it is easy enough to stretch that example further to illustrate why explainability is important. What if the use of aspirin was prohibited for a small minority of people and there was a reliable, opaque model to decide who belonged to that group? If you were part of that group, would you not want to know why? Why should you have to endure headaches for the rest of your life while others do not?\nIn summary, I think that‚Äîlike it or not‚Äîwe do need to bother.\n\n\nThe second major debate is about what constitutes a good explanation, because, crucially, explanations are not unique: was your headache cured by the aspirin you took before going to sleep or sleep itself? Or a combination of both? This multiplicity of explanations arises almost naturally in the context of counterfactual explanations. Unless the combination of input features for which the model predicts the target class or value is unique, there is always more than one possible explanation. As an illustrative example, consider the counterfactuals presented in Figure¬†1. All of these are valid explanations for turning a ‚Äònine‚Äô into ‚Äòseven‚Äô according to the underlying classifier (a simple multi-layer perceptron). They are all valid in the sense the model predicts the target label with high probability in each case. The troubling part is that even though all of the generated counterfactuals provide valid explanations for why the model predicts ‚Äòseven‚Äô instead of ‚Äònine‚Äô, they all look very different.\n\n\n\n\n\n\nFigure¬†1: Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using Wachter (Wachter, Mittelstadt, and Russell 2017), Schut (Schut et al. 2021) and REVISE (Joshi et al. 2019).\n\n\n\nSo, which explanations do we trust most? Which one would you choose to present to an audience to explain how the classifier decides which digit to predict? Arguably, the counterfactual on the far right looks most like a ‚Äòseven‚Äô, so I am willing to bet that most people would simply choose that one. It is valid after all and it looks plausible, while the other two counterfactuals might just lead to awkward questions from more interrogative audience members. In any case, I mentioned earlier that more plausible explanations tend to also be more actionable and robust, so this seems fair game. The counterfactual produced by REVISE (Joshi et al. 2019) is the poison we will pick‚Äîdump the rest and move on. Plausibility is all we need!2\nI am exaggerating but I do think that as a community of researchers studying counterfactual explanations, we have become so absorbed by the pursuit of a few desiderata that we have forgotten that ultimately we are in the business of explaining models. Our primary mandate is to design tools that help us understand why models predict certain outcomes. How useful is a plausible, actionable, sparse, causally valid explanation in gaining that understanding, if there exist a whole bunch of other valid explanations that do not meet these desiderata? Have we significantly improved our understanding of the underlying classifier in Figure¬†1 and therefore established a higher degree of trust in the model, simply because we have found a plausible counterfactual?\nIn my mind, we most certainly have not. I would argue that the existence of a valid and plausible explanation merely serves to reassure us that the model is not entirely ignorant about meaningful representations in the data. But as long as entirely implausible counterfactuals are also valid according to the model, selectively relying only on the subset of plausible counterfactuals may lead to a wrong sense of trust in untrustworthy models. That is why in our paper we argue that explanations should be faithful first, and plausible second."
  },
  {
    "objectID": "blog/posts/eccco/index.html#faithful-first-plausible-second",
    "href": "blog/posts/eccco/index.html#faithful-first-plausible-second",
    "title": "ECCCos from the Black Box",
    "section": "Faithful First, Plausible Second",
    "text": "Faithful First, Plausible Second\nTo navigate the interplay between faithfulness and plausibility, we propose a way to generate counterfactuals that are consistent with what the model has learned about the data. In doing so, we can also achieve plausibility but only in case the model has learned something meaningful.\n\nFaithful Counterfactuals\nWhen inquiring about what is ‚Äúconsistent with what the model has learned about the data‚Äù, we are essentially asking about the model‚Äôs posterior conditional distribution of the input data given the target output. It turns out that we can approximate that distribution using ideas relevant to energy-based modelling. In particular, we can use something called Stochastic Gradient Langevin Dynamics (SGLD) to sample from the model‚Äôs posterior conditional distribution (Welling and Teh 2011).\nWithout going into too much detail here, the idea is to use the model‚Äôs energy function to guide the sampling process. The energy function is a scalar function that assigns a value to each possible configuration of the input data. The lower the energy, the higher the likelihood corresponding to the configuration. This is a powerful tool: Grathwohl et al. (2020), for example, use SGLD in this fashion to train hybrid models‚Äîjoint-energy models (JEM)‚Äîthat are trained to both classify and generate data.\nFigure¬†2 illustrates this concept. It shows samples (yellow stars) drawn from the posterior of a simple JEM trained on linearly separable data. The contour shows the kernel density estimate (KDE) for the learned conditional distribution. Although it seems that the posterior is too sharp in this case, the learned conditional distribution is overall consistent with the data (at least the mode is).\n\n\n\n\n\n\n\n\nFigure¬†2: Kernel Density Estimate (KDE) for the learned conditional distribution. Yellow stars indicate samples generated through Stochastic Gradient Langevin Dynamics for a joint energy model (JEM).\n\n\n\nAlso shown in Figure¬†2 is a single counterfactual path from the orange to the blue class. I have relied on the baseline approach proposed in Wachter, Mittelstadt, and Russell (2017) here using only a small penalty for the distance between the counterfactual and the original input. A truly faithful counterfactual, as we define it in our paper, would be one that we could expect to sample from the learned conditional distribution (with high probability)3. Based on this notion, we would not characterize the counterfactual in Figure¬†2 as faithful, but it also is not too far off.\nIt is easy to see how other desiderata may conflict with faithfulness. If I had penalized the distance between the counterfactual and the original input more, for example, then the counterfactual would have been less costly but also less faithful. This is the sort of trade-off between different desiderata that we always need to navigate carefully in the context of counterfactual explanations. As we will see next, the same also applies to plausibility but in a different way.\n\n\nPlausible Counterfactuals\nIf you have followed the discussion so far, then you have already understood the trickiest concept in our paper. Plausibility can be defined much like we have done for faithfulness, but it is a bit more straightforward. In our paper, we broadly define plausible counterfactals as those that are indistinguishable from the observed data in the target domain. We already touched on this above when discussing the counterfactual images in Figure¬†1.\n\n\n\n\n\n\n\n\nFigure¬†3: KDE for the conditional distribution based on observed data. Counterfactual path as in Figure¬†2.\n\n\n\nFigure¬†3 illustrates the same concept for the same JEM as in Figure¬†2. The KDE in Figure¬†3 shows the conditional distribution based on the observed data. The counterfactual path is the same as in Figure¬†2. The counterfactual is plausible in this case since it is not easily distinguishable from the observed data in the target domain.\nLooking at both Figure¬†2 and Figure¬†3, it becomes evident why the interplay between faithfulness and plausibility need not necessary be a trade-off. In this case, the counterfactual is neither terribly unfaithful nor implausible. This is because the learned conditional distribution is broadly consistent with the observed distribution of the data."
  },
  {
    "objectID": "blog/posts/eccco/index.html#our-approach-eccco",
    "href": "blog/posts/eccco/index.html#our-approach-eccco",
    "title": "ECCCos from the Black Box",
    "section": "Our approach: ECCCo",
    "text": "Our approach: ECCCo\nNow that we have covered the two major concepts in our paper, we can move on to our proposed approach for generating faithful counterfactuals: ECCCo. As the title of the paper suggests, ECCCo is an acronym for Energy-Constrained Conformal Counterfactuals. We leverage ideas from energy-based modelling and conformal prediction, in particular from Grathwohl et al. (2020) and Stutz et al. (2022), respectively. Our proposed counterfactual generation process involves little to no overhead and is broadly applicable to any model that can be trained using stochastic gradient descent. Technical details can be found in the paper. For now, let us focus on the high-level idea.\nFigure¬†4 compares the counterfactual path generated by Wachter (Wachter, Mittelstadt, and Russell 2017) to those generated by ECCCo, where we use ablation to remove the energy constraint‚ÄîECCCo (no EBM)‚Äîand the conformal prediction component‚ÄîECCCo (no CP). In this case, the counterfactual generated by Wachter is neither faithful nor plausible. It does, however, minimize the distance between the counterfactual and the original input.\nThe counterfactual generated by ECCCo (no EBM) is deeper inside the blue class and has avoided points near the decision boundary on its path to its final destination. This is because ECCCo (no EBM) involves a penalty term for predictive uncertainty, which is high near the decision boundary. Intuitively, we would expect that avoiding regions of high predictive uncertainty in our counterfactual search should help with plausibility (Schut et al. 2021). In this particular case, the final counterfactual is neither more faithful nor more plausible than the one generated by Wachter, but in our experiments we have generally found that penalizing predictive uncertainty alone can help to generate more faithful and plausible counterfactuals.\nThe counterfactual generated by ECCCo (no CP) is more faithful than the one generated by Wachter and ECCCo (no EBM). This is because the energy constraint induces counterfactuals that are more consistent with the learned conditional distribution (as in Figure¬†2). Since the model has learned something meaningful about the data, the counterfactual is also more plausible than the one generated by Wachter and ECCCo (no EBM) in this case.\nThe counterfactual path generated by ECCCo combines benefits from both the energy constraint and the conformal prediction component. It avoids regions of high predictive uncertainty and ends up at a point that is consistent with the learned conditional distribution.\n\n\n\n\n\n\nFigure¬†4: Gradient fields and counterfactual paths for different generators."
  },
  {
    "objectID": "blog/posts/eccco/index.html#results",
    "href": "blog/posts/eccco/index.html#results",
    "title": "ECCCos from the Black Box",
    "section": "Results",
    "text": "Results\nIn the paper, we present results from extensive empirical studies involving eight datasets from different domains and a variety of models. We compare ECCCo to state-of-the-art counterfactual generators and show that it consistently outperforms these in terms of faithfulness and often achieves the highest degrees of plausibility. Here we will highlight some visual results from the MNIST dataset.\nFigure¬†5 shows counterfactuals generated using different counterfactual generators on the MNIST dataset. In this example, the goal is to generate a counterfactual in class ‚Äòfive‚Äô for the factual ‚Äòthree‚Äô. The ECCCo+ generator is a variant of ECCCo that performs gradient search in the space spanned by the first few principal components. This reduces computational costs and often helps with plausibility, sometimes at a small cost of faithfulness. The counterfactuals generated by ECCCo and ECCCo+ are visibly more plausible than those generated by the other generators. In the paper, we quantify this using custom metrics for plausibility and faithfulness that we propose.\n\n\n\n\n\n\nFigure¬†5: Results for different generators (from 3 to 5).\n\n\n\nWe also find that the counterfactuals generated by ECCCo are more faithful in this case. The underlying model is a LeNet-5 convolutional neural network (LeCun et al. 1998). Even today, convolutional neural networks are still among the most popular neural network architectures for image classification. Contrary to the simple multi-layer perceptron (MLP) used in Figure¬†1, the LeNet-5 model is a bit more complex and it is not surprising that it has distilled more meaningful representations in the data.\nMore generally, we find that ECCCo is particularly effective at producing plausible counterfactuals for models that we would expect to have learned more meaningful representations of the data. This is consistent with our claim that ECCCo generates faithful counterfactuals. Figure¬†5 shows the results for applying ECCCo to the same factual ‚Äònine‚Äô as in Figure¬†1 for different models from left to right and top to bottom: (a) an MLP, (b) a deep ensemble of MLPs, (c) a JEM, and, (d) a deep ensemble of JEMs. The plausibility of the generated counterfactual gradually improves from left to right and top to bottom as we get more rigorous about model complexity and training: deep ensembling can help to capture predictive uncertainty and joint-energy modelling is explicitly concerned with learning meaningful representations in the data.\n\n\n\n\n\n\n\n\nFigure¬†6: Turning a 9 into a 7. ECCCo applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).\n\n\n\nWe would argue that in general, this is a desirable property of a counterfactual explainer, because it helps to distinguish trustworthy from unreliable models. The generated counterfactual for the MLP in (a) in Figure¬†6 is grainy and altogether not very plausible. But this is precisely because the MLP is not very trustworthy: it is sensitive to input perturbations that are not meaningful. We think that explanations should reflect these kinds of shortcomings of models instead of hiding them."
  },
  {
    "objectID": "blog/posts/eccco/index.html#conclusion",
    "href": "blog/posts/eccco/index.html#conclusion",
    "title": "ECCCos from the Black Box",
    "section": "Conclusion",
    "text": "Conclusion\nThis post has provided a brief and accessible overview of our AAAI 2024 paper that introduces ECCCo: a new way to generate faithful model explanations through energy-constrained conformal counterfactuals. The post has covered some of the main points from the paper:\n\nWe have argued that explanations should be faithful first, and plausible second.\nWe show that ECCCo consistently outperforms state-of-the-art counterfactual generators in terms of faithfulness and often achieves the highest degrees of plausibility.\nWe believe that ECCCo opens avenues for researchers and practitioners seeking tools to better distinguish trustworthy from unreliable models."
  },
  {
    "objectID": "blog/posts/eccco/index.html#software",
    "href": "blog/posts/eccco/index.html#software",
    "title": "ECCCos from the Black Box",
    "section": "Software",
    "text": "Software\nThe code for the experiments in the paper is available on GitHub: https://github.com/pat-alt/ECCCo.jl. The repo contains job scripts for running the experiments on a SLURM cluster, as well as the source code for the ECCCo package. The package is written in Julia and built on top of CounterfactualExplanations.jl, which will eventually absorb the functionality of ECCCo."
  },
  {
    "objectID": "blog/posts/eccco/index.html#footnotes",
    "href": "blog/posts/eccco/index.html#footnotes",
    "title": "ECCCos from the Black Box",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBesides my co-authors, I also want to thank the anonymous reviewers at both NeurIPS and AAAI for their valuable feedback as well as Nico Potyka and Francesco Leofante for interesting discussions on the topic.‚Ü©Ô∏é\nConsidering how much I have cited Joshi et al. (2019) in the past, I think it should go without saying that I very much like this paper, despite taking a critical stance on it here.‚Ü©Ô∏é\nI have had an interesting chat with Nico Potyka and Francesco Leofante, recently, where they rightly pointed out that this definition of faithfulness needs to be refined. In particular, one might wonder what constitutes a ‚Äòhigh probability‚Äô in this context. I think this is a very valid point and I am looking forward to discussing this further with them.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html",
    "href": "blog/posts/bayesian-logit/index.html",
    "title": "Bayesian Logistic Regression",
    "section": "",
    "text": "Simulation of changing parameter distribution.\n\n\n\nIf you‚Äôve ever searched for evaluation metrics to assess model accuracy, chances are that you found many different options to choose from (too many?). Accuracy is in some sense the holy grail of prediction so it‚Äôs not at all surprising that the machine learning community spends a lot time thinking about it. In a world where more and more high-stake decisions are being automated, model accuracy is in fact a very valid concern.\nBut does this recipe for model evaluation seem like a sound and complete approach to automated decision-making? Haven‚Äôt we forgot anything? Some would argue that we need to pay more attention to model uncertainty. No matter how many times you have cross-validated your model, the loss metric that it is being optimized against as well as its parameters and predictions remain inherently random variables. Focusing merely on prediction accuracy and ignoring uncertainty altogether can install a false level of confidence in automated decision-making systems. Any trustworthy approach to learning from data should therefore at the very least be transparent about its own uncertainty.\nHow can we estimate uncertainty around model parameters and predictions? Frequentist methods for uncertainty quantification generally involve either closed-form solutions based on asymptotic theory or bootstrapping (see for example here for the case of logistic regression). In Bayesian statistics and machine learning we are instead concerned with modelling the posterior distribution over model parameters. This approach to uncertainty quantification is known as Bayesian Inference because we treat model parameters in a Bayesian way: we make assumptions about their distribution based on prior knowledge or beliefs and update these beliefs in light of new evidence. The frequentist approach avoids the need for being explicit about prior beliefs, which in the past has sometimes been considered as unscientific. However, frequentist methods come with their own assumptions and pitfalls (see for example Murphy (2012)) for a discussion). Without diving further into this argument, let us now see how Bayesian Logistic Regression can be implemented from the bottom up."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#uncertainty",
    "href": "blog/posts/bayesian-logit/index.html#uncertainty",
    "title": "Bayesian Logistic Regression",
    "section": "",
    "text": "Simulation of changing parameter distribution.\n\n\n\nIf you‚Äôve ever searched for evaluation metrics to assess model accuracy, chances are that you found many different options to choose from (too many?). Accuracy is in some sense the holy grail of prediction so it‚Äôs not at all surprising that the machine learning community spends a lot time thinking about it. In a world where more and more high-stake decisions are being automated, model accuracy is in fact a very valid concern.\nBut does this recipe for model evaluation seem like a sound and complete approach to automated decision-making? Haven‚Äôt we forgot anything? Some would argue that we need to pay more attention to model uncertainty. No matter how many times you have cross-validated your model, the loss metric that it is being optimized against as well as its parameters and predictions remain inherently random variables. Focusing merely on prediction accuracy and ignoring uncertainty altogether can install a false level of confidence in automated decision-making systems. Any trustworthy approach to learning from data should therefore at the very least be transparent about its own uncertainty.\nHow can we estimate uncertainty around model parameters and predictions? Frequentist methods for uncertainty quantification generally involve either closed-form solutions based on asymptotic theory or bootstrapping (see for example here for the case of logistic regression). In Bayesian statistics and machine learning we are instead concerned with modelling the posterior distribution over model parameters. This approach to uncertainty quantification is known as Bayesian Inference because we treat model parameters in a Bayesian way: we make assumptions about their distribution based on prior knowledge or beliefs and update these beliefs in light of new evidence. The frequentist approach avoids the need for being explicit about prior beliefs, which in the past has sometimes been considered as unscientific. However, frequentist methods come with their own assumptions and pitfalls (see for example Murphy (2012)) for a discussion). Without diving further into this argument, let us now see how Bayesian Logistic Regression can be implemented from the bottom up."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#the-ground-truth",
    "href": "blog/posts/bayesian-logit/index.html#the-ground-truth",
    "title": "Bayesian Logistic Regression",
    "section": "The ground truth",
    "text": "The ground truth\nIn this post we will work with a synthetic toy data set \\(\\mathcal{D}\\) composed of \\(N\\) binary labels \\(y_n\\in\\{0,1\\}\\) and corresponding feature vectors \\(\\mathbf{x}_n\\in \\mathbb{R}^D\\). Working with synthetic data has the benefit that we have control over the ground truth that generates our data. In particular, we will assume that the binary labels \\(y_n\\) are generated by a logistic regression model\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& p(y_n|\\mathbf{x}_n;\\mathbf{w})&\\sim\\text{Ber}(y_n|\\sigma(\\mathbf{w}^T\\mathbf{x}_n)) \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{1}\\]\nwhere \\(\\sigma(a)=1/(1+e^{-a})\\) is the sigmoid or logit function (Murphy 2022).1 Features are generated from a mixed Gaussian model.\nTo add a little bit of life to our example we will assume that the binary labels classify samples into cats and dogs, based on their height and tail length. Figure¬†1 shows the synthetic data in the two-dimensional feature domain. Following an introduction to Bayesian Logistic Regression in the next section we will use the synthetic data \\(\\mathcal{D}\\) to estimate our model.\n\n\n\n\n\n\n\n\nFigure¬†1: Ground truth labels."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#the-maths",
    "href": "blog/posts/bayesian-logit/index.html#the-maths",
    "title": "Bayesian Logistic Regression",
    "section": "The maths",
    "text": "The maths\nEstimation usually boils down to finding the vector of parameters \\(\\hat{\\mathbf{w}}\\) that maximizes the likelihood of observing \\(\\mathcal{D}\\) under the assumed model. That estimate can then be used to compute predictions for some new unlabelled data set \\(\\mathcal{D}=\\{x_m:m=1,...,M\\}\\).\n\nProblem setup\nThe starting point for Bayesian Logistic Regression is Bayes‚Äô Theorem:\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& p(\\mathbf{w}|\\mathcal{D})&\\propto p(\\mathcal{D}|\\mathbf{w})p(\\mathbf{w}) \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{2}\\]\nFormally, this says that the posterior distribution of parameters \\(\\mathbf{w}\\) is proportional to the product of the likelihood of observing \\(\\mathcal{D}\\) given \\(\\mathbf{w}\\) and the prior density of \\(\\mathbf{w}\\). Applied to our context this can intuitively be understood as follows: our posterior beliefs around \\(\\mathbf{w}\\) are formed by both our prior beliefs and the evidence we observe. Yet another way to look at this is that maximising Equation¬†2 with respect to \\(\\mathbf{w}\\) corresponds to maximum likelihood estimation regularized by prior beliefs (we will come back to this).\nUnder the assumption that individual label-feature pairs are independently and identically distributed, their joint likelihood is simply the product over their individual densities. The prior beliefs around \\(\\mathbf{w}\\) are at our discretion. In practice they may be derived from previous experiments. Here we will use a zero-mean spherical Gaussian prior for reasons explained further below. To sum this up we have\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& p(\\mathcal{D}|\\mathbf{w})& \\sim \\prod_{n=1}^N p(y_n|\\mathbf{x}_n;\\mathbf{w})\\\\\n&& p(\\mathbf{w})& \\sim \\mathcal{N} \\left( \\mathbf{w} | \\mathbf{w}_0, \\Sigma_0 \\right) \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{3}\\]\nwith \\(\\mathbf{w}_0=\\mathbf{0}\\) and \\(\\Sigma_0=\\sigma^2\\mathbf{I}\\). Plugging this into Bayes‚Äô rule we finally have\n\\[\n\\begin{aligned}\n&& p(\\mathbf{w}|\\mathcal{D})&\\propto\\prod_{n=1}^N \\text{Ber}(y_n|\\sigma(\\mathbf{w}^T\\mathbf{x}_n))\\mathcal{N} \\left( \\mathbf{w} | \\mathbf{w}_0, \\Sigma_0 \\right) \\\\\n\\end{aligned}\n\\]\nUnlike with linear regression there are no closed-form analytical solutions to estimating or maximising this posterior, but fortunately accurate approximations do exist (Murphy 2022). One of the simplest approaches called Laplace Approximation is straight-forward to implement and computationally very efficient. It relies on the observation that under the assumption of a Gaussian prior, the posterior of logistic regression is also approximately Gaussian: in particular, this Gaussian distribution is centered around the maximum a posteriori (MAP) estimate \\(\\hat{\\mathbf{w}}=\\arg\\max_{\\mathbf{w}} p(\\mathbf{w}|\\mathcal{D})\\) with a covariance matrix equal to the inverse Hessian evaluated at the mode \\(\\hat{\\Sigma}=(\\mathbf{H}(\\hat{\\mathbf{w}}))^{-1}\\). With that in mind, finding \\(\\hat{\\mathbf{w}}\\) seems like a natural next step.\n\n\nSolving the problem\nIn practice we do not maximize the posterior \\(p(\\mathbf{w}|\\mathcal{D})\\) directly. Instead we minimize the negative log likelihood, which is an equivalent optimization problem and easier to implement. In Equation¬†4 below I have denoted the negative log likelihood as \\(\\ell(\\mathbf{w})\\) indicating that this is the loss function we aim to minimize. The following two lines in Equation¬†4 show the gradient and Hessian - so the first- and second-order derivatives of \\(\\ell\\) with respect to \\(\\mathbf{w}\\) - where \\(\\mathbf{H}_0=\\Sigma_0^{-1}\\) and \\(\\mu_n=\\sigma(\\mathbf{w}^T\\mathbf{x}_n)\\). To understand how exactly the gradient and Hessian are derived see for example chapter 10 in Murphy (2022).2.\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& \\ell(\\mathbf{w})&=- \\sum_{n=1}^{N} [y_n \\log \\mu_n + (1-y_n)\\log (1-\\mu_n)] + \\frac{1}{2} (\\mathbf{w}-\\mathbf{w}_0)^T\\mathbf{H}_0(\\mathbf{w}-\\mathbf{w}_0) \\\\\n&& \\nabla_{\\mathbf{w}}\\ell(\\mathbf{w})&= \\sum_{n=1}^{N} (\\mu_n-y_n) \\mathbf{x}_n + \\mathbf{H}_0(\\mathbf{w}-\\mathbf{w}_0) \\\\\n&& \\nabla^2_{\\mathbf{w}}\\ell(\\mathbf{w})&= \\sum_{n=1}^{N} (\\mu_n-y_n) \\left( \\mu_n(1-\\mu_n) \\mathbf{x}_n \\mathbf{x}_n^T \\right) + \\mathbf{H}_0\\\\\n\\end{aligned}\n\\end{equation}\n\\tag{4}\\]\n\nSIDENOTE üí°\nNote how earlier I mentioned that maximising the posterior likelihood can be seen as regularized maximum likelihood estimation. We can now make that connection explicit: in Equation¬†4 let us assume that \\(\\mathbf{w}_0=\\mathbf{0}\\). Then since \\(\\mathbf{H}_0=\\lambda\\mathbf{I}\\) with \\(1/\\sigma^2\\) the second term in the first line is simply \\(\\lambda \\frac{1}{2} \\mathbf{w}^T\\mathbf{w}=\\lambda \\frac{1}{2} ||\\mathbf{w}||_2^2\\). This is equivalent to running logistic regression with an \\(\\ell_2\\)-penalty (Bishop 2006).\n\n\nSince minimizing the loss function in Equation¬†4 is a convex optimization problem we have many efficient algorithms to choose from in order to solve this problem. With the Hessian at hand it seems natural to use a second-order method, because incorporating information about the curvature of the loss function generally leads to faster convergence. Here we will implement Newton‚Äôs method in line with the presentation in chapter 8 of Murphy (2022).\n\n\nPosterior predictive\nSuppose now that we have trained the Bayesian Logistic Regression model as our binary classifier \\(g_N(\\mathbf{x})\\) using our training data \\(\\mathcal{D}\\). A new unlabelled sample \\((\\mathbf{x}_{N+1},?)\\) arrives. As with any binary classifier we can predict the missing label by simply plugging the new sample into our classifier \\(\\hat{y}_{N+1}=g_N(\\mathbf{x}_{N+1})=\\sigma(\\hat{\\mathbf{w}}^T\\mathbf{x}_{N+1})\\), where \\(\\hat{\\mathbf{w}}\\) is the MAP estimate as before. If at training phase we have found \\(g_N(\\mathbf{x})\\) to achieve good accuracy, we may expect \\((\\mathbf{x}_{N+1},\\hat{y}_{N+1})\\) to be a reasonably good approximation of the true and unobserved pair \\((\\mathbf{x}_{N+1},y_{N+1})\\). But since we are still dealing with an expected value of a random variable, we would generally like to have an idea of how noisy this prediction is.\nFormally, we are interested in the posterior predictive distribution:\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& p(y=1|\\mathbf{x}, \\mathcal{D})&= \\int \\sigma(\\mathbf{w}^T \\mathbf{x})p(\\mathbf{w}|\\mathcal{D})d\\mathbf{w} \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{5}\\]\n\nSIDENOTE üí°\nThe approach that ignores uncertainty altogether corresponds to what is referred to as plugin approximation of the posterior predictive. Formally, it imposes \\(p(y=1|\\mathbf{x}, \\mathcal{D})\\approx p(y=1|\\mathbf{x}, \\hat{\\mathbf{w}})\\).\n\n\nWith the posterior distribution over model parameters \\(p(\\mathbf{w}|\\mathcal{D})\\) at hand we have the necessary ingredients to estimate the posterior predictive distribution \\(p(y=1|\\mathbf{x}, \\mathcal{D})\\).\nAn obvious, but computationally expensive way to estimate it is through Monte Carlo: draw \\(\\mathbf{w}_s\\) from \\(p(\\mathbf{w}|\\mathcal{D})\\) for \\(s=1:S\\) and compute fitted values \\(\\sigma(\\mathbf{w_s}^T\\mathbf{x})\\) each. Then the posterior predictive distribution corresponds to the average over all fitted values, \\(p(y=1|\\mathbf{x}, \\mathcal{D})=1/S \\sum_{s=1}^{S}\\sigma(\\mathbf{w_s}^T\\mathbf{x})\\). By the law of large numbers the Monte Carlo estimate is an accurate estimate of the true posterior predictive for large enough \\(S\\). Of course, ‚Äúlarge enough‚Äù is somewhat loosely defined here and depending on the problem can mean ‚Äúvery large‚Äù. Consequently, the computational costs involved essentially know no upper bound.\nFortunately, it turns out that we can trade off a little bit of accuracy in return for a convenient analytical solution. In particular, we have that \\(\\sigma(a) \\approx \\Phi(\\lambda a)\\) where \\(\\Phi(.)\\) is the standard Gaussian cdf and \\(\\lambda=\\pi/8\\) ensures that the two functions have the same slope at the origin (Figure¬†2). Without dwelling further on the details we can use this finding to approximate the integral in Equation¬†5 as a sigmoid function. This is called probit approximation and implemented below.\n\n\n\n\n\n\n\n\nFigure¬†2: Demonstration of the probit approximation."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#the-code",
    "href": "blog/posts/bayesian-logit/index.html#the-code",
    "title": "Bayesian Logistic Regression",
    "section": "The code",
    "text": "The code\nWe now have all the necessary ingredients to code Bayesian Logistic Regression up from scratch. While in practice we would usually want to rely on existing packages that have been properly tested, I often find it very educative and rewarding to program algorithms from the bottom up. You will see that Julia‚Äôs syntax so closely resembles the mathematical formulas we have seen above, that going from maths to code is incredibly easy. Seeing those formulas and algorithms then actually doing their magic is quite fun! The code chunk below, for example, shows the implementation of the loss function and its derivatives from Equation¬†4 above. Take a moment to go through the code line-by-line and try to understand how it relates back to the equations in Equation¬†4. Isn‚Äôt it amazing how closely the code resembles the actual equations?\n\nAside from the optimization routine this is essentially all there is to coding up Bayesian Logistic Regression from scratch in Julia Language. If you are curious to see the full source code in detail you can check out this interactive notebook. Now let us finally turn back to our synthetic data and see how Bayesian Logistic Regression can help us understand the uncertainty around our model predictions.\n\nDISCLAIMER ‚ùóÔ∏è\nI should mention that this is the first time I program in Julia, so for any Julia pros out there: please bear with me! Happy to hear your suggestions/comments."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#the-estimates",
    "href": "blog/posts/bayesian-logit/index.html#the-estimates",
    "title": "Bayesian Logistic Regression",
    "section": "The estimates",
    "text": "The estimates\nFigure¬†3 below shows the resulting posterior distribution for \\(w_2\\) and \\(w_3\\) at varying degrees of prior uncertainty \\(\\sigma\\). The constant \\(w_1\\) is held constant at the mode (\\(\\hat{w}_1\\)). The red dot indicates the MLE. Note how for the choice of \\(\\sigma\\rightarrow 0\\) the posterior is equal to the prior. This is intuitive since we have imposed that we have no uncertainty around our prior beliefs and hence no amount of new evidence can move us in any direction. Conversely, for \\(\\sigma \\rightarrow \\infty\\) the posterior distribution is centered around the unconstrained MLE: prior knowledge is very uncertain and hence the posterior is dominated by the likelihood of the data.\n\n\n\n\n\n\nFigure¬†3: Posterior distribution for \\(w_2\\) and \\(w_3\\) at varying degrees of prior uncertainty \\(\\sigma\\).\n\n\n\nWhat about the posterior predictive? The story is similar: since for \\(\\sigma\\rightarrow 0\\) the posterior is completely dominated by the zero-mean prior we have \\(p(y=1|\\mathbf{x},\\hat{\\mathbf{w}})=0.5\\) everywhere (top left panel in Figure¬†4. As we gradually increase uncertainty around our prior the predictive posterior depends more and more on the data \\(\\mathcal{D}\\): uncertainty around predicted labels is high only in regions that are not populated by samples \\((y_n, \\mathbf{x}_n)\\). Not surprisingly, this effect is strongest for the MLE (\\(\\sigma\\rightarrow \\infty\\)) where we see some evidence of overfitting.\n\n\n\n\n\n\nFigure¬†4: Predictive posterior distribution at varying degrees of prior uncertainty \\(\\sigma\\)."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#wrapping-up",
    "href": "blog/posts/bayesian-logit/index.html#wrapping-up",
    "title": "Bayesian Logistic Regression",
    "section": "Wrapping up",
    "text": "Wrapping up\nIn this post we have seen how Bayesian Logistic Regression can be implemented from scratch in Julia language. The estimated posterior distribution over model parameters can be used to quantify uncertainty around coefficients and model predictions. I have argued that it is important to be transparent about model uncertainty to avoid being overly confident in estimates.\nThere are many more benefits associated with Bayesian (probabilistic) machine learning. Understanding where in the input domain our model exerts high uncertainty can for example be instrumental in labelling data: see for example Gal, Islam, and Ghahramani (2017) and follow-up works for an interesting application to active learning for image data. Similarly, there is a recent work that uses estimates of the posterior predictive in the context of algorithmic recourse (Schut et al. 2021). For a brief introduction to algorithmic recourse see one of my previous posts.\nAs a great reference for further reading about probabilistic machine learning I can highly recommend Murphy (2022). An electronic version of the book is currently freely available as a draft. Finally, remember that if you want to try yourself at the code, you can check out this interactive notebook."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#references",
    "href": "blog/posts/bayesian-logit/index.html#references",
    "title": "Bayesian Logistic Regression",
    "section": "References",
    "text": "References\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. springer.\n\n\nGal, Yarin, Riashat Islam, and Zoubin Ghahramani. 2017. ‚ÄúDeep Bayesian Active Learning with Image Data.‚Äù In International Conference on Machine Learning, 1183‚Äì92. PMLR.\n\n\nMurphy, Kevin P. 2012. Machine Learning: A Probabilistic Perspective. MIT press.\n\n\n‚Äî‚Äî‚Äî. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR."
  },
  {
    "objectID": "blog/posts/bayesian-logit/index.html#footnotes",
    "href": "blog/posts/bayesian-logit/index.html#footnotes",
    "title": "Bayesian Logistic Regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe let \\(\\mathbf{w}=(10, 0.75, -2.5)^T\\) define the true coefficients.‚Ü©Ô∏é\nNote that the author works with the negative log likelihood scaled by the sample size‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html",
    "title": "A year of using Quarto with Julia",
    "section": "",
    "text": "A year of using Quarto with Julia.\nEarlier this year in July, I gave a short Experience Talk at JuliaCon. In a related blog post I explained how the introduction of Quarto made my transition from R to Julia painless: I would be able to start learning Julia without having to give up on all the benefits associated with R Markdown.\nIn November, 2022, I am presenting on this topic again at the 2nd JuliaLang Eindhoven meetup. In addition to the slides, I thought I‚Äôd share a small companion blog post that highlights some useful tips and tricks for anyone interested in using Quarto with Julia."
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#general-things",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#general-things",
    "title": "A year of using Quarto with Julia",
    "section": "General things",
    "text": "General things\nWe will start in this section with a few general recommendations.\n\nSetup\nI continue to recommend using VSCode for any work with Quarto and Julia. The Quarto docs explain how to get started by installing the necessary Quarto and IJulia extensions. Since most Julia users will regularly want to update their Julia version, I would additionally recommend to add IJulia.jl to your ~/.julia/config/startup.jl file:1\n# Setup OhMyREPL, Revise and Term\nimport Pkg\nlet\n    pkgs = [\"Revise\", \"OhMyREPL\", \"Term\", \"IJulia\"]\n    for pkg in pkgs\n        if Base.find_package(pkg) === nothing\n            Pkg.add(pkg)\n        end\n    end\nend\nAdditionally, you only need to remember that ‚Ä¶\n\n‚Ä¶ if you install a new Julia binary [‚Ä¶], you must update the IJulia installation [‚Ä¶] by running Pkg.build(\"IJulia\")\n‚Äî Source: IJulia docs\n\nI guess this step can also be automated in ~/.julia/config/startup.jl, but haven‚Äôt tried that yet.\n\n\nUsing .ipynb vs .qmd\nI also continue to recommend working with Quarto notebooks as opposed to Jupyter notebooks (files ending in .qmd and .ipynb, respectively). This is partially just based on preference (from R Markdown I‚Äôm used to working with .Rmd files), but there is also a good reason to consider using .qmd, even if you‚Äôre used to working with Jupyter: the code chunks in your Quarto notebook automatically link to the Julia REPL in VSCode. In other words, you can run code chunks in your notebook and then access any variable that you may have created in the REPL. I find this quite useful, cause it allows me to quickly test code. Perhaps there‚Äôs a good way to do this with Jupyter notebooks as well, but when I last used them I would always have to insert new code cells to test stuff.\nEither way switching between Jupyter and Quarto notebooks is straight-forward: quarto convert notebook.qmd will convert any Quarto notebook into a Jupyter notebook and vice versa. One potential benefit of Jupyter notebooks is their connection to Google Colab: it is possible to store Jupyter notebooks on Github and make them available on Colab, allowing users to quickly interact with your code without the need to clone anything. If this is important to you, you can still work with .qmd documents and simply specify keep-ipynb: true in the YAML header.\n\n\nDynamic Content\n\nThe world and the data that describes it is not static üìà. Why should scientific outputs be?\n\nOne of the things I have always really loved about R Markdown was the ability to use inline code: the Knitr engine allows you to call and render any object x that you have created in preceding R chunks like this: r x. This is very powerful, because it enables us to bridge the gap between computations and output. In other words, it allows us to easily produce reproducible and dynamic content.\nUntil recently I had not been aware that this is also possible for Julia. Consider the following example. The code below depends on remote data that is continuously updated:\n\n\nCode\nusing MarketData\nsnp = yahoo(\"^GSPC\")\n\nusing Dates\nlast_trade_day = timestamp(snp[end])[1]\np_close = values(snp[end,:Close])[1]\nlast_trade_day_formatted = Dates.format(last_trade_day, \"U d, yyyy\")\n\n\nIt loads the most recent publicly available data on equity prices from Yahoo finance. In an ideal world, we‚Äôd like any updates to these inputs to be reflected in our output. That way you can just re-render the Quarto notebook to get an updated report. To render Julia code inline, we use Markdown.jl like so:\n\n\nCode\nusing Markdown\nMarkdown.parse(\"\"\"\nWhen the S&P 500 last traded, on $(last_trade_day_formatted), it closed at $(p_close). \n\"\"\")\n\n\nWhen the S&P 500 last traded, on April 25, 2025, it closed at 5482.16015625. \n\n\n\nIn practice, one would of course set #| echo: false in this case. Whatever content you publish, this approach will keep it up-to-date. This practice of simply re-rendering the source notebook also ensures that any other output remains up-to-date (e.g. Figure¬†1)\n\n\nPrecompiling Plots...\n   1390.7 ms  ‚úì DataStructures\n   1844.1 ms  ‚úì Latexify\n    706.9 ms  ‚úì SortingAlgorithms\n    900.9 ms  ‚úì Latexify ‚Üí SparseArraysExt\n   1296.2 ms  ‚úì UnitfulLatexify\n   1971.4 ms  ‚úì StatsBase\n  39887.7 ms  ‚úì Plots\n   4021.1 ms  ‚úì Plots ‚Üí UnitfulExt\n  8 dependencies successfully precompiled in 49 seconds. 174 already precompiled.\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Price history of the S&P 500.\n\n\n\n\n\n\nCode Execution\nRelated to the previous point, I typically define the following execution options in my _quarto.yml or _metadata.yml. The freeze: auto option ensures that documents are only rerendered if the source changes. In cases where code should always be re-executed you whould want to set freeze: false, instead. I set output: false because typically I have a lot of code chunks that don‚Äôt generate any output that is of immediate interest to readers.\nengine: julia\nexecute:\n  freeze: auto\n  eval: true\n  echo: true\n  output: false\n\n\nReproducibility\nTo ensure that your content can be repoduced easily, it may additionally be helpful to explicitly specify the Julia version you used (``) and set up a global or local Julia environments. Inserting the following at the beginning of your Quarto notebook\nusing Pkg; Pkg.activate(\"&lt;path&gt;\")\nensures that the desired environemnt that lives in &lt;path&gt; is actually activated and used."
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#package-documentation",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#package-documentation",
    "title": "A year of using Quarto with Julia",
    "section": "Package Documentation",
    "text": "Package Documentation\nI have also continued to use Quarto in combination with Documenter.jl to document my Julia packages. This essentially boils down to writing up documentation using interactive .qmd notebooks and then rendering those to .md files as inputs for Documenter.jl. There are a few good reasons for this approach, especially if you‚Äôre used to working with Quarto anyway:\n\nRe-rendering any docs with eval: true provides an additional layer of quality assurance: if any of the code chunks throws an error, you know that your documentation is outdated (perhaps due to an API change). It also offers a straight-forward way to test package functions that produce non-testable (e.g.¬†stochastic) output. In such cases, the use of jldoctest is not always straight-forward (see here).\nYou get some stuff for free, e.g.¬†citation management. Unfortunately, as far as I‚Äôm aware there is still no support for cross-referencing.\nYou can use Quarto execution options like execute-dir: project and resources: www/ to globally specify the working directory and a directory for external resources like images.\n\nThere are also a few peculiarities to be aware of. To avoid any issues with Documenter.jl, I‚Äôve found it useful to ensure that the rendered .md files do not contain any raw HTML and to preserve text wrapping:\nformat: \n  commonmark:\n    variant: -raw_html\n    wrap: preserve\nWhen working with .qmd files you also need to use a slightly different syntax for admonitions. The following syntax inside the .qmd\n| !!! note \\\"An optional title\\\"\n|     Here is something that you should pay attention to.   \nwill generate the desired output inside the rendered .md:2\n!!! note \"An optional title\"\n    Here is something that you should pay attention to.   \nAny of my package repos ‚Äî CounterfactualExplanations.jl, LaplaceRedux.jl, ConformalPrediction.jl ‚Äî should provide additional colour on this topic."
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#quarto-for-academic-journal-articles",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#quarto-for-academic-journal-articles",
    "title": "A year of using Quarto with Julia",
    "section": "Quarto for Academic Journal Articles",
    "text": "Quarto for Academic Journal Articles\nQuarto supports \\(\\LaTeX\\) templates/classes, which has helped me with paper submissions in the past (e.g.¬†my pending JuliaCon Proceedings submissions). I‚Äôve found that rticles still has an edge here, but the list of out-of-the-box templates for journal articles is growing. Should I find some time in the future, I will try to add a template for JuliaCon Proceedings. The beauty of this is that it should enable publishers to not only use traditional forms of publication (PDF), but also include more dynamic formats with ease (think distill, but more than that.)"
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#wrapping-up",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#wrapping-up",
    "title": "A year of using Quarto with Julia",
    "section": "Wrapping up",
    "text": "Wrapping up\nThis short post has provided a bit of an update on using Quarto with Julia. From my own experience so far, things have been getting easier and better (thanks to the amazing work of Quarto dev team). I‚Äôm exicted to see things improve even further and still think that Quarto is a revolutionary new tool for scientific publishing. Let‚Äôs hope publishers eventually recognise this value üëÄ."
  },
  {
    "objectID": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#footnotes",
    "href": "blog/posts/tips-and-tricks-for-using-quarto-with-julia/index.html#footnotes",
    "title": "A year of using Quarto with Julia",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nUnrelated to Quarto, but this thread on discourse is full of other useful ideas for your startup.jl.‚Ü©Ô∏é\nSee related discussion.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/welcome/index.html",
    "href": "blog/posts/welcome/index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to my blog!\nHaving worked with R Markdown and some of Yihui Xie‚Äôs amazing packages for years, I have only now come across his blogdown package. For a while I have been thinking about a good way to share some of my work and actually started collecting snippets in a Gitbook through bookdown quite some time ago. While the book is a work-in-progress that I aim to finish eventually, I will use this website to regularly share content related to my work, research and other things.\n\n\n\n\n\n\nNote\n\n\n\nUpdate on Feb 20, 2022\nI have recently migrated this blog and pretty much everything else I do to quarto.\n\nQuarto¬Æ is an open-source scientific and technical publishing system built on Pandoc.\n\nBased on my first few experiences I would go further and say that quarto is the only open-source scientific and technical publishing system you‚Äôll ever need. The project is supported by RStudio and (unsurprisingly) Yihui Xie is one of the contributors. Go check it out!\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{altmeyer2021,\n  author = {Altmeyer, Patrick and Altmeyer, Patrick},\n  title = {Welcome},\n  date = {2021-02-01},\n  url = {https://www.patalt.org/blog/posts/welcome/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAltmeyer, Patrick, and Patrick Altmeyer. 2021. ‚ÄúWelcome.‚Äù\nFebruary 1, 2021. https://www.patalt.org/blog/posts/welcome/."
  },
  {
    "objectID": "blog/posts/trillion-dollar-words/index.html",
    "href": "blog/posts/trillion-dollar-words/index.html",
    "title": "TrillionDollarWords.jl",
    "section": "",
    "text": "#| echo: false\n\nprojectdir = splitpath(pwd()) |&gt;\n    ss -&gt; joinpath(ss[1:findall([s == \"pat-alt.github.io\" for s in ss])[1]]...) \ncd(projectdir)\n\ninclude(\"$(projectdir)/blog/posts/trillion-dollar-words/src/setup.jl\")\nIn a recent post, I questioned the idea that finding patterns in latent embeddings of models is indicative of AGI or even surprising. One of the models we investigate in our related paper (Altmeyer et al. 2024) is the FOMC-RoBERTa model trained on the Trillion Dollar Words dataset, both of which were published by Shah, Paturi, and Chava (2023) in a recent ACL 2023 paper: Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis (Shah, Paturi, and Chava 2023). To run our experiments and facilitate working with the data and model in Julia, I have developed a small package: TrillionDollarWords.jl. This short post introduces the package and its basic functionality."
  },
  {
    "objectID": "blog/posts/trillion-dollar-words/index.html#trilliondollarwords.jl",
    "href": "blog/posts/trillion-dollar-words/index.html#trilliondollarwords.jl",
    "title": "TrillionDollarWords.jl",
    "section": "TrillionDollarWords.jl",
    "text": "TrillionDollarWords.jl\n    \nTrillionDollarWords.jl is a light-weight package that provides Julia useres easy access to the Trillion Dollar Words dataset and model (Shah, Paturi, and Chava 2023).\n\n\n\n\n\n\nDisclaimer\n\n\n\nPlease note that I am not the author of the Trillion Dollar Words paper nor am I affiliated with the authors. The package was developed as a by-product of our research and is not officially endorsed by the authors of the paper.\n\n\nYou can install the package from Julia‚Äôs general registry as follows:\nusing Pkg\nPkg.add(url=\"TrillionDollarWords.jl\")\nTo install the development version, use the following command:\nusing Pkg\nPkg.add(url=\"https://github.com/pat-alt/TrillionDollarWords.jl\")\n\nBasic Functionality\nThe package provides the following functionality:\n\nLoad pre-processed data.\nLoad the model proposed in the paper.\nBasic model inference: compute forward passes and layer-wise activations.\nDownload pre-computed activations for probing the model.\n\nThe latter two are particularly useful for downstream tasks related to mechanistic interpretability. In times of increasing scrutiny of AI models, it is important to understand how they work and what they have learned. Mechanistic interpretability is a promising approach to this end, as it aims to understand the model‚Äôs internal representations and how they relate to the task at hand. As we make abundantly clear in our own paper (Altmeyer et al. 2024), interpretability is not a silver bullet, but merely a step towards understanding, monitoring and improving AI models.\n\n\nLoading the Data\nThe Trillion Dollar Words dataset is a collection of preprocessed sentences around 40,000 time-stamped sentences from meeting minutes, press conferences and speeches by members of the Federal Open Market Committee (FOMC) (Shah, Paturi, and Chava 2023). The total sample period spans from January, 1996, to October, 2022. In order to train various rule-based models and large language models (LLM) to classify sentences as either ‚Äòhawkish‚Äô, ‚Äòdovish‚Äô or ‚Äòneutral‚Äô, they have manually annotated a subset of around 2,500 sentences. The best-performing model, a large BERT model with around 355 million parameters, was open-sourced on HuggingFace. The authors also link the sentences to market data, which makes it possible to study the relationship between language and financial markets. While the authors of the paper did publish their data, much of it is unfortunately scattered across CSV and Excel files stored in a public GitHub repo. I have collected and merged that data, yielding a combined dataset with indexed sentences and additional metadata that may be useful for downstream tasks.\nThe entire dataset of all available sentences used in the paper can be loaded as follows:\n#| output: true\n\nusing TrillionDollarWords\nload_all_sentences() |&gt; show\nThe combined dataset is also available as a DataFrame and can be loaded as follows:\n#| output: true\n\nload_all_data() |&gt; show\nAdditional functionality for data loading is available (see docs).\n\n\nLoading the Model\nThe model can be loaded with or without the classifier head (below without the head). Under the hood, this function uses Transformers.jl to retrieve the model from HuggingFace. Any keyword arguments accepted by Transformers.HuggingFace.HGFConfig can also be passed. For example, to load the model without the classifier head and enable access to layer-wise activations, the following command can be used:\n#| output: true\n\nload_model(; load_head=false, output_hidden_states=true) |&gt; show\n\n\nBasic Model Inference\nUsing the model and data, layer-wise activations can be computed as below (here for the first 5 sentences). When called on a DataFrame, the layerwise_activations returns a data frame that links activations to sentence identifiers. This makes it possible to relate activations to market data by using the sentence_id key. Alternatively, layerwise_activations also accepts a vector of sentences.\n#| output: true\n\ndf = load_all_sentences()\nmod = load_model(; load_head=false, output_hidden_states=true)\nn = 5\nqueries = df[1:n, :]\nlayerwise_activations(mod, queries) |&gt; show\n\n\nProbe Findings\nFor our own research (Altmeyer et al. 2024), we have been interested in probing the model. This involves using linear models to estimate the relationship between layer-wise transformer embeddings and some outcome variable of interest (Alain and Bengio 2016). To do this, we first had to run a single forward pass for each sentence through the RoBERTa model and store the layerwise emeddings. As we have seen above, the package ships with functionality for doing just that, but to save others valuable GPU hours we have archived activations of the hidden state on the first entity token for each layer as artifacts. To download the last-layer activations in an interactive Julia session, for example, users can proceed as follows:\nusing LazyArtifacts\n\njulia&gt; artifact\"activations_layer_24\"\nWe have found that despite the small sample size, the FOMC-RoBERTa model appears to have distilled useful representations for downstream tasks that it was not explicitly trained for. Figure¬†1 below shows the average out-of-sample root mean squared error for predicting various market indicators from layer activations. Consistent with findings in related work (Alain and Bengio 2016), we find that performance typically improves for layers closer to the final output layer of the transformer model. The measured performance is at least on par with baseline autoregressive models. For more information on this, see also my other recent post.\n\n\n\n\n\n\nFigure¬†1: Out-of-sample root mean squared error (RMSE) for the linear probe plotted against FOMC-RoBERTa‚Äôs \\(n\\)-th layer for different indicators. The values correspond to averages computed across cross-validation folds, where we have used an expanding window approach to split the time series."
  },
  {
    "objectID": "blog/posts/trillion-dollar-words/index.html#intended-purpose-and-goals",
    "href": "blog/posts/trillion-dollar-words/index.html#intended-purpose-and-goals",
    "title": "TrillionDollarWords.jl",
    "section": "Intended Purpose and Goals",
    "text": "Intended Purpose and Goals\nI hope that this small package may be useful to members of the Julia community who are interested in the interplay between Economics, Finance and Artificial Intelligence. It should serve as a good starting point for the following ideas:\n\nFine-tune additional models on the classification task or other tasks of interest.\nFurther model probing, e.g.¬†using other market indicators not discussed in the original paper.\nImprove and extend the label annotations.\n\nAny contributions are very much welcome."
  },
  {
    "objectID": "blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html",
    "href": "blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html",
    "title": "A peek inside the ‚ÄòBlack Box‚Äô - interpreting neural networks",
    "section": "",
    "text": "Propelled by advancements in modern computer technology, deep learning has re-emerged as perhaps the most promising artificial intelligence (AI) technology of the last two decades. By treating problems as a nested, hierarchy of hidden layers deep artificial neural networks achieve the power and flexibility necessary for AI systems to navigate complex real-world environments. Unfortunately, their very nature has earned them a reputation as Black Box algorithms and their lack of interpretability remains a major impediment to their more wide-spread application.\nIn science, research questions usually demand not just answers but also explanations and variable selection is often as important as prediction (Ish-Horowicz et al. 2019). Economists, for example, recognise the undeniable potential of deep learning, but are rightly hesitant to employ novel tools that are not fully transparent and ultimately cannot be trusted. Similarly, real-world applications of AI have come under increasing scrutiny with regulators imposing that individuals influenced by algorithms should have the right to obtain explanations (Fan, Xiong, and Wang 2020). In high-risk decision-making fields such as AI systems that drive autonomous vehicles the need for explanations is self-evident (Ish-Horowicz et al. 2019).\nIn light of these challenges it is not surprising that research on explainable AI has recently gained considerable momentum (Arrieta et al. 2020). While in this short essay we will focus on deep learning in particular, it should be noted that this growing body of literature is concerned with a broader realm of machine learning models. The rest of this note is structured as follows: the first section provides a brief overview of recent advancements towards interpreting deep neural networks largely drawing on Fan, Xiong, and Wang (2020); the second section considers a novel entropy-based approach towards interpretability proposed by Crawford et al. (2019); finally, in the last section we will see how this approach can be applied to deep neural networks as proposed in Ish-Horowicz et al. (2019)."
  },
  {
    "objectID": "blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html#footnotes",
    "href": "blog/posts/a-peek-inside-the-black-box-interpreting-neural-networks/index.html#footnotes",
    "title": "A peek inside the ‚ÄòBlack Box‚Äô - interpreting neural networks",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSimulatability describes the overall, high-level understandability of the mechanisms underlying the model ‚Äì put simply, the less complex the model, the higher its simulatability. Decomposability concerns the extent to which the model can be taken apart into smaller pieces ‚Äì neural networks by there very nature are compositions of multiple layers. Finally, algorithmic transparency refers to the extent to which the training of the algorithm is well-understood and to some extent observable ‚Äì since DNNs generally deal with optimization of non-convex functions and often lack unique solution they are inherently intransparent.‚Ü©Ô∏é\nFor more detail see for example here.‚Ü©Ô∏é\nFor simplicity I have omitted the deterministic bias term.‚Ü©Ô∏é"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome.",
    "section": "",
    "text": "Welcome.\nMy name is Patrick Altmeyer.\nI‚Äôm a PhD Candidate in Trustworthy Artificial Intelligence at Delft University of Technology working on the intersection of Computer Science and Finance.\nMy current research revolves around Counterfactual Explanations and Probabilistic Machine Learning. Previously, I worked as an Economist for the Bank of England.\nI primarily code in Julia and publish through Quarto. Occasionally I also use R, Python and C++. As much as possible I contribute to open-source: Github.\nYou can find the code that builds this website using Quarto in this repo.\n\nNews\n\nOn May 7-8, I‚Äôll be presenting some of my PhD research at the DSCNext Conference Europe 2025.\nTaija, the organization that hosts software geared towards Trustworthy Artificial Intelligence in Julia, has its own website now: www.taija.org. The ecosystem keeps slowly growing. If you‚Äôre interested in contributing, please get in touch!\nIn July 2024, I presented our position paper ‚ÄúStop Making Unscientific AGI Performance Claims‚Äù at ICML 2024. We argue that finding patterns in latent embeddings of models like LLMs is not surprising and call for the academic community to exercise extra caution when interpreting such findings. [preprint], [blog post], [slides/poster]\nIn May 2024, I was in London to present research at ECONDAT 2024 (King‚Äôs College London), The Alan Turing Institute and Imperial College London.\nIn Frebruary 2024, I attended AAAI 2024 in Vancouver, Canada presenting our work on Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals. If you‚Äôre around, come say hi! [preprint], [blog], [TDS], [code], [slides/poster]\n\n\n\nFeatured Visual\n\n\n\nOne of my favorite illustrations of how our recently proposed ECCCo counterfactual generator works compared to Wachter: gradient fields and counterfactual paths for Wachter, ECCCo (no energy constraint), ECCCo (no conformal prediction), ECCCo (full objective).\n\n\n\n\nContact\nYou can find me on Bluesky, LinkedIn, GitHub or reach out to me through email: patalt[at]patalt.org."
  },
  {
    "objectID": "content/about/biography.html",
    "href": "content/about/biography.html",
    "title": "patalt",
    "section": "",
    "text": "Biography\nResearching Trustworthy Artificial Intelligence (AI) for Finance and Economics. I am an economist by background with an interest in cross-disciplinary research on the intersection of Trustworthy AI and Financial Economics. For my PhD in Trustworthy AI, I currently focus on Counterfactual Explanations and Probabilisitic Machine Learning under supervision of Cynthia Liem and Arie van Deursen at Delft University of Technology. I am also a member of the AI for Fintech Research Lab.\nPreviously, I worked as an economist for Bank of England where I was involved in research, monetary policy briefings and market intelligence. I hold two masters degrees from Barcelona School of Economics, one in Data Science and one in Finance. I also hold an undergraduate degree in Economics from the University of Edinburgh.\nüìÑ Resume: [detailed, compact]"
  },
  {
    "objectID": "content/about/contact.html",
    "href": "content/about/contact.html",
    "title": "patalt",
    "section": "",
    "text": "Contact\nYou can find me on Bluesky, LinkedIn, GitHub or reach out to me through email: patalt[at]patalt.org."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/index.html",
    "href": "content/talks/posts/2023-goethe/index.html",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "",
    "text": "Presentatieslides voor mijn eerste presentatie in het Nederlands."
  },
  {
    "objectID": "content/talks/posts/2025-dscn/index.html",
    "href": "content/talks/posts/2025-dscn/index.html",
    "title": "DSCNext Conference Europe 2025",
    "section": "",
    "text": "You can find the slides below or click here to open them in full screen.\nFor the PDF version of the slides use this link instead."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/index.html",
    "href": "content/talks/posts/2023-julia-hpc-delft/index.html",
    "title": "Julia on HPC",
    "section": "",
    "text": "I gave a tutorial introducing a group of bachelor and master students to working with Julia on the DelftBlue supercomputer. The following topics were covered:\n\nNative and intuitive support for different forms of parallelization offered by CounterfactualExplanations.jl.\nCommon challenges and solutions when working with Julia on one of TU Delft‚Äôs clusters (see also this unpolished repo with examples).\nInteractive session where students were guided towards running their first benchmark of counterfactual explanations on DelftBlue (see also docs).\n\nYou can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#kurz-zu-mir",
    "href": "content/talks/posts/2024-tuev/presentation.html#kurz-zu-mir",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Kurz zu mir ‚Ä¶",
    "text": "Kurz zu mir ‚Ä¶\n\n\n\nMA Hons Economics an der University of Edinburgh, dann Master in Economics and Finance an der Barcelona School of Economics (BSE)\nZwei Jahre Geldpolitik bei der Bank of England, dann Master in Data Science an der BSE.\nHeute Doktorand im Fachbereich Vertraubare KI an der Technischen Universit√§t Delft.\n\n\n\nHier geht‚Äôs zur Website:"
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#agenda",
    "href": "content/talks/posts/2024-tuev/presentation.html#agenda",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Agenda",
    "text": "Agenda\n\n\nEinf√ºhrung: Counterfactual Explantions (Section¬†2).\nProbleme bei der Anwendung (Section¬†3).\nWer die Wahl hat ‚Ä¶ (Section¬†4).\nVertrauensw√ºrdig oder nicht? (Section¬†5).\nQ&A (12:30-13:00) (Section¬†6)."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#problemstellung",
    "href": "content/talks/posts/2024-tuev/presentation.html#problemstellung",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Problemstellung",
    "text": "Problemstellung\nTypischerweise geht es um belangreiche diskrete Entscheidungen:\n\n\nKreditw√ºrdig oder nicht?\nBetrugsverdacht oder nicht?\nStra√üenzulassung oder nicht?\nKrebs oder nicht?"
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#problemstellung-1",
    "href": "content/talks/posts/2024-tuev/presentation.html#problemstellung-1",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Problemstellung",
    "text": "Problemstellung\nTypischerweise geht es um belangreiche diskrete Entscheidungen:\n\n\nHund üê∂ oder Katze üê±?\n\n\n\n\nKreditw√ºrdig oder nicht?\nBetrugsverdacht oder nicht?\nStra√üenzulassung oder nicht?\nKrebs oder nicht?"
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2024-tuev/presentation.html#counterfactual-explanations",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\n\nCounterfactual Explanations (CE) erkl√§ren welche Ver√§nderungen n√∂tig gewesen w√§ren, damit der Algorithmus eine andere Entscheidung trifft.1\n\n\n\nWeitere einleitende Lekt√ºre: Blog post oder üìú Altmeyer, Deursen, and Liem (2023)."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#wer-tr√§gt-die-kosten",
    "href": "content/talks/posts/2024-tuev/presentation.html#wer-tr√§gt-die-kosten",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Wer tr√§gt die Kosten?",
    "text": "Wer tr√§gt die Kosten?\n\n\n\n\n\n\n\nIndividuelle Kostenminimierung ist nicht immer optimal.1\n\n\n\nMehr zu dem Thema in unserem SaTML üìú (Altmeyer et al. 2023)."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#mangelnde-eindeutigkeit",
    "href": "content/talks/posts/2024-tuev/presentation.html#mangelnde-eindeutigkeit",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Mangelnde Eindeutigkeit",
    "text": "Mangelnde Eindeutigkeit\n\n\n\nErkl√§rungen f√ºr Algorithmen sind selten eindeutig.\nDiversit√§t kann sogar erw√ºnschlich sein (Mothilal, Sharma, and Tan 2020).\n\n\n\n\n\n\n\n\n\nDiverse Erkl√§rungen durch CE. Quelle: Altmeyer, Deursen, and Liem (2023)."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#viele-bed√ºrfnisse",
    "href": "content/talks/posts/2024-tuev/presentation.html#viele-bed√ºrfnisse",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Viele Bed√ºrfnisse",
    "text": "Viele Bed√ºrfnisse\n\n\nProximit√§t: individuelle Kostenminimierung (Wachter, Mittelstadt, and Russell 2017).\nUmsetzbarkeit: nicht alle Ver√§nderungen sind m√∂glich (Ustun, Spangher, and Liu 2019).\nRobustheit: Erkl√§rungen sollten auch morgen noch g√ºltig sein (Upadhyay, Joshi, and Lakkaraju 2021; Slack et al. 2021; Pawelczyk et al. 2023).\nPlausibilit√§t: nicht alle Ver√§nderungen sind plausibel (Joshi et al. 2019; Poyiadzi et al. 2020)."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2024-tuev/presentation.html#pick-your-poison",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Pick your Poison",
    "text": "Pick your Poison\nAlle Erkl√§rungen in Figure¬†1 sind g√ºltig.\n\nWelche nehmen wir?\n\n\n\n\n\n\n\nFigure¬†1: Aus 9 wird 7: CEs f√ºr einen Bildklassifikator generiert durch Wachter (Wachter, Mittelstadt, and Russell 2017), Schut (Schut et al. 2021) and REVISE (Joshi et al. 2019)."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#treue-trumpft-plausibilit√§t",
    "href": "content/talks/posts/2024-tuev/presentation.html#treue-trumpft-plausibilit√§t",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Treue trumpft Plausibilit√§t",
    "text": "Treue trumpft Plausibilit√§t\n\n\n\n\n\n\n\n\nFigure¬†2: ECCCos f√ºr MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).\n\n\n\n\nECCCo generiert CE die1\n\nQualit√§t treu repr√§sentiert (Figure¬†2).\nPlausibilit√§t erreicht (Figure¬†3).\n\n\n\n\n\n\n\nFigure¬†3: Ergebnisse f√ºr verschiedene Generatoren (from 3 to 5).\n\n\n\n\nMehr zum Thema in unserem AAAI üìú (Altmeyer et al. 2024)."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#robustheit-f√∂rdert-erkl√§rbarkeit",
    "href": "content/talks/posts/2024-tuev/presentation.html#robustheit-f√∂rdert-erkl√§rbarkeit",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Robustheit f√∂rdert Erkl√§rbarkeit",
    "text": "Robustheit f√∂rdert Erkl√§rbarkeit\nMehrere Bachelorarbeiten, die untersuchen welche Methoden die Qualit√§t von Modellen verbessern.\n\n\nVorallem Aversarial Training scheint zu helfen (Figure¬†4)1.\n\n\n\n\n\n\n\n\nFigure¬†4: ECCCos f√ºr standard Model (mitte) und Model mit Aversarial Training (rechts).\n\n\n\n\nMehr zum Thema in Rithik Appachi‚Äôs Thesis."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#weitere-themen",
    "href": "content/talks/posts/2024-tuev/presentation.html#weitere-themen",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "Weitere Themen",
    "text": "Weitere Themen\n\n\nForschung: K√∂nnen wir CE schon w√§hrend des Trainings verwenden?\nOpen-Source: Unser open-source √ñkosystem for Trustworthy AI in Julia (Taija) w√§chst\n\n\n\n\n\n\nCounterfactual Explanations\nConformal Prediction\nBayesian Deep Learning\n\n\n\n\n\nJoint Energy Models\nAdversarial Robustness\n‚Ä¶"
  },
  {
    "objectID": "content/talks/posts/2024-tuev/presentation.html#references",
    "href": "content/talks/posts/2024-tuev/presentation.html#references",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "References",
    "text": "References\n\n\n\n\nAltmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia CS Liem. 2023. ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse.‚Äù In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 418‚Äì31. IEEE.\n\n\nAltmeyer, Patrick, Arie van Deursen, and Cynthia C. S. Liem. 2023. ‚ÄúExplaining Black-Box Models through Counterfactuals.‚Äù In Proceedings of the JuliaCon Conferences, 1:130.\n\n\nAltmeyer, Patrick, Mojtaba Farmanbar, Arie van Deursen, and Cynthia C. S. Liem. 2024. ‚ÄúFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals.‚Äù In Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence, 38:10829‚Äì37. 10. https://doi.org/10.1609/aaai.v38i10.28956.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nPawelczyk, Martin, Teresa Datta, Johannes van-den-Heuvel, Gjergji Kasneci, and Himabindu Lakkaraju. 2023. ‚ÄúProbabilistically Robust Recourse: Navigating the Trade-Offs Between Costs and Robustness in Algorithmic Recourse.‚Äù https://arxiv.org/abs/2203.06768.\n\n\nPoyiadzi, Rafael, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, and Peter Flach. 2020. ‚ÄúFACE: Feasible and Actionable Counterfactual Explanations.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 344‚Äì50.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nSlack, Dylan, Anna Hilgard, Himabindu Lakkaraju, and Sameer Singh. 2021. ‚ÄúCounterfactual Explanations Can Be Manipulated.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nUstun, Berk, Alexander Spangher, and Yang Liu. 2019. ‚ÄúActionable Recourse in Linear Classification.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 10‚Äì19. https://doi.org/10.1145/3287560.3287566.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289."
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#agenda",
    "href": "content/talks/posts/2024-progress/presentation.html#agenda",
    "title": "Progress Meeting",
    "section": "Agenda",
    "text": "Agenda\n\n\nStocktake‚Äîwhat has been accomplished and where are we at?\nNext Steps‚Äîplans for the 3-4 months\nBig Picture‚Äîputting it all together and some tentative career plans\nHousekeeping‚Äîmeeting series, ‚Ä¶"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#papers",
    "href": "content/talks/posts/2024-progress/presentation.html#papers",
    "title": "Progress Meeting",
    "section": "Papers",
    "text": "Papers\nSolid progress on chapters 3 to 5 of the thesis:\n\n\n2 papers published (ECCCo @ AAAI: [Ch3], Stop Making Unscientific AGI Claims @ ICML: [Ch5]).\n1 paper in progress (CE and Adversarial Robustness @ ICML/NeurIPS/workshops ‚ùì: [Ch4.1])\n1 paper initiated (Counterfactual Training @ ICML ‚ùì (timing‚Äôs good): [Ch4.2])\n1 paper (extended abstract) submitted (LaplaceRedux.jl @ JuliaCon)"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#talks-and-posters",
    "href": "content/talks/posts/2024-progress/presentation.html#talks-and-posters",
    "title": "Progress Meeting",
    "section": "Talks and Posters",
    "text": "Talks and Posters\nA total of 12 talks and posters\n\n\nAcademia (4): AAAI (poster), ECONDAT, Imperial College London, ICML (poster)\nCompanies (3): De Nederlandsche Bank, The Alan Turing Institute, T√úV AI Lab (next week)\nSoftware (5): JuliaCon (4 talks), Julia on HPC tutorial @ TU Delft"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#open-source-and-science",
    "href": "content/talks/posts/2024-progress/presentation.html#open-source-and-science",
    "title": "Progress Meeting",
    "section": "Open Source and Science",
    "text": "Open Source and Science\n\n\nUnified ecosystem for Trustworthy AI in Julia, Taija.\n\nContinuous maintenance and development, in particular CE.jl, LR.jl and CP.jl.\nWork on various base and meta packages for parallelization, visualization and more.\n\nPublished 7 blog posts: personal (4), Taija (3)\nMentored two Google/Julia Summer of Code students who contributed to Taija: (1) causal recourse, (2) conformal Bayes."
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#graduate-school",
    "href": "content/talks/posts/2024-progress/presentation.html#graduate-school",
    "title": "Progress Meeting",
    "section": "Graduate School",
    "text": "Graduate School\n\n\n\n1 Research project (4 ECTS: research).\n1 Software project (2 ECTS: research).\n4 Master‚Äôs theses (4 ECTS: research)\n\n\n\nNeurIPS 2024 reviewing (3 ECTS: research).\nJuliaCon, ICML, AAAI, ECONDAT (2 ECTS each: research).\n2-week Dutch course (4 ECTS: transferable).\n\n\nTotal (missing): research (-21.5 ‚ö†Ô∏è), discipline (5), transferable (6)"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#time-management-1",
    "href": "content/talks/posts/2024-progress/presentation.html#time-management-1",
    "title": "Progress Meeting",
    "section": "Time Management (1)",
    "text": "Time Management (1)\n\n\nLast year I thought it should be feasible to have the following papers in (near-) final form by now: ECCCo [Ch3] ‚úÖ, LaplaceRedux [not planned as chapter] ‚úÖ, ConformalPrediction ‚ùå, 3rd research paper [Ch5] ‚úÖ.\nAt that point, I thought we‚Äôd be looking at a comprehensive thesis: JuliaCon paper(s) forming the introduction and 3 research papers forming the core.\n\nStill missing work on imroving models üü®üü®üü®üü®‚¨õ"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#time-management-2",
    "href": "content/talks/posts/2024-progress/presentation.html#time-management-2",
    "title": "Progress Meeting",
    "section": "Time Management (2)",
    "text": "Time Management (2)\n4th year can then be used to:\n\nTackle 4th research paper and collate chapters (thesis).\nEnsure Taija and Graduate School credits are in order and next career steps are planned.\nGoogle Summer of Code ‚úÖ? Teaching ‚úÖ? Research Visit? Internship? Book about Taija?\nWrite paper on JointEnergyModels.jl."
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#ce-and-adversial-robustness",
    "href": "content/talks/posts/2024-progress/presentation.html#ce-and-adversial-robustness",
    "title": "Progress Meeting",
    "section": "CE and Adversial Robustness",
    "text": "CE and Adversial Robustness\nPromising results but ‚Ä¶\n\nNeed more granular grid for gradient-based adversarial training and additional datasets.\nNeed to test other forms of adversarial robustness (e.g.¬†LBDN), because\n\nLink above has been established to some degree.\nLink above is not surprising, because AE and CE are virtually identical.\n\n\n@ ICML 2025, NeurIPS Data & Bmks 2025, workshops, ‚ùì"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#counterfactual-training",
    "href": "content/talks/posts/2024-progress/presentation.html#counterfactual-training",
    "title": "Progress Meeting",
    "section": "Counterfactual Training",
    "text": "Counterfactual Training\n\n\n\n\n\n\nAE ‚äÜ CE\n\n\nAdversarial Examples (AE) can be thought of as a specific type of CE. Why not use CE in a similar fashion during training?\n\n\n\n\n\n\n\nLiterature review ‚úÖ\nProof-of-concept ‚úÖ\nExploration phase ‚è≥ (until mid-November)\n\n\n\n\n\nRun experiments üî≤ (mid-Novermber to early January)\nWrap up üî≤ (January)\n\n\n\n\n‚ùì Aiming for ICML but in 2024 there was little on CE."
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#thesis-structure",
    "href": "content/talks/posts/2024-progress/presentation.html#thesis-structure",
    "title": "Progress Meeting",
    "section": "Thesis Structure",
    "text": "Thesis Structure\nChapter 1\nIntroduction\n\nBroadly: Taija‚ÄîTrustworthy AI in Julia (reference relevant blog posts, NAACL and student papers.)\nFocus: Counterfactual Explanations (JCon Proc) ‚úÖ"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#thesis-structure-1",
    "href": "content/talks/posts/2024-progress/presentation.html#thesis-structure-1",
    "title": "Progress Meeting",
    "section": "Thesis Structure",
    "text": "Thesis Structure\nChapter 2\nAlgorithmic Recourse in Practice\n\nFocus: Endogenous Macrodynamics in Algorithmic Recourse (SaTML) ‚úÖ\nTransition: If not minimal costs, then what? (integrate blog post on REVISE)"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#thesis-structure-2",
    "href": "content/talks/posts/2024-progress/presentation.html#thesis-structure-2",
    "title": "Progress Meeting",
    "section": "Thesis Structure",
    "text": "Thesis Structure\nChapter 3\nFaithfulness first, Plausibility second\n\nFocus: Faithful Model Explanations Through Energy-Constrained Conformal Counterfactuals (AAAI) ‚úÖ\nIntermezzo: Assessing the endogenous macrodynamics caused by ECCCo"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#thesis-structure-3",
    "href": "content/talks/posts/2024-progress/presentation.html#thesis-structure-3",
    "title": "Progress Meeting",
    "section": "Thesis Structure",
    "text": "Thesis Structure\nChapter 4\nLearning Plausible Explanations\n\nTransition: Adversarial Training and Counterfactual Explanations ‚è≥\nFocus: Counterfactual Training ‚è≥"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#thesis-structure-4",
    "href": "content/talks/posts/2024-progress/presentation.html#thesis-structure-4",
    "title": "Progress Meeting",
    "section": "Thesis Structure",
    "text": "Thesis Structure\nChapter 5\nTrustworthy AI in Times of LLMs\n\nIntermezzo: Stop Making Unscientific AGI Claims (ICML) ‚úÖ\nDiscussion: Can AI be Trustworthy? (reference works by Karol and Aleks)"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#thesis-structure-5",
    "href": "content/talks/posts/2024-progress/presentation.html#thesis-structure-5",
    "title": "Progress Meeting",
    "section": "Thesis Structure",
    "text": "Thesis Structure\nChapter 6\nCausality? Global CE?\nSome ideas:\n\nCausality: Causal Abstraction & ECCCo\nGlobal CE: extend ideas presented in T-CREx (Bewley et al. 2024)."
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#summer-2025",
    "href": "content/talks/posts/2024-progress/presentation.html#summer-2025",
    "title": "Progress Meeting",
    "section": "Summer 2025",
    "text": "Summer 2025\n\nConnected with Tom Bewley from J.P. Morgan AI Research at ICML and implemented his paper.\n\nNovel approach to generate global counterfactual rule explanations.\nMotivated me to apply to Summer Associate Program (could work on extension [Ch6]), although I was aiming to defend in September.\n\nAlternatively, hoping for HuggingFace to offer internships again but nothing yet."
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#in-an-ideal-world",
    "href": "content/talks/posts/2024-progress/presentation.html#in-an-ideal-world",
    "title": "Progress Meeting",
    "section": "In an ideal world ‚Ä¶",
    "text": "In an ideal world ‚Ä¶\n\nPretty set on either Amsterdam or D√ºsseldorf.\nLeaning towards industry, but remain curious about opportunities in academia.\nDesire to continue with Julia, ideally Taija.\nContinue developing and implementing interesting research ideas in software, add application and deployment (research engineer?).\nCurious to explore subject areas outside of my PhD but maintain focus on ‚ÄúAI for Good‚Äù."
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#industry",
    "href": "content/talks/posts/2024-progress/presentation.html#industry",
    "title": "Progress Meeting",
    "section": "Industry",
    "text": "Industry\n\nJ.P. Morgan AI Research\nHuggingFace\nEU AI Office\nJulia shops: LazyDynamics, EvoVest\n\nIf industry, ideally combine my backgrounds in economics and AI."
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#academia",
    "href": "content/talks/posts/2024-progress/presentation.html#academia",
    "title": "Progress Meeting",
    "section": "Academia",
    "text": "Academia\n\nPotentially, post-doc at Delft/VU/UvA with interesting external partner, i.e.¬†any of the companies on previous slide or:\n\nEScience Centre\nDNB (?)\n\nAssistant professor at Delft (EWI/TPM), VU, UvA"
  },
  {
    "objectID": "content/talks/posts/2024-progress/presentation.html#references",
    "href": "content/talks/posts/2024-progress/presentation.html#references",
    "title": "Progress Meeting",
    "section": "References",
    "text": "References\n\n\n\n\nBewley, Tom, Salim I. Amoukou, Saumitra Mishra, Daniele Magazzeni, and Manuela Veloso. 2024. ‚ÄúCounterfactual Metarules for Local and Global Recourse.‚Äù In Proceedings of the 41st International Conference on Machine Learning, edited by Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp, 235:3707‚Äì24. Proceedings of Machine Learning Research. PMLR. https://proceedings.mlr.press/v235/bewley24a.html."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#motivation",
    "href": "content/talks/posts/2024-icml/presentation.html#motivation",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Motivation",
    "text": "Motivation\n\n\\(A_1\\): \\(enc(\\)‚ÄûIt is essential to bring inflation back to target to avoid drifting into deflation territory.‚Äú\\()\\)\n\\(A_2\\): \\(enc(\\)‚ÄûIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.‚Äú\\()\\)"
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#motivation-1",
    "href": "content/talks/posts/2024-icml/presentation.html#motivation-1",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Motivation",
    "text": "Motivation\n\n\n\n\\(A_1\\): \\(enc(\\)‚ÄûIt is essential to bring inflation back to target to avoid drifting into deflation territory.‚Äú\\()\\)\n\\(A_2\\): \\(enc(\\)‚ÄûIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.‚Äú\\()\\)\n\n\n‚ÄúThey‚Äôre exactly the same.‚Äù\n‚Äî Linear probe \\(\\widehat{cpi}=f(A)\\)"
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#position",
    "href": "content/talks/posts/2024-icml/presentation.html#position",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Position",
    "text": "Position\n\nCurrent LLMs embed knowledge. They don‚Äòt ‚Äûunderstand‚Äú anything. They are useful tools, but tools nonetheless.\n\n\n\nMeaningful patterns in embeddings are like doves in the sky.\nHumans are prone to seek patterns and anthropomorphize.\nObserved ‚Äòsparks‚Äô of Artificial General Intelligence are spurious.\nThe academic community should exercise extra caution.\nPublishing incentives need to be adjusted."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#outline",
    "href": "content/talks/posts/2024-icml/presentation.html#outline",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Outline",
    "text": "Outline\n\n\nExperiments: We probe models of varying complexity including random projections, matrix decompositions, deep autoencoders and transformers.\n\nAll of them successfully distill knowledge and yet none of them develop true understanding.\n\nSocial sciences review: Humans are prone to seek patterns and anthropomorphize.\nConclusion and outlook: More caution at the individual level, and different incentives at the institutional level."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#the-holy-grail",
    "href": "content/talks/posts/2024-icml/presentation.html#the-holy-grail",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "The Holy Grail",
    "text": "The Holy Grail\nAchievement of Artificial General Intelligence (AGI) has become a grand challenge, and in some cases, an explicit business goal.\n\n\nDefinition\nThe definition of AGI itself is not as clear-cut or consistent:\n\n(loosely) a phenomenon contrasting with ‚Äònarrow AI‚Äô systems, that were trained for specific tasks (Goertzel 2014).\n\n\nPractice\nResearchers have sought to show that AI models generalize to different (and possibly unseen) tasks or show performance considered ‚Äòsurprising‚Äô to humans.\n\nFor example, Google DeepMind claimed their AlphaGeometry model (Trinh et al. 2024) reached a ‚Äòmilestone‚Äô towards AGI."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#a-perfect-storm",
    "href": "content/talks/posts/2024-icml/presentation.html#a-perfect-storm",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "A Perfect Storm",
    "text": "A Perfect Storm\nRecent developments in the field have created a ‚Äòperfect storm‚Äô for inflated claims:\n\n\nEarly sharing of preprints and code.\nVolume of publishable work has exploded.\nSocial media influencers start playing a role in article discovery and citeability (Weissburg et al. 2024).\nComplexity is increasing because it is incentivized (Birhane et al. 2022)."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#not-mere-stochastic-parrots",
    "href": "content/talks/posts/2024-icml/presentation.html#not-mere-stochastic-parrots",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "‚ÄúNot Mere Stochastic Parrots‚Äù",
    "text": "‚ÄúNot Mere Stochastic Parrots‚Äù\n\nWe consider a recently viral work (Gurnee and Tegmark 2023a), in which claims about the learning of world models by LLMs were made.\n\nLinear probes (ridge regression) were successfully used to predict geographical locations from LLM embeddings.\n\nClaims on X that this indicates that LLMs are not mere ‚Äòstochastic parrots‚Äô (Bender et al. 2021).\nReactions on X seemed to largely exhibit excitement and surprise at the authors‚Äô findings."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#are-neural-networks-born-with-world-models",
    "href": "content/talks/posts/2024-icml/presentation.html#are-neural-networks-born-with-world-models",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Are Neural Networks Born with World Models?",
    "text": "Are Neural Networks Born with World Models?\n\n\n\nLlama-2 model tested in Gurnee and Tegmark (2023b) has ingested huge amounts of publicly available data (Touvron et al. 2023).\n\nGeographical locations are literally in the training data: e.g.¬†Wikipedia article for ‚ÄúLondon‚Äù.\nWhere would this information be encoded if not in the embedding space \\(\\mathcal{A}\\)? Is it surprising that \\(A_{\\text{LDN}}=enc(\\text{\"London\"}) \\not\\!\\perp\\!\\!\\!\\perp (\\text{lat}_{\\text{LDN}},\\text{long}_{\\text{LDN}})\\)?\n\nFigure¬†1 shows the predicted coordinates of a linear probe on the final-layer activations of an untrained neural network.\n\n\n\n\n\n\n\n\nFigure¬†1: Predicted coordinate values (out-of-sample) from a linear probe on final-layer activations of an untrained neural network.\n\n\n\n\nModel has seen noisy coordinates plus \\(d\\) random features.\nSingle hidden layer with \\(h &lt; d\\) hidden units."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#pca-as-a-yield-curve-interpreter",
    "href": "content/talks/posts/2024-icml/presentation.html#pca-as-a-yield-curve-interpreter",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "PCA as a Yield Curve Interpreter",
    "text": "PCA as a Yield Curve Interpreter\nWhat are principal components if not model embeddings?\n\n\n\n\n\n\nFigure¬†2: Top chart: The first two principal components of US Treasury yields over time at daily frequency. Bottom chart: Observed average level and 10yr-3mo spread of the yield curve. Vertical stalks roughly indicate the onset (|GFC) and the beginning of the aftermath (GFC|) of the Global Financial Crisis."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#autoencoders-as-economic-growth-predictors",
    "href": "content/talks/posts/2024-icml/presentation.html#autoencoders-as-economic-growth-predictors",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Autoencoders as Economic Growth Predictors",
    "text": "Autoencoders as Economic Growth Predictors\n\n\n\nWe train a neural network with a bottleneck layer to predict GDP growth from the yield curve Figure¬†3.\n\nInput: UST yields at different maturities.\nHidden layer, bottleneck layer, hidden layer.\nOutput: GDP growth.\n\nCan we use this for more than just forecasting?\n\n\n\n\n\n\n\n\nFigure¬†3: Simple autoencoder architecture."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#autoencoders-as-economic-growth-predictors-1",
    "href": "content/talks/posts/2024-icml/presentation.html#autoencoders-as-economic-growth-predictors-1",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Autoencoders as Economic Growth Predictors",
    "text": "Autoencoders as Economic Growth Predictors\n\nYes, this can be used for feature extraction and forecasting:\n\nBottle-neck layer embeddings predict spread and level of the yield curve.\n\n\n\n\n\n\n\n\nFigure¬†4: The left chart shows the actual GDP growth and fitted values from the autoencoder model. The right chart shows the observed average level and spread of the yield curve (solid) along with the predicted values (in-sample) from the linear probe based on the latent embeddings (dashed)"
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#embedding-fomc-comms",
    "href": "content/talks/posts/2024-icml/presentation.html#embedding-fomc-comms",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Embedding FOMC comms",
    "text": "Embedding FOMC comms\n\nBERT-based model trained on FOMC minutes, speeches and press conferences to classify statements as hawkish or dovish (or neutral) (Shah, Paturi, and Chava 2023).\nWe linearly probe all layers to predict unseen economic indicators (CPI, PPI, UST yields).\nPredictive power increases with layer depth and probes outperform simple AR(\\(p\\)) models.\n\n\n\n\n\n\n\nFigure¬†5: Out-of-sample root mean squared error (RMSE) for the linear probe plotted against FOMC-RoBERTa‚Äôs n-th layer for different indicators."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#sparks-of-economic-understanding",
    "href": "content/talks/posts/2024-icml/presentation.html#sparks-of-economic-understanding",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Sparks of Economic Understanding?",
    "text": "Sparks of Economic Understanding?\nPremise: If probe results were indicative of some intrinsic ‚Äòunderstanding‚Äô of the economy, then the probe should not be sensitive to random sentences unrelated to economics.\nParrot Test\n\nSelect the best-performing probe for each economic indicator.\nPredict inflation levels for real (related) and perturbed (unrelated) sentences.\n\n\n\n\n\n\n\nFigure¬†6: Probe predictions for sentences about inflation of prices (IP), deflation of prices (DP), inflation of birds (IB) and deflation of birds (DB). The vertical axis shows predicted inflation levels subtracted by the average predicted value of the probe for random noise.\n\n\n\nAs evidenced by Figure¬†6, the probe is easily fooled."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#spurious-relationships",
    "href": "content/talks/posts/2024-icml/presentation.html#spurious-relationships",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Spurious Relationships",
    "text": "Spurious Relationships\nDefiniton: Varies somewhat (Haig 2003) but distinctly implies that the observation of correlations does not imply causation.\n\nHumans struggle to tell the difference between random and non-random sequences (Falk and Konold 1997).\nLack of expectation that randomness that hints towards a causal relationship will still appear at random.\nEven experts perceive correlations of inflated magnitude (Nickerson 1998) and causal relationships where none exist (Zgraggen et al. 2018)."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#antropomorphism",
    "href": "content/talks/posts/2024-icml/presentation.html#antropomorphism",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Antropomorphism",
    "text": "Antropomorphism\nDefinition: Human tendency to attribute human-like characteristics to non-human agents and/or objects.\n\nExperience as humans is an always-readily-available template to interpret the world (Epley, Waytz, and Cacioppo 2007).\nMotivation to avoid loneliness may lead us to anthropomorphize inanimate objects Waytz, Epley, and Cacioppo (2010).\nMotivation to be competent may lead us anthropomorphize opaque technologies like LLMs Waytz, Epley, and Cacioppo (2010)"
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#confirmation-bias",
    "href": "content/talks/posts/2024-icml/presentation.html#confirmation-bias",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Confirmation Bias",
    "text": "Confirmation Bias\nDefinition: Favoring interpretations of evidence that support existing beliefs or hypotheses (Nickerson 1998).\n\nHypotheses in present-day AI research are often implicit, often framed simply as a system being more accurate or efficient, compared to other systems.\n\nFailing to articulate a sufficiently strong null hypothesis leading to a ‚Äòweak‚Äô experiment (Claesen et al. 2022).\n\nIndividuals may place greater emphasis on evidence in support of their hypothesis, and lesser emphasis on evidence that opposes it (Nickerson 1998)."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#conclusion-and-outlook",
    "href": "content/talks/posts/2024-icml/presentation.html#conclusion-and-outlook",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Conclusion and Outlook",
    "text": "Conclusion and Outlook\n\nWe call for the community to create explicit room for organized skepticism\n\nWelcome negative results\nEncouraging replication studies.\nMove from authorship to contribution-based credit (see e.g.¬†Liem and Demetriou, 2023 and Smith, 1997).\n\nReturn to the Mertonian norms (communism, universalism, disinterestedness, organized skepticism) (Merton et al. 1942)."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#references",
    "href": "content/talks/posts/2024-icml/presentation.html#references",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "References",
    "text": "References\n\n\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. ‚ÄúOn the dangers of stochastic parrots: Can language models be too big? .‚Äù In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 610‚Äì23.\n\n\nBirhane, Abeba, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit Dotan, and Michelle Bao. 2022. ‚ÄúThe Values Encoded in Machine Learning Research.‚Äù In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT ‚Äô22).\n\n\nClaesen, Aline, Daniel Lakens, Noah van Dongen, et al. 2022. ‚ÄúSeverity and Crises in Science: Are We Getting It Right When We‚Äôre Right and Wrong When We‚Äôre Wrong?‚Äù\n\n\nEpley, Nicholas, Adam Waytz, and John T Cacioppo. 2007. ‚ÄúOn seeing human: a three-factor theory of anthropomorphism.‚Äù Psychological Review 114 (4): 864.\n\n\nFalk, Ruma, and Clifford Konold. 1997. ‚ÄúMaking sense of randomness: Implicit encoding as a basis for judgment.‚Äù Psychological Review 104 (2): 301.\n\n\nGoertzel, Ben. 2014. ‚ÄúArtificial general intelligence: concept, state of the art, and future prospects.‚Äù Journal of Artificial General Intelligence 5 (1): 1.\n\n\nGurnee, Wes, and Max Tegmark. 2023b. ‚ÄúLanguage Models Represent Space and Time.‚Äù arXiv Preprint arXiv:2310.02207v2.\n\n\n‚Äî‚Äî‚Äî. 2023a. ‚ÄúLanguage Models Represent Space and Time.‚Äù arXiv Preprint arXiv:2310.02207v1.\n\n\nHaig, Brian D. 2003. ‚ÄúWhat is a spurious correlation?‚Äù Understanding Statistics: Statistical Issues in Psychology, Education, and the Social Sciences 2 (2): 125‚Äì32.\n\n\nMerton, Robert K et al. 1942. ‚ÄúScience and technology in a democratic order.‚Äù Journal of Legal and Political Sociology 1 (1): 115‚Äì26.\n\n\nNickerson, Raymond S. 1998. ‚ÄúConfirmation bias: A ubiquitous phenomenon in many guises.‚Äù Review of General Psychology 2 (2): 175‚Äì220.\n\n\nShah, Agam, Suvan Paturi, and Sudheer Chava. 2023. ‚ÄúTrillion Dollar Words: A New Financial Dataset, Task & Market Analysis.‚Äù arXiv Preprint arXiv:2310.02207v1. https://arxiv.org/abs/2305.07972.\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, et al. 2023. ‚ÄúLLaMA: Open and Efficient Foundation Language Models.‚Äù https://arxiv.org/abs/2302.13971.\n\n\nTrinh, T. H., Wu, Y., Le, and Q. V. et al. 2024. ‚ÄúSolving olympiad geometry without human demonstrations.‚Äù Nature 625, 476‚Äì82. https://doi.org/https://doi.org/10.1038/s41586-023-06747-5.\n\n\nWaytz, Adam, Nicholas Epley, and John T Cacioppo. 2010. ‚ÄúSocial cognition unbound: Insights into anthropomorphism and dehumanization.‚Äù Current Directions in Psychological Science 19 (1): 58‚Äì62.\n\n\nWeissburg, Iain Xie, Mehir Arora, Liangming Pan, and William Yang Wang. 2024. ‚ÄúTweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility.‚Äù arXiv Preprint arXiv:2401.13782.\n\n\nZgraggen, Emanuel, Zheguang Zhao, Robert Zeleznik, and Tim Kraska. 2018. ‚ÄúInvestigating the effect of the multiple comparisons problem in visual analysis.‚Äù In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, 1‚Äì12."
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#image-sources",
    "href": "content/talks/posts/2024-icml/presentation.html#image-sources",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Image sources",
    "text": "Image sources\n\nLeonardo DiCaprio: Meme template by user on Reddit\nTarot cards: Photo by Viva Luna Studios on Unsplash\nWall-E: Photo by ray rui on Unsplash"
  },
  {
    "objectID": "content/talks/posts/2024-icml/presentation.html#quote-sources",
    "href": "content/talks/posts/2024-icml/presentation.html#quote-sources",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Quote sources",
    "text": "Quote sources\n\n‚ÄúThere! It‚Äôs sentient‚Äù‚Äîthat engineer at Google (probably!)\n‚ÄúThe human mind is a pattern-seeking device‚Äù‚ÄîDaniel Kahneman\n‚ÄúWe‚Äôre fascinated with robots because they are reflections of ourselves.‚Äù‚ÄîKen Goldberg"
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/index.html",
    "href": "content/talks/posts/2023-ieee-satml/index.html",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "",
    "text": "In February 2023, I presented our paper ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse‚Äù at the first IEEE SaTML conference. You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/index.html",
    "href": "content/talks/posts/2023-delft-fintech/index.html",
    "title": "Echos from the Black Box",
    "section": "",
    "text": "In May 2023, I presented some of our work at the Delft FinTech Lab Launch organized by Mondai House of AI. You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#trustworthy-ai-in-julia",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#trustworthy-ai-in-julia",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "Trustworthy AI in JuliA",
    "text": "Trustworthy AI in JuliA\n\n\n\n\n\n\n%%{\n  init: {\n    'theme': 'base',\n    'themeVariables': {\n      'primaryColor': '#BB2528',\n      'primaryTextColor': '#fff',\n      'primaryBorderColor': '#7C0000',\n      'lineColor': '#F8B229',\n      'secondaryColor': '#006100',\n      'tertiaryColor': '#e9edfb',\n      'fontFamily': \"avenir\"\n    }\n  }\n}%%\n\nflowchart TB\n\n    classDef taija fill:#389836,stroke:#333,color:#fff;\n    classDef core fill:#CB3C33,stroke:#333,color:#fff;\n    classDef base fill:#9558B2,stroke:#333,color:#fff;\n\n    %% Base\n    base[\"TaijaBase.jl\"]\n\n    %% Meta\n    interop[\"TaijaInteroperability.jl\"]\n    data[\"TaijaData.jl\"]\n    parallel[\"TaijaParallel.jl\"]\n    plotting[\"TaijaPlotting.jl\"]\n\n    %% Core\n    ce[\"CounterfactualExplanations.jl\"]\n    cp[\"ConformalPrediction.jl\"]\n    lr[\"LaplaceRedux.jl\"]\n    jem[\"JointEnergyModels.jl\"]\n\n    %% External\n    mlj[\"MLJ.jl\"]\n    flux[\"Flux.jl\"]\n\n    class base base;\n    class interop,data,parallel,plotting taija;\n    class ce,cp,lr,jem core;\n\n    %% Graph\n    base --&gt; ce & cp & lr & jem\n\n    subgraph \"Core Packages\"\n        ce & cp & lr & jem \n    end\n\n    subgraph \"Meta Packages\"\n        data & plotting & parallel & interop\n    end \n\n    subgraph \"External Packages\"\n        mlj & flux\n    end\n\n\n\n\nFigure¬†1: Overview of the Taija ecosystem. Early-stage packages ommitted."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#why-supercomputing",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#why-supercomputing",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "Why Supercomputing?",
    "text": "Why Supercomputing?\nEfforts towards trustworthy AI tend to increase the computational burden involved in training or inference:\n\n\nExplainable AI: we are often required to generate many local explanations for many individuals.\nConformal Prediction: many techniques involve cross-validation or bootstrapping.\n(Quasi) Bayesian DL like deep ensembles.\n\n\n\n\nGood news: all of these tasks can be parallelized!"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#benchmarking-explanations",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#benchmarking-explanations",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "Benchmarking Explanations",
    "text": "Benchmarking Explanations\n\n\nGoal: Generate faithful counterfactual explanations that reflect model quality.\n\nFinal benchmark: total of ~10 million counterfactuals across 8 datasets and different DL models.\nParallelized across 50 to 300 CPUs on DelftBlue using combination of multi-threading and -processing.\n\n\n\n\n\nCounterfactual explanations for different models. Source: Altmeyer et al. (2024)"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#source-code",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#source-code",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "Source Code",
    "text": "Source Code\n\nECCCo.jl is a small package build for Altmeyer et al. (2024) that leverages and extends CounterfactualExplanations.jl, ConformalPrediction.jl, and JointEnergyModels.jl.\nParallelization is achieved through TaijaParallel.jl.\nFunctionality now being absorbed by CounterfactualExplanations.jl.\n\n\n\n\n\nCode is open-sourced and available on GitHub."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#user-interface",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#user-interface",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "User Interface",
    "text": "User Interface\n\n\n\nWe aim to minimize the burden on users.\n\n\nUsers will mostly interact with custom macro @with_parallelizer.\nIn Figure¬†2, mpi is an instance of type MPIParallelizer.\n\n\n\n\n\n\n\n\nFigure¬†2: Generating counterfactuals in parallel using MPI. See docs for details."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#high-level-architecture",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#high-level-architecture",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "High-level Architecture",
    "text": "High-level Architecture\n\nTaijaBase.jl ships basic parallelization functions and symbols to make them available to all Taija packages.\n\nCounterfactualExplanations.benchmark, for example, accepts a parallelizer argument of type Union{Nothing,AbstractParallelizer}.\n\nTaijaParallel.jl adds out-of-the-box support for parallelization through multi-threading.\nMulti-processing through MPI.jl handled through an extension."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#backend",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#backend",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "Backend",
    "text": "Backend\n\nThe @with_parallelizer macro defined here parses inputs and calls the parallelize function.\nparallelize is dispatched on the type of parallelizer and the function to be parallelized.\nEasy to add support for new parallelization backends and functions by overloading parallelize.\nPossible to combine different forms of parallelization, e.g., multi-threading and multi-processing (see here for an example)."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#caveats-and-future-work",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#caveats-and-future-work",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "Caveats and Future Work",
    "text": "Caveats and Future Work\n\nThe functions to be parallelized must be broadcastable: generate_counterfactual, for example, can be broadcasted over a batch of inputs.\nCurrently, the package only supports CounterfactualExplanations.jl.\nWork on ConformalPrediction.jl is in progress, and hinges on the ability to parallelize cross-validation. Requires changes to ConformalPrediction.jl."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#all-the-counterfactuals",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#all-the-counterfactuals",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "ALL the Counterfactuals!",
    "text": "ALL the Counterfactuals!\n\n\nTrustworthy AI may be slow but ‚Ä¶\n\nJulia go vroom vroom!\n\n\n\n\n\n\n\nGenerating 10,000 counterfactuals for MNIST in parallel in under 2s on a MacBook."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#references",
    "href": "content/talks/posts/2024-juliacon/taija-supercomp/presentation.html#references",
    "title": "Trustworthy AI in Julia meets Supercomputing",
    "section": "References",
    "text": "References\n\n\n\n\nAltmeyer, Patrick, Mojtaba Farmanbar, Arie van Deursen, and Cynthia CS Liem. 2024. ‚ÄúFaithful Model Explanations Through Energy-Constrained Conformal Counterfactuals.‚Äù In Proceedings of the AAAI Conference on Artificial Intelligence, 38:10829‚Äì37. 10."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#ecosystem-overview",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#ecosystem-overview",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Ecosystem Overview",
    "text": "Ecosystem Overview\n\n\n\n\n\n%%{\n  init: {\n    'theme': 'base',\n    'themeVariables': {\n      'primaryColor': '#BB2528',\n      'primaryTextColor': '#fff',\n      'primaryBorderColor': '#7C0000',\n      'lineColor': '#F8B229',\n      'secondaryColor': '#006100',\n      'tertiaryColor': '#e9edfb',\n      'fontFamily': \"avenir\"\n    }\n  }\n}%%\n\nflowchart TB\n\n    classDef taija fill:#389836,stroke:#333,color:#fff;\n    classDef core fill:#CB3C33,stroke:#333,color:#fff;\n    classDef base fill:#9558B2,stroke:#333,color:#fff;\n\n    %% Base\n    base[\"TaijaBase.jl\"]\n\n    %% Meta\n    interop[\"TaijaInteroperability.jl\"]\n    data[\"TaijaData.jl\"]\n    parallel[\"TaijaParallel.jl\"]\n    plotting[\"TaijaPlotting.jl\"]\n\n    %% Core\n    ce[\"CounterfactualExplanations.jl\"]\n    cp[\"ConformalPrediction.jl\"]\n    lr[\"LaplaceRedux.jl\"]\n    jem[\"JointEnergyModels.jl\"]\n\n    %% External\n    mlj[\"MLJ.jl\"]\n    flux[\"Flux.jl\"]\n\n    class base base;\n    class interop,data,parallel,plotting taija;\n    class ce,cp,lr,jem core;\n\n    %% Graph\n    base --&gt; ce & cp & lr & jem\n\n    subgraph \"Core Packages\"\n        ce & cp & lr & jem \n    end\n\n    subgraph \"Meta Packages\"\n        data & plotting & parallel & interop\n    end \n\n    subgraph \"External Packages\"\n        mlj & flux\n    end\n\n\n Overview of the Taija ecosystem. Early-stage packages omitted."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#ecosystem-overview-1",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#ecosystem-overview-1",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Ecosystem Overview",
    "text": "Ecosystem Overview\n\n\n\n\n\n%%{\n  init: {\n    'theme': 'base',\n    'themeVariables': {\n      'primaryColor': '#BB2528',\n      'primaryTextColor': '#fff',\n      'primaryBorderColor': '#7C0000',\n      'lineColor': '#F8B229',\n      'secondaryColor': '#006100',\n      'tertiaryColor': '#e9edfb',\n      'fontFamily': \"avenir\"\n    }\n  }\n}%%\n\nflowchart TB\n\n    classDef taija fill:#389836,stroke:#333,color:#fff;\n    classDef core fill:#CB3C33,stroke:#333,color:#fff;\n    classDef base fill:#9558B2,stroke:#333,color:#fff;\n\n    %% Base\n    base[\"TaijaBase.jl\"]\n\n    %% Meta\n    interop[\"TaijaInteroperability.jl\"]\n    data[\"TaijaData.jl\"]\n    parallel[\"TaijaParallel.jl\"]\n    plotting[\"TaijaPlotting.jl\"]\n\n    %% Core\n    ce[\"CounterfactualExplanations.jl\"]\n    cp[\"ConformalPrediction.jl\"]\n    lr[\"LaplaceRedux.jl\"]\n    jem[\"JointEnergyModels.jl\"]\n\n    %% External\n    mlj[\"MLJ.jl\"]\n    flux[\"Flux.jl\"]\n\n    class base base;\n    class interop,data,parallel,plotting taija;\n    class ce,cp,lr,jem core;\n\n    %% Graph\n    base --&gt; ce & cp & lr & jem\n\n    subgraph \"Core Packages\"\n        ce & cp & lr & jem \n    end\n\n    subgraph \"Meta Packages\"\n        data & plotting & parallel & interop\n    end \n\n    subgraph \"External Packages\"\n        mlj & flux\n    end\n\n\n Overview of the Taija ecosystem. Early-stage packages omitted."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#whos-behind-taija",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#whos-behind-taija",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Who‚Äôs behind Taija?",
    "text": "Who‚Äôs behind Taija?\n\n2021-2022: Initially developed by myself to support my PhD research in Trustworthy AI (still ongoing).\n2023-2024: Expanded by a growing community of contributors, including TU Delft and G/JSoC students.\n\n\nThanks to @MojiFarmanbar, @JorgeLuizFranco, @Rockdeldiablo, @kmariuszk, @RaunoArike, @VincentPikand, @severinbratus, @rithik83, @navimakarov, @laurikskl, @MarkArdman, @adelinacazacu, @Andrei32Ionescu and many others!"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#use-cases",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#use-cases",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Use Cases",
    "text": "Use Cases\n\nWho could benefit from Taija?\n\n\n\nResearchers in AI and ML, particularly in the fields of explainability, uncertainty quantification, and Bayesian deep learning: (, ‚Ä¶)\nPractitioners using conventional ML and DL models who are interested in understanding the models‚Äô decisions and their uncertainty.\nJulia developers who want to contribute to the ecosystem (any level of expertise is welcome!)."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#counterfactual-explanations",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\nThe largest single category of CE methods solves the following optimization through gradient descent:\n\\[\n\\begin{aligned}\n\\mathbf{s}^* &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\left\\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)}+ \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\right\\}\n\\end{aligned}\n\\]\n\n\nCounterfactual Explanations explain how inputs into a model need to change for it to produce different outputs.\n\n\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#pick-your-poison",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Pick your Poison",
    "text": "Pick your Poison\nAll of these counterfactuals are valid explanations ‚Ä¶\n\n‚Ä¶ which one would you pick?\n\n\n\n\n\n\n\nFigure¬†2: Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using Wachter (Wachter, Mittelstadt, and Russell 2017), Schut (Schut et al. 2021) and REVISE (Joshi et al. 2019)."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#faithful-counterfactuals",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#faithful-counterfactuals",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Faithful Counterfactuals",
    "text": "Faithful Counterfactuals\n\n\n\n\n\n\n\n\nFigure¬†3: Turning a 9 into a 7. ECCCo applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).\n\n\n\n\nECCCo1 counterfactuals\n\nexplain models faithfully (Figure¬†3).\nachieve SOTA plausibility (Figure¬†4).\n\n\n\n\n\n\n\nFigure¬†4: Results for different generators (from 3 to 5).\n\n\n\n\nPackage and link to AAAI 2024 paper: github.com/pat-alt/ECCCo.jl."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#intent-classification",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#intent-classification",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Intent Classification",
    "text": "Intent Classification\nIntent classification (IC) in dialogue systems is a common task and a natural place for conformal prediction.\n\n\n\nSimply returning top-1 softmax likely wrong.\nExisting ad-hoc approach is top-\\(k\\).\nConformal classifiers predict sets that fulfill coverage guarantee.\n\n\n\n\n\n\n\n\nFigure¬†5: A simple conformal chat bot in the Julia REPL using ConformalPrediction.jl."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#conformal-ic-and-clarification",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#conformal-ic-and-clarification",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Conformal IC and Clarification",
    "text": "Conformal IC and Clarification\n\nOur NAACL 2024 paper introduces CICC: a framework for fast and accurate intent classification in conversational AI.\nWinning project at ING Experiment Week 2023.\n\n\nSee also Building a Conformal Chatbot in Julia with ConformalPrediction.jl and Transformers.jl1.\n\nExperiments in Hengst et al. (2024) were run in parallel using Python‚Äôs MAPIE and ConformalPrediction.jl, in order to cross-check results. Reported results were produced using MAPIE."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#more-research",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#more-research",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "More Research",
    "text": "More Research\n\nStop Making Unscientific AGI Performance Claims (Altmeyer et al. 2024) upcoming at ICML 2024.1\nEndogenous Macrodynamics in Algorithmic Recourse (Altmeyer et al. 2023) published at IEEE SaTML 2023.\nVarious Master‚Äôs theses on CE for imbalanced data (Zagorac 2024), CE for LLMs (draft PR), and more ‚Ä¶\nBachelor‚Äôs theses on What Makes Models Explainable? Evidence from Counterfactuals (related development: AdversarialRobustness.jl).\n\nOur related package is not currently part of Taija but may be in the future."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#composable-generators",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#composable-generators",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Composable Generators",
    "text": "Composable Generators\nRecall that for most generators, we have:\n\\[\n\\begin{aligned}\n\\mathbf{s}^* &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\left\\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)}+ \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\right\\}\n\\end{aligned}\n\\]\n\n\nWhy not compose generators that combine ideas from different off-the-shelf generators?\n\n\n\n@chain generator begin\n    @objective logitcrossentropy \n      + 1.0ddp_diversity     # DiCE (Mothilal et al. 2020)\n    @with_optimiser Flux.Adam(0.1)                      \n    @search_latent_space     # REVISE (Joshi et al. 2019)\nend"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#explaining-different-models",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#explaining-different-models",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Explaining Different Models",
    "text": "Explaining Different Models\nBesides any Flux.jl model, extensions add support for\n\n\n\nDecisionTree.jl\nNeuroTrees.jl (see Jeremie‚Äôs talk Fri 10:10‚Äì10:20 For Loop)\nLaplaceRedux.jl\nJointEnergyModel.jl (upcoming)\n\n\n\n\n\n\n\n\nFigure¬†6: Counterfactual for differentiable decision tree classifier."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#benchmarking-explanations",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#benchmarking-explanations",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Benchmarking Explanations",
    "text": "Benchmarking Explanations\nExtensive support for evaluating and benchmarking explanations.\n\n\nEvaluation\n# Generate counterfactuals\nces = generate_counterfactual(\n  factual, \n  target_label, \n  data, \n  M, \n  generator; \n  num_counterfactuals=5\n)\n\n# Evaluate them\nevaluate(ces)\n\nBenchmarks\nBenchmark all available generators and models at once in parallel1:\nusing TaijaParallel\npllr = ThreadsParallelizer()\nbmk = benchmark(\n  counterfactual_data; \n  parallelizer = pllr\n)\n\nTaijaParallel.jl adds support for parallelization. Join Friday 11:50‚Äì12:00, Else (1.3)"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#student-contributions",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#student-contributions",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Student Contributions",
    "text": "Student Contributions\n\nSupport for multi-class problems.\nSupport for more scalable Hessian approximations.\nInterface to MLJ for easy model training and evaluation.\n\n\n\n\n\n\n\nFigure¬†7: Hessian approximations. Source: Daxberger et al. (2021)\n\n\n\n\nCheck out their blog post!"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#ongoing-work",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#ongoing-work",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Ongoing Work",
    "text": "Ongoing Work\nTaija has been running two Julia Season of Code projects this summer.\n\n(Conformal Bayes) Bridging the gap between Bayesian and frequentist approaches to Predictive Uncertainty Quantification with @Rockdeldiablo and co-supervisor @MojiFarmanbar\n(Causal Recourse) From minimal perturbations to minimal interventions for Algorithmic Recourse with @JorgeLuizFranco and co-supervisor @mschauer."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#student-testimonials",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#student-testimonials",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Student Testimonials",
    "text": "Student Testimonials\nStudents have generally been enthusiastic about their experience with Julia and Taija:\n\n‚ÄúProgramming in Julia has definitely helped us become better programmers. [‚Ä¶] whenever we had such questions and asked them [to] the wider Julia community, there were always people ready to help in my experience, which was nice.‚Äù\n‚Äî @RaunoArike"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#get-involved",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#get-involved",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "Get Involved",
    "text": "Get Involved\n\nWorking on related projects?\nInterested in contributing to Taija?\nWant to learn more about Trustworthy AI in Julia?\nAny suggestions or feedback?\n\n\nGet in touch with me or any of the contributors! Join our #taija channel on the JuliaLang Slack or visit our GitHub organization."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/taija-update/presentation.html#references",
    "href": "content/talks/posts/2024-juliacon/taija-update/presentation.html#references",
    "title": "What‚Äôs new in Trustworthy AI in JuliA?",
    "section": "References",
    "text": "References\n\n\n\n\nAltmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia CS Liem. 2023. ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse.‚Äù In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 418‚Äì31. IEEE.\n\n\nAltmeyer, Patrick, Andrew M. Demetriou, Antony Bartlett, and Cynthia C. S. Liem. 2024. ‚ÄúPosition Paper: Against Spurious Sparks-Dovelating Inflated AI Claims.‚Äù https://arxiv.org/abs/2402.03962.\n\n\nAltmeyer, Patrick, Arie van Deursen, et al. 2023. ‚ÄúExplaining Black-Box Models Through Counterfactuals.‚Äù In Proceedings of the JuliaCon Conferences, 1:130. 1.\n\n\nDaxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. ‚ÄúLaplace Redux-Effortless Bayesian Deep Learning.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nHengst, Floris den, Ralf Wolter, Patrick Altmeyer, and Arda Kaygan. 2024. ‚ÄúConformal Intent Classification and Clarification for Fast and Accurate Intent Recognition.‚Äù https://arxiv.org/abs/2403.18973.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nSchut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nZagorac, Ivor. 2024. ‚ÄúA Study on Counterfactual Explanations: Investigating the Impact of Inter-Class Distance and Data Imbalance.‚Äù"
  },
  {
    "objectID": "content/talks/posts/2024-aaai/index.html",
    "href": "content/talks/posts/2024-aaai/index.html",
    "title": "Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals",
    "section": "",
    "text": "In February 2024, I will present our work on Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals at AAAI 2024."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/index.html#slides",
    "href": "content/talks/posts/2024-aaai/index.html#slides",
    "title": "Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals",
    "section": "Slides",
    "text": "Slides\nYou can find the slides below or click here to open them in full screen.\nFor the PDF version of the slides use this link instead.\nFor more information about the paper see also here or the preprint of the paper itself."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/index.html#poster",
    "href": "content/talks/posts/2024-aaai/index.html#poster",
    "title": "Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals",
    "section": "Poster",
    "text": "Poster\nYou can find the poster below or click here to open it in full screen."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/index.html",
    "href": "content/talks/posts/2023-insurance-academy/index.html",
    "title": "Faithful Model Explanations",
    "section": "",
    "text": "In October 2023, I presented some of our work at the Datamiddag 2023: van PET tot Haring organized by the Dutch Association of Insurers (Verbond van Verzekeraas). You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/index.html",
    "href": "content/talks/posts/2022-julia-eindhoven/index.html",
    "title": "A year of using Quarto with Julia",
    "section": "",
    "text": "In November, 2022, I gave talked about how I‚Äôve been using Quarto with Julia for the past year. You can find the slides below or click here to open them in full screen. There is also a companion blog post here"
  },
  {
    "objectID": "content/talks/posts/2024-imperial/index.html",
    "href": "content/talks/posts/2024-imperial/index.html",
    "title": "Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals",
    "section": "",
    "text": "You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2023-ictopen/index.html",
    "href": "content/talks/posts/2023-ictopen/index.html",
    "title": "Taija - Trustworthy AI in Julia",
    "section": "",
    "text": "In April 2023, I gave a demo at the NWO ICT.Open about our ongoing efforts to build and grow Taija: an Open-Source ecosystem for Trustworthy Artificial Intelligence in Julia. You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/index.html",
    "href": "content/talks/posts/2023-dnb/index.html",
    "title": "Faithful Model Explanations",
    "section": "",
    "text": "In November 2023, I presented some of our work at the Dutch Central Bank (De Nederlandsche Bank). You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2024-turing/index.html",
    "href": "content/talks/posts/2024-turing/index.html",
    "title": "Trustworthy AI in Julia",
    "section": "",
    "text": "You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/index.html",
    "href": "content/talks/posts/2024-econdat/index.html",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "",
    "text": "You can find the slides below or click here to open them in full screen.\nFor more information about the paper see also here or the preprint of the paper itself."
  },
  {
    "objectID": "content/talks/posts/2022-boe/index.html",
    "href": "content/talks/posts/2022-boe/index.html",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "",
    "text": "In November 2022, I gave a New Methods Seminar at the Bank of England. You can find the slides below or click here to open them in a new tab."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/quarto.html#quarto-a-new-old-way-to-publish-science",
    "href": "content/talks/posts/2022-juliacon/quarto.html#quarto-a-new-old-way-to-publish-science",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "Quarto ‚Äì A New (Old) Way to Publish Science",
    "text": "Quarto ‚Äì A New (Old) Way to Publish Science\n\nHave used R Markdown for many years for essentially anything work-related.\nGenerate multiple different output formats with ease:\n\nThe old school: LaTeX and PDF (including Beamer); MS Office\nThe brave new world: beautiful HTML content\n\nwebsites\ne-books\napps\n‚Ä¶\n\n\nAll of this starting from the same place ‚Ä¶\n\n\nA plain Markdown document blended with your favourite programming language of your choice and a YAML header defining your output."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/quarto.html#julia-and-quarto-a-perfect-match",
    "href": "content/talks/posts/2022-juliacon/quarto.html#julia-and-quarto-a-perfect-match",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "Julia and Quarto: a perfect match üíôüíúüíö",
    "text": "Julia and Quarto: a perfect match üíôüíúüíö\n\n\n\nPreferred setup: VSCode, Quarto and Julia\n\nCan switch between Jupyter and .qmd with ease.\nWhen working with .qmd, code chunks connect to REPL.\n\n\n\nDocumenter.jl and Quarto\n\nGenerally play nicely with each other (both Markdown based).\n\nformat: \n  commonmark:\n    variant: -raw_html\n\nYou get some stuff for free, e.g.¬†citation management.\nUnfotunately lose support for cross-referencing ‚Ä¶\n\n\n\nSuggestion: Quarto for JuliaCon Proceedings\n\nQuarto supports LaTex templates/classes ‚Ä¶\n‚Ä¶ but why only publish proceedings in PDF form?\nQuarto opens gateway to more innovative forms of publishing!\n\n\n\n\n\nCode\nusing Javis, Animations, Colors\nwww_path = \"www\"\n\nsize = 600\nradius_factor = 0.33\n\nfunction ground(args...)\n    background(\"transparent\")\n    sethue(\"white\")\nend\n\nfunction rotate_anim(idx::Number, total::Number) \n    distance_circle = 0.875\n    steps = collect(range(distance_circle,1-distance_circle,length=total))\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [0, steps[idx]*2œÄ],\n        [sineio()],\n    )\nend\n\ntranslate_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(size*radius_factor, 0)],\n    [sineio()],\n)\n\ntranslate_back_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(-(size*radius_factor), 0)],\n    [sineio()],\n)\n\njulia_colours = Dict(\n    :blue =&gt; \"#4063D8\",\n    :green =&gt; \"#389826\",\n    :purple =&gt; \"#9558b2\",\n    :red =&gt; \"#CB3C33\"\n)\ncolour_order = [:red, :purple, :green, :blue]\nn_colours = length(julia_colours)\nfunction color_anim(start_colour::String, quarto_col::String=\"#4b95d0\")\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [Lab(color(start_colour)), Lab(color(quarto_col))],\n        [sineio()],\n    )\nend\n\nvideo = Video(size, size)\n\nframe_starts = 1:10:40\nn_total = 250\nn_frames = 150\nBackground(1:n_total, ground)\n\n# Blob:\nfunction element(; radius = 1)\n    circle(O, radius, :fill) # The 4 is to make the circle not so small\nend\n\n# Cross:\nfunction cross(color=\"black\";orientation=:horizontal)\n    sethue(color)\n    setline(10)\n    if orientation==:horizontal\n        out = line(Point(-size,0),Point(size,0), :stroke)\n    else\n        out = line(Point(0,-size),Point(0,size), :stroke)\n    end\n    return out\nend\n\nfor (i, frame_start) in enumerate(1:10:40)\n\n    # Julia circles:\n    blob = Object(frame_start:n_total, (args...;radius=1) -&gt; element(;radius=radius))\n    act!(blob, Action(1:Int(round(n_frames*0.25)), change(:radius, 1 =&gt; 75))) # scale up\n    act!(blob, Action(n_frames:(n_frames+50), change(:radius, 75 =&gt; 250))) # scale up further\n    act!(blob, Action(1:30, translate_anim, translate()))\n    act!(blob, Action(31:120, rotate_anim(i, n_colours), rotate_around(Point(-(size*radius_factor), 0))))\n    act!(blob, Action(121:150, translate_back_anim, translate()))\n    act!(blob, Action(1:150, color_anim(julia_colours[colour_order[i]]), sethue()))\n\n    # Quarto cross:\n    cross_h = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:horizontal))\n    cross_v = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:vertical))\nend\n\nrender(\n    video;\n    pathname = joinpath(www_path, \"intro.gif\"),\n)\n\n\n\n\n\n\n\n\nFigure¬†1: Julia and Quarto: a perfect match. Image by author (heavily borrowing from Javis.jl tutorial)"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/quarto.html#more-resources",
    "href": "content/talks/posts/2022-juliacon/quarto.html#more-resources",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nRelated blog post (hosted on a blog that itself is built with Quarto and involves lots of Julia content).\nExamples of Julia package documentation I‚Äôve built with Quarto + Documenter.jl:\n\nCounterfactualExplanations.jl\nLaplaceRedux.jl\n\nQuarto‚Äôs own guide to using Quarto with Julia."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/index.html",
    "href": "content/talks/posts/2022-juliacon/index.html",
    "title": "JuliaCon 2022",
    "section": "",
    "text": "In July, 2022, I gave three different talks at JuliaCon 2022."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/index.html#explaining-black-box-models-through-counterfactuals",
    "href": "content/talks/posts/2022-juliacon/index.html#explaining-black-box-models-through-counterfactuals",
    "title": "JuliaCon 2022",
    "section": "Explaining Black-Box Models through Counterfactuals",
    "text": "Explaining Black-Box Models through Counterfactuals\nYou can watch the video below. See here for the slides."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/index.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "href": "content/talks/posts/2022-juliacon/index.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "title": "JuliaCon 2022",
    "section": "Effortless Bayesian Deep Learning through Laplace Redux",
    "text": "Effortless Bayesian Deep Learning through Laplace Redux\nYou can watch the video below. See here for the slides."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/index.html#julia-and-quarto-a-match-made-in-heaven",
    "href": "content/talks/posts/2022-juliacon/index.html#julia-and-quarto-a-match-made-in-heaven",
    "title": "JuliaCon 2022",
    "section": "Julia and Quarto: a Match Made in Heaven? üå§Ô∏è",
    "text": "Julia and Quarto: a Match Made in Heaven? üå§Ô∏è\nSee here for the slides."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/index.html",
    "href": "content/talks/posts/2023-juliacon/index.html",
    "title": "Predictive Uncertainty Quantification in Machine Learning",
    "section": "",
    "text": "In July 2023, I gave a talk at JuliaCon 2023 on Predictive Uncertainty Quantification in Machine Learning using ConformalPrediction.jl. The conference was held in person at MIT in Cambridge, Massachusetts. You can find the slides below or click here to open them in full screen."
  },
  {
    "objectID": "content/news.html",
    "href": "content/news.html",
    "title": "patalt",
    "section": "",
    "text": "News\n\nOn May 7-8, I‚Äôll be presenting some of my PhD research at the DSCNext Conference Europe 2025.\nTaija, the organization that hosts software geared towards Trustworthy Artificial Intelligence in Julia, has its own website now: www.taija.org. The ecosystem keeps slowly growing. If you‚Äôre interested in contributing, please get in touch!\nIn July 2024, I presented our position paper ‚ÄúStop Making Unscientific AGI Performance Claims‚Äù at ICML 2024. We argue that finding patterns in latent embeddings of models like LLMs is not surprising and call for the academic community to exercise extra caution when interpreting such findings. [preprint], [blog post], [slides/poster]\nIn May 2024, I was in London to present research at ECONDAT 2024 (King‚Äôs College London), The Alan Turing Institute and Imperial College London.\nIn Frebruary 2024, I attended AAAI 2024 in Vancouver, Canada presenting our work on Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals. If you‚Äôre around, come say hi! [preprint], [blog], [TDS], [code], [slides/poster]\n\n\n\nFeatured Visual\n\n\n\nOne of my favorite illustrations of how our recently proposed ECCCo counterfactual generator works compared to Wachter: gradient fields and counterfactual paths for Wachter, ECCCo (no energy constraint), ECCCo (no conformal prediction), ECCCo (full objective)."
  },
  {
    "objectID": "content/publications/posts/icml-2024/index.html",
    "href": "content/publications/posts/icml-2024/index.html",
    "title": "Position: Stop Making Unscientific AGI Performance Claims",
    "section": "",
    "text": "Developments in the field of AI in general, and Large Language Models (LLMs) in particular, have created a ‚Äòperfect storm‚Äô for observing ‚Äòsparks‚Äô of Artificial General Intelligence (AGI) that are spurious. Like simpler models, LLMs distill representations in their latent embeddings that have been shown to correlate with meaningful phenomena. Nonetheless, the correlation of such representations has often been linked to human-like intelligence in the latter but not the former. We probe models of varying degrees of sophistication including random projections, matrix decompositions, deep autoencoders and transformers: all of them successfully distill knowledge and yet none of them develop true understanding. Specifically, we show that embeddings of a language model fine-tuned on central bank communications can make meaningful predictions, via correlations with unseen economic variables, such as price inflation. However, we then show that inflation is also predicted for nonsense prompts about growing and shrinking bird populations (‚Äòdovelation‚Äô). We therefore argue that patterns in latent spaces are spurious sparks of AGI. Additionally, we review literature from the social sciences that shows that humans are prone to seek patterns and anthropomorphize. We, therefore, argue that both the methodological setup and common public image of AI are ideal for the misinterpretation that correlations between model representations and some variables of interest are ‚Äòcaused‚Äô by the model‚Äôs understanding of underlying ‚Äòground truth‚Äô relationships. We therefore call for the academic community to exercise extra caution, and to be keenly aware of principles of academic integrity, in interpreting and communicating about AI research outcomes.\nFull paper: please find all available versions here (preprint).\nBlog post: please find a blog post summarizing the paper here."
  },
  {
    "objectID": "content/publications/posts/icml-2024/index.html#abstract",
    "href": "content/publications/posts/icml-2024/index.html#abstract",
    "title": "Position: Stop Making Unscientific AGI Performance Claims",
    "section": "",
    "text": "Developments in the field of AI in general, and Large Language Models (LLMs) in particular, have created a ‚Äòperfect storm‚Äô for observing ‚Äòsparks‚Äô of Artificial General Intelligence (AGI) that are spurious. Like simpler models, LLMs distill representations in their latent embeddings that have been shown to correlate with meaningful phenomena. Nonetheless, the correlation of such representations has often been linked to human-like intelligence in the latter but not the former. We probe models of varying degrees of sophistication including random projections, matrix decompositions, deep autoencoders and transformers: all of them successfully distill knowledge and yet none of them develop true understanding. Specifically, we show that embeddings of a language model fine-tuned on central bank communications can make meaningful predictions, via correlations with unseen economic variables, such as price inflation. However, we then show that inflation is also predicted for nonsense prompts about growing and shrinking bird populations (‚Äòdovelation‚Äô). We therefore argue that patterns in latent spaces are spurious sparks of AGI. Additionally, we review literature from the social sciences that shows that humans are prone to seek patterns and anthropomorphize. We, therefore, argue that both the methodological setup and common public image of AI are ideal for the misinterpretation that correlations between model representations and some variables of interest are ‚Äòcaused‚Äô by the model‚Äôs understanding of underlying ‚Äòground truth‚Äô relationships. We therefore call for the academic community to exercise extra caution, and to be keenly aware of principles of academic integrity, in interpreting and communicating about AI research outcomes.\nFull paper: please find all available versions here (preprint).\nBlog post: please find a blog post summarizing the paper here."
  },
  {
    "objectID": "content/publications/posts/aaai-2024/index.html",
    "href": "content/publications/posts/aaai-2024/index.html",
    "title": "Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals",
    "section": "",
    "text": "Counterfactual explanations offer an intuitive and straightforward way to explain black-box models and offer algorithmic recourse to individuals. To address the need for plausible explanations, existing work has primarily relied on surrogate models to learn how the input data is distributed. This effectively reallocates the task of learning realistic explanations for the data from the model itself to the surrogate. Consequently, the generated explanations may seem plausible to humans but need not necessarily describe the behaviour of the black-box model faithfully. We formalise this notion of faithfulness through the introduction of a tailored evaluation metric and propose a novel algorithmic framework for generating Energy-Constrained Conformal Counterfactuals that are only as plausible as the model permits. Through extensive empirical studies, we demonstrate that ECCCo reconciles the need for faithfulness and plausibility. In particular, we show that for models with gradient access, it is possible to achieve state-of-the-art performance without the need for surrogate models. To do so, our framework relies solely on properties defining the black-box model itself by leveraging recent advances in energy-based modelling and conformal prediction. To our knowledge, this is the first venture in this direction for generating faithful counterfactual explanations. Thus, we anticipate that ECCCo can serve as a baseline for future research. We believe that our work opens avenues for researchers and practitioners seeking tools to better distinguish trustworthy from unreliable models.\nFull paper: please find all available versions here (preprint)."
  },
  {
    "objectID": "content/publications/posts/aaai-2024/index.html#abstract",
    "href": "content/publications/posts/aaai-2024/index.html#abstract",
    "title": "Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals",
    "section": "",
    "text": "Counterfactual explanations offer an intuitive and straightforward way to explain black-box models and offer algorithmic recourse to individuals. To address the need for plausible explanations, existing work has primarily relied on surrogate models to learn how the input data is distributed. This effectively reallocates the task of learning realistic explanations for the data from the model itself to the surrogate. Consequently, the generated explanations may seem plausible to humans but need not necessarily describe the behaviour of the black-box model faithfully. We formalise this notion of faithfulness through the introduction of a tailored evaluation metric and propose a novel algorithmic framework for generating Energy-Constrained Conformal Counterfactuals that are only as plausible as the model permits. Through extensive empirical studies, we demonstrate that ECCCo reconciles the need for faithfulness and plausibility. In particular, we show that for models with gradient access, it is possible to achieve state-of-the-art performance without the need for surrogate models. To do so, our framework relies solely on properties defining the black-box model itself by leveraging recent advances in energy-based modelling and conformal prediction. To our knowledge, this is the first venture in this direction for generating faithful counterfactual explanations. Thus, we anticipate that ECCCo can serve as a baseline for future research. We believe that our work opens avenues for researchers and practitioners seeking tools to better distinguish trustworthy from unreliable models.\nFull paper: please find all available versions here (preprint)."
  },
  {
    "objectID": "content/publications/posts/boe/index.html",
    "href": "content/publications/posts/boe/index.html",
    "title": "Yield curve sensitivity to investor positioning around economic shocks",
    "section": "",
    "text": "Speculative trading activity may either support efficient market functioning or introduce price distortions. Using granular, daily EMIR Trade Repository data on short sterling futures, we investigate the interaction of speculative trading and macroeconomic shocks on UK yield curve pricing over a 16-month sample period from 2018 to 2020. Our results are largely consistent with efficient market functioning throughout the period, although we find some evidence that short speculative positions amplified yield curve moves in response to Brexit shocks, while long speculative positions had a dampening effect.\nFull paper: please find all available versions here."
  },
  {
    "objectID": "content/publications/posts/boe/index.html#abstract",
    "href": "content/publications/posts/boe/index.html#abstract",
    "title": "Yield curve sensitivity to investor positioning around economic shocks",
    "section": "",
    "text": "Speculative trading activity may either support efficient market functioning or introduce price distortions. Using granular, daily EMIR Trade Repository data on short sterling futures, we investigate the interaction of speculative trading and macroeconomic shocks on UK yield curve pricing over a 16-month sample period from 2018 to 2020. Our results are largely consistent with efficient market functioning throughout the period, although we find some evidence that short speculative positions amplified yield curve moves in response to Brexit shocks, while long speculative positions had a dampening effect.\nFull paper: please find all available versions here."
  },
  {
    "objectID": "content/publications/posts/satml-2023/index.html",
    "href": "content/publications/posts/satml-2023/index.html",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "",
    "text": "Existing work on Counterfactual Explanations (CE) and Algorithmic Recourse (AR) has largely focused on single individuals in a static environment: given some estimated model, the goal is to find valid counterfactuals for an individual instance that fulfill various desiderata. The ability of such counterfactuals to handle dynamics like data and model drift remains a largely unexplored research challenge. There has also been surprisingly little work on the related question of how the actual implementation of recourse by one individual may affect other individuals. Through this work, we aim to close that gap. We first show that many of the existing methodologies can be collectively described by a generalized framework. We then argue that the existing framework does not account for a hidden external cost of recourse, that only reveals itself when studying the endogenous dynamics of recourse at the group level. Through simulation experiments involving various state-of-the-art counterfactual generators and several benchmark datasets, we generate large numbers of counterfactuals and study the resulting domain and model shifts. We find that the induced shifts are substantial enough to likely impede the applicability of Algorithmic Recourse in some situations. Fortunately, we find various strategies to mitigate these concerns. Our simulation framework for studying recourse dynamics is fast and open-sourced.\nFull paper: please find all available versions here.\n\n\n\nPhoto taken during poster session following my presentation at SaTML."
  },
  {
    "objectID": "content/publications/posts/satml-2023/index.html#abstract",
    "href": "content/publications/posts/satml-2023/index.html#abstract",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "",
    "text": "Existing work on Counterfactual Explanations (CE) and Algorithmic Recourse (AR) has largely focused on single individuals in a static environment: given some estimated model, the goal is to find valid counterfactuals for an individual instance that fulfill various desiderata. The ability of such counterfactuals to handle dynamics like data and model drift remains a largely unexplored research challenge. There has also been surprisingly little work on the related question of how the actual implementation of recourse by one individual may affect other individuals. Through this work, we aim to close that gap. We first show that many of the existing methodologies can be collectively described by a generalized framework. We then argue that the existing framework does not account for a hidden external cost of recourse, that only reveals itself when studying the endogenous dynamics of recourse at the group level. Through simulation experiments involving various state-of-the-art counterfactual generators and several benchmark datasets, we generate large numbers of counterfactuals and study the resulting domain and model shifts. We find that the induced shifts are substantial enough to likely impede the applicability of Algorithmic Recourse in some situations. Fortunately, we find various strategies to mitigate these concerns. Our simulation framework for studying recourse dynamics is fast and open-sourced.\nFull paper: please find all available versions here.\n\n\n\nPhoto taken during poster session following my presentation at SaTML."
  },
  {
    "objectID": "content/publications/posts/jcon-ce/index.html",
    "href": "content/publications/posts/jcon-ce/index.html",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "",
    "text": "We present CounterfactualExplanations.jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia. CE explain how inputs into a model need to change to yield specific model predictions. Explanations that involve realistic and actionable changes can be used to provide AR: a set of proposed actions for individuals to change an undesirable outcome for the better. In this article, we discuss the usefulness of CE for Explainable Artificial Intelligence and demonstrate the functionality of our package. The package is straightforward to use and designed with a focus on customization and extensibility. We envision it to one day be the go-to place for explaining arbitrary predictive models in Julia through a diverse suite of counterfactual generators.\nFull paper: please find all available versions here."
  },
  {
    "objectID": "content/publications/posts/jcon-ce/index.html#abstract",
    "href": "content/publications/posts/jcon-ce/index.html#abstract",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "",
    "text": "We present CounterfactualExplanations.jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia. CE explain how inputs into a model need to change to yield specific model predictions. Explanations that involve realistic and actionable changes can be used to provide AR: a set of proposed actions for individuals to change an undesirable outcome for the better. In this article, we discuss the usefulness of CE for Explainable Artificial Intelligence and demonstrate the functionality of our package. The package is straightforward to use and designed with a focus on customization and extensibility. We envision it to one day be the go-to place for explaining arbitrary predictive models in Julia through a diverse suite of counterfactual generators.\nFull paper: please find all available versions here."
  },
  {
    "objectID": "content/publications/index.html",
    "href": "content/publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "Below you may find a list of featured publications. For a full list, see my Google Scholar profile.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Year - Oldest\n        \n         \n          Year - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nYear\n\n\nVenue\n\n\nDescription\n\n\n\n\n\n\nPosition: Stop Making Unscientific AGI Performance Claims\n\n\n2024\n\n\nForty-first International Conference on Machine Learning (ICML)\n\n\nWe call for the academic community to exercise caution in interpreting and communicating about AI research outcomes.\n\n\n\n\nFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals\n\n\n2024\n\n\nThe 38th Annual AAAI Conference on Artificial Intelligence\n\n\nWe present a novel framework for generating faithful counterfactual explanations that solely on properties defining the black-box model itself by leveraging recent advances in energy-based modelling and conformal prediction.\n\n\n\n\nExplaining Black-Box Models through Counterfactuals\n\n\n2023\n\n\nJuliaCon Proceedings\n\n\nWe present CounterfactualExplanations.jl: a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box models in Julia.\n\n\n\n\nYield curve sensitivity to investor positioning around economic shocks\n\n\n2023\n\n\nBank of England Staff Working Paper\n\n\nUsing granular, daily EMIR Trade Repository data on short sterling futures, we investigate the interaction of speculative trading and macroeconomic shocks on UK yield curve pricing.\n\n\n\n\nEndogenous Macrodynamics in Algorithmic Recourse\n\n\n2023\n\n\nIEEE Conference on Secure and Trustworthy Machine Learning (SaTML)\n\n\nWe present evidence suggesting that state-of-the-art applications of Algorithmic Recourse to groups of individuals induce large domain and model shifts and propose ways to mitigate this.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#talk-agenda",
    "href": "content/talks/posts/2023-juliacon/presentation.html#talk-agenda",
    "title": "ConformalPrediction.jl",
    "section": "Talk Agenda1",
    "text": "Talk Agenda1\n\n\n\nIntroduction (5min)\nApplications (5min)\nInteractive demo of ConformalPrediction.jl (10min)\nUnder Construction (5min)\nQ&A\n\n\n\nCode along üíª tinyurl.com/cpjcon2023\n\n\n\n\nFeeling lucky? Use binder!\n\n\n\nLink to slides: tinyurl.com/cpjcon2023slides"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-prediction",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-prediction",
    "title": "ConformalPrediction.jl",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nConformal Prediction involves turning heuristic measures of Predictive Uncertainty into rigorous ones.\n\n\n\nA first crucial step towards building trustworthy AI systems is to be transparent about predictive uncertainty."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#example-split-cp",
    "href": "content/talks/posts/2023-juliacon/presentation.html#example-split-cp",
    "title": "ConformalPrediction.jl",
    "section": "Example: Split CP",
    "text": "Example: Split CP\n\nProper training set and separate calibration set: \\(\\mathcal{D}_n=\\mathcal{D}^{\\text{train}} \\cup \\mathcal{D}^{\\text{cali}}\\).\nTrain model on proper training set: \\(\\hat\\mu_{i \\in \\mathcal{D}^{\\text{train}}}(X_i,Y_i)\\).\nCompute nonconformity scores, \\(\\mathcal{S}\\), using calibration data \\(\\mathcal{D}^{\\text{cali}}\\) and fitted model \\(\\hat\\mu_{i \\in \\mathcal{D}^{\\text{train}}}\\).\nFor user-specified coverage ratio \\((1-\\alpha)\\) compute the corresponding quantile, \\(\\hat{q}\\), of \\(\\mathcal{S}\\).\nFor the given quantile and test sample \\(X_{\\text{test}}\\), form the corresponding conformal prediction set: \\(C(X_{\\text{test}})=\\{y:s(X_{\\text{test}},y) \\le \\hat{q}\\}\\).\n\n\n\n\nBlog posts\n\n\n\nConformal Classification ([blog], [TDS], [Forem])\nConformal Regression ([blog], [TDS], [Forem])"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#split-cp-illustrated",
    "href": "content/talks/posts/2023-juliacon/presentation.html#split-cp-illustrated",
    "title": "ConformalPrediction.jl",
    "section": "Split CP illustrated",
    "text": "Split CP illustrated\n\n\n\n\n\n\nFigure¬†1: Softmax output for class 1 (top left); non-conformity scores for calibration set (top right); (1-Œ±)-quantile (bottom left); non-conformity function applied to test point (bottom right). Solid bars make it into prediction set."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#cp-meets-sr",
    "href": "content/talks/posts/2023-juliacon/presentation.html#cp-meets-sr",
    "title": "ConformalPrediction.jl",
    "section": "CP meets SR",
    "text": "CP meets SR\nRemember SymbolicRegression.jl by Miles Cranmer?\n\n\n\n\n# Standard MLJ workflow:\nusing MLJ\nimport SymbolicRegression: SRRegressor\nmodel = SRRegressor(\n  niterations=50,\n  binary_operators=[+, -, *],\n  unary_operators=[sin],\n)\n\n# Conformalize:\nusing ConformalPrediction\nconf_model = conformal_model(model)\nmach = machine(conf_model, X, y)\nfit!(mach, rows=train)"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-chatbot",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-chatbot",
    "title": "ConformalPrediction.jl",
    "section": "Conformal Chatbot",
    "text": "Conformal Chatbot\n\nOverviewDemo\n\n\n\n\n\n\n\n\nFigure¬†2: High-level overview of Conformal Intent Classifier. Won 1st üèÜ at ING Global Experiment Week 2023.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3: Demo of a REPL-based conformalized intent classifier.\n\n\n\n\nCICC substantially outperforms baseline approaches (e.g.¬†top-\\(K\\)).\n\n\n\nBlog post\n\n\nBuilding a Conformal Chatbot in Julia (blog, TDS)"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-image-classifier",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-image-classifier",
    "title": "ConformalPrediction.jl",
    "section": "Conformal Image Classifier",
    "text": "Conformal Image Classifier\n\n\nA simple MNIST classifier.\n# MLJFlux workflow:\nusing MLJFlux\nImageClassifier = @load ImageClassifier\n\n# Conformalize:\nusing ConformalPrediction\nconf_model = conformal_model(clf)\nmach = machine(conf_model, X, y)\nfit!(mach)\n\n\n\n\n\n\n\nFigure¬†4: Probably a 7 ü§î\n\n\n\n\n\n\n\nBlog post\n\n\nHow to Conformalize a Deep Image Classifier (blog, TDS, Forem)"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#time-series",
    "href": "content/talks/posts/2023-juliacon/presentation.html#time-series",
    "title": "ConformalPrediction.jl",
    "section": "Time Series",
    "text": "Time Series\n\n\nEnsemble Batch Prediction Intervals (Xu and Xie 2021) contributed by Mojtaba Farmanbar üì£.\n\n\n\nTutorial\n\n\nHow to Conformalize a Time Series Model (docs)\n\n\n\n\n\n\n\n\n\n\nFigure¬†5: EnbPI for Victoria electricity demand dataset."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-laplaceredux.jl",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-laplaceredux.jl",
    "title": "ConformalPrediction.jl",
    "section": "Conformal LaplaceRedux.jl",
    "text": "Conformal LaplaceRedux.jl\n\n\n\nPredictive posterior as heuristic (Angelopoulos and Bates 2022).\nImportance Sampling (Fong and Holmes 2021).\n\n\n\n\n\n\n\nContribute\n\n\nLaplaceRedux.jl interfaced to MLJFlux.jl. Planning to add both ideas [#64]."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#conformal-counterfactuals",
    "href": "content/talks/posts/2023-juliacon/presentation.html#conformal-counterfactuals",
    "title": "ConformalPrediction.jl",
    "section": "Conformal Counterfactuals",
    "text": "Conformal Counterfactuals\n\n\n\nStutz et al. (2022) introduce Conformal Training: conformal predictions (left), set size (centre) and smooth set size loss (right).\n\n\n\n\n\n\n\nConformal CounterfactualExplanations.jl.\n\n\n\n\n\n\nContribute\n\n\nCurrently working on full conformal training implementation [#62]."
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#trustworthy-ai-in-julia",
    "href": "content/talks/posts/2023-juliacon/presentation.html#trustworthy-ai-in-julia",
    "title": "ConformalPrediction.jl",
    "section": "Trustworthy AI in Julia",
    "text": "Trustworthy AI in Julia\n\n\nTaija collects Julia packages geared towards Trustworthy AI:\n\nCounterfactualExplanations.jl\nConformalPrediction.jl\nLaplaceRedux.jl\nJointEnergyModels.jl\n‚Ä¶\n\n\nContributions welcome! üòä"
  },
  {
    "objectID": "content/talks/posts/2023-juliacon/presentation.html#references",
    "href": "content/talks/posts/2023-juliacon/presentation.html#references",
    "title": "ConformalPrediction.jl",
    "section": "References",
    "text": "References\n\n\n\n\nAngelopoulos, Anastasios N., and Stephen Bates. 2022. ‚ÄúA Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.‚Äù https://arxiv.org/abs/2107.07511.\n\n\nFong, Edwin, and Chris Holmes. 2021. ‚ÄúConformal Bayesian Computation.‚Äù arXiv. https://doi.org/10.48550/arXiv.2106.06137.\n\n\nStutz, David, Krishnamurthy, Dvijotham, Ali Taylan Cemgil, and Arnaud Doucet. 2022. ‚ÄúLearning Optimal Conformal Classifiers.‚Äù https://arxiv.org/abs/2110.09192.\n\n\nXu, Chen, and Yao Xie. 2021. ‚ÄúConformal Prediction Interval for Dynamic Time-Series.‚Äù In, 11559‚Äì69. PMLR. https://proceedings.mlr.press/v139/xu21h.html."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#overview",
    "href": "content/talks/posts/2022-juliacon/laplace.html#overview",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Overview",
    "text": "Overview\n\n\nThe Case for Bayesian Deep Learning\nLaplace Redux in Julia üì¶\n\nFrom Bayesian Logistic Regression ‚Ä¶\n‚Ä¶ to Bayesian Neural Networks.\n\nGoals and Ambitions üéØ"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#bayesian-model-averaging",
    "href": "content/talks/posts/2022-juliacon/laplace.html#bayesian-model-averaging",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Bayesian Model Averaging",
    "text": "Bayesian Model Averaging\n\nDon‚Äôt put all your ü•ö in one üß∫.\n\n\n\nIn Deep Learning we typically maximise highly non-convex functions full of local optima and saddle points.\nThere may be many \\(\\hat\\theta_1, ..., \\hat\\theta_m\\) that are slightly different, but yield similar performance.\n\n\n\n\n[‚Ä¶] parameters correspond to a diverse variety of compelling explanations for the data. (Wilson 2020)\n\n\n\n\\(\\theta\\) is a random variable. Shouldn‚Äôt we treat it that way?\n\\[\np(y|x,\\mathcal{D}) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D})d\\theta\n\\qquad(1)\\]\n\nIntractable!\n\n\n\nIn practice we typically rely on a plugin approximation (Murphy 2022).\n\\[\np(y|x,\\mathcal{D}) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D})d\\theta \\approx p(y|x,\\hat\\theta)\n\\qquad(2)\\]\n\nYes, ‚Äúplugin‚Äù is literal ‚Ä¶ can we do better?"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#enter-bayesian-deep-learning",
    "href": "content/talks/posts/2022-juliacon/laplace.html#enter-bayesian-deep-learning",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Enter: Bayesian Deep Learning üîÆ",
    "text": "Enter: Bayesian Deep Learning üîÆ\n\nYes, we can!\n\n\n\nPopular approaches include ‚Ä¶\n\n\nMCMC (see Turing)\n\n\nVariational Inference (Blundell et al. 2015)\n\n\nMonte Carlo Dropout (Gal and Ghahramani 2016)\n\n\nDeep Ensembles (Lakshminarayanan, Pritzel, and Blundell 2017)\n\n\n\nLaplace Redux (Immer, Korzepa, and Bauer (2020),Daxberger et al. (2021))\n\n. . .\n\n\n\n\n\n\nFigure¬†1: Pierre-Simon Laplace as chancellor of the Senate under the First French Empire. Source: Wikipedia\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: Simulation of changing posteriour predictive distribution. Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#laplace-approximation",
    "href": "content/talks/posts/2022-juliacon/laplace.html#laplace-approximation",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Laplace Approximation",
    "text": "Laplace Approximation\n\nWe first need to estimate the weight posterior \\(p(\\theta|\\mathcal{D})\\) ‚Ä¶\n\n\nIdea üí°: Taylor approximation at the mode.\n\n\nGoing through the maths we find that this yields a Gaussian posteriour centered around the MAP estimate \\(\\hat\\theta\\) (see pp.¬†148/149 in Murphy (2022)).\nCovariance corresponds to inverse Hessian at the mode (in practice we may have to rely on approximations).\n\n\n\n\n\n\n\nUnnormalized log-posterior and corresponding Laplace Approximation. Source: Murphy (2022).\n\n\n\nNow we can rely on MC or Probit Approximation to compute posterior predictive (classification)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#laplaceredux.jl---a-small-package",
    "href": "content/talks/posts/2022-juliacon/laplace.html#laplaceredux.jl---a-small-package",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "LaplaceRedux.jl - a small package üì¶",
    "text": "LaplaceRedux.jl - a small package üì¶\n  \n\nWhat started out as my first coding project Julia ‚Ä¶\n\n\n\nBig fan of learning by coding so after reading the first chapters of Murphy (2022) I decided to code up Bayesian Logisitic Regression from scratch.\nI also wanted to learn Julia at the time, so tried to hit two birds with one stone.\nOutcome: 1. This blog post. 2. I have since been hooked on Julia.\n\n\n\n\n‚Ä¶ has turned into a small package üì¶ with great potential.\n\n\n\nWhen coming across the NeurIPS 2021 paper on Laplace Redux for deep learning (Daxberger et al. 2021), I figured I could step it up a notch.\nOutcome: LaplaceRedux.jl and another blog post.\n\n\n\n\nSo let‚Äôs add the package ‚Ä¶\nusing Pkg\nPkg.add(\"https://github.com/juliatrustworthyai/LaplaceRedux.jl\")\n‚Ä¶ and use it.\n\nusing LaplaceRedux"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#from-bayesian-logistic-regression",
    "href": "content/talks/posts/2022-juliacon/laplace.html#from-bayesian-logistic-regression",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "From Bayesian Logistic Regression ‚Ä¶",
    "text": "From Bayesian Logistic Regression ‚Ä¶\n\n\nFrom maths ‚Ä¶\n. . .\nWe assume a Gaussian prior for our weights ‚Ä¶ \\[\np(\\theta) \\sim \\mathcal{N} \\left( \\theta | \\mathbf{0}, \\lambda^{-1} \\mathbf{I} \\right)=\\mathcal{N} \\left( \\theta | \\mathbf{0}, \\mathbf{H}_0^{-1} \\right)\n\\qquad(3)\\]\n. . .\n‚Ä¶ which corresponds to logit binary crossentropy loss with weight decay:\n\\[\n\\ell(\\theta)= - \\sum_{n}^N [y_n \\log \\mu_n + (1-y_n)\\log (1-\\mu_n)] + \\\\ \\frac{1}{2} (\\theta-\\theta_0)^T\\mathbf{H}_0(\\theta-\\theta_0)\n\\qquad(4)\\]\n. . .\nFor Logistic Regression we have the Hessian in closed form (p.¬†338 in Murphy (2022)):\n\\[\n\\nabla_{\\theta}\\nabla_{\\theta}^\\mathsf{T}\\ell(\\theta) = \\frac{1}{N} \\sum_{n}^N(\\mu_n(1-\\mu_n)\\mathbf{x}_n)\\mathbf{x}_n^\\mathsf{T} + \\mathbf{H}_0\n\\qquad(5)\\]\n\n‚Ä¶ to code\n. . .\n# Hessian:\nfunction ‚àá‚àáùìÅ(Œ∏,Œ∏_0,H_0,X,y)\n    N = length(y)\n    Œº = sigmoid(Œ∏,X)\n    H = ‚àë(Œº[n] * (1-Œº[n]) * X[n,:] * X[n,:]' for n=1:N)\n    return H + H_0\nend\n\nGotta love Julia ‚ù§Ô∏èüíúüíö\n\n. . .\nLogistic Regression can be done in Flux ‚Ä¶\n\nusing Flux\n# Initializing weights as zeros only for illustrative purposes:\nnn = Chain(Dense(zeros(1,2),zeros(1)))\n\n. . .\n‚Ä¶ but now we autograd! Leveraged in LaplaceRedux.\n\nla = Laplace(nn, Œª=Œª)\nfit!(la, data)\n\n\n\n\n\n\n\nFigure¬†3: Posterior predictive distribution of Logistic regression in the 2D feature space using plugin estimator (left) and Laplace approximation (right). Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#to-bayesian-neural-networks",
    "href": "content/talks/posts/2022-juliacon/laplace.html#to-bayesian-neural-networks",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "‚Ä¶ to Bayesian Neural Networks",
    "text": "‚Ä¶ to Bayesian Neural Networks\n\n\nCode\n. . .\nAn actual MLP ‚Ä¶\n\n# Build MLP:\nn_hidden = 32\nD = size(X)[1]\nnn = Chain(\n    Dense(\n      randn(n_hidden,D)./10,\n      zeros(n_hidden), œÉ\n    ),\n    Dense(\n      randn(1,n_hidden)./10,\n      zeros(1)\n    )\n)\n\n. . .\n‚Ä¶ same API call:\n\nla = Laplace(\n  nn, Œª=Œª, \n  subset_of_weights=:last_layer\n)\nfit!(la, data)\n\n. . .\n\nResults\n. . .\n\n\n\n\n\n\nFigure¬†4: Posterior predictive distribution of MLP in the 2D feature space using plugin estimator (left) and Laplace approximation (right). Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#a-quick-note-on-the-prior",
    "href": "content/talks/posts/2022-juliacon/laplace.html#a-quick-note-on-the-prior",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "A quick note on the prior",
    "text": "A quick note on the prior\nLow prior uncertainty \\(\\rightarrow\\) posterior dominated by prior. High prior uncertainty \\(\\rightarrow\\) posterior approaches MLE.\nLogistic Regression\n\n\n\n\n\n\nFigure¬†5: Prior uncertainty increases from left to right (Logsitic Regression). Image by author.\n\n\n\nMLP\n\n\n\n\n\n\nFigure¬†6: Prior uncertainty increases from left to right (MLP). Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#a-crucial-detail-i-skipped",
    "href": "content/talks/posts/2022-juliacon/laplace.html#a-crucial-detail-i-skipped",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "A crucial detail I skipped",
    "text": "A crucial detail I skipped\n\nWe‚Äôre really been using linearized neural networks ‚Ä¶\n\n\n\n\nMC fails\n\n\nCould do Monte Carlo for true BNN predictive, but this performs poorly when using approximations for the Hessian.\nInstead we rely on linear expansion of predictive around mode (Immer, Korzepa, and Bauer 2020).\nIntuition: Hessian approximation involves linearization, then so should the predictive.\n\n\n. . .\n\nApplying the GNN approximation [‚Ä¶] turns the underlying probabilistic model locally from a BNN into a GLM [‚Ä¶] Because we have effectively done inference in the GGN-linearized model, we should instead predict using these modified features. ‚Äî Immer, Korzepa, and Bauer (2020)\n\n\n\n\n\n\n\n\nFigure¬†7: MC samples from the Laplace posterior (Lawrence 2001)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#juliacon-2022-and-beyond",
    "href": "content/talks/posts/2022-juliacon/laplace.html#juliacon-2022-and-beyond",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "JuliaCon 2022 and beyond",
    "text": "JuliaCon 2022 and beyond\n\n\n\nTo JuliaCon ‚Ä¶\n\nLearn about Laplace Redux by implementing it in Julia.\n\n\nTurn code into a small package.\n\n\nSubmit to JuliaCon 2022 and share the idea.\n\n\n‚Ä¶ and beyond\n. . .\nPackage is bare-bones at this point and needs a lot of work.\n\n\nGoal: reach same level of maturity as Python counterpart. (Beautiful work btw!)\nProblem: limited capacity and fairly new to Julia.\nSolution: find contributors ü§ó.\n\n\n\n\n\n\nPhoto by Ivan Diaz on Unsplash"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#specific-goals",
    "href": "content/talks/posts/2022-juliacon/laplace.html#specific-goals",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "Specific Goals",
    "text": "Specific Goals\n\n\nEasy\n\nStill missing support for multi-class and regression.\nDue diligence: peer review and unit testing.\n\nHarder\n\nHessian approximations still quadratically large: use factorizations.\nHyperparameter tuning: what about that prior?\nScaling things up: subnetwork inference.\nEarly stopping: do we really end up at the mode?\n‚Ä¶\n\n\n\n\n\nSource: Giphy"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#more-resources",
    "href": "content/talks/posts/2022-juliacon/laplace.html#more-resources",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nBlog post (1) ‚Äì Bayesian Logisitic Regression: [TDS, homepage].\nBlog post (2) ‚Äì Bayesian Deep Learning: [TDS, homepage].\nDetailed slide pack generously shared by Professor Jos√© Miguel Hern√°ndez-Lobato: [pdf]\nPackage docs.\n\n\n‚Ä¶ or even better: get involved! ü§ó"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/laplace.html#references",
    "href": "content/talks/posts/2022-juliacon/laplace.html#references",
    "title": "Effortless Bayesian Deep Learning through Laplace Redux",
    "section": "References",
    "text": "References\n\n\n\n\nBlundell, Charles, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. 2015. ‚ÄúWeight Uncertainty in Neural Network.‚Äù In International Conference on Machine Learning, 1613‚Äì22. PMLR.\n\n\nDaxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. ‚ÄúLaplace Redux-Effortless Bayesian Deep Learning.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nGal, Yarin, and Zoubin Ghahramani. 2016. ‚ÄúDropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning.‚Äù In International Conference on Machine Learning, 1050‚Äì59. PMLR.\n\n\nImmer, Alexander, Maciej Korzepa, and Matthias Bauer. 2020. ‚ÄúImproving Predictions of Bayesian Neural Networks via Local Linearization.‚Äù https://arxiv.org/abs/2008.08400.\n\n\nLakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2017. ‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù In Proceedings of the 31st International Conference on Neural Information Processing Systems, 6405‚Äì16. NIPS‚Äô17. Red Hook, NY, USA: Curran Associates Inc.\n\n\nLawrence, Neil David. 2001. ‚ÄúVariational Inference in Probabilistic Models.‚Äù PhD thesis, University of Cambridge.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nWilson, Andrew Gordon. 2020. ‚ÄúThe Case for Bayesian Deep Learning.‚Äù https://arxiv.org/abs/2001.10995."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#overview",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#overview",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Overview",
    "text": "Overview\n\n\nThe Problem with Black Boxes ‚¨õ\n\nWhat are black-box models? Why do we need explainability?\n\nEnter: Counterfactual Explanations üîÆ\n\nWhat are they? What are they not?\n\nCounterfactual Explanations in Julia (and beyond!) üì¶\n\nIntroducing: CounterfactualExplanations.jl\nPackage architecture\nUsage examples - what can it do?\n\nGoals and Ambitions üéØ\n\nFuture developments - where can it go?\nContributor‚Äôs guide"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#short-lists-pandas-and-gibbons",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#short-lists-pandas-and-gibbons",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Short Lists, Pandas and Gibbons",
    "text": "Short Lists, Pandas and Gibbons\n\nFrom human to data-driven decision-making ‚Ä¶\n\n\n\nBlack-box models like deep neural networks are being deployed virtually everywhere.\nIncludes safety-critical and public domains: health care, autonomous driving, finance, ‚Ä¶\nMore likely than not that your loan or employment application is handled by an algorithm.\n\n\n\n\n‚Ä¶ where black boxes are recipe for disaster.\n\n\n\nWe have no idea what exactly we‚Äôre cooking up ‚Ä¶\n\nHave you received an automated rejection email? Why didn‚Äôt you ‚ÄúmEet tHe sHoRtLisTiNg cRiTeRia‚Äù? üôÉ\n\n‚Ä¶ but we do know that some of it is junk.\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Adversarial attacks on deep neural networks. Source: Goodfellow, Shlens, and Szegedy (2015)"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#weapons-of-math-destruction",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#weapons-of-math-destruction",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "‚ÄúWeapons of Math Destruction‚Äù",
    "text": "‚ÄúWeapons of Math Destruction‚Äù\n\n\n\n‚ÄúYou cannot appeal to (algorithms). They do not listen. Nor do they bend.‚Äù\n‚Äî Cathy O‚ÄôNeil in Weapons of Math Destruction, 2016\n\n\n\n\n\n\n\nFigure¬†2: Cathy O‚ÄôNeil. Source: Cathy O‚ÄôNeil a.k.a. mathbabe.\n\n\n\n\n\n\nIf left unchallenged, these properties of black-box models can create undesirable dynamics in automated decision-making systems:\n\nHuman operators in charge of the system have to rely on it blindly.\nIndividuals subject to the decisions generally have no way to challenge their outcome."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-1",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-1",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nCurrent Standard in ML\nWe typically want to maximize the likelihood of observing \\(\\mathcal{D}_n\\) under given parameters (Murphy 2022):\n\\[\n\\theta^* = \\arg \\max_{\\theta} p(\\mathcal{D}_n|\\theta)\n\\qquad(1)\\]\nCompute an MLE (or MAP) point estimate \\(\\hat\\theta = \\mathbb{E} \\theta^*\\) and use plugin approximation for prediction:\n\\[\np(y|x,\\mathcal{D}_n) \\approx p(y|x,\\hat\\theta)\n\\qquad(2)\\]\n\nIn an ideal world we can just use parsimonious and interpretable models like GLM (Rudin 2019), for which in many cases we can rely on asymptotic properties of \\(\\theta\\) to quantify uncertainty.\nIn practice these models often have performance limitations.\nBlack-box models like deep neural networks are popular, but they are also the very opposite of parsimonious.\n\nObjective"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-2",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-2",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nObjective\n. . .\n\n[‚Ä¶] deep neural networks are typically very underspecified by the available data, and [‚Ä¶] parameters [therefore] correspond to a diverse variety of compelling explanations for the data. (Wilson 2020)\n\nIn this setting it is often crucial to treat models probabilistically!\n\\[\np(y|x,\\mathcal{D}_n) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D}_n)d\\theta\n\\qquad(3)\\]\n. . .\n\nProbabilistic models covered briefly today. More in my other talk on Laplace Redux ‚Ä¶"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-3",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#towards-trustworthy-ai-3",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\n\nWe can now make predictions ‚Äì great! But do we know how the predictions are actually being made?\n\n\nObjective\nWith the model trained for its task, we are interested in understanding how its predictions change in response to input changes.\n\\[\n\\nabla_x p(y|x,\\mathcal{D}_n;\\hat\\theta)\n\\qquad(4)\\]\n\n\nCounterfactual reasoning (in this context) boils down to simple questions: what if \\(x\\) (factual) \\(\\Rightarrow\\) \\(x\\prime\\) (counterfactual)?\nBy strategically perturbing features and checking the model output, we can (begin to) understand how the model makes its decisions.\nCounterfactual Explanations always have full fidelity by construction (as opposed to surrogate explanations, for example).\n\n\n. . .\n\nImportant to realize that we are keeping \\(\\hat\\theta\\) constant!"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#a-framework-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#a-framework-for-counterfactual-explanations",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "A Framework for Counterfactual Explanations",
    "text": "A Framework for Counterfactual Explanations\n\nEven though [‚Ä¶] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the ‚Äúblack box‚Äù. (Wachter, Mittelstadt, and Russell 2017)\n\n\n\nFramework\n. . .\nObjective originally proposed by Wachter, Mittelstadt, and Russell (2017) is as follows\n\\[\n\\min_{x\\prime \\in \\mathcal{X}} h(x\\prime) \\ \\ \\ \\mbox{s. t.} \\ \\ \\ M(x\\prime) = t\n\\qquad(5)\\]\nwhere \\(h\\) relates to the complexity of the counterfactual and \\(M\\) denotes the classifier.\n. . .\nTypically this is approximated through regularization:\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) + \\lambda h(x\\prime)\n\\qquad(6)\\]\n\nIntuition\n. . .\n\n\n\n\n\n\nFigure¬†3: A cat performing gradient descent in the feature space √† la Wachter, Mittelstadt, and Russell (2017)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#counterfactuals-as-in-adversarial-examples",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#counterfactuals-as-in-adversarial-examples",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Adversarial Examples?",
    "text": "Counterfactuals ‚Ä¶ as in Adversarial Examples?\n\n\nYes and no!\n\nWhile both are methodologically very similar, adversarial examples are meant to go undetected while CEs ought to be meaningful.\n\n\n\nEffective counterfactuals should meet certain criteria ‚úÖ\n\n\ncloseness: the average distance between factual and counterfactual features should be small (Wachter, Mittelstadt, and Russell (2017))\nactionability: the proposed feature perturbation should actually be actionable (Ustun, Spangher, and Liu (2019), Poyiadzi et al. (2020))\nplausibility: the counterfactual explanation should be plausible to a human (Joshi et al. (2019))\nunambiguity: a human should have no trouble assigning a label to the counterfactual (Schut et al. (2021))\nsparsity: the counterfactual explanation should involve as few individual feature changes as possible (Schut et al. (2021))\nrobustness: the counterfactual explanation should be robust to domain and model shifts (Upadhyay, Joshi, and Lakkaraju (2021))\ndiversity: ideally multiple diverse counterfactual explanations should be provided (Mothilal, Sharma, and Tan (2020))\ncausality: counterfactual explanations reflect the structural causal model underlying the data generating process (Karimi et al. (2020), Karimi, Sch√∂lkopf, and Valera (2021))"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#counterfactuals-as-in-causal-inference",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#counterfactuals-as-in-causal-inference",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Causal Inference?",
    "text": "Counterfactuals ‚Ä¶ as in Causal Inference?\n\nNO!\n\n\n\nCausal inference: counterfactuals are thought of as unobserved states of the world that we would like to observe in order to establish causality.\n\nThe only way to do this is by actually interfering with the state of the world: \\(p(y|do(x),\\theta)\\).\nIn practice we can only move some individuals to the counterfactual state of the world and compare their outcomes to a control group.\nProvided we have controlled for confounders, properly randomized, ‚Ä¶ we can estimate an average treatment effect: \\(\\hat\\theta\\).\n\nCounterfactual Explanations: involves perturbing features after some model has been trained.\n\nWe end up comparing modeled outcomes \\(p(y|x,\\hat\\phi)\\) and \\(p(y|x\\prime,\\hat\\phi)\\) for individuals.\nWe have not magically solved causality.\n\n\n\n\nThe number of ostensibly pro data scientists confusing themselves into believing that \"counterfactual explanations\" capture real-world causality is just staggeringü§¶‚Äç‚ôÄÔ∏è. Where do we go from here? How can a community that doesn't even understand what's already known make advances?\n\n‚Äî Zachary Lipton (@zacharylipton) June 20, 2022"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#probabilistic-methods-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#probabilistic-methods-for-counterfactual-explanations",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Probabilistic Methods for Counterfactual Explanations",
    "text": "Probabilistic Methods for Counterfactual Explanations\nWhen people say that counterfactuals should look realistic or plausible, they really mean that counterfactuals should be generated by the same Data Generating Process (DGP) as the factuals:\n\\[\nx\\prime \\sim p(x)\n\\]\nBut how do we estimate \\(p(x)\\)? Two probabilistic approaches ‚Ä¶\n\n\nAPPROACH 1: use the model itselfAPPROACH 2: use some generative model\n\n\n\n\nSchut et al. (2021) note that by maximizing predictive probabilities \\(\\sigma(M(x\\prime))\\) for probabilistic models \\(M\\in\\mathcal{\\widetilde{M}}\\) one implicitly minimizes epistemic and aleotoric uncertainty.\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) \\ \\ \\ , \\ \\ \\ M\\in\\mathcal{\\widetilde{M}}\n\\qquad(7)\\]\n\n\n\n\n\n\n\nFigure¬†4: A cat performing gradient descent in the feature space √† la Schut et al. (2021)\n\n\n\n\n\n\n\n\nInstead of perturbing samples directly, some have proposed to instead traverse a lower-dimensional latent embedding learned through a generative model (Joshi et al. 2019).\n\\[\nz\\prime = \\arg \\min_{z\\prime}  \\ell(M(dec(z\\prime)),t) + \\lambda h(x\\prime)\n\\qquad(8)\\]\nand\n\\[x\\prime = dec(z\\prime)\\]\nwhere \\(dec(\\cdot)\\) is the decoder function.\n\n\n\n\n\n\n\nFigure¬†5: Counterfactual (yellow) generated through latent space search (right panel) following Joshi et al. (2019). The corresponding counterfactual path in the feature space is shown in the left panel."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#limited-software-availability",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#limited-software-availability",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Limited Software Availability",
    "text": "Limited Software Availability\n\nWork currently scattered across different GitHub repositories ‚Ä¶\n\n\n\n\n\nOnly one unifying Python library: CARLA (Pawelczyk et al. 2021).\n\nComprehensive and (somewhat) extensible.\nBut not language-agnostic and some desirable functionality not supported.\nAlso not composable: each generator is treated as different class/entity.\n\nBoth R and Julia lacking any kind of implementation.\n\n\n\n\n\n\nPhoto by Volodymyr Hryshchenko on Unsplash."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#enter-counterfactualexplanations.jl",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#enter-counterfactualexplanations.jl",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Enter: CounterfactualExplanations.jl üì¶",
    "text": "Enter: CounterfactualExplanations.jl üì¶\n   \n\n‚Ä¶ until now!\n\n\n\n\n\nA unifying framework for generating Counterfactual Explanations.\nBuilt in Julia, but essentially language agnostic:\n\nCurrently supporting explanations for differentiable models built in Julia (e.g.¬†Flux) and torch (R and Python).\n\nDesigned to be easily extensible through dispatch.\nDesigned to be composable allowing users and developers to combine different counterfactual generators.\n\n\n\n\n\n\nPhoto by Denise Jans on Unsplash.\n\n\n\n\n\nJulia has an edge with respect to Trustworthy AI: it‚Äôs open-source, uniquely transparent and interoperable üî¥üü¢üü£"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#overview-1",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#overview-1",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Overview",
    "text": "Overview\n\n\n\n\n\n\nFigure¬†6: Overview of package architecture. Modules are shown in red, structs in green and functions in blue."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#generators",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#generators",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Generators",
    "text": "Generators\n\nusing CounterfactualExplanations, Plots, GraphRecipes\nplt = plot(AbstractGenerator, method=:tree, fontsize=10, nodeshape=:rect, size=(1000,700))\nsavefig(plt, joinpath(www_path,\"generators.png\"))\n\n\n\n\n\n\n\nFigure¬†7: Type tree for AbstractGenerator."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#models",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#models",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Models",
    "text": "Models\n\nplt = plot(AbstractFittedModel, method=:tree, fontsize=10, nodeshape=:rect, size=(1000,700))\nsavefig(plt, joinpath(www_path,\"models.png\"))\n\n\n\n\n\n\n\nFigure¬†8: Type tree for AbstractFittedModel."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#a-simple-example",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#a-simple-example",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "A simple example",
    "text": "A simple example\n\n\n\nLoad and prepare some toy data.\nSelect a random sample.\nGenerate counterfactuals using different approaches.\n\n\n# Data:\nusing Random\nRandom.seed!(123)\nN = 100\nusing CounterfactualExplanations\nxs, ys = toy_data_linear(N)\nX = hcat(xs...)\ncounterfactual_data = CounterfactualData(X,ys')\n\n# Randomly selected factual:\nx = select_factual(counterfactual_data,rand(1:size(X)[2]))\n\n\n\n\n\n\n\n\nFigure¬†9: Synthetic data."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#generic-generator",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#generic-generator",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Generic Generator",
    "text": "Generic Generator\n\n\nCode\n. . .\nWe begin by instantiating the fitted model ‚Ä¶\n\n# Model\nw = [1.0 1.0] # estimated coefficients\nb = 0 # estimated bias\nM = LogisticModel(w, [b])\n\n. . .\n‚Ä¶ then based on its prediction for \\(x\\) we choose the opposite label as our target ‚Ä¶\n\n# Select target class:\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target\n\n. . .\n‚Ä¶ and finally generate the counterfactual.\n\n# Counterfactual search:\ngenerator = GenericGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\nOutput\n. . .\n\n‚Ä¶ et voil√†!\n\n\n\n\n\n\n\nFigure¬†10: Counterfactual path (left) and predicted probability (right) for GenericGenerator. The contour (left) shows the predicted probabilities of the classifier (Logistic Regression)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#greedy-generator",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#greedy-generator",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Greedy Generator",
    "text": "Greedy Generator\n\n\nCode\n. . .\nThis time we use a Bayesian classifier ‚Ä¶\n\nusing LinearAlgebra\nŒ£ = Symmetric(reshape(randn(9),3,3).*0.01 + UniformScaling(1)) # MAP covariance matrix\nŒº = hcat(b, w)\nM = BayesianLogisticModel(Œº, Œ£)\n\n. . .\n‚Ä¶ and once again choose our target label as before ‚Ä¶\n\n# Select target class:\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target\n\n. . .\n‚Ä¶ to then finally use greedy search to find a counterfactual.\n\n# Counterfactual search:\nparams = GreedyGeneratorParams(\n  Œ¥ = 0.5,\n  n = 10\n)\ngenerator = GreedyGenerator(;params=params)\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\nOutput\n. . .\n\nIn this case the Bayesian approach yields a similar outcome.\n\n\n\n\n\n\n\nFigure¬†11: Counterfactual path (left) and predicted probability (right) for GreedyGenerator. The contour (left) shows the predicted probabilities of the classifier (Bayesian Logistic Regression)."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#revise-generator",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#revise-generator",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "REVISE Generator",
    "text": "REVISE Generator\n\n\nCode\nUsing the same classifier as before we can either use the specific REVISEGenerator ‚Ä¶\n\n# Counterfactual search:\ngenerator = REVISEGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n. . .\n‚Ä¶ or realize that that REVISE (Joshi et al. 2019) just boils down to generic search in a latent space:\n\n# Counterfactual search:\ngenerator = GenericGenerator()\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator,\n  latent_space=true\n)\n\n\nOutput\n. . .\n\nWe have essentially combined latent search with a probabilistic classifier (as in Antor√°n et al. (2020)).\n\n\n\n\n\n\n\nFigure¬†12: Counterfactual path (left) and predicted probability (right) for REVISEGenerator."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#mnist---latent-space-search",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#mnist---latent-space-search",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "MNIST - Latent Space Search",
    "text": "MNIST - Latent Space Search\n\n\nGood VAE\n. . .\nLoading pre-trained classifiers and VAE ‚Ä¶\n\nX, ys = mnist_data() \nmodel = mnist_model() # simple MLP\n\n. . .\n‚Ä¶ instantiating model and attaching VAE.\n\nM = FluxModel(model, likelihood=:classification_multi)\ncounterfactual_data = CounterfactualData(X,ys)\nvae = mnist_vae()\ncounterfactual_data.generative_model = vae\n\n. . .\n\nThe results in Figure¬†13 look great!\n\n\n\n\n\n\n\nFigure¬†13: Turning a nine (9) into a four (4) using REVISE. It appears that the VAE is well-specified in this case.\n\n\n\n\nBad VAE\n. . .\n\nBut things can also go wrong ‚Ä¶\n\nThe VAE used to generate the counterfactual in Figure¬†14 is not expressive enough.\n\n\n\n\n\n\nFigure¬†14: Turning a seven (7) into a nine (9) using REVISE with a weak VAE.\n\n\n\n. . .\n\nThe counterfactual in Figure¬†15 is also valid ‚Ä¶ what to do?\n\n\n\n\n\n\n\nFigure¬†15: Turning a seven (7) into a nine (9) using generic search."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-models---deep-ensemble",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-models---deep-ensemble",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Custom Models - Deep Ensemble",
    "text": "Custom Models - Deep Ensemble\n\nLoading the pre-trained deep ensemble ‚Ä¶\n\nensemble = mnist_ensemble() # deep ensemble\n\n\n\nStep 1: add composite type as subtype of AbstractFittedModel.\n\nstruct FittedEnsemble &lt;: Models.AbstractFittedModel\n    ensemble::AbstractArray\nend\n\n\n\nStep 2: dispatch logits and probs methods for new model type.\n\nusing Statistics\nimport CounterfactualExplanations.Models: logits, probs\nlogits(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([nn(X) for nn in M.ensemble],3), dims=3)\nprobs(M::FittedEnsemble, X::AbstractArray) = mean(Flux.stack([softmax(nn(X)) for nn in M.ensemble],3),dims=3)\nM = FittedEnsemble(ensemble)\n\n\n\n\nResults for a simple deep ensemble also look convincing!\n\n\n\n\n\n\n\nFigure¬†16: Turning a nine (9) into a four (4) using generic (Wachter) and greedy search for MLP and deep ensemble."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-models---interoperability",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-models---interoperability",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Custom Models - Interoperability",
    "text": "Custom Models - Interoperability\nAdding support for torch models was easy! Here‚Äôs how I implemented it for torch classifiers trained in R.\n\n\n\nSource code\n. . .\nStep 1: add composite type as subtype of AbstractFittedModel\n\nImplemented here.\n\nStep 2: dispatch logits and probs methods for new model type.\n\nImplemented here.\n\n. . .\nStep 3: add gradient access.\n\nImplemented here.\n\n\nUnchanged API\n. . .\n\nM = RTorchModel(model)\n# Select target class:\ny = round(probs(M, x)[1])\ntarget = ifelse(y==1.0,0.0,1.0) # opposite label as target\n# Define generator:\ngenerator = GenericGenerator()\n# Generate recourse:\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\n\n\n\n\n\nFigure¬†17: Counterfactual path (left) and predicted probability (right) for GenericGenerator and RTorchModel."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-generators",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#custom-generators",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "Custom Generators",
    "text": "Custom Generators\nIdea üí°: let‚Äôs implement a generic generator with dropout!\n\n\n\nDispatch\n. . .\nStep 1: create a subtype of AbstractGradientBasedGenerator (adhering to some basic rules).\n\n# Constructor:\nabstract type AbstractDropoutGenerator &lt;: AbstractGradientBasedGenerator end\nstruct DropoutGenerator &lt;: AbstractDropoutGenerator\n    loss::Symbol # loss function\n    complexity::Function # complexity function\n    mutability::Union{Nothing,Vector{Symbol}} # mutibility constraints \n    Œª::AbstractFloat # strength of penalty\n    œµ::AbstractFloat # step size\n    œÑ::AbstractFloat # tolerance for convergence\n    p_dropout::AbstractFloat # dropout rate\nend\n\n. . .\nStep 2: implement logic for generating perturbations.\n\nimport CounterfactualExplanations.Generators: generate_perturbations, ‚àá\nusing StatsBase\nfunction generate_perturbations(generator::AbstractDropoutGenerator, counterfactual_state::State)\n    ùê†‚Çú = ‚àá(generator, counterfactual_state.M, counterfactual_state) # gradient\n    # Dropout:\n    set_to_zero = sample(1:length(ùê†‚Çú),Int(round(generator.p_dropout*length(ùê†‚Çú))),replace=false)\n    ùê†‚Çú[set_to_zero] .= 0\n    Œîx‚Ä≤ = - (generator.œµ .* ùê†‚Çú) # gradient step\n    return Œîx‚Ä≤\nend\n\n\nUnchanged API\n. . .\n\n# Instantiate:\nusing LinearAlgebra\ngenerator = DropoutGenerator(\n    :logitbinarycrossentropy,\n    norm,\n    nothing,\n    0.1,\n    0.1,\n    1e-5,\n    0.5\n)\ncounterfactual = generate_counterfactual(\n  x, target, counterfactual_data, M, generator\n)\n\n\n\n\n\n\n\nFigure¬†18: Counterfactual path (left) and predicted probability (right) for custom DropoutGenerator and RTorchModel."
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#juliacon-2022-and-beyond",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#juliacon-2022-and-beyond",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "JuliaCon 2022 and beyond",
    "text": "JuliaCon 2022 and beyond\n\n\n\nTo JuliaCon ‚Ä¶\n\nDevelop package, register and submit to JuliaCon 2022.\n\n\nNative support for deep learning models (Flux, torch).\n\n\nAdd latent space search.\n\n\n‚Ä¶ and beyond\n. . .\n\nAdd more generators:\n\nDiCE (Mothilal, Sharma, and Tan 2020)\nROAR (Upadhyay, Joshi, and Lakkaraju 2021)\nMINT (Karimi, Sch√∂lkopf, and Valera 2021)\n\n\n. . .\n\nAdd support for more models:\n\nMLJ, GLM, ‚Ä¶\nNon-differentiable\n\n\n. . .\n\nEnhance preprocessing functionality.\n\n. . .\n\nExtend functionality to regression problems.\n\n. . .\n\nUse Flux optimizers.\n\n. . .\n\n‚Ä¶\n\n\n\n\n\nPhoto by Ivan Diaz on Unsplash"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#more-resources",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#more-resources",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nBlog post introducing CE: [TDS, homepage].\nBlog post introducing package: [TDS, homepage].\nPackage docs with lots of examples.\n\n\n‚Ä¶ or get involved! ü§ó\n\n\nContributor‚Äôs Guide"
  },
  {
    "objectID": "content/talks/posts/2022-juliacon/counterfactuals.html#references",
    "href": "content/talks/posts/2022-juliacon/counterfactuals.html#references",
    "title": "Explaining Black-Box Models through Counterfactuals",
    "section": "References",
    "text": "References\n\n\n\n\nAntor√°n, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and Jos√© Miguel Hern√°ndez-Lobato. 2020. ‚ÄúGetting a Clue: A Method for Explaining Uncertainty Estimates.‚Äù https://arxiv.org/abs/2006.06848.\n\n\nGoodfellow, Ian, Jonathon Shlens, and Christian Szegedy. 2015. ‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù https://arxiv.org/abs/1412.6572.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKarimi, Amir-Hossein, Bernhard Sch√∂lkopf, and Isabel Valera. 2021. ‚ÄúAlgorithmic Recourse: From Counterfactual Explanations to Interventions.‚Äù In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 353‚Äì62. FAccT ‚Äô21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445899.\n\n\nKarimi, Amir-Hossein, Julius Von K√ºgelgen, Bernhard Sch√∂lkopf, and Isabel Valera. 2020. ‚ÄúAlgorithmic Recourse Under Imperfect Causal Knowledge: A Probabilistic Approach.‚Äù https://arxiv.org/abs/2006.06831.\n\n\nKaur, Harmanpreet, Harsha Nori, Samuel Jenkins, Rich Caruana, Hanna Wallach, and Jennifer Wortman Vaughan. 2020. ‚ÄúInterpreting Interpretability: Understanding Data Scientists‚Äô Use of Interpretability Tools for Machine Learning.‚Äù In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1‚Äì14. https://doi.org/10.1145/3313831.3376219.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nPawelczyk, Martin, Sascha Bielawski, Johannes van den Heuvel, Tobias Richter, and Gjergji Kasneci. 2021. ‚ÄúCARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms.‚Äù https://arxiv.org/abs/2108.00783.\n\n\nPoyiadzi, Rafael, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, and Peter Flach. 2020. ‚ÄúFACE: Feasible and Actionable Counterfactual Explanations.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 344‚Äì50.\n\n\nRudin, Cynthia. 2019. ‚ÄúStop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.‚Äù Nature Machine Intelligence 1 (5): 206‚Äì15. https://doi.org/10.1038/s42256-019-0048-x.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nSlack, Dylan, Sophie Hilgard, Emily Jia, Sameer Singh, and Himabindu Lakkaraju. 2020. ‚ÄúFooling Lime and Shap: Adversarial Attacks on Post Hoc Explanation Methods.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 180‚Äì86.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nUstun, Berk, Alexander Spangher, and Yang Liu. 2019. ‚ÄúActionable Recourse in Linear Classification.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 10‚Äì19. https://doi.org/10.1145/3287560.3287566.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nWilson, Andrew Gordon. 2020. ‚ÄúThe Case for Bayesian Deep Learning.‚Äù https://arxiv.org/abs/2001.10995."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#blurb",
    "href": "content/talks/posts/2022-boe/presentation.html#blurb",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Blurb",
    "text": "Blurb\nCounterfactual Explanations explain how inputs into a model need to change for it to produce different outputs. Explanations that involve realistic and actionable changes can be used for the purpose of Algorithmic Recourse: they offer human stakeholders a principled approach to not only understand the model they are seeking to explain, but also react to it or adjust it.\nThe general setup lends itself naturally to Bank datasets that revolve around counterparty risk, for example. In this seminar I will introduce the topic and place it into the broader context of Explainable AI. Using my Julia package I will go through a worked example involving a publicly available credit data set. Finally, I will also briefly present some of our recent research that points to potential pitfalls of current state-of-the-art approaches and proposes mitigation strategies.\nDISCLAIMER: Views presented in this presentation are my own."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#quick-intro",
    "href": "content/talks/posts/2022-boe/presentation.html#quick-intro",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Quick Intro",
    "text": "Quick Intro\n\n\n\nCurrently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nWorking on Counterfactual Explanations and Probabilistic Machine Learning with applications in Finance.\nPreviously, educational background in Economics and Finance and two years at the Bank of England (MPAT \\(\\subset\\) MIAD).\nEnthusiastic about free open-source software, in particular Julia and Quarto."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#the-problem-with-todays-ai",
    "href": "content/talks/posts/2022-boe/presentation.html#the-problem-with-todays-ai",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "The Problem with Today‚Äôs AI",
    "text": "The Problem with Today‚Äôs AI\n\nFrom human to data-driven decision-making ‚Ä¶\n\n\n\nBlack-box models like deep neural networks are being deployed virtually everywhere.\nIncludes safety-critical and public domains: health care, autonomous driving, finance, ‚Ä¶\nMore likely than not that your loan or employment application is handled by an algorithm.\n\n\n\n\n‚Ä¶ where black boxes are recipe for disaster.\n\n\n\nWe have no idea what exactly we‚Äôre cooking up ‚Ä¶\n\nHave you received an automated rejection email? Why didn‚Äôt you ‚ÄúmEet tHe sHoRtLisTiNg cRiTeRia‚Äù? üôÉ\n\n‚Ä¶ but we do know that some of it is junk.\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Adversarial attacks on deep neural networks. Source: Goodfellow, Shlens, and Szegedy (2015)"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai",
    "href": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-1",
    "href": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-1",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nCurrent Standard in ML\nWe typically want to maximize the likelihood of observing \\(\\mathcal{D}_n\\) under given parameters (Murphy 2022):\n\\[\n\\theta^* = \\arg \\max_{\\theta} p(\\mathcal{D}_n|\\theta)\n\\qquad(1)\\]\nCompute an MLE (or MAP) point estimate \\(\\hat\\theta = \\mathbb{E} \\theta^*\\) and use plugin approximation for prediction:\n\\[\np(y|x,\\mathcal{D}_n) \\approx p(y|x,\\hat\\theta)\n\\qquad(2)\\]\n\nIn an ideal world we can just use parsimonious and interpretable models like GLM (Rudin 2019), for which in many cases we can rely on asymptotic properties of \\(\\theta\\) to quantify uncertainty.\nIn practice these models often have performance limitations.\nBlack-box models like deep neural networks are popular, but they are also the very opposite of parsimonious.\n\nObjective"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-2",
    "href": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-2",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\nObjective\n. . .\n\n[‚Ä¶] deep neural networks are typically very underspecified by the available data, and [‚Ä¶] parameters [therefore] correspond to a diverse variety of compelling explanations for the data. (Wilson 2020)\n\nIn this setting it is often crucial to treat models probabilistically!\n\\[\np(y|x,\\mathcal{D}_n) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D}_n)d\\theta\n\\qquad(3)\\]"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-3",
    "href": "content/talks/posts/2022-boe/presentation.html#towards-trustworthy-ai-3",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Towards Trustworthy AI",
    "text": "Towards Trustworthy AI\n\n\nGround Truthing\n\n\nProbabilistic Models\n\n\nCounterfactual Reasoning\n\n\n\nWe can now make predictions ‚Äì great! But do we know how the predictions are actually being made?\n\n\nObjective\nWith the model trained for its task, we are interested in understanding how its predictions change in response to input changes.\n\\[\n\\nabla_x p(y|x,\\mathcal{D}_n;\\hat\\theta)\n\\qquad(4)\\]\n\n\nCounterfactual reasoning (in this context) boils down to simple questions: what if \\(x\\) (factual) \\(\\Rightarrow\\) \\(x\\prime\\) (counterfactual)?\nBy strategically perturbing features and checking the model output, we can (begin to) understand how the model makes its decisions.\nCounterfactual Explanations always have full fidelity by construction (as opposed to surrogate explanations, for example).\n\n\n. . .\n\nImportant to realize that we are keeping \\(\\hat\\theta\\) constant!"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#todays-talk",
    "href": "content/talks/posts/2022-boe/presentation.html#todays-talk",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Today‚Äôs talk",
    "text": "Today‚Äôs talk\n\nüîÆ Explaining Black-Box Models through Counterfactuals (\\(\\approx\\) 10min)\n\nWhat are they? What are they not?\nCounterfactual Explanations in the broader XAI landscape\nFrom Counterfactual Explanations to Algorithmic Recourse\n\nüõ†Ô∏è Hands-on examples ‚Äî CounterfactualExplanations.jl in Julia (\\(\\approx\\) 15min)\nüìä Endogenous Macrodynamics in Algorithmic Recourse (\\(\\approx\\) 10min)\n‚ùì Q&A (\\(\\approx\\) 10min)\nüöÄ Related Research Topics (\\(\\approx\\) 10min)\n\nPredictive Uncertainty Quantification"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#a-framework-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-boe/presentation.html#a-framework-for-counterfactual-explanations",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "A Framework for Counterfactual Explanations",
    "text": "A Framework for Counterfactual Explanations\n\nEven though [‚Ä¶] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the ‚Äúblack box‚Äù. (Wachter, Mittelstadt, and Russell 2017)\n\n\n\nFramework\n. . .\nObjective originally proposed by Wachter, Mittelstadt, and Russell (2017) is as follows\n\\[\n\\min_{x\\prime \\in \\mathcal{X}} h(x\\prime) \\ \\ \\ \\mbox{s. t.} \\ \\ \\ M(x\\prime) = t\n\\qquad(5)\\]\nwhere \\(h\\) relates to the complexity of the counterfactual and \\(M\\) denotes the classifier.\n. . .\nTypically this is approximated through regularization:\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) + \\lambda h(x\\prime)\n\\qquad(6)\\]\n\nIntuition\n. . .\n\n\n\n\n\n\nFigure¬†2: A cat performing gradient descent in the feature space √† la Wachter, Mittelstadt, and Russell (2017)."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#counterfactuals-as-in-adversarial-examples",
    "href": "content/talks/posts/2022-boe/presentation.html#counterfactuals-as-in-adversarial-examples",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Adversarial Examples?",
    "text": "Counterfactuals ‚Ä¶ as in Adversarial Examples?\n\n\n\nYes and no!\n\nWhile both are methodologically very similar, adversarial examples are meant to go undetected while CEs ought to be meaningful.\n\n\nDesiderata\n\n\ncloseness: the average distance between factual and counterfactual features should be small (Wachter, Mittelstadt, and Russell (2017))\nactionability: the proposed feature perturbation should actually be actionable (Ustun, Spangher, and Liu (2019), Poyiadzi et al. (2020))\nplausibility: the counterfactual explanation should be plausible to a human (Joshi et al. (2019))\nunambiguity: a human should have no trouble assigning a label to the counterfactual (Schut et al. (2021))\nsparsity: the counterfactual explanation should involve as few individual feature changes as possible (Schut et al. (2021))\nrobustness: the counterfactual explanation should be robust to domain and model shifts (Upadhyay, Joshi, and Lakkaraju (2021))\ndiversity: ideally multiple diverse counterfactual explanations should be provided (Mothilal, Sharma, and Tan (2020))\ncausality: counterfactual explanations reflect the structural causal model underlying the data generating process (Karimi et al. (2020), Karimi, Sch√∂lkopf, and Valera (2021))"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#counterfactuals-as-in-causal-inference",
    "href": "content/talks/posts/2022-boe/presentation.html#counterfactuals-as-in-causal-inference",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Counterfactuals ‚Ä¶ as in Causal Inference?",
    "text": "Counterfactuals ‚Ä¶ as in Causal Inference?\n\nNO!\n\n\n\nCausal inference: counterfactuals are thought of as unobserved states of the world that we would like to observe in order to establish causality.\n\nThe only way to do this is by actually interfering with the state of the world: \\(p(y|do(x),\\theta)\\).\nIn practice we can only move some individuals to the counterfactual state of the world and compare their outcomes to a control group.\nProvided we have controlled for confounders, properly randomized, ‚Ä¶ we can estimate an average treatment effect: \\(\\hat\\theta\\).\n\nCounterfactual Explanations: involves perturbing features after some model has been trained.\n\nWe end up comparing modeled outcomes \\(p(y|x,\\hat\\phi)\\) and \\(p(y|x\\prime,\\hat\\phi)\\) for individuals.\nWe have not magically solved causality.\n\n\n\n\nThe number of ostensibly pro data scientists confusing themselves into believing that \"counterfactual explanations\" capture real-world causality is just staggeringü§¶‚Äç‚ôÄÔ∏è. Where do we go from here? How can a community that doesn't even understand what's already known make advances?\n\n‚Äî Zachary Lipton (@zacharylipton) June 20, 2022"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#the-xai-landscape",
    "href": "content/talks/posts/2022-boe/presentation.html#the-xai-landscape",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "The XAI Landscape",
    "text": "The XAI Landscape\n\nOverviewLiterature\n\n\n\nA (highly) simplified and incomplete overview ‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3: A (highly) simplified and incomplete overview of the XAI landscape loosely based on Molnar (2022).\n\n\n\n\n\n\n\nSurrogate Explainers\n\nLundberg and Lee (2017) propose SHAP as a provably unified approach to additive feature attribution methods (including LIME) with certain desiderata. Contrary to LIME, this approach involves permuting through the feature space and checking how different features impact model predictions when they are included in the permutations.\nRibeiro, Singh, and Guestrin (2016) propose Local Interpretable Model-Agnostic Explanations (LIME): the approach involves generating local perturbations in the input space, deriving predictions from the original classifier and than fitting a white box model (e.g.¬†linear regression) on this synthetic data set.\n\nCounterfactual Explanations\n\nWachter, Mittelstadt, and Russell (2017) were among the first to propose counterfactual explanations that do not require knowledge about the inner workings of a black-box model.\nJoshi et al. (2019) extend the framework of Ustun, Spangher, and Liu (2019). Their proposed REVISE method is applicable to a broader class of models including black box classifiers and structural causal models. For a summary see here and for a set of slides see here.\nSchut et al. (2021) introduce Bayesian modeling to the context of CE: their approach implicitly minimizes aleatoric and epistemic uncertainty to generate a CE that us unambiguous and realistic, respectively.\n\nCriticism (XAI)\n\n‚ÄúExplanatory models by definition do not produce 100% reliable explanations, because they are approximations. This means explanations can‚Äôt be fully trusted, and so neither can the original model.‚Äù ‚Äì causaLens, 2021\n\n\nMittelstadt, Russell, and Wachter (2019) points out that there is a gap in the understanding of what explanations are between computer scientists and explanation scientists (social scientists, cognitive scientists, pyschologists, ‚Ä¶). Current methods produce at best locally reliable explanations. There needs to be shift towards interactive explanations.\nRudin (2019) argues that instead of bothering with explanations for black box models we should focus on designing inherently interpretable models. In her view the trade-off between (intrinsic) explainability and performance is not as clear-cut as people claim.\nLakkaraju and Bastani (2020) show how misleading black box explanations can manipulate users into trusting an untrustworthy model.\nSlack et al. (2020) demonstrate that both LIME and SHAP are not reliable: their reliance on feature perturbations makes them susceptible to adversarial attacks.\nSlack et al. (2021) show that (gradient-based) Counterfactual Explanations that are also vulnerable to manipulation, but various simple mitigation strategies can be used to avoid this."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#from-counterfactual-explanations-to-algorithmic-recourse",
    "href": "content/talks/posts/2022-boe/presentation.html#from-counterfactual-explanations-to-algorithmic-recourse",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "From Counterfactual Explanations to Algorithmic Recourse",
    "text": "From Counterfactual Explanations to Algorithmic Recourse\n\n\n\n‚ÄúYou cannot appeal to (algorithms). They do not listen. Nor do they bend.‚Äù\n‚Äî Cathy O‚ÄôNeil in Weapons of Math Destruction, 2016\n\n\n\n\n\n\n\nFigure¬†4: Cathy O‚ÄôNeil. Source: Cathy O‚ÄôNeil a.k.a. mathbabe.\n\n\n\n\nAlgorithmic Recourse\n. . .\n\nO‚ÄôNeil (2016) points to various real-world involving black-box models and affected individuals facing adverse outcomes.\n\n. . .\n\nThese individuals generally have no way to challenge their outcome.\n\n. . .\n\nCounterfactual Explanations that involve actionable and realistic feature perturbations can be used for the purpose of Algorithmic Recourse."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#counterfactualexplanations.jl",
    "href": "content/talks/posts/2022-boe/presentation.html#counterfactualexplanations.jl",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "CounterfactualExplanations.jl üì¶",
    "text": "CounterfactualExplanations.jl üì¶\n     \n\n\n\n\nA unifying framework for generating Counterfactual Explanations.\nFast, extensible and composable allowing users and developers to add and combine different counterfactual generators.\nImplements a number of SOTA generators.\nBuilt in Julia, but can be used to explain models built in R and Python (still experimental).\nStatus üîÅ: ready for research, not production. Thought/challenge/contributions welcome!\n\n\n\n\n\n\nPhoto by Denise Jans on Unsplash.\n\n\n\n\n\nJulia has an edge with respect to Trustworthy AI: it‚Äôs open-source, uniquely transparent and interoperable üî¥üü¢üü£"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#a-simple-example",
    "href": "content/talks/posts/2022-boe/presentation.html#a-simple-example",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "A simple example",
    "text": "A simple example\n\n\n\nLoad and prepare some toy data.\nSelect a random sample.\nGenerate counterfactuals using different approaches."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#generic-generator",
    "href": "content/talks/posts/2022-boe/presentation.html#generic-generator",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Generic Generator",
    "text": "Generic Generator\n\n\nCode\n. . .\nWe begin by instantiating the fitted model ‚Ä¶\n. . .\n‚Ä¶ then based on its prediction for \\(x\\) we choose the opposite label as our target ‚Ä¶\n. . .\n‚Ä¶ and finally generate the counterfactual.\n\nOutput\n. . .\n\n‚Ä¶ et voil√†!"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#probabilistic-methods-for-counterfactual-explanations",
    "href": "content/talks/posts/2022-boe/presentation.html#probabilistic-methods-for-counterfactual-explanations",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Probabilistic Methods for Counterfactual Explanations",
    "text": "Probabilistic Methods for Counterfactual Explanations\nWhen people say that counterfactuals should look realistic or plausible, they really mean that counterfactuals should be generated by the same Data Generating Process (DGP) as the factuals:\n\\[\nx\\prime \\sim p(x)\n\\]\nBut how do we estimate \\(p(x)\\)? Two probabilistic approaches ‚Ä¶\n\n\nAPPROACH 1: use the model itselfAPPROACH 2: use some generative model\n\n\n\n\nSchut et al. (2021) note that by maximizing predictive probabilities \\(\\sigma(M(x\\prime))\\) for probabilistic models \\(M\\in\\mathcal{\\widetilde{M}}\\) one implicitly minimizes epistemic and aleotoric uncertainty.\n\\[\nx\\prime = \\arg \\min_{x\\prime}  \\ell(M(x\\prime),t) \\ \\ \\ , \\ \\ \\ M\\in\\mathcal{\\widetilde{M}}\n\\qquad(7)\\]\n\n\n\n\n\n\n\nFigure¬†5: A cat performing gradient descent in the feature space √† la Schut et al. (2021)\n\n\n\n\n\n\n\n\nInstead of perturbing samples directly, some have proposed to instead traverse a lower-dimensional latent embedding learned through a generative model (Joshi et al. 2019).\n\\[\nz\\prime = \\arg \\min_{z\\prime}  \\ell(M(dec(z\\prime)),t) + \\lambda h(x\\prime)\n\\qquad(8)\\]\nand\n\\[x\\prime = dec(z\\prime)\\]\nwhere \\(dec(\\cdot)\\) is the decoder function.\n\n\n\n\n\n\n\nFigure¬†6: Counterfactual (yellow) generated through latent space search (right panel) following Joshi et al. (2019). The corresponding counterfactual path in the feature space is shown in the left panel."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#greedy-generator",
    "href": "content/talks/posts/2022-boe/presentation.html#greedy-generator",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Greedy Generator",
    "text": "Greedy Generator\n\n\nCode\n. . .\nThis time we use a Bayesian classifier ‚Ä¶\n. . .\n‚Ä¶ and once again choose our target label as before ‚Ä¶\n. . .\n‚Ä¶ to then finally use greedy search to find a counterfactual.\n\nOutput\n. . .\n\nIn this case the Bayesian approach yields a similar outcome."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#latent-space-generator",
    "href": "content/talks/posts/2022-boe/presentation.html#latent-space-generator",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Latent Space Generator",
    "text": "Latent Space Generator\n\n\nCode\n. . .\nUsing the same classifier as before we can either use the specific REVISEGenerator ‚Ä¶\n. . .\n‚Ä¶ or realize that that REVISE (Joshi et al. 2019) just boils down to generic search in a latent space:\n\nOutput\n. . .\n\nWe have essentially combined latent search with a probabilistic classifier (as in Antor√°n et al. (2020))."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#diverse-counterfactuals",
    "href": "content/talks/posts/2022-boe/presentation.html#diverse-counterfactuals",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Diverse Counterfactuals",
    "text": "Diverse Counterfactuals\n\n\nCode\n. . .\nWe can use the DiCEGenerator to produce multiple diverse counterfactuals:\n\nOutput\n. . ."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#a-real-world-example---credit-default",
    "href": "content/talks/posts/2022-boe/presentation.html#a-real-world-example---credit-default",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "A Real-World Example - Credit Default",
    "text": "A Real-World Example - Credit Default\n\nThe Give Me Some Credit dataset is publicly available from Kaggle.\n\n\nImprove on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years.\n\n\nWe have \\(y \\in \\{0=\\text{no stress},1=\\text{stress}\\}\\) and a number of demographic and credit-related features \\(X\\)."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#ignoring-mutability",
    "href": "content/talks/posts/2022-boe/presentation.html#ignoring-mutability",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Ignoring Mutability",
    "text": "Ignoring Mutability\nUsing DiCE to generate counterfactuals for a single individual, ignoring actionability:"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#respecting-mutability",
    "href": "content/talks/posts/2022-boe/presentation.html#respecting-mutability",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Respecting Mutability",
    "text": "Respecting Mutability\nUsing the generic generator to generate counterfactuals for multiple individuals, respecting that age cannot be decreased (you might argue that age also cannot be easily increased ‚Ä¶):"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#motivation",
    "href": "content/talks/posts/2022-boe/presentation.html#motivation",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Motivation",
    "text": "Motivation\n\n\n\nTL;DR: We find that standard implementation of various SOTA approaches to AR can induce substantial domain and model shifts. We argue that these dynamics indicate that individual recourse generates hidden external costs and provide mitigation strategies.\n\nIn this work we investigate what happens if Algorithmic Recourse is actually implemented by a large number of individuals.\nFigure¬†7 illustrates what we mean by Endogenous Macrodynamics in Algorithmic Recourse:\n\nPanel (a): we have a simple linear classifier trained for binary classification where samples from the negative class (y=0) are marked in blue and samples of the positive class (y=1) are marked in orange\nPanel (b): the implementation of AR for a random subset of individuals leads to a noticable domain shift\nPanel (c): as the classifier is retrained we observe a corresponding model shift (Upadhyay, Joshi, and Lakkaraju 2021)\nPanel (d): as this process is repeated, the decision boundary moves away from the target class.\n\n\n\n\n\n\n\n\nFigure¬†7: Proof of concept: repeated implementation of AR leads to domain and model shifts.\n\n\n\n\nWe argue that these shifts should be considered as an expected external cost of individual recourse and call for a paradigm shift from individual to collective recourse in these types of situations."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#generalised-framework",
    "href": "content/talks/posts/2022-boe/presentation.html#generalised-framework",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Generalised Framework",
    "text": "Generalised Framework\nFrom individual recourse ‚Ä¶\nWe restate Equation¬†6 to encapsulate latent space search:\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\left\\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)}+ \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\right\\}\n\\end{aligned}\n\\qquad(9)\\]\n‚Ä¶ towards collective recourse\nWe borrow the notion of negative externalities from Economics, to formalise the idea that individual recourse fails to account for external costs:\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\{ {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)} \\\\ &+ \\lambda_1 {\\text{cost}(f(\\mathbf{s}^\\prime))} + \\lambda_2 {\\text{extcost}(f(\\mathbf{s}^\\prime))} \\}\n\\end{aligned}\n\\qquad(10)\\]"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#findings",
    "href": "content/talks/posts/2022-boe/presentation.html#findings",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Findings",
    "text": "Findings\n\n\n\n\n\nResults for synthetic data.\n\n\n\n\n\n\nResults for real-word data."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#mitigation-strategies",
    "href": "content/talks/posts/2022-boe/presentation.html#mitigation-strategies",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Mitigation Strategies",
    "text": "Mitigation Strategies\n\n\n\nChoose more conservative decision thresholds.\nClassifer Preserving ROAR (ClaPROAR): penalise classifier loss.\n\n\\[\n\\begin{aligned}\n\\text{extcost}(f(\\mathbf{s}^\\prime)) = l(M(f(\\mathbf{s}^\\prime)),y^\\prime)\n\\end{aligned}\n\\qquad(11)\\]\n\nGravitational Counterfactual Explanations: penalise distance to some sensible point in the target domain.\n\n\\[\n\\begin{aligned}\n\\text{extcost}(f(\\mathbf{s}^\\prime)) = \\text{dist}(f(\\mathbf{s}^\\prime),\\bar{x})  \n\\end{aligned}\n\\qquad(12)\\]\n\n\n\n\n\n\n\nFigure¬†8: Illustrative example demonstrating the properties of the various mitigation strategies. Samples from the negative class \\((y = 0)\\) are marked in blue while samples of the positive class \\((y = 1)\\) are marked in orange.\n\n\n\n\n\n\n\n\n\nMitigation strategies applied to synthetic data.\n\n\n\n\n\n\nMitigation strategies applied to real-world data."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "href": "content/talks/posts/2022-boe/presentation.html#effortless-bayesian-deep-learning-through-laplace-redux",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Effortless Bayesian Deep Learning through Laplace Redux",
    "text": "Effortless Bayesian Deep Learning through Laplace Redux\n   \n\n\nLaplaceRedux.jl (formerly BayesLaplace.jl) is a small package that can be used for effortless Bayesian Deep Learning and Logistic Regression trough Laplace Approximation. It is inspired by this Python library and its companion paper.\n\n\n\nPlugin Approximation (left) and Laplace Posterior (right) for simple artificial neural network.\n\n\n\n\n\n\nSimulation of changing posteriour predictive distribution. Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#conformalprediction.jl",
    "href": "content/talks/posts/2022-boe/presentation.html#conformalprediction.jl",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "ConformalPrediction.jl",
    "text": "ConformalPrediction.jl\n      \nConformalPrediction.jl is a package for Uncertainty Quantification (UQ) through Conformal Prediction (CP) in Julia. It is designed to work with supervised models trained in MLJ (Blaom et al. 2020). Conformal Prediction is distribution-free, easy-to-understand, easy-to-use and model-agnostic.\n\n\n\nConformal Prediction in action: Prediction sets for two different samples and changing coverage rates. As coverage grows, so does the size of the prediction sets."
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#more-resources",
    "href": "content/talks/posts/2022-boe/presentation.html#more-resources",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nBlog post introducing CE: [TDS], [blog].\nBlog post on Laplace Redux: [TDS], [blog].\nBlog post on Conformal Prediction: [TDS], [blog].\n\n\n‚Ä¶ or get involved! ü§ó\n\n\nContributor‚Äôs Guide for CounterfactualExplanations.jl\nContributor‚Äôs Guide for ConformalPrediction.jl"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#image-sources",
    "href": "content/talks/posts/2022-boe/presentation.html#image-sources",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "Image Sources",
    "text": "Image Sources\n\nCrystal ball on beach: Nicole Avagliano on Unsplash\nColour gradient: A.Z on Unsplash\nElephant herd: Sergi Ferrete on Unsplash\nBank of England logo: Bank of England here"
  },
  {
    "objectID": "content/talks/posts/2022-boe/presentation.html#references",
    "href": "content/talks/posts/2022-boe/presentation.html#references",
    "title": "Explaining Machine Learning Models through Counterfactuals",
    "section": "References",
    "text": "References\n\n\n\n\nAntor√°n, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and Jos√© Miguel Hern√°ndez-Lobato. 2020. ‚ÄúGetting a Clue: A Method for Explaining Uncertainty Estimates.‚Äù https://arxiv.org/abs/2006.06848.\n\n\nBlaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. ‚ÄúMLJ: A Julia Package for Composable Machine Learning.‚Äù Journal of Open Source Software 5 (55): 2704. https://doi.org/10.21105/joss.02704.\n\n\nGoodfellow, Ian, Jonathon Shlens, and Christian Szegedy. 2015. ‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù https://arxiv.org/abs/1412.6572.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKarimi, Amir-Hossein, Bernhard Sch√∂lkopf, and Isabel Valera. 2021. ‚ÄúAlgorithmic Recourse: From Counterfactual Explanations to Interventions.‚Äù In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 353‚Äì62. FAccT ‚Äô21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445899.\n\n\nKarimi, Amir-Hossein, Julius Von K√ºgelgen, Bernhard Sch√∂lkopf, and Isabel Valera. 2020. ‚ÄúAlgorithmic Recourse Under Imperfect Causal Knowledge: A Probabilistic Approach.‚Äù https://arxiv.org/abs/2006.06831.\n\n\nLakkaraju, Himabindu, and Osbert Bastani. 2020. ‚Äú\" How Do I Fool You?\" Manipulating User Trust via Misleading Black Box Explanations.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 79‚Äì85.\n\n\nLundberg, Scott M, and Su-In Lee. 2017. ‚ÄúA Unified Approach to Interpreting Model Predictions.‚Äù In Proceedings of the 31st International Conference on Neural Information Processing Systems, 4768‚Äì77.\n\n\nMittelstadt, Brent, Chris Russell, and Sandra Wachter. 2019. ‚ÄúExplaining Explanations in AI.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 279‚Äì88. https://doi.org/10.1145/3287560.3287574.\n\n\nMolnar, Christoph. 2022. Interpretable Machine Learning: A Guide for Making Black Box Models Explainable. 2nd ed. https://christophm.github.io/interpretable-ml-book.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nO‚ÄôNeil, Cathy. 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown.\n\n\nPoyiadzi, Rafael, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, and Peter Flach. 2020. ‚ÄúFACE: Feasible and Actionable Counterfactual Explanations.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 344‚Äì50.\n\n\nRibeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. ‚Äú\"Why Should i Trust You?\" Explaining the Predictions of Any Classifier.‚Äù In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1135‚Äì44.\n\n\nRudin, Cynthia. 2019. ‚ÄúStop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead.‚Äù Nature Machine Intelligence 1 (5): 206‚Äì15. https://doi.org/10.1038/s42256-019-0048-x.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nSlack, Dylan, Anna Hilgard, Himabindu Lakkaraju, and Sameer Singh. 2021. ‚ÄúCounterfactual Explanations Can Be Manipulated.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nSlack, Dylan, Sophie Hilgard, Emily Jia, Sameer Singh, and Himabindu Lakkaraju. 2020. ‚ÄúFooling Lime and Shap: Adversarial Attacks on Post Hoc Explanation Methods.‚Äù In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 180‚Äì86.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nUstun, Berk, Alexander Spangher, and Yang Liu. 2019. ‚ÄúActionable Recourse in Linear Classification.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 10‚Äì19. https://doi.org/10.1145/3287560.3287566.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nWilson, Andrew Gordon. 2020. ‚ÄúThe Case for Bayesian Deep Learning.‚Äù https://arxiv.org/abs/2001.10995."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#motivation",
    "href": "content/talks/posts/2024-econdat/presentation.html#motivation",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Motivation",
    "text": "Motivation\n\n\\(A_1\\): \\(enc(\\)‚ÄûIt is essential to bring inflation back to target to avoid drifting into deflation territory.‚Äú\\()\\)\n\\(A_2\\): \\(enc(\\)‚ÄûIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.‚Äú\\()\\)"
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#motivation-1",
    "href": "content/talks/posts/2024-econdat/presentation.html#motivation-1",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Motivation",
    "text": "Motivation\n\n\n\n\\(A_1\\): \\(enc(\\)‚ÄûIt is essential to bring inflation back to target to avoid drifting into deflation territory.‚Äú\\()\\)\n\\(A_2\\): \\(enc(\\)‚ÄûIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.‚Äú\\()\\)\n\n\n‚ÄúThey‚Äôre exactly the same.‚Äù\n‚Äî Linear probe \\(\\widehat{cpi}=f(A)\\)"
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#position",
    "href": "content/talks/posts/2024-econdat/presentation.html#position",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Position",
    "text": "Position\n\nCurrent LLMs embed knowledge. They don‚Äòt ‚Äûunderstand‚Äú anything. They are useful tools, but tools nonetheless.\n\n\n\nMeaningful patterns in embeddings are like doves in the sky.\nHumans are prone to seek patterns and anthropomorphize.\nObserved ‚Äòsparks‚Äô of Artificial General Intelligence are spurious.\nThe academic community should exercise extra caution.\nPublishing incentives need to be adjusted."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#outline",
    "href": "content/talks/posts/2024-econdat/presentation.html#outline",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Outline",
    "text": "Outline\n\n\nExperiments: We probe models of varying complexity including random projections, matrix decompositions, deep autoencoders and transformers.\n\nAll of them successfully distill knowledge and yet none of them develop true understanding.\n\nSocial sciences review: Humans are prone to seek patterns and anthropomorphize.\nConclusion and outlook: More caution at the individual level, and different incentives at the institutional level."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#the-holy-grail",
    "href": "content/talks/posts/2024-econdat/presentation.html#the-holy-grail",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "The Holy Grail",
    "text": "The Holy Grail\nAchievement of Artificial General Intelligence (AGI) has become a grand challenge, and in some cases, an explicit business goal.\n\n\nDefinition\nThe definition of AGI itself is not as clear-cut or consistent:\n\n(loosely) a phenomenon contrasting with ‚Äònarrow AI‚Äô systems, that were trained for specific tasks (Goertzel 2014).\n\n\nPractice\nResearchers have sought to show that AI models generalize to different (and possibly unseen) tasks or show performance considered ‚Äòsurprising‚Äô to humans.\n\nFor example, Google DeepMind claimed their AlphaGeometry model (Trinh et al. 2024) reached a ‚Äòmilestone‚Äô towards AGI."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#a-perfect-storm",
    "href": "content/talks/posts/2024-econdat/presentation.html#a-perfect-storm",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "A Perfect Storm",
    "text": "A Perfect Storm\nRecent developments in the field have created a ‚Äòperfect storm‚Äô for inflated claims:\n\n\nEarly sharing of preprints and code.\nVolume of publishable work has exploded.\nSocial media influencers start playing a role in article discovery and citeability (Weissburg et al. 2024).\nComplexity is increasing because it is incentivized (Birhane et al. 2022)."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#not-mere-stochastic-parrots",
    "href": "content/talks/posts/2024-econdat/presentation.html#not-mere-stochastic-parrots",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "‚ÄúNot Mere Stochastic Parrots‚Äù",
    "text": "‚ÄúNot Mere Stochastic Parrots‚Äù\n\nWe consider a recently viral work (Gurnee and Tegmark 2023a), in which claims about the learning of world models by LLMs were made.\n\nLinear probes (ridge regression) were successfully used to predict geographical locations from LLM embeddings.\n\nClaims on X that this indicates that LLMs are not mere ‚Äòstochastic parrots‚Äô (Bender et al. 2021).\nReactions on X seemed to largely exhibit excitement and surprise at the authors‚Äô findings."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#are-neural-networks-born-with-world-models",
    "href": "content/talks/posts/2024-econdat/presentation.html#are-neural-networks-born-with-world-models",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Are Neural Networks Born with World Models?",
    "text": "Are Neural Networks Born with World Models?\n\n\n\nLlama-2 model tested in Gurnee and Tegmark (2023b) has ingested huge amounts of publicly available data (Touvron et al. 2023).\n\nGeographical locations are literally in the training data: e.g.¬†Wikipedia article for ‚ÄúLondon‚Äù.\nWhere would this information be encoded if not in the embedding space \\(\\mathcal{A}\\)? Is it surprising that \\(A_{\\text{LDN}}=enc(\\text{\"London\"}) \\not\\!\\perp\\!\\!\\!\\perp (\\text{lat}_{\\text{LDN}},\\text{long}_{\\text{LDN}})\\)?\n\nFigure¬†1 shows the predicted coordinates of a linear probe on the final-layer activations of an untrained neural network.\n\n\n\n\n\n\n\n\nFigure¬†1: Predicted coordinate values (out-of-sample) from a linear probe on final-layer activations of an untrained neural network.\n\n\n\n\nModel has seen noisy coordinates plus \\(d\\) random features.\nSingle hidden layer with \\(h &lt; d\\) hidden units."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#pca-as-a-yield-curve-interpreter",
    "href": "content/talks/posts/2024-econdat/presentation.html#pca-as-a-yield-curve-interpreter",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "PCA as a Yield Curve Interpreter",
    "text": "PCA as a Yield Curve Interpreter\nWhat are principal components if not model embeddings?\n\n\n\n\n\n\nFigure¬†2: Top chart: The first two principal components of US Treasury yields over time at daily frequency. Bottom chart: Observed average level and 10yr-3mo spread of the yield curve. Vertical stalks roughly indicate the onset (|GFC) and the beginning of the aftermath (GFC|) of the Global Financial Crisis."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#autoencoders-as-economic-growth-predictors",
    "href": "content/talks/posts/2024-econdat/presentation.html#autoencoders-as-economic-growth-predictors",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Autoencoders as Economic Growth Predictors",
    "text": "Autoencoders as Economic Growth Predictors\n\n\n\nWe train a neural network with a bottleneck layer to predict GDP growth from the yield curve Figure¬†3.\n\nInput: UST yields at different maturities.\nHidden layer, bottleneck layer, hidden layer.\nOutput: GDP growth.\n\nCan we use this for more than just forecasting?\n\n\n\n\n\n\n\n\nFigure¬†3: Simple autoencoder architecture."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#autoencoders-as-economic-growth-predictors-1",
    "href": "content/talks/posts/2024-econdat/presentation.html#autoencoders-as-economic-growth-predictors-1",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Autoencoders as Economic Growth Predictors",
    "text": "Autoencoders as Economic Growth Predictors\n\nYes, this can be used for feature extraction and forecasting:\n\nBottle-neck layer embeddings predict spread and level of the yield curve.\n\n\n\n\n\n\n\n\nFigure¬†4: The left chart shows the actual GDP growth and fitted values from the autoencoder model. The right chart shows the observed average level and spread of the yield curve (solid) along with the predicted values (in-sample) from the linear probe based on the latent embeddings (dashed)"
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#embedding-fomc-comms",
    "href": "content/talks/posts/2024-econdat/presentation.html#embedding-fomc-comms",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Embedding FOMC comms",
    "text": "Embedding FOMC comms\n\nBERT-based model trained on FOMC minutes, speeches and press conferences to classify statements as hawkish or dovish (or neutral) (Shah, Paturi, and Chava 2023).\nWe linearly probe all layers to predict unseen economic indicators (CPI, PPI, UST yields).\nPredictive power increases with layer depth and probes outperform simple AR(\\(p\\)) models.\n\n\n\n\n\n\n\nFigure¬†5: Out-of-sample root mean squared error (RMSE) for the linear probe plotted against FOMC-RoBERTa‚Äôs n-th layer for different indicators."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#sparks-of-economic-understanding",
    "href": "content/talks/posts/2024-econdat/presentation.html#sparks-of-economic-understanding",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Sparks of Economic Understanding?",
    "text": "Sparks of Economic Understanding?\nPremise: If probe results were indicative of some intrinsic ‚Äòunderstanding‚Äô of the economy, then the probe should not be sensitive to random sentences unrelated to economics.\nParrot Test\n\nSelect the best-performing probe for each economic indicator.\nPredict inflation levels for real (related) and perturbed (unrelated) sentences.\n\n\n\n\n\n\n\nFigure¬†6: Probe predictions for sentences about inflation of prices (IP), deflation of prices (DP), inflation of birds (IB) and deflation of birds (DB). The vertical axis shows predicted inflation levels subtracted by the average predicted value of the probe for random noise.\n\n\n\nAs evidenced by Figure¬†6, the probe is easily fooled."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#spurious-relationships",
    "href": "content/talks/posts/2024-econdat/presentation.html#spurious-relationships",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Spurious Relationships",
    "text": "Spurious Relationships\nDefiniton: Varies somewhat (Haig 2003) but distinctly implies that the observation of correlations does not imply causation.\n\nHumans struggle to tell the difference between random and non-random sequences (Falk and Konold 1997).\nLack of expectation that randomness that hints towards a causal relationship will still appear at random.\nEven experts perceive correlations of inflated magnitude (Nickerson 1998) and causal relationships where none exist (Zgraggen et al. 2018)."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#antropomorphism",
    "href": "content/talks/posts/2024-econdat/presentation.html#antropomorphism",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Antropomorphism",
    "text": "Antropomorphism\nDefinition: Human tendency to attribute human-like characteristics to non-human agents and/or objects.\n\nExperience as humans is an always-readily-available template to interpret the world (Epley, Waytz, and Cacioppo 2007).\nMotivation to avoid loneliness may lead us to anthropomorphize inanimate objects Waytz, Epley, and Cacioppo (2010).\nMotivation to be competent may lead us anthropomorphize opaque technologies like LLMs Waytz, Epley, and Cacioppo (2010)"
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#confirmation-bias",
    "href": "content/talks/posts/2024-econdat/presentation.html#confirmation-bias",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Confirmation Bias",
    "text": "Confirmation Bias\nDefinition: Favoring interpretations of evidence that support existing beliefs or hypotheses (Nickerson 1998).\n\nHypotheses in present-day AI research are often implicit, often framed simply as a system being more accurate or efficient, compared to other systems.\n\nFailing to articulate a sufficiently strong null hypothesis leading to a ‚Äòweak‚Äô experiment (Claesen et al. 2022).\n\nIndividuals may place greater emphasis on evidence in support of their hypothesis, and lesser emphasis on evidence that opposes it (Nickerson 1998)."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#conclusion-and-outlook",
    "href": "content/talks/posts/2024-econdat/presentation.html#conclusion-and-outlook",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Conclusion and Outlook",
    "text": "Conclusion and Outlook\n\nWe call for the community to create explicit room for organized skepticism\n\nWelcome negative results\nEncouraging replication studies.\nMove from authorship to contribution-based credit (see e.g.¬†Liem and Demetriou, 2023 and Smith, 1997).\n\nReturn to the Mertonian norms (communism, universalism, disinterestedness, organized skepticism) (Merton et al. 1942)."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#references",
    "href": "content/talks/posts/2024-econdat/presentation.html#references",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "References",
    "text": "References\n\n\nBender, Emily M, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. ‚ÄúOn the dangers of stochastic parrots: Can language models be too big? .‚Äù In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 610‚Äì23.\n\n\nBirhane, Abeba, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit Dotan, and Michelle Bao. 2022. ‚ÄúThe Values Encoded in Machine Learning Research.‚Äù In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT ‚Äô22).\n\n\nClaesen, Aline, Daniel Lakens, Noah van Dongen, et al. 2022. ‚ÄúSeverity and Crises in Science: Are We Getting It Right When We‚Äôre Right and Wrong When We‚Äôre Wrong?‚Äù\n\n\nEpley, Nicholas, Adam Waytz, and John T Cacioppo. 2007. ‚ÄúOn seeing human: a three-factor theory of anthropomorphism.‚Äù Psychological Review 114 (4): 864.\n\n\nFalk, Ruma, and Clifford Konold. 1997. ‚ÄúMaking sense of randomness: Implicit encoding as a basis for judgment.‚Äù Psychological Review 104 (2): 301.\n\n\nGoertzel, Ben. 2014. ‚ÄúArtificial general intelligence: concept, state of the art, and future prospects.‚Äù Journal of Artificial General Intelligence 5 (1): 1.\n\n\nGurnee, Wes, and Max Tegmark. 2023b. ‚ÄúLanguage Models Represent Space and Time.‚Äù arXiv Preprint arXiv:2310.02207v2.\n\n\n‚Äî‚Äî‚Äî. 2023a. ‚ÄúLanguage Models Represent Space and Time.‚Äù arXiv Preprint arXiv:2310.02207v1.\n\n\nHaig, Brian D. 2003. ‚ÄúWhat is a spurious correlation?‚Äù Understanding Statistics: Statistical Issues in Psychology, Education, and the Social Sciences 2 (2): 125‚Äì32.\n\n\nMerton, Robert K et al. 1942. ‚ÄúScience and technology in a democratic order.‚Äù Journal of Legal and Political Sociology 1 (1): 115‚Äì26.\n\n\nNickerson, Raymond S. 1998. ‚ÄúConfirmation bias: A ubiquitous phenomenon in many guises.‚Äù Review of General Psychology 2 (2): 175‚Äì220.\n\n\nShah, Agam, Suvan Paturi, and Sudheer Chava. 2023. ‚ÄúTrillion Dollar Words: A New Financial Dataset, Task & Market Analysis.‚Äù arXiv Preprint arXiv:2310.02207v1. https://arxiv.org/abs/2305.07972.\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth√©e Lacroix, Baptiste Rozi√®re, et al. 2023. ‚ÄúLLaMA: Open and Efficient Foundation Language Models.‚Äù https://arxiv.org/abs/2302.13971.\n\n\nTrinh, T. H., Wu, Y., Le, and Q. V. et al. 2024. ‚ÄúSolving olympiad geometry without human demonstrations.‚Äù Nature 625, 476‚Äì82. https://doi.org/https://doi.org/10.1038/s41586-023-06747-5.\n\n\nWaytz, Adam, Nicholas Epley, and John T Cacioppo. 2010. ‚ÄúSocial cognition unbound: Insights into anthropomorphism and dehumanization.‚Äù Current Directions in Psychological Science 19 (1): 58‚Äì62.\n\n\nWeissburg, Iain Xie, Mehir Arora, Liangming Pan, and William Yang Wang. 2024. ‚ÄúTweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility.‚Äù arXiv Preprint arXiv:2401.13782.\n\n\nZgraggen, Emanuel, Zheguang Zhao, Robert Zeleznik, and Tim Kraska. 2018. ‚ÄúInvestigating the effect of the multiple comparisons problem in visual analysis.‚Äù In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, 1‚Äì12."
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#image-sources",
    "href": "content/talks/posts/2024-econdat/presentation.html#image-sources",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Image sources",
    "text": "Image sources\n\nLeonardo DiCaprio: Meme template by user on Reddit\nTarot cards: Photo by Viva Luna Studios on Unsplash\nWall-E: Photo by ray rui on Unsplash"
  },
  {
    "objectID": "content/talks/posts/2024-econdat/presentation.html#quote-sources",
    "href": "content/talks/posts/2024-econdat/presentation.html#quote-sources",
    "title": "Against Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è",
    "section": "Quote sources",
    "text": "Quote sources\n\n‚ÄúThere! It‚Äôs sentient‚Äù‚Äîthat engineer at Google (probably!)\n‚ÄúThe human mind is a pattern-seeking device‚Äù‚ÄîDaniel Kahneman\n‚ÄúWe‚Äôre fascinated with robots because they are reflections of ourselves.‚Äù‚ÄîKen Goldberg"
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#motivation",
    "href": "content/talks/posts/2024-turing/presentation.html#motivation",
    "title": "Trustworthy AI in Julia",
    "section": "Motivation",
    "text": "Motivation\nWhy Trustworthy AI and why in Julia?\n\n\nOpaque AI technologies have entered the public domain with far-reaching stakes.\nThese technologies are here to stay, so at best, we can make them more trustworthy.\nJulia has an edge:\n\nTransparency: most packages are written in pure Julia.\nIntuitiveness: great Lisp-like support for symbolic computing.\nCommunity: welcoming, supportive and diverse (sort of!).\nAutodiff: top-notch support, which helps with common XAI approaches."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#outline",
    "href": "content/talks/posts/2024-turing/presentation.html#outline",
    "title": "Trustworthy AI in Julia",
    "section": "Outline",
    "text": "Outline\n\n\nTaija: A brief overview of the Taija ecosystem.\n\nOverview, Projects, Research.\n\nDeep Dive: A closer look at some of our core packages.\n\nCounterfactual Explanations, Conformal Prediction, Laplace Redux, Joint Energy Models.\n\nThe Journey: Julia throught my PhD\n\nFrom ‚ÄúI‚Äôll try this out‚Äù to ‚ÄúI‚Äôll never go back‚Äù."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#overview",
    "href": "content/talks/posts/2024-turing/presentation.html#overview",
    "title": "Trustworthy AI in Julia",
    "section": "Overview",
    "text": "Overview\nCore Packages\n\nModel Explainability (CounterfactualExplanations.jl)\nPredictive Uncertainty Quantification (ConformalPrediction.jl)\nEffortless Bayesian Deep Learning (LaplaceRedux.jl)\n\nMeta Packages\n\nPlotting (TaijaPlotting.jl)\nDatasets for testing and benchmarking (TaijaData.jl)\nParallelization (TaijaParallel.jl)\nInteroperability with other programming languages (TaijaInteroperability.jl)\n\nThe TaijaBase.jl package provides common symbols, types and functions that are used across all or multiple Taija packages."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#milestones",
    "href": "content/talks/posts/2024-turing/presentation.html#milestones",
    "title": "Trustworthy AI in Julia",
    "section": "Milestones",
    "text": "Milestones\n2021\n\nFirst small-scale project in Julia on Bayesian regression."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#milestones-1",
    "href": "content/talks/posts/2024-turing/presentation.html#milestones-1",
    "title": "Trustworthy AI in Julia",
    "section": "Milestones",
    "text": "Milestones\n2022\n\nPresented CounterfactualExplanations.jl and LaplaceRedux.jl at JuliaCon.\n\n2021\n\nFirst small-scale project in Julia on Bayesian regression."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#milestones-2",
    "href": "content/talks/posts/2024-turing/presentation.html#milestones-2",
    "title": "Trustworthy AI in Julia",
    "section": "Milestones",
    "text": "Milestones\n2023\n\nPresented ConformalPrediction.jl at JuliaCon.\nTU Delft students work on CounterfactualExplanations.jl and LaPlaceRedux.jl.\nCounterfactualExplanations.jl published in JuliaCon proceedings.\n\n2022\n\nPresented CounterfactualExplanations.jl and LaplaceRedux.jl at JuliaCon.\n\n2021\n\nFirst small-scale project in Julia on Bayesian regression."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#milestones-3",
    "href": "content/talks/posts/2024-turing/presentation.html#milestones-3",
    "title": "Trustworthy AI in Julia",
    "section": "Milestones",
    "text": "Milestones\n2024\n\nMultiple presentations at JuliaCon this summer.\nGSoC/JSoC projects on Causal Counterfactuals and Conformal Bayes.\nTU Delft students working on TaijaInteractive.jl.\n\n2023\n\nPresented ConformalPrediction.jl at JuliaCon.\nTU Delft students work on CounterfactualExplanations.jl and LaPlaceRedux.jl.\nCounterfactualExplanations.jl published in JuliaCon proceedings.\n\n2022\n\nPresented CounterfactualExplanations.jl and LaplaceRedux.jl at JuliaCon.\n\n2021\n\nFirst small-scale project in Julia on Bayesian regression."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#research",
    "href": "content/talks/posts/2024-turing/presentation.html#research",
    "title": "Trustworthy AI in Julia",
    "section": "Research",
    "text": "Research\nTaija has been used in the following publications:\n\nConformal Intent Classification and Clarification for Fast and Accurate Intent Recognition (Hengst et al. 2024) upcoming in ACL‚Äôs NAACL Findings 20241.\nFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals (Altmeyer et al. 2024) published in Proceedings of the AAAI Conference on Artificial Intelligence 2024.\nExplaining Black-Box Models through Counterfactuals (Altmeyer, Deursen, and Liem 2023) published in JuliaCon Proceedings.\nEndogenous Macrodynamics in Algorithmic Recourse (Altmeyer, Angela, et al. 2023) published in Proceedings of the 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML).\n\nExperiments were run in parallel using Python‚Äôs MAPIE and ConformalPrediction.jl, in order to cross-check results. Reported results were produced using MAPIE."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#background",
    "href": "content/talks/posts/2024-turing/presentation.html#background",
    "title": "Trustworthy AI in Julia",
    "section": "Background",
    "text": "Background\n\\[\n\\begin{aligned}\n\\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} + \\lambda {\\text{cost}(f(\\mathbf{Z}^\\prime)) }  \\}\n\\end{aligned}\n\\]\n\n\nCounterfactual Explanations (CE) explain how inputs into a model need to change for it to produce different outputs.\nüìú Altmeyer, Deursen, and Liem (2023) @ JuliaCon 2022.\n\n\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#examples",
    "href": "content/talks/posts/2024-turing/presentation.html#examples",
    "title": "Trustworthy AI in Julia",
    "section": "Examples",
    "text": "Examples\n\nA motivating example.\nA simple usage example.\nWhistle-stop tour of different generators here.\nComposing a custom generator using simple macros here.\nScaling things up with parallelization here.\nExtension for differentiable tree-based models here."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2024-turing/presentation.html#pick-your-poison",
    "title": "Trustworthy AI in Julia",
    "section": "Pick your Poison",
    "text": "Pick your Poison\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction.\n\nWhich one would you pick?\n\n\n\n\n\n\n\nFigure¬†2: Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using Wachter (Wachter, Mittelstadt, and Russell 2017), Schut (Schut et al. 2021) and REVISE (Joshi et al. 2019)."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#ecccos-from-the-black-box",
    "href": "content/talks/posts/2024-turing/presentation.html#ecccos-from-the-black-box",
    "title": "Trustworthy AI in Julia",
    "section": "ECCCos from the Black-Box",
    "text": "ECCCos from the Black-Box\n\n\nüìú Altmeyer, Farmanbar, et al. (2023) @ AAAI 2024\n\n\n\nKey Idea\n\n\nUse the hybrid objective of joint energy models (JEM) and a model-agnostic penalty for predictive uncertainty: Energy-Constrained (\\(\\mathcal{E}_{\\theta}\\)) Conformal (\\(\\Omega\\)) Counterfactuals (ECCCo).\n\n\n\n\nECCCo objective1:\n\\[\n\\begin{aligned}\n& \\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {L_{\\text{clf}}(f(\\mathbf{Z}^\\prime);M_{\\theta},\\mathbf{y}^+)}+ \\lambda_1 {\\text{cost}(f(\\mathbf{Z}^\\prime)) } \\\\\n&+ \\lambda_2 \\mathcal{E}_{\\theta}(f(\\mathbf{Z}^\\prime)|\\mathbf{y}^+) + \\lambda_3 \\Omega(C_{\\theta}(f(\\mathbf{Z}^\\prime);\\alpha)) \\}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nFigure¬†3: Gradient fields and counterfactual paths for different generators.\n\n\n\n\nWe leverage ideas from Grathwohl et al. (2020) and Stutz et al. (2022). See the paper and appendix for a derivation of the objective from first principles."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#faithful-counterfactuals",
    "href": "content/talks/posts/2024-turing/presentation.html#faithful-counterfactuals",
    "title": "Trustworthy AI in Julia",
    "section": "Faithful Counterfactuals",
    "text": "Faithful Counterfactuals\n\n\n\n\n\n\n\n\nFigure¬†4: Turning a 9 into a 7. ECCCo applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).\n\n\n\n\nECCCo generates counterfactuals that\n\nfaithfully represent model quality (Figure¬†4).\nachieve state-of-the-art plausibility (Figure¬†5).\n\n\n\n\n\n\n\nFigure¬†5: Results for different generators (from 3 to 5)."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#ongoing-work",
    "href": "content/talks/posts/2024-turing/presentation.html#ongoing-work",
    "title": "Trustworthy AI in Julia",
    "section": "Ongoing Work",
    "text": "Ongoing Work\n\nJSoC 2024: From Counterfactuals to Interventions - Recourse through Minimal Causal Interventions with Jorge Luiz Franco and co-mentor Moritz Schauer (CausalInference.jl)\n\nWe typically make the implicit causal assumption that all features are independent.\nIf we have (imperfect) causal knowledge, we can use it to guide the search for counterfactuals.\n\nWhat Makes Models Explainable?: using ECCCo to benchmark models.\nFour master‚Äôs theses all using CounterfactualExplanations.jl (LLM explainability, imbalanced data, recourse in practice and counterfactuals for model testing)."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#background-1",
    "href": "content/talks/posts/2024-turing/presentation.html#background-1",
    "title": "Trustworthy AI in Julia",
    "section": "Background",
    "text": "Background\nIntuitively, CP works under the premise of turning heuristic notions of uncertainty into rigorous uncertainty estimates through repeated sampling or the use of dedicated calibration data.\n\n\n\nConformal Prediction in action: prediction intervals at varying coverage rates. As coverage grows, so does the width of the prediction interval."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#examples-1",
    "href": "content/talks/posts/2024-turing/presentation.html#examples-1",
    "title": "Trustworthy AI in Julia",
    "section": "Examples",
    "text": "Examples\n\nA simple usage example.\nConformalizing an image classifier here.\nHow to build a conformal chatbot here.\n\n\n\n\nConformalPrediction.jl meets SymbolicRegression.jl."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#ongoing-work-1",
    "href": "content/talks/posts/2024-turing/presentation.html#ongoing-work-1",
    "title": "Trustworthy AI in Julia",
    "section": "Ongoing Work",
    "text": "Ongoing Work\n\nGSoC 2024: Add the support to Conformal Bayes to Taija with Pasquale Caterino and co-mentor Mojtaba Farmanbar\nSupport for conformal training (Stutz et al. 2022).\nCode refactoring to allow adding support for parallelization using TaijaParallel.jl.\nJuliaCon Proceedings paper (in planning)."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#interactive-tour",
    "href": "content/talks/posts/2024-turing/presentation.html#interactive-tour",
    "title": "Trustworthy AI in Julia",
    "section": "Interactive Tour",
    "text": "Interactive Tour\n‚Ä¶ if time permits at the end.\n\nFirst time here? Take a quick interactive tour to see what this package can do right on JuliaHub (To run the notebook, hit login and then edit).\n\nThis Pluto.jl üéà notebook won the 2nd Price in the JuliaCon 2023 Notebook Competition."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#background-2",
    "href": "content/talks/posts/2024-turing/presentation.html#background-2",
    "title": "Trustworthy AI in Julia",
    "section": "Background",
    "text": "Background\nWe want BMA for neural networks underspecified by the data (Wilson 2020),\n\\[\np(y|x,\\mathcal{D}) = \\int p(y|x,\\theta)p(\\theta|\\mathcal{D})d\\theta\n\\tag{1}\\]\nwhere \\(p(y|x,\\theta)\\) is the likelihood, \\(p(\\theta|\\mathcal{D})\\) is the posterior and \\(\\mathcal{D}\\) is the training data.\n\n\n\nProblem üò¢: Intractable posterior \\(p(\\theta|\\mathcal{D})\\).\nConvention ü§î: Use MAP estimate \\(p(y|x,\\mathcal{D}) \\approx p(y|x,\\hat\\theta)\\) with \\(\\hat\\theta=\\arg\\max_{\\theta}p(\\theta|\\mathcal{D})\\).\nIdea üí°: Taylor approximation at the mode amounts to multivariate Gaussian centered around MAP.\n\n\n\n\n\nUnnormalized log-posterior and corresponding Laplace Approximation. Source: Murphy (2022)."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#model-assumptions",
    "href": "content/talks/posts/2024-turing/presentation.html#model-assumptions",
    "title": "Trustworthy AI in Julia",
    "section": "Model Assumptions",
    "text": "Model Assumptions\nExample (binary classification): We assume Bernoulli likelihood and a Gaussian prior for our weights ‚Ä¶\n\\[\np(y_n|\\mathbf{x}_n;\\mathbf{w})\\sim\\text{Ber}(y_n|\\sigma(\\mathbf{w}^T\\mathbf{x}_n))\n\\tag{2}\\]\n\\[\np(\\theta) \\sim \\mathcal{N} \\left( \\theta | \\mathbf{0}, \\lambda^{-1} \\mathbf{I} \\right)=\\mathcal{N} \\left( \\theta | \\mathbf{0}, \\mathbf{H}_0^{-1} \\right)\n\\tag{3}\\]\n\n‚Ä¶ which yields the following negative log-likelihood (or energy) function (Murphy 2022):\n\\[\n\\psi(\\theta)= - \\sum_{n}^N [y_n \\log \\mu_n + (1-y_n)\\log (1-\\mu_n)] + \\\\ \\frac{1}{2} (\\theta-\\theta_0)^T\\mathbf{H}_0(\\theta-\\theta_0)\n\\tag{4}\\]"
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#taylor-expansion",
    "href": "content/talks/posts/2024-turing/presentation.html#taylor-expansion",
    "title": "Trustworthy AI in Julia",
    "section": "Taylor Expansion",
    "text": "Taylor Expansion\nWe have the following normalized posterior:\n\\[\np(\\theta|\\mathcal{D}) = Z^{-1} p(\\mathcal{D}|\\theta)p(\\theta) = Z^{-1} \\exp(-\\psi(\\theta))\n\\tag{5}\\]\nwith \\(Z = \\int p(\\mathcal{D}|\\theta) p(\\theta)\\).\n\nThen, second-order Taylor expansion of the energy function around the mode \\(\\theta_0\\) gives us the Laplace approximation (Murphy 2022):\n\\[\n\\psi(\\theta) \\approxeq \\psi(\\hat\\theta) + \\frac{1}{2} (\\theta-\\hat\\theta)^T \\mathbf{H}(\\theta-\\hat\\theta)\n\\tag{6}\\]\n\n\nThus, we have\n\\[\np(\\theta|\\mathcal{D}) \\approxeq \\mathcal{N}(\\theta;\\hat\\theta,-\\mathbf{H}^{-1})\n\\tag{7}\\]"
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#hessian-approximation",
    "href": "content/talks/posts/2024-turing/presentation.html#hessian-approximation",
    "title": "Trustworthy AI in Julia",
    "section": "Hessian Approximation",
    "text": "Hessian Approximation\n\nChallenge lies in computing the Hessian \\(\\mathbf{H}\\).\nWe can use the Empirical Fisher or Generalized Gauss-Newton approximation (Murphy 2022).\n\nStill quadratic in the number of parameters.\n\nFor scalable solutions, we can use the diagonal approximation or the K-FAC approximation or work with a subnetwork."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#examples-2",
    "href": "content/talks/posts/2024-turing/presentation.html#examples-2",
    "title": "Trustworthy AI in Julia",
    "section": "Examples",
    "text": "Examples\n\nA basic usage example.\nA binary classification example with prior tuning through empirical Bayes.\nCounterfactual explanations with Laplace Redux here."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#background-3",
    "href": "content/talks/posts/2024-turing/presentation.html#background-3",
    "title": "Trustworthy AI in Julia",
    "section": "Background",
    "text": "Background\nJoint Energy Models (JEM) are a class of energy-based models that learn a joint distribution over inputs and outputs (Grathwohl et al. 2020).\n\n\n\nTraining JEMs."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#package",
    "href": "content/talks/posts/2024-turing/presentation.html#package",
    "title": "Trustworthy AI in Julia",
    "section": "Package",
    "text": "Package\n\n\n\nPackage used in Altmeyer et al. (2024), but less mature than the other packages.\nSimple usage example can be found here.\n\n\nContributions welcome!\n\n\n\n\n\nSamples generated through SGLD for JEM ensemble."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#timeline",
    "href": "content/talks/posts/2024-turing/presentation.html#timeline",
    "title": "Trustworthy AI in Julia",
    "section": "Timeline",
    "text": "Timeline\n\nBackground in R and Python (mostly R), a little bit of MATLAB during my master‚Äôs\nFirst looked at Julia (v0.6) in 2017 during my master‚Äôs but quickly abandoned it.\nDuring my master‚Äôs in Data Science (2021) I started to get frustrated with the speed of R and Python.\n\nDid some work in C++ and Rcpp, but it was too cumbersome.\n\nStarted my PhD in Trustworthy AI in September 2021 and decided to give Julia another go.\nHaven‚Äôt looked back since!"
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#the-good",
    "href": "content/talks/posts/2024-turing/presentation.html#the-good",
    "title": "Trustworthy AI in Julia",
    "section": "The Good",
    "text": "The Good\n\nJulia is uniquely expressive and intuitive, making it easy to prototype and test ideas (especially in research).\nThe package manager will have you writing and shipping your own packages in no time.\nStudents at TU Delft have been able to pick up Julia quickly and contribute to Taija projects.\nMultiple dispatch is a game-changer for writing clean and efficient code.\nThe release of Quarto in 2021 has made it easy to transition from R (Studio) to Julia."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#the-bad",
    "href": "content/talks/posts/2024-turing/presentation.html#the-bad",
    "title": "Trustworthy AI in Julia",
    "section": "The Bad",
    "text": "The Bad\n\nExpect to implement things from scratch (not always a bad thing!).\nSome important packages are still in development and lack contributors (e.g.¬†Transformers.jl).\nI‚Äôm still sometimes puzzled by implicit imports (and I know my students are too!).\nAI research is still dominated by Python/R, so developing in Julia does not always feel impactful."
  },
  {
    "objectID": "content/talks/posts/2024-turing/presentation.html#references",
    "href": "content/talks/posts/2024-turing/presentation.html#references",
    "title": "Trustworthy AI in Julia",
    "section": "References",
    "text": "References\n\n\nAltmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia CS Liem. 2023. ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse.‚Äù In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 418‚Äì31. IEEE.\n\n\nAltmeyer, Patrick, Arie van Deursen, and Cynthia C. S. Liem. 2023. ‚ÄúExplaining Black-Box Models through Counterfactuals.‚Äù In Proceedings of the JuliaCon Conferences, 1:130.\n\n\nAltmeyer, Patrick, Mojtaba Farmanbar, Arie van Deursen, and Cynthia C. S. Liem. 2023. ‚ÄúFaithful Model Explanations Through Energy-Constrained Conformal Counterfactuals.‚Äù https://arxiv.org/abs/2312.10648.\n\n\n‚Äî‚Äî‚Äî. 2024. ‚ÄúFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals.‚Äù In Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence, 38:10829‚Äì37. 10. https://doi.org/10.1609/aaai.v38i10.28956.\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nHengst, Floris den, Ralf Wolter, Patrick Altmeyer, and Arda Kaygan. 2024. ‚ÄúConformal Intent Classification and Clarification for Fast and Accurate Intent Recognition.‚Äù https://arxiv.org/abs/2403.18973.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. MIT Press.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nStutz, David, Krishnamurthy, Dvijotham, Ali Taylan Cemgil, and Arnaud Doucet. 2022. ‚ÄúLearning Optimal Conformal Classifiers.‚Äù https://arxiv.org/abs/2110.09192.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nWilson, Andrew Gordon. 2020. ‚ÄúThe Case for Bayesian Deep Learning.‚Äù https://arxiv.org/abs/2001.10995."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#quick-introduction",
    "href": "content/talks/posts/2023-dnb/presentation.html#quick-introduction",
    "title": "Faithful Model Explanations",
    "section": "Quick Introduction",
    "text": "Quick Introduction\n\n\nSlides on my website, scan this code!\n\n\n\n\n\n3rd year PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nPart of AI for FinTech Research Lab‚Äî5yr collaboration between TU Delft and ING.\nPreviously, educational background in Economics and Finance and two years in Monetary Policy at the Bank of England.\nResearch: Trustworthy AI for real-world problems, particularly finance.\nBlogger, Julia developer and founder of Taija."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#research",
    "href": "content/talks/posts/2023-dnb/presentation.html#research",
    "title": "Faithful Model Explanations",
    "section": "Research",
    "text": "Research\n\n\nTo give you a better idea of my research profile, I‚Äôve listed some of my publications below.\nThe focus today will be on Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals, which is still under review.\n\n\n\n\nTrustworthy AI\n\nFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals (under review).\nEndogenous Macrodynamics in Algorithmic Recourse (Altmeyer, Angela, et al. 2023).\nExplaining Black-Box Models Through Counterfactuals (Altmeyer, Deursen, and Liem 2023).\n\n\nFinance and Economics\n\nYield curve sensitivity to investor positioning around economic shocks (Altmeyer, Boneva, et al. 2023) (BoE Staff Working Paper).\nDeep vector autoregression for macroeconomic data (Agustƒ±ÃÅ, Altmeyer, and Vidal-Quadras 2021) (NeurIPS MLECON 2021, DNB DS workshop and published through BIS)\nOption pricing in the Heston stochastic volatility model: an empirical evaluation (Altmeyer et al. 2018)"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#in-a-nutshell",
    "href": "content/talks/posts/2023-dnb/presentation.html#in-a-nutshell",
    "title": "Faithful Model Explanations",
    "section": "In A Nutshell",
    "text": "In A Nutshell\n\n‚Äú[‚Ä¶] unified front of our expertise in this area formed to help the financial industry solve the growingly complex challenges.‚Äù\n‚ÄîDelft FinTech Lab\n\n\n\nBackground\n\nFinance at the forefront of digitalization.\nOver 50 TU Delft researchers in FinTech.\nWith dozens of societal partners.\n\n\nObjective\n\nStrengthen societal and industrial impact.\nIncrease collaboration and visibility."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#core-pillars",
    "href": "content/talks/posts/2023-dnb/presentation.html#core-pillars",
    "title": "Faithful Model Explanations",
    "section": "Core Pillars",
    "text": "Core Pillars\n\n\n\nTrustworthy Financial Systems led by Stefan Buijsman.\nQuantitative Modelling led by Antonis Papapantoleon.\nFinancial Data Intelligence led by Asterios Katsifodimos.\nBlockchain led by J√©r√©mie Decouchant.\n\n\n\n\n\n\nReliable and trustworthy financial systems are explainable and transparent.\nModel development and validation, derivative pricing, and investment analysis.\nArtificial intelligence, data and software analytics.\nDevelopment of decentralized systems.\n\n\n\n\nWhat about topics specific to supervision?"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#natural-language-processing",
    "href": "content/talks/posts/2023-dnb/presentation.html#natural-language-processing",
    "title": "Faithful Model Explanations",
    "section": "Natural language processing",
    "text": "Natural language processing\n\n\nIn this context, this is usually about ‚Ä¶\nBut perhaps also other things like sentiment analysis as a proxy for uncertainty or risk.\n\n\n\nMine large volumes of text.\nRetrieve relevant information from large collections of text.\nLong document understanding and track/identify/predict anomaly patterns.\nExplainable AI for NLP (Arous et al. 2021).\nPredictive Uncertainty Quantification for LLMs (see blog post)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#privacy-enhancing-technologies-pet",
    "href": "content/talks/posts/2023-dnb/presentation.html#privacy-enhancing-technologies-pet",
    "title": "Faithful Model Explanations",
    "section": "Privacy Enhancing Technologies (PET)",
    "text": "Privacy Enhancing Technologies (PET)\n\n\nThis is not my area of expertise but, of course, it is very important to ensure that data is handled in a privacy-preserving manner.\nI attended a conference earlier this year that involved a competition to extract training data from a large language model and the results were quite shocking.\nThis is a huge concern especially in the context of highly sensitive financial data.\n\n\n\nSynthetic data generation by ML, algorithmic, probabilistic and statistical techniques (Porsius Martins 2023; Werf 2021).\nStatistics/econometrics under privacy constraints ex. differential privacy.\nMultiparty computations and homomorphic encryptions."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#human-ai-collaboration",
    "href": "content/talks/posts/2023-dnb/presentation.html#human-ai-collaboration",
    "title": "Faithful Model Explanations",
    "section": "Human-AI Collaboration",
    "text": "Human-AI Collaboration\n\n\nNext, we have human-AI collaboration and here we are getting a bit closer to my area of expertise.\nA term you may have heard a lot recently is ‚Äòhuman alignment‚Äô: we want to ensure that AI systems are aligned with human values.\nThat can be achieved by keeping humans in the loop.\n\n\n\nAugmenting human experts with AI.\n\n\nHybrid human-AI workflows: amplify human intelligence, reduce human costs, and improve precaution.\nCollaborative human-AI knowledge synthesis.\nExplainable AI (Anand et al. 2022; Leonhardt, Rudra, and Anand 2023), and human-in-the-loop continual learning (Yang et al. 2018)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#automated-compliance",
    "href": "content/talks/posts/2023-dnb/presentation.html#automated-compliance",
    "title": "Faithful Model Explanations",
    "section": "Automated Compliance",
    "text": "Automated Compliance\n\n\nAnd finally, another relevant topic is automated compliance.\nWe want to ensure, for example, that ‚Ä¶\n\n\n\nEnsure decisions made by banks‚Äô models are compliant by being explainable and robust:\n\n\nCounterfactual reasoning and contestability (Altmeyer, Angela, et al. 2023; Altmeyer, Deursen, and Liem 2023)\n\n\nEthics assessment, AI governance\nPredictive uncertainty: How robust/uncertain predictions are (conformal predictions) in a model-agnostic manner."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2023-dnb/presentation.html#counterfactual-explanations",
    "title": "Faithful Model Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\nBorn out of the need for explanations ‚Ä¶\n\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs (Wachter, Mittelstadt, and Russell 2017).\n\nProvided the changes are realistic and actionable, they can be used for Algorithmic Recourse (AR) to help individuals who face adverse outcomes."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-consumer-credit",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-consumer-credit",
    "title": "Faithful Model Explanations",
    "section": "Example: Consumer Credit",
    "text": "Example: Consumer Credit\nFrom ‚Äòloan denied‚Äô to ‚Äòloan supplied‚Äô: CounterfactualExplanations.jl üì¶.\n\n\n\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search.\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-insurance-premium",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-insurance-premium",
    "title": "Faithful Model Explanations",
    "section": "Example: Insurance Premium1",
    "text": "Example: Insurance Premium1\n\n\nInput \\(\\mathbf{X}\\): A dataset of individuals containing demographic and financial information.\nAdditional Input \\(\\mathbf{Z}\\): Individuals can opt-in to provide their personal Apple Health data to improve their chance of receiving a lower premium.\nBinary output \\(\\mathbf{Y}\\): based on the data, the individual is either eligible (\\(y=1\\)) or not eligible (\\(y=0\\)) for a lower premium.\nTo model \\(p(y=1|X)\\) the insurance provider can rely on an interpretable linear classifier.\nTo model \\(p(y=1|X,Z)\\) the insurance provider turns to a more accurate but less interpretable black-box model.\n\n\nFor simplicity, we‚Äôll stay in the classification setting. Work on counterfactual regression like Spooner et al. (2021) exists but it is scarce."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-insurance-premium-1",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-insurance-premium-1",
    "title": "Faithful Model Explanations",
    "section": "Example: Insurance Premium",
    "text": "Example: Insurance Premium\nIn the EU, individuals have the right ‚Äú[‚Ä¶] to obtain an explanation of the decision reached after such assessment and to challenge the decision.‚Äù (Recital 71 of the General Data Protection Regulation (GDPR))\n\n\nIn our example, who do you think is most likely to ask for an explanation?"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#gradient-based-counterfactual-search",
    "href": "content/talks/posts/2023-dnb/presentation.html#gradient-based-counterfactual-search",
    "title": "Faithful Model Explanations",
    "section": "Gradient-based Counterfactual Search",
    "text": "Gradient-based Counterfactual Search\nThe starting point for most counterfactual generators is as follows,\n\\[\n\\begin{aligned}\n\\mathbf{Z}^\\prime =& \\arg \\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} \\\\ &+ \\lambda {\\text{cost}(f(\\mathbf{Z}^\\prime)) }  \\}\n\\end{aligned}\n\\tag{1}\\]\nwhere \\(\\mathbf{Z}^\\prime\\) is a counterfactual, \\(M_{\\theta}\\) is the black-box model and \\(\\mathbf{y}^+\\) is the desired output."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#but-wait-a-second",
    "href": "content/talks/posts/2023-dnb/presentation.html#but-wait-a-second",
    "title": "Faithful Model Explanations",
    "section": "But wait a second ‚Ä¶",
    "text": "But wait a second ‚Ä¶\nEquation¬†1 looks a lot like an adversarial attack (Goodfellow, Shlens, and Szegedy 2015), doesn‚Äôt it?\n\n\n\n\n\n\nFigure¬†3: Adversarial attack on an Image Classifier.\n\n\n\nIn both settings, we take gradients with respect to features \\(\\nabla_{\\mathbf{Z}^\\prime}\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)\\) in order to trigger changes in the model‚Äôs output."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#gradient-descend-visualized",
    "href": "content/talks/posts/2023-dnb/presentation.html#gradient-descend-visualized",
    "title": "Faithful Model Explanations",
    "section": "Gradient Descend Visualized",
    "text": "Gradient Descend Visualized\n\n\n\n\n\n\nFigure¬†4: Gradient-based counterfactual search."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#open-questions",
    "href": "content/talks/posts/2023-dnb/presentation.html#open-questions",
    "title": "Faithful Model Explanations",
    "section": "Open Questions",
    "text": "Open Questions\n\n\nWhat makes a counterfactual plausible?\nWhy do we need plausibility?\nIs plausibility all we need?\nWhat makes models more explainable?"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#plausibility",
    "href": "content/talks/posts/2023-dnb/presentation.html#plausibility",
    "title": "Faithful Model Explanations",
    "section": "Plausibility",
    "text": "Plausibility\nThere‚Äôs no consensus on the exact definition of plausibility but we think about it as follows:\n\nDefinition 1 (Plausible Counterfactuals) Let \\(\\mathcal{X}|\\mathbf{y}^+= p(\\mathbf{x}|\\mathbf{y}^+)\\) denote the true conditional distribution of samples in the target class \\(\\mathbf{y}^+\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a plausible counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}|\\mathbf{y}^+\\)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#counter-example",
    "href": "content/talks/posts/2023-dnb/presentation.html#counter-example",
    "title": "Faithful Model Explanations",
    "section": "Counter Example",
    "text": "Counter Example\n\n\n\nThe counterfactual in Figure¬†5 is valid: it has crossed the decision boundary.\nBut is it consistent with the data in the target class (blue)?\n\n\n\n\n\n\n\n\nFigure¬†5: A valid but implausible counterfactual. Source: Altmeyer, Deursen, and Liem (2023)"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#why-plausibility",
    "href": "content/talks/posts/2023-dnb/presentation.html#why-plausibility",
    "title": "Faithful Model Explanations",
    "section": "Why Plausibility?",
    "text": "Why Plausibility?\n\nActionability: If a counterfactual is implausible, it is unlikely to be actionable.\nFairness: If a counterfactual is implausible, it is unlikely to be fair.\nRobustness: If a counterfactual is implausible, it is unlikely to be robust.\n\nBut: Higher plausibility seems to require larger changes and hence increase costs to individuals."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#recourse-dynamics",
    "href": "content/talks/posts/2023-dnb/presentation.html#recourse-dynamics",
    "title": "Faithful Model Explanations",
    "section": "Recourse Dynamics",
    "text": "Recourse Dynamics\nMoving just across the decision boundary may minimize costs to individuals but it may also generate external costs for other stakeholders (Altmeyer, Angela, et al. 2023)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#a-balancing-act",
    "href": "content/talks/posts/2023-dnb/presentation.html#a-balancing-act",
    "title": "Faithful Model Explanations",
    "section": "A Balancing Act",
    "text": "A Balancing Act\n\n\nMinimizing private costs generates external costs for other stakeholders.\nTo avoid this, counterfactuals need to be plausible, i.e.¬†comply with the data-generating process.\nIn practice, costs to various stakeholders need to be carefully balanced.\n\n\n\n\nIs plausibility really all we need?"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2023-dnb/presentation.html#pick-your-poison",
    "title": "Faithful Model Explanations",
    "section": "Pick your Poison?",
    "text": "Pick your Poison?\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction. Which one would you pick?\n\n\n\n\n\n\nFigure¬†6: Turning a 9 into a 7: Counterfactual Examplanations for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#what-do-models-learn",
    "href": "content/talks/posts/2023-dnb/presentation.html#what-do-models-learn",
    "title": "Faithful Model Explanations",
    "section": "What do Models Learn?",
    "text": "What do Models Learn?\nThese images are sampled from the posterior distribution learned by the model. Looks different, no?\n\n\n\n\n\n\nFigure¬†7: Conditional Generated Images from the Image Classifier"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#faithful-counterfactuals",
    "href": "content/talks/posts/2023-dnb/presentation.html#faithful-counterfactuals",
    "title": "Faithful Model Explanations",
    "section": "Faithful Counterfactuals",
    "text": "Faithful Counterfactuals\n\n\nWe propose a way to generate counterfactuals that are as plausible as the underlying model permits (under review).\n\nDefinition 2 (Faithful Counterfactuals) Let \\(\\mathcal{X}_{\\theta}|\\mathbf{y}^+ = p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\) denote the conditional distribution of \\(\\mathbf{x}\\) in the target class \\(\\mathbf{y}^+\\), where \\(\\theta\\) denotes the parameters of model \\(M_{\\theta}\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a faithful counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}_{\\theta}|\\mathbf{y}^+\\).\n\n\n\n\n\n\n\n\n\n\nFigure¬†8: Gradient fields and counterfactual paths for different generators."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#improving-models",
    "href": "content/talks/posts/2023-dnb/presentation.html#improving-models",
    "title": "Faithful Model Explanations",
    "section": "Improving Models",
    "text": "Improving Models\nNow that we have a tool to faithfully explain models we may ask: how do models learn plausible explanations? Initial evidence:\n\nIncorporating predictive uncertainty (e.g.¬†ensembling).\nAddressing robustness (e.g.¬†adversarial training in Schut et al. (2021)).\nBetter model architectures.\nHybrid modelling (i.e.¬†combining generative and discriminative models)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-architecture",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-architecture",
    "title": "Faithful Model Explanations",
    "section": "Example: Architecture",
    "text": "Example: Architecture\n\n\n\n\n\n\nFigure¬†9: Counterfactuals for LeNet-5 convolutional neural network (LeCun et al. 1998)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#example-jem-ensemble",
    "href": "content/talks/posts/2023-dnb/presentation.html#example-jem-ensemble",
    "title": "Faithful Model Explanations",
    "section": "Example: JEM Ensemble",
    "text": "Example: JEM Ensemble\n\n\n\n\n\n\nFigure¬†10: Counterfactuals for an ensemble of Joint Energy Models (JEM) (Grathwohl et al. 2020)."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#taija",
    "href": "content/talks/posts/2023-dnb/presentation.html#taija",
    "title": "Faithful Model Explanations",
    "section": "üê∂ Taija",
    "text": "üê∂ Taija\n\nResearch informs development, development informs research.\n\n\nTrustworthy Artificial Intelligence in Julia.Taija is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.\nOur work has been presented online for JuliaCon 2022, at MIT in Boston for JuliaCon 2023 and hopefully beyond."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#counterfactual-explanations-1",
    "href": "content/talks/posts/2023-dnb/presentation.html#counterfactual-explanations-1",
    "title": "Faithful Model Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\nAll the work presented today is powered by CounterfactualExplanations.jl üì¶.\nThere is also a corresponding paper, Explaining Black-Box Models through Counterfactuals, which has been published in JuliaCon Proceedings.\nIf you decide to use this package in your work, please consider citing the paper:"
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#conformal-prediction",
    "href": "content/talks/posts/2023-dnb/presentation.html#conformal-prediction",
    "title": "Faithful Model Explanations",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nConformal Prediction is a model-agnostic, distribution-free approach to Predictive Uncertainty Quantification: ConformalPrediction.jl üì¶.\n\n\n\n\n\n\n\n\nFigure¬†11: Conformal Prediction intervals for regression.\n\n\n\n\n\n\n\n\n\n\nFigure¬†12: Conformal Prediction sets for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#laplace-redux",
    "href": "content/talks/posts/2023-dnb/presentation.html#laplace-redux",
    "title": "Faithful Model Explanations",
    "section": "Laplace Redux",
    "text": "Laplace Redux\n\n\nEffortless Bayesian Deep Learning through Laplace Approximation Daxberger et al. (2021): LaplaceRedux.jl üì¶.\n\n\n\n\n\n\n\nFigure¬†13: Predictive interval for neural network with Laplace Approximation."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#joint-energy-models",
    "href": "content/talks/posts/2023-dnb/presentation.html#joint-energy-models",
    "title": "Faithful Model Explanations",
    "section": "Joint Energy Models",
    "text": "Joint Energy Models\nJoint Energy Models (JEMs) are hybrid models trained to learn the conditional output and input distribution (Grathwohl et al. 2020): JointEnergyModels.jl üì¶.\n\n\n\n\n\n\nFigure¬†14: A JEM trained on Circles data."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#questions",
    "href": "content/talks/posts/2023-dnb/presentation.html#questions",
    "title": "Faithful Model Explanations",
    "section": "Questions?",
    "text": "Questions?\n\n\nIncludes joint work with Cynthia C. S. Liem, Arie van Deursen, Mojtaba Farmanbar, Aleksander Buszydlik, Karol Dobiczek, Giovan Angela and many other students at TU Delft.\nSlides power by Quarto."
  },
  {
    "objectID": "content/talks/posts/2023-dnb/presentation.html#references",
    "href": "content/talks/posts/2023-dnb/presentation.html#references",
    "title": "Faithful Model Explanations",
    "section": "References",
    "text": "References\n\n\n\n\nAgustƒ±ÃÅ, Marc, Patrick Altmeyer, and Ignacio Vidal-Quadras. 2021. ‚ÄúDeep Vector Autoregression for Macroeconomic Data.‚Äù\n\n\nAltmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia CS Liem. 2023. ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse.‚Äù In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 418‚Äì31. IEEE.\n\n\nAltmeyer, Patrick, Lena Boneva, Rafael Kinston, Shreyosi Saha, and Evarist Stoja. 2023. ‚ÄúYield Curve Sensitivity to Investor Positioning Around Economic Shocks.‚Äù\n\n\nAltmeyer, Patrick, Arie van Deursen, and Cynthia C. S. Liem. 2023. ‚ÄúExplaining Black-Box Models through Counterfactuals.‚Äù In Proceedings of the JuliaCon Conferences, 1:130.\n\n\nAltmeyer, Patrick, Jacob Daniel Grapendal, Makar Pravosud, and Gand Derry Quintana. 2018. ‚ÄúOption Pricing in the Heston Stochastic Volatility Model: An Empirical Evaluation.‚Äù\n\n\nAnand, Avishek, Lijun Lyu, Maximilian Idahl, Yumeng Wang, Jonas Wallat, and Zijian Zhang. 2022. ‚ÄúExplainable Information Retrieval: A Survey.‚Äù arXiv Preprint arXiv:2211.02405.\n\n\nArous, Ines, Ljiljana Dolamic, Jie Yang, Akansha Bhardwaj, Giuseppe Cuccu, and Philippe Cudr√©-Mauroux. 2021. ‚ÄúMarta: Leveraging Human Rationales for Explainable Text Classification.‚Äù In Proceedings of the AAAI Conference on Artificial Intelligence, 35:5868‚Äì76. 7.\n\n\nDaxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. ‚ÄúLaplace Redux-Effortless Bayesian Deep Learning.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nGoodfellow, Ian, Jonathon Shlens, and Christian Szegedy. 2015. ‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù https://arxiv.org/abs/1412.6572.\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nImmer, Alexander, Maciej Korzepa, and Matthias Bauer. 2020. ‚ÄúImproving Predictions of Bayesian Neural Networks via Local Linearization.‚Äù https://arxiv.org/abs/2008.08400.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit.\n\n\nLeCun, Yann, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. ‚ÄúGradient-Based Learning Applied to Document Recognition.‚Äù Proceedings of the IEEE 86 (11): 2278‚Äì2324.\n\n\nLeonhardt, Jurek, Koustav Rudra, and Avishek Anand. 2023. ‚ÄúExtractive Explanations for Interpretable Text Ranking.‚Äù ACM Transactions on Information Systems 41 (4): 1‚Äì31.\n\n\nPorsius Martins, C√©lio. 2023. ‚ÄúPrivate Cycle Detection in Financial Transactions.‚Äù\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nSpooner, Thomas, Danial Dervovic, Jason Long, Jon Shepard, Jiahao Chen, and Daniele Magazzeni. 2021. ‚ÄúCounterfactual Explanations for Arbitrary Regression Models.‚Äù https://arxiv.org/abs/2106.15212.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nWerf, Daan van der. 2021. ‚ÄúOne Step Ahead: A Weakly-Supervised Approach to Training Robust Machine Learning Models for Transaction Monitoring.‚Äù\n\n\nYang, Jie, Thomas Drake, Andreas Damianou, and Yoelle Maarek. 2018. ‚ÄúLeveraging Crowdsourcing Data for Deep Active Learning an Application: Learning Intents in Alexa.‚Äù In Proceedings of the 2018 World Wide Web Conference, 23‚Äì32."
  },
  {
    "objectID": "content/talks/posts/2023-ictopen/presentation.html#taija",
    "href": "content/talks/posts/2023-ictopen/presentation.html#taija",
    "title": "Taija - Trustworthy AI in Julia",
    "section": "üê∂ Taija",
    "text": "üê∂ Taija\n\nResearch informs development, development informs research.\n\n\nTrustworthy Artificial Intelligence in Julia.Taija is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.\nOur work has been presented at JuliaCon 2022 and will be presented again at JuliaCon 2023 and hopefully beyond."
  },
  {
    "objectID": "content/talks/posts/2023-ictopen/presentation.html#current-state",
    "href": "content/talks/posts/2023-ictopen/presentation.html#current-state",
    "title": "Taija - Trustworthy AI in Julia",
    "section": "üõ†Ô∏è Current State",
    "text": "üõ†Ô∏è Current State\n\n\nTowards Trustworthy AI in Julia\n\nCounterfactualExplanations.jl (JuliaCon 2022)\nConformalPrediction.jl (JuliaCon 2023)\nLaplaceRedudx.jl (JuliaCon 2022)\nAlgorithmicRecourseDynamics.jl (IEEE SaTML 2023)\nJointEnergyModels.jl (JuliaCon 2024 ‚Ä¶ I hope?)\n\n‚Ä¶ contributions welcome! üòä"
  },
  {
    "objectID": "content/talks/posts/2023-ictopen/presentation.html#future-plans",
    "href": "content/talks/posts/2023-ictopen/presentation.html#future-plans",
    "title": "Taija - Trustworthy AI in Julia",
    "section": "üöÄ Future Plans",
    "text": "üöÄ Future Plans\n\nPatrick has been actively developing Taija since starting his PhD in 2021 and plans to continue doing so until he graduates in 2025 and beyond.\nTU Delft Student Software Project 2023: a total of 10 students will be working on Taija for the next 2-3 months.\nWe have managed to attract contributors from the Julia community and are looking for more."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2024-imperial/presentation.html#counterfactual-explanations",
    "title": "ECCCos from the Black Box",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\\[\n\\begin{aligned}\n\\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} + \\lambda {\\text{cost}(f(\\mathbf{Z}^\\prime)) }  \\}\n\\end{aligned}\n\\]\n\n\nCounterfactual Explanations (CE) explain how inputs into a model need to change for it to produce different outputs.\n\n\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2024-imperial/presentation.html#pick-your-poison",
    "title": "ECCCos from the Black Box",
    "section": "Pick your Poison",
    "text": "Pick your Poison\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction.\n\nWhich one would you pick?\n\n\n\n\n\n\n\nFigure¬†2: Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using Wachter (Wachter, Mittelstadt, and Russell 2017), Schut (Schut et al. 2021) and REVISE (Joshi et al. 2019)."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#summary",
    "href": "content/talks/posts/2024-imperial/presentation.html#summary",
    "title": "ECCCos from the Black Box",
    "section": "Summary",
    "text": "Summary\n\n\nIdea: generate counterfactuals that are consistent with what the model has learned about the data.\nMethod: constrain the model‚Äôs energy and predictive uncertainty for the counterfactual.\nResult: faithful counterfactuals that are as plausible as the model permits.\nBenefits: enable us to distinguish trustworthy from unreliable models."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#plausibility",
    "href": "content/talks/posts/2024-imperial/presentation.html#plausibility",
    "title": "ECCCos from the Black Box",
    "section": "Plausibility",
    "text": "Plausibility\n\n\n\nDefinition 1 (Plausible Counterfactuals) Let \\(\\mathcal{X}|\\mathbf{y}^+= p(\\mathbf{x}|\\mathbf{y}^+)\\) denote the true conditional distribution of samples in the target class \\(\\mathbf{y}^+\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a plausible counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}|\\mathbf{y}^+\\).\n\n\n\n\nWhy Plausibility?\n\n\nPlausibility is positively associated with actionability, robustness (Artelt et al. 2021) and causal validity (Mahajan, Tan, and Sharma 2020).\n\n\n\n\n\n\n\n\n\n\nFigure¬†3: Kernel density estimate (KDE) for the conditional distribution, \\(p(\\mathbf{x}|\\mathbf{y}^+)\\), based on observed data. Counterfactual path as in Figure¬†1."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#faithfulness",
    "href": "content/talks/posts/2024-imperial/presentation.html#faithfulness",
    "title": "ECCCos from the Black Box",
    "section": "Faithfulness",
    "text": "Faithfulness\n\n\n\nDefinition 2 (Faithful Counterfactuals) Let \\(\\mathcal{X}_{\\theta}|\\mathbf{y}^+ = p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\) denote the conditional distribution of \\(\\mathbf{x}\\) in the target class \\(\\mathbf{y}^+\\), where \\(\\theta\\) denotes the parameters of model \\(M_{\\theta}\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a faithful counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}_{\\theta}|\\mathbf{y}^+\\).\n\n\n\n\nTrustworthy Models\n\n\nIf the model posterior approximates the true posterior (\\(p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+) \\rightarrow p(\\mathbf{x}|\\mathbf{y}^+)\\)), faithful counterfactuals are also plausible.\n\n\n\n\n\n\n\n\n\n\nFigure¬†4: KDE for learned conditional distribution, \\(p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\). Yellow stars indicate conditional samples generated through SGLD for a joint energy model (JEM)."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#eccco",
    "href": "content/talks/posts/2024-imperial/presentation.html#eccco",
    "title": "ECCCos from the Black Box",
    "section": "ECCCo",
    "text": "ECCCo\n\n\n\n\n\nKey Idea\n\n\nUse the hybrid objective of joint energy models (JEM) and a model-agnostic penalty for predictive uncertainty: Energy-Constrained (\\(\\mathcal{E}_{\\theta}\\)) Conformal (\\(\\Omega\\)) Counterfactuals (ECCCo).\n\n\n\n\nECCCo objective1:\n\\[\n\\begin{aligned}\n& \\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {L_{\\text{clf}}(f(\\mathbf{Z}^\\prime);M_{\\theta},\\mathbf{y}^+)}+ \\lambda_1 {\\text{cost}(f(\\mathbf{Z}^\\prime)) } \\\\\n&+ \\lambda_2 \\mathcal{E}_{\\theta}(f(\\mathbf{Z}^\\prime)|\\mathbf{y}^+) + \\lambda_3 \\Omega(C_{\\theta}(f(\\mathbf{Z}^\\prime);\\alpha)) \\}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nFigure¬†5: Gradient fields and counterfactual paths for different generators.\n\n\n\n\nWe leverage ideas from Grathwohl et al. (2020) and Stutz et al. (2022). See the paper and appendix for a derivation of the objective from first principles."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#visual-evidence",
    "href": "content/talks/posts/2024-imperial/presentation.html#visual-evidence",
    "title": "ECCCos from the Black Box",
    "section": "Visual Evidence",
    "text": "Visual Evidence\n\n\n\n\n\n\n\n\nFigure¬†6: Turning a 9 into a 7. ECCCo applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).\n\n\n\n\nECCCo generates counterfactuals that\n\nfaithfully represent model quality (Figure¬†6).\nachieve state-of-the-art plausibility (Figure¬†7).\n\n\n\n\n\n\n\nFigure¬†7: Results for different generators (from 3 to 5)."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#the-numbers",
    "href": "content/talks/posts/2024-imperial/presentation.html#the-numbers",
    "title": "ECCCos from the Black Box",
    "section": "The Numbers",
    "text": "The Numbers\n\nLarge benchmarks on a variety of models and datasets from various domains.\nECCCo achieves state-of-the-art faithfulness across models and datasets and approaches state-of-the-art plausibility for more trustworthy models."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#code",
    "href": "content/talks/posts/2024-imperial/presentation.html#code",
    "title": "ECCCos from the Black Box",
    "section": "Code",
    "text": "Code\nThe code used to run the analysis for this work is built on top of CounterfactualExplanations.jl, part of Taija.\nHighlights\n\nEasily combine different research ideas through composable counterfactual generators.\nBenefit from Julia‚Äôs speed and native, intuitive support for parallelization.\nExtensions for Laplace Redux and differentiable tree-based models.\n\nüìú Explaining Black-Box Models through Counterfactuals in JuliaCon Proceedings."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#shamelessly-plugging",
    "href": "content/talks/posts/2024-imperial/presentation.html#shamelessly-plugging",
    "title": "ECCCos from the Black Box",
    "section": "Shamelessly plugging ‚Ä¶",
    "text": "Shamelessly plugging ‚Ä¶\n‚Ä¶ more research\n\nPosition: Against Spurious Sparks - Dovelating Inflated AI Claims üïäÔ∏è (Altmeyer et al. 2024) to be published at ICML 2024. [preprint], [blog post]\nEndogenous Macrodynamics in Algorithmic Recourse (Altmeyer et al. 2023) published in Proceedings of the 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)."
  },
  {
    "objectID": "content/talks/posts/2024-imperial/presentation.html#references",
    "href": "content/talks/posts/2024-imperial/presentation.html#references",
    "title": "ECCCos from the Black Box",
    "section": "References",
    "text": "References\n\n\n\n\nAltmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia CS Liem. 2023. ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse.‚Äù In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 418‚Äì31. IEEE.\n\n\nAltmeyer, Patrick, Andrew M. Demetriou, Antony Bartlett, and Cynthia C. S. Liem. 2024. ‚ÄúPosition Paper: Against Spurious Sparks-Dovelating Inflated AI Claims.‚Äù https://arxiv.org/abs/2402.03962.\n\n\nArtelt, Andr√©, Valerie Vaquet, Riza Velioglu, Fabian Hinder, Johannes Brinkrolf, Malte Schilling, and Barbara Hammer. 2021. ‚ÄúEvaluating Robustness of Counterfactual Explanations.‚Äù In 2021 IEEE Symposium Series on Computational Intelligence (SSCI), 01‚Äì09. IEEE.\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nMahajan, Divyat, Chenhao Tan, and Amit Sharma. 2020. ‚ÄúPreserving Causal Constraints in Counterfactual Explanations for Machine Learning Classifiers.‚Äù https://arxiv.org/abs/1912.03277.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nStutz, David, Krishnamurthy, Dvijotham, Ali Taylan Cemgil, and Arnaud Doucet. 2022. ‚ÄúLearning Optimal Conformal Classifiers.‚Äù https://arxiv.org/abs/2110.09192.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#blurb",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#blurb",
    "title": "A year of using Quarto with Julia",
    "section": "Blurb",
    "text": "Blurb\n\nAs a Julia practitioner you may want to publish your work in various forms: notebooks, Markdown, HTML, PDF and more. What if you could produce all these different outputs from the same input? I will share how I‚Äôve been using Quarto with Julia, for package documentation, blogging and JuliaCon proceedings.\n\nDISCLAIMER: Views presented in this presentation are my own. I am not affiliated with either Quarto or Posit (RStudio)."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#quick-intro",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#quick-intro",
    "title": "A year of using Quarto with Julia",
    "section": "Quick Intro",
    "text": "Quick Intro\n\n\n\nCurrently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nWorking on Counterfactual Explanations and Probabilistic Machine Learning with applications in Finance.\nPreviously, educational background in Economics and Finance and two years at the Bank of England.\nEnthusiastic about free open-source software, in particular Julia and Quarto."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#from-r-markdown",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#from-r-markdown",
    "title": "A year of using Quarto with Julia",
    "section": "From R Markdown ‚Ä¶",
    "text": "From R Markdown ‚Ä¶\n\n\n\nR Markdown users have enjoyed many of the benefits highlighted in today‚Äôs for many years.\nFor me personally, the workflow enabled by R Markdown was for many years a key reason to rely on R whenever possible (see here).\nIn recent years Posit (formerly RStudio) has first embraced Python and then geared towards multi-language support.\n\n\n\n\nWe have some wonderful news: RStudio is now Posit! üéâWhile many things will stay the same, our rebrand will result in changes beyond a new name. To start, our new website https://t.co/vI56Gz7Yqf is now live. Please check out our new home and let us know what you think! pic.twitter.com/hzJGXsX0tj\n\n‚Äî Posit PBC (@posit_pbc) November 2, 2022"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#to-quarto",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#to-quarto",
    "title": "A year of using Quarto with Julia",
    "section": "‚Ä¶ to Quarto",
    "text": "‚Ä¶ to Quarto\n\n\n\nGenerate multiple different output formats with ease:\n\nThe old school: \\(\\LaTeX\\) and PDF (including Beamer); MS Office\nThe brave new world: beautiful, dynamic HTML content\n\nwebsites\ne-books\napps\n‚Ä¶\n\n\nAll of this starting from the same place ‚Ä¶\n\n\n\n\n\nQuarto at JuliaCon 2022.\n\n\n\n\nA plain Markdown document blended with your favorite programming language and a YAML header defining your output."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#effective-communication-and-reproducibility-in-science",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#effective-communication-and-reproducibility-in-science",
    "title": "A year of using Quarto with Julia",
    "section": "Effective Communication and Reproducibility in Science",
    "text": "Effective Communication and Reproducibility in Science\n\nMost science today involves code. Often code forms such an integral part of the science, that it deserves its place in the final publication.\nScientific Ideas can often be most effectively communicated through dynamic visualizations.\nRequirements and preferences vary.\nQuarto allows us to cater to those needs, while at the same time facilitating reproducibility by bridging the gap between computations and writing.\n\n\nQuarto enables effective communication and reproducibility without compromises."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#code-chunks",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#code-chunks",
    "title": "A year of using Quarto with Julia",
    "section": "Code chunks",
    "text": "Code chunks\nMost science today involves code.\n\nusing Markdown\nMarkdown.parse(\"\"\"\nOften code forms such an integral part of the science, that it deserves its place in the final publication.\n\"\"\")\n\nOften code forms such an integral part of the science, that it deserves its place in the final publication.\n\n\n\nUsing simple YAML options, we can specify how code is displayed. For example, we may want to use code folding to avoid unnecessary interruptions or hide large code chunks like this one that builds Figure¬†1.\n\n\nCode\nusing Javis, Animations, Colors\nwww_path = \"www/images\"\n\n_size = 600\nradius_factor = 0.33\n\nfunction ground(args...)\n    background(\"transparent\")\n    sethue(\"white\")\nend\n\nfunction rotate_anim(idx::Number, total::Number) \n    distance_circle = 0.875\n    steps = collect(range(distance_circle,1-distance_circle,length=total))\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [0, steps[idx]*2œÄ],\n        [sineio()],\n    )\nend\n\ntranslate_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(_size*radius_factor, 0)],\n    [sineio()],\n)\n\ntranslate_back_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(-(_size*radius_factor), 0)],\n    [sineio()],\n)\n\njulia_colours = Dict(\n    :blue =&gt; \"#4063D8\",\n    :green =&gt; \"#389826\",\n    :purple =&gt; \"#9558b2\",\n    :red =&gt; \"#CB3C33\"\n)\ncolour_order = [:red, :purple, :green, :blue]\nn_colours = length(julia_colours)\nfunction color_anim(start_colour::String, quarto_col::String=\"#4b95d0\")\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [Lab(color(start_colour)), Lab(color(quarto_col))],\n        [sineio()],\n    )\nend\n\nvideo = Video(_size, _size)\n\nframe_starts = 1:10:40\nn_total = 250\nn_frames = 150\nBackground(1:n_total, ground)\n\n# Blob:\nfunction element(; radius = 1)\n    circle(O, radius, :fill) # The 4 is to make the circle not so small\nend\n\n# Cross:\nfunction cross(color=\"black\";orientation=:horizontal)\n    sethue(color)\n    setline(10)\n    if orientation==:horizontal\n        out = line(Point(-_size,0),Point(_size,0), :stroke)\n    else\n        out = line(Point(0,-_size),Point(0,_size), :stroke)\n    end\n    return out\nend\n\nfor (i, frame_start) in enumerate(1:10:40)\n\n    # Julia circles:\n    blob = Object(frame_start:n_total, (args...;radius=1) -&gt; element(;radius=radius))\n    act!(blob, Action(1:Int(round(n_frames*0.25)), change(:radius, 1 =&gt; 75))) # scale up\n    act!(blob, Action(n_frames:(n_frames+50), change(:radius, 75 =&gt; 250))) # scale up further\n    act!(blob, Action(1:30, translate_anim, translate()))\n    act!(blob, Action(31:120, rotate_anim(i, n_colours), rotate_around(Point(-(_size*radius_factor), 0))))\n    act!(blob, Action(121:150, translate_back_anim, translate()))\n    act!(blob, Action(1:150, color_anim(julia_colours[colour_order[i]]), sethue()))\n\n    # Quarto cross:\n    cross_h = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:horizontal))\n    cross_v = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:vertical))\nend\n\nrender(\n    video;\n    pathname = joinpath(www_path, \"julia_quarto.gif\"),\n)\n\n\n\n\n\n\n\n\nFigure¬†1: A simple animation built with Javis.jl."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#dynamic-visualizations",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#dynamic-visualizations",
    "title": "A year of using Quarto with Julia",
    "section": "Dynamic Visualizations",
    "text": "Dynamic Visualizations\nScientific Ideas can often be most effectively communicated through dynamic visualizations.\n\nusing Plots\nusing StatsBase\n\nsteps = randn(1)\nT = 100\n\nanim = @animate for t in 2:T\n    append!(steps, randn(1))\n    random_walk = cumsum(steps)\n    p1 = plot(random_walk, color=1, label=\"\", title=\"A Gaussian random walk ...\", xlims=(0,T))\n    acf = autocor(random_walk)\n    p2 = bar(acf, color=1, label=\"\", title=\"... is non-stationary\", xlims=(0,10), ylims=(0,1))\n    plot(p1, p2, size=(800,300))\nend\ngif(anim, fps=5)"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#meeting-varying-requirements",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#meeting-varying-requirements",
    "title": "A year of using Quarto with Julia",
    "section": "Meeting Varying Requirements",
    "text": "Meeting Varying Requirements\n\nQuarto has fantastic support for traditional and modern scholarly writing.\n\n\n\nThe challenge ‚Ä¶\n. . .\nSome people still prefer to read paper or work with MS Office. Most scientific journals, for example, still work with PDF and \\(\\LaTeX\\).\n\n\n\n\n\n\nFigure¬†2: Source: Giphy\n\n\n\n\n‚Ä¶ and Quarto‚Äôs answer\n. . .\nEquations like Equation¬†1 (as well as Sections, Figures, Theorems, ‚Ä¶) can be cross-referenced in a standardized way.\n$$\n\\begin{aligned}\nZ &= \\sum_{t=0}^T X_t, && X_t \\sim N(\\mu, \\sigma)\n\\end{aligned}\n$$ {#eq-bm}\n\\[\n\\begin{aligned}\nZ &= \\sum_{t=0}^T X_t, && X_t \\sim N(\\mu, \\sigma)\n\\end{aligned}\n\\qquad(1)\\]"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#reproducible-and-dynamic-content",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#reproducible-and-dynamic-content",
    "title": "A year of using Quarto with Julia",
    "section": "Reproducible and Dynamic Content",
    "text": "Reproducible and Dynamic Content\nQuarto allows us to cater to different requirements, while at the same time facilitating reproducibility by bridging the gap between computations and writing.\n\nThe world and the data that describes it is not static üìà. Why should scientific outputs be?\n\n\n\n\nFrom dynamic inputs ‚Ä¶\n. . .\nThe code below depends on remote data that is continuously updated:\n\nusing MarketData\nsnp = yahoo(\"^GSPC\")\n\nusing Dates\nlast_trade_day = timestamp(snp[end])[1]\np_close = values(snp[end,:Close])[1]\nlast_trade_day_formatted = Dates.format(last_trade_day, \"U d, yyyy\")\n\nWe‚Äôd like any updates to the inputs to automatically affect our output (ideally, all the way through to the finished report or paper).\n\n‚Ä¶ to dynamic outputs\n. . .\n\nMarkdown.parse(\"\"\"\nWhen the S&P 500 last traded, on $(last_trade_day_formatted), it closed at $(p_close). \n\"\"\")\n\nWhen the S&P 500 last traded, on June 14, 2024, it closed at 5431.600098."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#in-this-section",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#in-this-section",
    "title": "A year of using Quarto with Julia",
    "section": "In this section ‚Ä¶",
    "text": "In this section ‚Ä¶\n\nPreferred setup: VSCode, Quarto and Julia\n\nUsing Julia and VSCode? There‚Äôs a Quarto extension for VSCode, so you can stick with your preferred IDE.\n\n\n\nBlogging\n\nQuarto makes it easy to build beautiful websites and blogs.\n\n\n\nJulia Packages\n\nDocumenter.jl and Quarto play nicely with each other (both Markdown based).\nTurning Julia packages into Quarto projects comes with a few advantages.\n\n\n\nJuliaCon Proceedings\n\nJuliaCon proceedings submissions currently work with a GitHub template that requires users to submit a .tex file.\nQuarto can be used to generate that file, but there are additional benefits we could tab into."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#vscode-quarto-and-julia",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#vscode-quarto-and-julia",
    "title": "A year of using Quarto with Julia",
    "section": "VSCode, Quarto and Julia",
    "text": "VSCode, Quarto and Julia\n\nTo get started, see here.\n\n\nSome tips to get started\n\n\n\nAdd IJulia to startup.jl\n\n\nIf you install a new Julia binary [‚Ä¶], you must update the IJulia installation [‚Ä¶] by running Pkg.build(\"IJulia\")\n‚Äî Source: IJulia docs\n\n\n\nUser snippets need to be explicitly enabled (see here)\n\n{\n  \"Two columns\": {\n    \"prefix\": \"cols\",\n    \"body\": [\n      \"::::{.columns}::::\",\n      \":::{.column width='$1%'}\",\n      \":::\",\n      \":::{.column width='$2%'}\",\n      \":::\",\n      \"::::\"\n    ]\n  }\n}\n\n. . .\nUsing .ipynb vs .qmd\n\nCan switch between Jupyter and .qmd with ease.\nWhen working with .qmd, code chunks connect to REPL.\nSet keep-ipynb: true to have interactive notebooks in repo."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#blogging-1",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#blogging-1",
    "title": "A year of using Quarto with Julia",
    "section": "Blogging",
    "text": "Blogging\n\nThese very slides are not only built using Quarto, but also hosted on a website that is also run on Quarto.\n\n\nOrganization ‚Äî Quarto uses something call document listings: an easy way to collect, arrange and navigate content like this one.\n---\ntitle: \"Talks\"\nlisting:\n  contents: \n    - \"posts/*/index.qmd\"\n  sort: \"date desc\"\n  type: default\n  categories: false\n  fields: [image, date, title, description, author, file-modified]\n  image-align: left\n---\n\n\nCode Execution ‚Äî You can specify YAML options such that changes to your underlying Julia code will trigger your blog post to be rerendered. This essentially allows you to easily test that the code you publish actually runs:\nexecute:\n  freeze: auto\n  eval: true\n  echo: true\n  output: false\n\n\nReproducibility ‚Äî The Julia version and environment can be managed globally or locally for individual blog posts:\n\nusing Pkg; Pkg.activate(\"&lt;path&gt;\")\n\n\nCommunity Engagement ‚Äî It is remarkably easy to engage the community through support for commenting, an RSS Feed, ‚Ä¶\ncomments:\n  utterances:\n    repo: quarto-dev/quarto-docs"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#julia-packages-1",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#julia-packages-1",
    "title": "A year of using Quarto with Julia",
    "section": "Julia Packages",
    "text": "Julia Packages\n\nDocumenter.jl and Quarto generally play nicely with each other (both Markdown based).\n\nformat: \n  commonmark:\n    variant: -raw_html\n    wrap: preserve\n\nYou get some stuff for free, e.g.¬†citation management. Unfortunately, still no support for cross-referencing ‚Ä¶\nThe use of jldoctest is not always straight-forward (see here). Letting docs run through the Quarto engine provides an additional layer of quality assurance.\nAdmonitions can be used as follows (see related discussion):\n\n| !!! note \\\"An optional title\\\"\n| &nbsp; &nbsp; Here is something that you should pay attention to.   \n\n\nAs an example, we will look at ‚Ä¶ ü•Å\n\n\nLaplaceRedux.jl\n      \nLaplaceRedux.jl is a library written in pure Julia that can be used for effortless Bayesian Deep Learning trough Laplace Approximation (LA)."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#juliacon-proceedings-1",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#juliacon-proceedings-1",
    "title": "A year of using Quarto with Julia",
    "section": "JuliaCon Proceedings",
    "text": "JuliaCon Proceedings\n\nQuarto supports \\(\\LaTeX\\) templates/classes, but I‚Äôve found that rticles still has an edge here.\nThe list of out-of-the-box templates for journal articles is growing.\n\n\n\nAs an example we will look at ‚Ä¶ ü•Å\n\n\n‚Ä¶ my pending JuliaCon Proceedings submission for my 2022 talk: Explaining Black-Box Models through Counterfactuals\n\n\n\n\n‚Ä¶ but why only publish proceedings in PDF form?\nQuarto opens the floodgates to more innovative forms of publishing (think distill, but more than that)"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#counterfactualexplanations.jl",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#counterfactualexplanations.jl",
    "title": "A year of using Quarto with Julia",
    "section": "CounterfactualExplanations.jl",
    "text": "CounterfactualExplanations.jl\n   \n\n\nCounterfactualExplanations.jl is a package for generating Counterfactual Explanations (CE) and Algorithmic Recourse (AR) for black-box algorithms. Both CE and AR are related tools for explainable artificial intelligence (XAI). While the package is written purely in Julia, it can be used to explain machine learning algorithms developed and trained in other popular programming languages like Python and R. See below for short introduction and other resources or dive straight into the docs.\n\n\n\nTurning a nine (9) into a four (4).\n\n\n\n\n\n\nA sad üê± on its counterfactual path to its cool dog friends."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#laplaceredux.jl-1",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#laplaceredux.jl-1",
    "title": "A year of using Quarto with Julia",
    "section": "LaplaceRedux.jl",
    "text": "LaplaceRedux.jl\n   \nJuliaCon 22: Effortless Bayesian Deep Learning through Laplace Redux\n\n\nLaplaceRedux.jl is a small package that can be used for effortless Bayesian Deep Learning and Logistic Regression trough Laplace Approximation. It is inspired by this Python library and its companion paper.\n\n\n\nPlugin Approximation (left) and Laplace Posterior (right) for simple artificial neural network.\n\n\n\n\n\n\nSimulation of changing posteriour predictive distribution. Image by author."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#conformalprediction.jl",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#conformalprediction.jl",
    "title": "A year of using Quarto with Julia",
    "section": "ConformalPrediction.jl",
    "text": "ConformalPrediction.jl\n      \nConformalPrediction.jl is a package for Uncertainty Quantification (UQ) through Conformal Prediction (CP) in Julia. It is designed to work with supervised models trained in MLJ (Blaom et al. 2020). Conformal Prediction is distribution-free, easy-to-understand, easy-to-use and model-agnostic.\n\n\n\nConformal Prediction in action: Prediction sets for two different samples and changing coverage rates. As coverage grows, so does the size of the prediction sets."
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#more-resources",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#more-resources",
    "title": "A year of using Quarto with Julia",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nRelated blog posts (hosted on this website that itself is built with Quarto and involves lots of Julia content): [1] and [2].\nBlog post introducing CE: [TDS], [blog].\nBlog post on Laplace Redux: [TDS], [blog].\nBlog post on Conformal Prediction: [TDS], [blog].\n\n\n‚Ä¶ or get involved! ü§ó\n\n\nContributor‚Äôs Guide for CounterfactualExplanations.jl\nContributor‚Äôs Guide for ConformalPrediction.jl"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#image-sources",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#image-sources",
    "title": "A year of using Quarto with Julia",
    "section": "Image Sources",
    "text": "Image Sources\n\nQuarto logo. Source: Quarto\nJulia to Quarto animation. Source: author (heavily borrowing from Javis.jl tutorial)"
  },
  {
    "objectID": "content/talks/posts/2022-julia-eindhoven/presentation.html#references",
    "href": "content/talks/posts/2022-julia-eindhoven/presentation.html#references",
    "title": "A year of using Quarto with Julia",
    "section": "References",
    "text": "References\n\n\n\n\nBlaom, Anthony D., Franz Kiraly, Thibaut Lienart, Yiannis Simillides, Diego Arenas, and Sebastian J. Vollmer. 2020. ‚ÄúMLJ: A Julia Package for Composable Machine Learning.‚Äù Journal of Open Source Software 5 (55): 2704. https://doi.org/10.21105/joss.02704."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#quick-introduction",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#quick-introduction",
    "title": "Faithful Model Explanations",
    "section": "Quick Introduction",
    "text": "Quick Introduction\n\n\n\nRecently entered the 3rd year of my PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nPreviously, educational background in Economics and Finance and two years in Monetary Policy at the Bank of England.\nInterested in applying Trustworthy AI to real-world problems, particularly in the financial sector."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#counterfactual-explanations",
    "title": "Faithful Model Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\nBorn out of the need for explanations ‚Ä¶\n\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs (Wachter, Mittelstadt, and Russell 2017).\n\nProvided the changes are realistic and actionable, they can be used for Algorithmic Recourse (AR) to help individuals who face adverse outcomes."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-consumer-credit",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-consumer-credit",
    "title": "Faithful Model Explanations",
    "section": "Example: Consumer Credit",
    "text": "Example: Consumer Credit\nFrom ‚Äòloan denied‚Äô to ‚Äòloan supplied‚Äô: CounterfactualExplanations.jl üì¶.\n\n\n\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search.\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-insurance-premium",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-insurance-premium",
    "title": "Faithful Model Explanations",
    "section": "Example: Insurance Premium1",
    "text": "Example: Insurance Premium1\n\n\nInput \\(\\mathbf{X}\\): A dataset of individuals containing demographic and financial information.\nAdditional Input \\(\\mathbf{Z}\\): Individuals can opt-in to provide their personal Apple Health data to improve their chance of receiving a lower premium.\nBinary output \\(\\mathbf{Y}\\): based on the data, the individual is either eligible (\\(y=1\\)) or not eligible (\\(y=0\\)) for a lower premium.\nTo model \\(p(y=1|X)\\) the insurance provider can rely on an interpretable linear classifier.\nTo model \\(p(y=1|X,Z)\\) the insurance provider turns to a more accurate but less interpretable black-box model.\n\n\nFor simplicity, we‚Äôll stay in the classification setting. Work on counterfactual regression like Spooner et al. (2021) exists but it is scarce."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-insurance-premium-1",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-insurance-premium-1",
    "title": "Faithful Model Explanations",
    "section": "Example: Insurance Premium",
    "text": "Example: Insurance Premium\nIn the EU, individuals have the right ‚Äú[‚Ä¶] to obtain an explanation of the decision reached after such assessment and to challenge the decision.‚Äù (Recital 71 of the General Data Protection Regulation (GDPR))\n\n\nIn our example, who do you think is most likely to ask for an explanation?"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#gradient-based-counterfactual-search",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#gradient-based-counterfactual-search",
    "title": "Faithful Model Explanations",
    "section": "Gradient-based Counterfactual Search",
    "text": "Gradient-based Counterfactual Search\nThe starting point for most counterfactual generators is as follows,\n\\[\n\\begin{aligned}\n\\mathbf{Z}^\\prime =& \\arg \\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} \\\\ &+ \\lambda {\\text{cost}(f(\\mathbf{Z}^\\prime)) }  \\}\n\\end{aligned}\n\\tag{1}\\]\nwhere \\(\\mathbf{Z}^\\prime\\) is a counterfactual, \\(M_{\\theta}\\) is the black-box model and \\(\\mathbf{y}^+\\) is the desired output."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#but-wait-a-second",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#but-wait-a-second",
    "title": "Faithful Model Explanations",
    "section": "But wait a second ‚Ä¶",
    "text": "But wait a second ‚Ä¶\nEquation¬†1 looks a lot like an adversarial attack (Goodfellow, Shlens, and Szegedy 2015), doesn‚Äôt it?\n\n\n\n\n\n\nFigure¬†3: Adversarial attack on an Image Classifier.\n\n\n\nIn both settings, we take gradients with respect to features \\(\\nabla_{\\mathbf{Z}^\\prime}\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)\\) in order to trigger changes in the model‚Äôs output."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#gradient-descend-visualized",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#gradient-descend-visualized",
    "title": "Faithful Model Explanations",
    "section": "Gradient Descend Visualized",
    "text": "Gradient Descend Visualized\n\n\n\n\n\n\nFigure¬†4: Gradient-based counterfactual search."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#open-questions",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#open-questions",
    "title": "Faithful Model Explanations",
    "section": "Open Questions",
    "text": "Open Questions\n\n\nWhat makes a counterfactual plausible?\nWhy do we need plausibility?\nIs plausibility all we need?\nWhat makes models more explainable?"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#plausibility",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#plausibility",
    "title": "Faithful Model Explanations",
    "section": "Plausibility",
    "text": "Plausibility\nThere‚Äôs no consensus on the exact definition of plausibility but we think about it as follows:\n\nDefinition 1 (Plausible Counterfactuals) Let \\(\\mathcal{X}|\\mathbf{y}^+= p(\\mathbf{x}|\\mathbf{y}^+)\\) denote the true conditional distribution of samples in the target class \\(\\mathbf{y}^+\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a plausible counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}|\\mathbf{y}^+\\)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#counter-example",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#counter-example",
    "title": "Faithful Model Explanations",
    "section": "Counter Example",
    "text": "Counter Example\n\n\n\nThe counterfactual in Figure¬†5 is valid: it has crossed the decision boundary.\nBut is it consistent with the data in the target class (blue)?\n\n\n\n\n\n\n\n\nFigure¬†5: A valid but implausible counterfactual. Source: Altmeyer, Deursen, and Liem (2023)"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#why-plausibility",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#why-plausibility",
    "title": "Faithful Model Explanations",
    "section": "Why Plausibility?",
    "text": "Why Plausibility?\n\nActionability: If a counterfactual is implausible, it is unlikely to be actionable.\nFairness: If a counterfactual is implausible, it is unlikely to be fair.\nRobustness: If a counterfactual is implausible, it is unlikely to be robust.\n\nBut: Higher plausibility seems to require larger changes and hence increase costs to individuals."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#recourse-dynamics",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#recourse-dynamics",
    "title": "Faithful Model Explanations",
    "section": "Recourse Dynamics",
    "text": "Recourse Dynamics\nMoving just across the decision boundary may minimize costs to individuals but it may also generate external costs for other stakeholders (Altmeyer et al. 2023)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#a-balancing-act",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#a-balancing-act",
    "title": "Faithful Model Explanations",
    "section": "A Balancing Act",
    "text": "A Balancing Act\n\n\nMinimizing private costs generates external costs for other stakeholders.\nTo avoid this, counterfactuals need to be plausible, i.e.¬†comply with the data-generating process.\nIn practice, costs to various stakeholders need to be carefully balanced.\n\n\n\n\nIs plausibility really all we need?"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#pick-your-poison",
    "title": "Faithful Model Explanations",
    "section": "Pick your Poison?",
    "text": "Pick your Poison?\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction. Which one would you pick?\n\n\n\n\n\n\nFigure¬†6: Turning a 9 into a 7: Counterfactual Examplanations for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#what-do-models-learn",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#what-do-models-learn",
    "title": "Faithful Model Explanations",
    "section": "What do Models Learn?",
    "text": "What do Models Learn?\nThese images are sampled from the posterior distribution learned by the model. Looks different, no?\n\n\n\n\n\n\nFigure¬†7: Conditional Generated Images from the Image Classifier"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#faithful-counterfactuals",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#faithful-counterfactuals",
    "title": "Faithful Model Explanations",
    "section": "Faithful Counterfactuals",
    "text": "Faithful Counterfactuals\n\n\nWe propose a way to generate counterfactuals that are as plausible as the underlying model permits (under review).\n\nDefinition 2 (Faithful Counterfactuals) Let \\(\\mathcal{X}_{\\theta}|\\mathbf{y}^+ = p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\) denote the conditional distribution of \\(\\mathbf{x}\\) in the target class \\(\\mathbf{y}^+\\), where \\(\\theta\\) denotes the parameters of model \\(M_{\\theta}\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a faithful counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}_{\\theta}|\\mathbf{y}^+\\).\n\n\n\n\n\n\n\n\n\n\nFigure¬†8: Gradient fields and counterfactual paths for different generators."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#improving-models",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#improving-models",
    "title": "Faithful Model Explanations",
    "section": "Improving Models",
    "text": "Improving Models\nNow that we have a tool to faithfully explain models we may ask: how do models learn plausible explanations? Initial evidence:\n\nIncorporating predictive uncertainty (e.g.¬†ensembling).\nAddressing robustness (e.g.¬†adversarial training in Schut et al. (2021)).\nBetter model architectures.\nHybrid modelling (i.e.¬†combining generative and discriminative models)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-architecture",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-architecture",
    "title": "Faithful Model Explanations",
    "section": "Example: Architecture",
    "text": "Example: Architecture\n\n\n\n\n\n\nFigure¬†9: Counterfactuals for LeNet-5 convolutional neural network (LeCun et al. 1998)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#example-jem-ensemble",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#example-jem-ensemble",
    "title": "Faithful Model Explanations",
    "section": "Example: JEM Ensemble",
    "text": "Example: JEM Ensemble\n\n\n\n\n\n\nFigure¬†10: Counterfactuals for an ensemble of Joint Energy Models (JEM) (Grathwohl et al. 2020)."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#taija",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#taija",
    "title": "Faithful Model Explanations",
    "section": "üê∂ Taija",
    "text": "üê∂ Taija\n\nResearch informs development, development informs research.\n\n\nTrustworthy Artificial Intelligence in Julia.Taija is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.\nOur work has been presented online for JuliaCon 2022, at MIT in Boston for JuliaCon 2023 and hopefully beyond."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#counterfactual-explanations-1",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#counterfactual-explanations-1",
    "title": "Faithful Model Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\nAll the work presented today is powered by CounterfactualExplanations.jl üì¶.\nThere is also a corresponding paper, Explaining Black-Box Models through Counterfactuals, which has been published in JuliaCon Proceedings.\nIf you decide to use this package in your work, please consider citing the paper:"
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#conformal-prediction",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#conformal-prediction",
    "title": "Faithful Model Explanations",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nConformal Prediction is a model-agnostic, distribution-free approach to Predictive Uncertainty Quantification: ConformalPrediction.jl üì¶.\n\n\n\n\n\n\n\n\nFigure¬†11: Conformal Prediction intervals for regression.\n\n\n\n\n\n\n\n\n\n\nFigure¬†12: Conformal Prediction sets for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#laplace-redux",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#laplace-redux",
    "title": "Faithful Model Explanations",
    "section": "Laplace Redux",
    "text": "Laplace Redux\n\n\nEffortless Bayesian Deep Learning through Laplace Approximation Daxberger et al. (2021): LaplaceRedux.jl üì¶.\n\n\n\n\n\n\n\nFigure¬†13: Predictive interval for neural network with Laplace Approximation."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#joint-energy-models",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#joint-energy-models",
    "title": "Faithful Model Explanations",
    "section": "Joint Energy Models",
    "text": "Joint Energy Models\nJoint Energy Models (JEMs) are hybrid models trained to learn the conditional output and input distribution (Grathwohl et al. 2020): JointEnergyModels.jl üì¶.\n\n\n\n\n\n\nFigure¬†14: A JEM trained on Circles data."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#questions",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#questions",
    "title": "Faithful Model Explanations",
    "section": "Questions?",
    "text": "Questions?\n\n\nIncludes joint work with Cynthia C. S. Liem, Arie van Deursen, Mojtaba Farmanbar, Aleksander Buszydlik, Karol Dobiczek, Giovan Angela and many other students at TU Delft.\nSlides power by Quarto."
  },
  {
    "objectID": "content/talks/posts/2023-insurance-academy/presentation.html#references",
    "href": "content/talks/posts/2023-insurance-academy/presentation.html#references",
    "title": "Faithful Model Explanations",
    "section": "References",
    "text": "References\n\n\n\n\nAltmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia CS Liem. 2023. ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse.‚Äù In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 418‚Äì31. IEEE.\n\n\nAltmeyer, Patrick, Arie van Deursen, and Cynthia C. S. Liem. 2023. ‚ÄúExplaining Black-Box Models through Counterfactuals.‚Äù In Proceedings of the JuliaCon Conferences, 1:130.\n\n\nDaxberger, Erik, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp Hennig. 2021. ‚ÄúLaplace Redux-Effortless Bayesian Deep Learning.‚Äù Advances in Neural Information Processing Systems 34.\n\n\nGoodfellow, Ian, Jonathon Shlens, and Christian Szegedy. 2015. ‚ÄúExplaining and Harnessing Adversarial Examples.‚Äù https://arxiv.org/abs/1412.6572.\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nImmer, Alexander, Maciej Korzepa, and Matthias Bauer. 2020. ‚ÄúImproving Predictions of Bayesian Neural Networks via Local Linearization.‚Äù https://arxiv.org/abs/2008.08400.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit.\n\n\nLeCun, Yann, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. ‚ÄúGradient-Based Learning Applied to Document Recognition.‚Äù Proceedings of the IEEE 86 (11): 2278‚Äì2324.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nSpooner, Thomas, Danial Dervovic, Jason Long, Jon Shepard, Jiahao Chen, and Daniele Magazzeni. 2021. ‚ÄúCounterfactual Explanations for Arbitrary Regression Models.‚Äù https://arxiv.org/abs/2106.15212.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2024-aaai/presentation.html#pick-your-poison",
    "title": "ECCCos from the Black Box",
    "section": "Pick your Poison",
    "text": "Pick your Poison\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction.\n\nWhich one would you pick?\n\n\n\n\n\n\n\nFigure¬†1: Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using Wachter (Wachter, Mittelstadt, and Russell 2017), Schut (Schut et al. 2021) and REVISE (Joshi et al. 2019)."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#summary",
    "href": "content/talks/posts/2024-aaai/presentation.html#summary",
    "title": "ECCCos from the Black Box",
    "section": "Summary",
    "text": "Summary\n\n\nIdea: generate counterfactuals that are consistent with what the model has learned about the data.\nMethod: constrain the model‚Äôs energy and predictive uncertainty for the counterfactual.\nResult: faithful counterfactuals that are as plausible as the model permits.\nBenefits: enable us to distinguish trustworthy from unreliable models."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2024-aaai/presentation.html#counterfactual-explanations",
    "title": "ECCCos from the Black Box",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\\[\n\\begin{aligned}\n\\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} + \\lambda {\\text{cost}(f(\\mathbf{Z}^\\prime)) }  \\}\n\\end{aligned}\n\\]\n\n\nCounterfactual Explanations (CE) explain how inputs into a model need to change for it to produce different outputs.\n\n\n\n\n\n\n\nFigure¬†2: Gradient-based counterfactual search."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#plausibility",
    "href": "content/talks/posts/2024-aaai/presentation.html#plausibility",
    "title": "ECCCos from the Black Box",
    "section": "Plausibility",
    "text": "Plausibility\n\n\n\nDefinition 1 (Plausible Counterfactuals) Let \\(\\mathcal{X}|\\mathbf{y}^+= p(\\mathbf{x}|\\mathbf{y}^+)\\) denote the true conditional distribution of samples in the target class \\(\\mathbf{y}^+\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a plausible counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}|\\mathbf{y}^+\\).\n\n\n\n\nWhy Plausibility?\n\n\nPlausibility is positively associated with actionability, robustness (Artelt et al. 2021) and causal validity (Mahajan, Tan, and Sharma 2020).\n\n\n\n\n\n\n\n\n\n\nFigure¬†3: Kernel density estimate (KDE) for the conditional distribution, \\(p(\\mathbf{x}|\\mathbf{y}^+)\\), based on observed data. Counterfactual path as in Figure¬†2."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#faithfulness",
    "href": "content/talks/posts/2024-aaai/presentation.html#faithfulness",
    "title": "ECCCos from the Black Box",
    "section": "Faithfulness",
    "text": "Faithfulness\n\n\n\nDefinition 2 (Faithful Counterfactuals) Let \\(\\mathcal{X}_{\\theta}|\\mathbf{y}^+ = p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\) denote the conditional distribution of \\(\\mathbf{x}\\) in the target class \\(\\mathbf{y}^+\\), where \\(\\theta\\) denotes the parameters of model \\(M_{\\theta}\\). Then for \\(\\mathbf{x}^{\\prime}\\) to be considered a faithful counterfactual, we need: \\(\\mathbf{x}^{\\prime} \\sim \\mathcal{X}_{\\theta}|\\mathbf{y}^+\\).\n\n\n\n\nTrustworthy Models\n\n\nIf the model posterior approximates the true posterior (\\(p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+) \\rightarrow p(\\mathbf{x}|\\mathbf{y}^+)\\)), faithful counterfactuals are also plausible.\n\n\n\n\n\n\n\n\n\n\nFigure¬†4: KDE for learned conditional distribution, \\(p_{\\theta}(\\mathbf{x}|\\mathbf{y}^+)\\). Yellow stars indicate conditional samples generated through SGLD for a joint energy model (JEM)."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#eccco",
    "href": "content/talks/posts/2024-aaai/presentation.html#eccco",
    "title": "ECCCos from the Black Box",
    "section": "ECCCo",
    "text": "ECCCo\n\n\n\n\n\nKey Idea\n\n\nUse the hybrid objective of joint energy models (JEM) and a model-agnostic penalty for predictive uncertainty: Energy-Constrained (\\(\\mathcal{E}_{\\theta}\\)) Conformal (\\(\\Omega\\)) Counterfactuals (ECCCo).\n\n\n\n\nECCCo objective1:\n\\[\n\\begin{aligned}\n& \\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {L_{\\text{clf}}(f(\\mathbf{Z}^\\prime);M_{\\theta},\\mathbf{y}^+)}+ \\lambda_1 {\\text{cost}(f(\\mathbf{Z}^\\prime)) } \\\\\n&+ \\lambda_2 \\mathcal{E}_{\\theta}(f(\\mathbf{Z}^\\prime)|\\mathbf{y}^+) + \\lambda_3 \\Omega(C_{\\theta}(f(\\mathbf{Z}^\\prime);\\alpha)) \\}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nFigure¬†5: Gradient fields and counterfactual paths for different generators.\n\n\n\n\nWe leverage ideas from Grathwohl et al. (2020) and Stutz et al. (2022). See the paper and appendix for a derivation of the objective from first principles."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#visual-evidence",
    "href": "content/talks/posts/2024-aaai/presentation.html#visual-evidence",
    "title": "ECCCos from the Black Box",
    "section": "Visual Evidence",
    "text": "Visual Evidence\n\n\n\n\n\n\n\n\nFigure¬†6: Turning a 9 into a 7. ECCCo applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).\n\n\n\n\nECCCo generates counterfactuals that\n\nfaithfully represent model quality (Figure¬†6).\nachieve state-of-the-art plausibility (Figure¬†7).\n\n\n\n\n\n\n\nFigure¬†7: Results for different generators (from 3 to 5)."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#the-numbers",
    "href": "content/talks/posts/2024-aaai/presentation.html#the-numbers",
    "title": "ECCCos from the Black Box",
    "section": "The Numbers",
    "text": "The Numbers\n\nLarge benchmarks on a variety of models and datasets from various domains.\nECCCo achieves state-of-the-art faithfulness across models and datasets and approaches state-of-the-art plausibility for more trustworthy models."
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#code",
    "href": "content/talks/posts/2024-aaai/presentation.html#code",
    "title": "ECCCos from the Black Box",
    "section": "Code",
    "text": "Code\nThe code used to run the analysis for this work is built on top of CounterfactualExplanations.jl.\nThere is also a corresponding paper, Explaining Black-Box Models through Counterfactuals, which has been published in JuliaCon Proceedings.\n\nTrustworthy AI in Julia: github.com/JuliaTrustworthyAI"
  },
  {
    "objectID": "content/talks/posts/2024-aaai/presentation.html#references",
    "href": "content/talks/posts/2024-aaai/presentation.html#references",
    "title": "ECCCos from the Black Box",
    "section": "References",
    "text": "References\n\n\n\n\nArtelt, Andr√©, Valerie Vaquet, Riza Velioglu, Fabian Hinder, Johannes Brinkrolf, Malte Schilling, and Barbara Hammer. 2021. ‚ÄúEvaluating Robustness of Counterfactual Explanations.‚Äù In 2021 IEEE Symposium Series on Computational Intelligence (SSCI), 01‚Äì09. IEEE.\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nMahajan, Divyat, Chenhao Tan, and Amit Sharma. 2020. ‚ÄúPreserving Causal Constraints in Counterfactual Explanations for Machine Learning Classifiers.‚Äù https://arxiv.org/abs/1912.03277.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nStutz, David, Krishnamurthy, Dvijotham, Ali Taylan Cemgil, and Arnaud Doucet. 2022. ‚ÄúLearning Optimal Conformal Classifiers.‚Äù https://arxiv.org/abs/2110.09192.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#trilliondollarwords.jl",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#trilliondollarwords.jl",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "TrillionDollarWords.jl",
    "text": "TrillionDollarWords.jl\n    \nA light-weight package providing Julia users easy access to the Trillion Dollar Words dataset and model (Shah, Paturi, and Chava 2023).\n\n\n\nDisclaimer\n\n\nPlease note that I am not the author of the Trillion Dollar Words paper nor am I affiliated with the authors. The package was developed as a by-product of our research and is not officially endorsed by the authors of the paper."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#context",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#context",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Context",
    "text": "Context\nICML 2024 paper Stop Making Unscientific AGI Performance Claims (Altmeyer et al. 2024) (preprint, blog post, code):\n\n\n\nEven simple models can distill meaningful information that predicts external data.\nHumans are prone to seek patterns and anthropomorphize."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#basic-functionality",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#basic-functionality",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Basic Functionality",
    "text": "Basic Functionality\nThe package provides the following functionality:\n\nLoad pre-processed data.\nLoad the model proposed in the paper.\nBasic model inference: compute forward passes and layer-wise activations.\nDownload pre-computed activations for probing the model."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#loading-the-data",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#loading-the-data",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Loading the Data",
    "text": "Loading the Data\n\n\nSentences\n40,000 time-stamped sentences from\n\nmeeting minutes\npress conferences\nspeeches\n\nby members of the Federal Open Market Committee (FOMC):\n\nusing TrillionDollarWords\nload_all_sentences() |&gt;\n  x -&gt; names(x)\n\n8-element Vector{String}:\n \"sentence_id\"\n \"doc_id\"\n \"date\"\n \"event_type\"\n \"label\"\n \"sentence\"\n \"score\"\n \"speaker\"\n\n\n\nAll Data\nMerged data includes economic indicators\n\nConsumer Price Index (CPI)\nProducer Price Index (PPI)\nUS Treasury (UST) yields\n\n\nload_all_data() |&gt;\n  x -&gt; names(x)\n\n11-element Vector{String}:\n \"sentence_id\"\n \"doc_id\"\n \"date\"\n \"event_type\"\n \"label\"\n \"sentence\"\n \"score\"\n \"speaker\"\n \"value\"\n \"indicator\"\n \"maturity\""
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#loading-the-model",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#loading-the-model",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Loading the Model",
    "text": "Loading the Model\n\nCan be loaded with or without the classifier head.\nUses Transformers.jl to retrieve the model from HuggingFace.\nAny keyword arguments accepted by Transformers.HuggingFace.HGFConfig can also be passed.\n\n\nload_model(; load_head=false, output_hidden_states=true)"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#basic-model-inference",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#basic-model-inference",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Basic Model Inference",
    "text": "Basic Model Inference\n\n\nFrom Scratch\nLayer-wise activations can be computed as follows:\n\ndf = load_all_sentences()\nmod = load_model(\n  load_head=false, \n  output_hidden_states=true\n)\nn = 5\nqueries = df[1:n, :]\nlayerwise_activations(\n  mod, queries\n)\n\n\nFrom Artifacts\nWe have archived activations for each layer and sentence as artifacts:\nusing LazyArtifacts\n\nartifact\"activations_layer_24\"\n\nOK, but why would I need all this? ü§î"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#motivation",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#motivation",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Motivation",
    "text": "Motivation\n\n\\(A_1\\): \\(enc(\\)‚ÄûIt is essential to bring inflation back to target to avoid drifting into deflation territory.‚Äú\\()\\)\n\\(A_2\\): \\(enc(\\)‚ÄûIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.‚Äú\\()\\)"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#motivation-1",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#motivation-1",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Motivation",
    "text": "Motivation\n\n\n\n\\(A_1\\): \\(enc(\\)‚ÄûIt is essential to bring inflation back to target to avoid drifting into deflation territory.‚Äú\\()\\)\n\\(A_2\\): \\(enc(\\)‚ÄûIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.‚Äú\\()\\)\n\n\n‚ÄúThey‚Äôre exactly the same.‚Äù\n‚Äî Linear probe \\(\\widehat{cpi}=f(A)\\)"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#embedding-fomc-comms",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#embedding-fomc-comms",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Embedding FOMC comms",
    "text": "Embedding FOMC comms\n\nWe linearly probe all layers to predict unseen economic indicators (CPI, PPI, UST yields).\nPredictive power increases with layer depth and probes outperform simple AR(\\(p\\)) models.\n\n\n\n\n\n\n\nFigure¬†1: Out-of-sample root mean squared error (RMSE) for the linear probe plotted against FOMC-RoBERTa‚Äôs n-th layer for different indicators."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#sparks-of-economic-understanding",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#sparks-of-economic-understanding",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Sparks of Economic Understanding?",
    "text": "Sparks of Economic Understanding?\nIf probe results were indicative of some intrinsic ‚Äòunderstanding‚Äô, probe should not be sensitive to unrelated sentences.\n\n\n\n\n\n\nFigure¬†2: Probe predictions for sentences about inflation of prices (IP), deflation of prices (DP), inflation of birds (IB) and deflation of birds (DB). The vertical axis shows predicted inflation levels subtracted by the average predicted value of the probe for random noise."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#intended-purpose-and-goals",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#intended-purpose-and-goals",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Intended Purpose and Goals",
    "text": "Intended Purpose and Goals\nGood starting point for the following ideas:\n\nFine-tune additional models on the classification task or other tasks of interest.\nFurther model probing, e.g.¬†using other market indicators not discussed in the original paper.\nImprove and extend the label annotations.\n\nAny contributions are very much welcome."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#references",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#references",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "References",
    "text": "References\n\n\nAltmeyer, Patrick, Andrew M. Demetriou, Antony Bartlett, and Cynthia C. S. Liem. 2024. ‚ÄúPosition: Stop Making Unscientific AGI Performance Claims.‚Äù https://arxiv.org/abs/2402.03962.\n\n\nShah, Agam, Suvan Paturi, and Sudheer Chava. 2023. ‚ÄúTrillion Dollar Words: A New Financial Dataset, Task & Market Analysis.‚Äù arXiv Preprint arXiv:2310.02207v1. https://arxiv.org/abs/2305.07972."
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#image-sources",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#image-sources",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Image sources",
    "text": "Image sources\n\nLeonardo DiCaprio: Meme template by user on Reddit"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#quote-sources",
    "href": "content/talks/posts/2024-juliacon/trillion-dollar-words/presentation.html#quote-sources",
    "title": "üí∞ Trillion Dollar Words in Julia",
    "section": "Quote sources",
    "text": "Quote sources\n\n‚ÄúThere! It‚Äôs sentient‚Äù‚Äîthat engineer at Google (probably!)"
  },
  {
    "objectID": "content/talks/posts/2024-juliacon/index.html",
    "href": "content/talks/posts/2024-juliacon/index.html",
    "title": "JuliaCon 2024",
    "section": "",
    "text": "In July 2024, I gave various main and lightning talks on Taija, HPC, mechanistic interpretability and Quarto at JuliaCon 2024 in Eindhoven, The Netherlands. Click on the links below to view the presentations.\n\nWhat‚Äôs new in Trustworthy AI in JuliA?\nTrustworthy AI in Julia meets Supercomputing\nüí∞ Trillion Dollar Words in Julia\nQuarto Extensions for the Julia Community"
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#quick-introduction",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#quick-introduction",
    "title": "Echos from the Black Box",
    "section": "Quick Introduction",
    "text": "Quick Introduction\n\n\n\nCurrently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nPreviously, educational background in Economics and Finance and two years in Monetary Policy at the Bank of England.\nInterested in applying Trustworthy AI to real-world problems, particularly in the financial sector."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#counterfactual-explanations",
    "title": "Echos from the Black Box",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs.\n\nProvided the changes are realistic and actionable, they can be used for Algorithmic Recourse (AR) to help individuals who face adverse outcomes."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#example-consumer-credit",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#example-consumer-credit",
    "title": "Echos from the Black Box",
    "section": "Example: Consumer Credit",
    "text": "Example: Consumer Credit\nFrom ‚Äòloan denied‚Äô to ‚Äòloan supplied‚Äô: CounterfactualExplanations.jl üì¶.\n\n\n\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search.\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#conformal-prediction",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#conformal-prediction",
    "title": "Echos from the Black Box",
    "section": "Conformal Prediction",
    "text": "Conformal Prediction\nConformal Prediction is a model-agnostic, distribution-free approach to Predictive Uncertainty Quantification: ConformalPrediction.jl üì¶.\n\n\n\n\n\n\n\n\nFigure¬†3: Conformal Prediction intervals for regression.\n\n\n\n\n\n\n\n\n\n\nFigure¬†4: Conformal Prediction sets for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#joint-energy-models",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#joint-energy-models",
    "title": "Echos from the Black Box",
    "section": "Joint Energy Models",
    "text": "Joint Energy Models\nJoint Energy Models (JEMs) are hybrid models trained to learn the conditional output and input distribution (Grathwohl et al. 2020): JointEnergyModels.jl üì¶.\n\n\n\n\n\n\nFigure¬†5: A JEM trained on Circles data."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#recourse-dynamics",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#recourse-dynamics",
    "title": "Echos from the Black Box",
    "section": "Recourse Dynamics",
    "text": "Recourse Dynamics\nWe present evidence suggesting that state-of-the-art applications of Algorithmic Recourse to groups of individuals induce large domain and model shifts and propose ways to mitigate this (IEEE SaTML paper).\nJoint work with Giovan Angela, Karol Dobiczek, Aleksander Buszydlik, Arie van Deursen and Cynthia C. S. Liem (all TU Delft)."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#a-balancing-act",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#a-balancing-act",
    "title": "Echos from the Black Box",
    "section": "A Balancing Act",
    "text": "A Balancing Act\n\n\nMinimizing private costs generates external costs for other stakeholders.\nTo avoid this, counterfactuals need to be plausible, i.e.¬†comply with the data-generating process.\nIn practice, costs to various stakeholders need to be carefully balanced.\n\n\n\n\nIs plausibility really all we need?"
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#pick-your-poison",
    "title": "Echos from the Black Box",
    "section": "Pick your Poison?",
    "text": "Pick your Poison?\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction. Which one would you pick?\n\n\n\n\n\n\nFigure¬†6: Turning a 9 into a 7: Counterfactual Examplanations for an Image Classifier."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#what-do-models-learn",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#what-do-models-learn",
    "title": "Echos from the Black Box",
    "section": "What do Models Learn?",
    "text": "What do Models Learn?\nThese images are sampled from the posterior distribution learned by the model. Looks different, no?\n\n\n\n\n\n\nFigure¬†7: Conditional Generated Images from the Image Classifier"
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#ecccos-from-the-black-box",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#ecccos-from-the-black-box",
    "title": "Echos from the Black Box",
    "section": "ECCCos from the Black Box",
    "text": "ECCCos from the Black Box\n\n\nWe propose a framework for generating Energy-Constrained Conformal Counterfactuals (ECCCos) which explain black-box models faithfully.\nJoint work with Mojtaba Framanbar (ING), Arie van Deursen (TU Delft) and Cynthia C. S. Liem (TU Delft).\n\n\n\n\n\n\n\n\n\nFigure¬†8: Gradient fields and counterfactual paths for different generators."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#taija",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#taija",
    "title": "Echos from the Black Box",
    "section": "üê∂ Taija",
    "text": "üê∂ Taija\n\nResearch informs development, development informs research.\n\n\nTrustworthy Artificial Intelligence in Julia.Taija is a collection of open-source packages for Trustworthy AI in Julia. Our goal is to help researchers and practitioners assess the trustworthiness of predictive models.\nOur work has been presented at JuliaCon 2022 and will be presented again at JuliaCon 2023 and hopefully beyond."
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#questions",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#questions",
    "title": "Echos from the Black Box",
    "section": "Questions?",
    "text": "Questions?"
  },
  {
    "objectID": "content/talks/posts/2023-delft-fintech/presentation.html#references",
    "href": "content/talks/posts/2023-delft-fintech/presentation.html#references",
    "title": "Echos from the Black Box",
    "section": "References",
    "text": "References\n\n\n\n\nGrathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and Kevin Swersky. 2020. ‚ÄúYour Classifier Is Secretly an Energy Based Model and You Should Treat It Like One.‚Äù In International Conference on Learning Representations.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#background",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#background",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Background",
    "text": "Background\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs.\n\nProvided the changes are realistic and actionable, they can be used for Algorithmic Recourse (AR) to help individuals who face adverse outcomes."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#example-consumer-credit",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#example-consumer-credit",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Example: Consumer Credit",
    "text": "Example: Consumer Credit\nIn Figure¬†1, arrows indicate changes from factuals (loan denied) to counterfactuals (loan supplied).\n\n\n\n\n\n\nFigure¬†1: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#our-work-in-a-nutshell",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#our-work-in-a-nutshell",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Our work in a nutshell ‚Ä¶",
    "text": "Our work in a nutshell ‚Ä¶\n\n\n\n\n\n\nFigure¬†2: Dynamics in Algorithmic Recourse.\n\n\n\n\nWe show that counterfactuals can induce substantial domain and model shifts like in Figure¬†2.\n\n\n\nWe propose a novel perspective on AR that explicitly addresses this issue.\n\n\n\n\nWe open-source a Julia package to study the dynamics we point to."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#proof-of-concept",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#proof-of-concept",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Proof-of-Concept",
    "text": "Proof-of-Concept\n\n\n\n\n\n\n\n\nFigure¬†3: A bank has trained a model to evaluate credit applicants. Credit risk is highest in bottom-right corner.\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†4: The bank has provided recourse to unsuccessful applicants: endogenous domain shift.\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†5: The bank has retrained the classifier: endogenous model shift.\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†6: The outcome after the process has been repeated a few times. Average default risk has increased."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#questions",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#questions",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Questions ‚Ä¶",
    "text": "Questions ‚Ä¶\n\n\n\n\nWho should bear the cost?\nAre the counterfactuals genuinely valid in practice?\nWhat about fairness and privacy concerns?\n\n\n\n\n\n\n\n\n\nFigure¬†7: Indiviudals who received recourse are clearly distinguishable."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#empirical-setup",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#empirical-setup",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Empirical Setup",
    "text": "Empirical Setup\n\nEvaluation: we propose metrics to measure domain shifts and model shifts.\n\n\nModels: we use linear classifiers, deep neural networks and deep ensembles.\n\n\nData:\n\n\nSynthetic\n\nOverlapping, Linearly Separable, Circles, Moons.\n\n\n\nReal-World\n\nGive Me Some Credit (Kaggle 2011), UCI defaultCredit (Yeh and Lien 2009), California Housing\n\n\n\n\nGenerators: Wachter (Wachter, Mittelstadt, and Russell 2017), REVISE (Joshi et al. 2019), DiCE (Mothilal, Sharma, and Tan 2020), Greedy (Schut et al. 2021)"
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#principal-findings-synthetic",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#principal-findings-synthetic",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Principal Findings ‚Äî Synthetic",
    "text": "Principal Findings ‚Äî Synthetic\n\n\n\n\n\nDomain shifts for overlapping synthetic data using deep ensemble.\n\n\n\n\n\n\nPerformance deterioration for overlapping synthetic data using deep ensemble."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#principal-findings-real-world",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#principal-findings-real-world",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Principal Findings ‚Äî Real-World",
    "text": "Principal Findings ‚Äî Real-World\n\n\n\n\n\nModel shifts for Credit Default data using deep ensemble.\n\n\n\n\n\n\nPerformance deterioration for Credit Default data using deep ensemble."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#method-general",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#method-general",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "From Individual Recourse ‚Ä¶",
    "text": "From Individual Recourse ‚Ä¶\nMany existing approaches to CE and AR work with the following baseline:\n\\[\n\\begin{aligned}\n\\color{lightgrey} \\mathbf{s}^\\prime &\\color{lightgrey}= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)} \\\\&\\color{black} + \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\color{lightgrey} \\}\n\\end{aligned}\n\\tag{1}\\]\nTypically concern has centred around minimizing costs to a single individual."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#method-collective",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#method-collective",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "‚Ä¶ towards collective recourse",
    "text": "‚Ä¶ towards collective recourse\nWe propose to extend Equation¬†1 as follows:\n\\[\n\\begin{aligned}\n\\color{lightgrey}\\mathbf{s}^\\prime &\\color{lightgrey}= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\{ {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)} \\\\ &\\color{lightgrey}+ \\lambda_1 {\\text{cost}(f(\\mathbf{s}^\\prime))} + \\color{black}\\lambda_2 {\\text{extcost}(f(\\mathbf{s}^\\prime))} \\color{lightgrey}\\}  \n\\end{aligned}\n\\tag{2}\\]\nThe newly introduced term \\(\\text{extcost}(f(\\mathbf{s}^\\prime))\\) is meant to explicitly capture external costs generated by changes to \\(\\mathbf{s}^\\prime\\)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#background-externalities",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#background-externalities",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Background: Externalities",
    "text": "Background: Externalities\nWe borrow the concept of private vs.¬†external costs from Economics.\n\n\n\n\n\n\nFigure¬†8: Illustration of a negative externality. Source: Investopedia."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#externalities-in-our-context",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#externalities-in-our-context",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Externalities in our Context",
    "text": "Externalities in our Context\nRelating this bank to our opening example, the external cost is carried by the retail bank.\n\n\n\n\n\n\nFigure¬†9: External cost is carried by bank."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#mitigation-strategies",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#mitigation-strategies",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Mitigation Strategies",
    "text": "Mitigation Strategies\n\nMore Conservative Decision Thresholds\nClassifier Preserving ROAR (ClaPROAR)1\nGravitational Counterfactual Explanations\n\n\n\n\n\n\n\nFigure¬†10: Mitigation strategies.\n\n\n\nLoosely inspired by ROAR (Upadhyay, Joshi, and Lakkaraju 2021)"
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#secondary-findings",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#secondary-findings",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Secondary Findings",
    "text": "Secondary Findings\n\n\n\n\n\nDomain shifts for overlapping synthetic data using deep ensemble.\n\n\n\n\n\n\nPerformance deterioration for overlapping synthetic data using deep ensemble."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#key-takeaways",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#key-takeaways",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Key Takeaways üîë",
    "text": "Key Takeaways üîë\n\n\nState-of-the-art approaches to AR induce substantial domain and model shifts.\n\n\n\n\nExternal costs of Individual Recourse should be shared across stakeholders.\n\n\n\n\nAd-hoc solution: penalize external costs in the counterfactual search objective function (Equation¬†2).\n\n\n\n\nThis gives rise to interesting cross-disciplinary research ideas (e.g.¬†Pareto-optimal AR)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#counterfactual-explanations-and-probabilistic-machine-learning",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#counterfactual-explanations-and-probabilistic-machine-learning",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Counterfactual Explanations and Probabilistic Machine Learning",
    "text": "Counterfactual Explanations and Probabilistic Machine Learning\n\nMethodologies and open-source tools that help researchers and practitioners assess the trustworthiness of predictive models.\n\n\n\nTowards Trustworthy AI in Julia\n\nCounterfactualExplanations.jl (JuliaCon 2022)\nConformalPrediction.jl (JuliaCon 2023 ‚Äî I hope!)\nLaplaceRedudx.jl (JuliaCon 2022)\nAlgorithmicRecourseDynamics.jl\n\n‚Ä¶ contributions welcome! üòä"
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#more-reading",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#more-reading",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "üìö More Reading",
    "text": "üìö More Reading\n\nGranular results for all of our experiments can be found in this online companion: https://www.patalt.org/endogenous-macrodynamics-in-algorithmic-recourse/.\nMany other related posts on my blog."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#image-sources",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#image-sources",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Image Sources",
    "text": "Image Sources\n\nCopyright for stock images belongs to TU Delft.\nAll other images, graphics or animations were created by us."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/presentation.html#references",
    "href": "content/talks/posts/2023-ieee-satml/presentation.html#references",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "References",
    "text": "References\n\n\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nYeh, I-Cheng, and Che-hui Lien. 2009. ‚ÄúThe Comparisons of Data Mining Techniques for the Predictive Accuracy of Probability of Default of Credit Card Clients.‚Äù Expert Systems with Applications 36 (2): 2473‚Äì80. https://doi.org/10.1016/j.eswa.2007.12.020."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#quick-intro",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#quick-intro",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Quick Intro",
    "text": "Quick Intro\n\n\n\nCurrently 2nd year of PhD in Trustworthy Artificial Intelligence at Delft University of Technology.\nWorking on Counterfactual Explanations and Probabilistic Machine Learning with applications in Finance.\nPreviously, educational background in Economics and Finance and two years at the Bank of England.\nEnthusiastic about free open-source software, in particular Julia and Quarto."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#in-a-nutshell",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#in-a-nutshell",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "In a nutshell ‚Ä¶",
    "text": "In a nutshell ‚Ä¶\n\n[‚Ä¶] we run experiments that simulate the application of recourse in practice using various state-of-the-art counterfactual generators and find that all of them induce substantial domain and model shifts.\n\n\n\nCounterfactual Explanation (CE) explain how inputs into a model need to change for it to produce different outputs.\nCounterfactual Explanations that involve realistic and actionable changes can be used for the purpose of Algorithmic Recourse (AR) to help individuals who face adverse outcomes.\n\n\n\n\n\n\nüéØ Key Contributions\n\n\n\nWe find that the induced shifts are substantial enough to likely impede the applicability of Algorithmic Recourse in some situations.\nFortunately, we find various strategies to mitigate these concerns.\nOur simulation framework for studying recourse dynamics is fast and open-sourced."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#proof-of-concept",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#proof-of-concept",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Proof-of-Concept",
    "text": "Proof-of-Concept\n\n\n\nExample 1 (Consumer Credit) ¬†\n\nSuppose Figure¬†1 relates to an automated decision-making system used by a retail bank to evaluate credit applicants.\nCreditworthiness decreases in the South-East direction.\nOutcome: bank supplies credit to more borrowers (orange), but these borrowers are riskier on average, which represents a cost to the retail bank.\n\n\n\nExample 2 (Student Admission) ¬†\n\nSuppose Figure¬†1 relates to an automated decision-making system used by a university in its student admission process.\nLikelihood of students completing their degree decreases in the South-East direction.\nOutcome: more students are admitted to university (orange), but they are more likely to fail their degree; the university suspends its efforts to offer AR, which represents a cost to future applicants.\n\n\n\n\n\n\n\n\n\nFigure¬†1: Dynamics in Algorithmic Recourse: (a) we have a simple linear classifier trained for binary classification where samples from the negative class (\\(y=0\\)) are marked in orange and samples of the positive class (\\(y=1\\)) are marked in blue; (b) the implementation of AR for a random subset of individuals leads to a noticeable domain shift; (c) as the classifier is retrained we observe a corresponding model shift; (d) as this process is repeated, the decision boundary moves away from the target class."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#algorithmic-recourse",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#algorithmic-recourse",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Algorithmic Recourse",
    "text": "Algorithmic Recourse\n\nEven though [‚Ä¶] interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the ‚Äúblack box‚Äù. (Wachter, Mittelstadt, and Russell 2017)\n\n\n\nFramework\n. . .\nObjective originally proposed by Wachter, Mittelstadt, and Russell (2017) is as follows\n\\[\n\\min_{x^\\prime \\in \\mathcal{X}} \\text{cost}(x^\\prime) \\ \\ \\ \\mbox{s. t.} \\ \\ \\ M(x^\\prime) = y^*\n\\qquad(1)\\]\nTypically this is approximated through regularization:\n\\[\nx^\\prime = \\arg \\min_{x^\\prime}  \\text{yloss}(M(x^\\prime),y^*) + \\lambda \\text{cost}(x^\\prime)\n\\qquad(2)\\]\n\nIntuition\n. . .\n\n\n\n\n\n\nFigure¬†2: Counterfactuals for Give Me Some Credit dataset (Kaggle 2011)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#method-general",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#method-general",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "From individual recourse ‚Ä¶",
    "text": "From individual recourse ‚Ä¶\n\nWe include the following generators in our simulation experiments below: REVISE (Joshi et al. 2019), CLUE (Antor√°n et al. 2020), DiCE (Mothilal, Sharma, and Tan 2020) and a Greedy approach that relies on probabilistic models (Schut et al. 2021).\n\n\n\nAll of them can be described by the following generalized form of Equation¬†2:\n\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\left\\{  {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)}+ \\lambda {\\text{cost}(f(\\mathbf{s}^\\prime)) }  \\right\\}\n\\end{aligned}\n\\qquad(3)\\]\n\n\n\nHere \\(\\mathbf{s}^\\prime=\\left\\{s_k^\\prime\\right\\}_K\\) is a \\(K\\)-dimensional array of counterfactual states and \\(f: \\mathcal{S} \\mapsto \\mathcal{X}\\) maps from the counterfactual state space to the feature space.\n\n\n\n\n\n\n\n\n\nFigure¬†3: Feature space (left) and counterfactual state space (right)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#method-collective",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#method-collective",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "‚Ä¶ towards collective recourse",
    "text": "‚Ä¶ towards collective recourse\n\nAll of the different approaches introduced above tackle the problem of Algorithmic Recourse from the perspective of one single individual.\n\n\n\nWe propose to extend Equation¬†3 as follows:\n\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\{ {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)} \\\\ &+ \\lambda_1 {\\text{cost}(f(\\mathbf{s}^\\prime))} + \\lambda_2 {\\text{extcost}(f(\\mathbf{s}^\\prime))} \\}  \n\\end{aligned}\n\\qquad(4)\\]\n\n\n\nHere \\(\\text{cost}(f(\\mathbf{s}^\\prime))\\) denotes the proxy for private costs faced by the individual; the newly introduced term \\(\\text{extcost}(f(\\mathbf{s}^\\prime))\\) is meant to capture external costs generated by changes to \\(\\mathbf{s}^\\prime\\).\n\n\n\n\n\n\nüéì Negative Externalities\n\n\nThe underlying concept of private and external costs is borrowed from Economics and well-established in that field: when the decisions or actions by some individual market participant generate external costs, then the market is said to suffer from negative externalities and is considered inefficient (Pindyck and Rubinfeld 2014)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#research-questions",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#research-questions",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Research Questions",
    "text": "Research Questions\nPrincipal Concerns\n\nRQ 1 (Endogenous Shifts) Does the repeated implementation of recourse provided by state-of-the-art generators lead to shifts in the domain and model?\n\n\nRQ 2 (Costs) If so, are these dynamics substantial enough to be considered costly to stakeholders involved in real-world automated decision-making processes?\n\n\nRQ 3 (Heterogeneity) Do different counterfactual generators yield significantly different outcomes in this context? Furthermore, is there any heterogeneity concerning the chosen classifier and dataset?\n\n\nRQ 4 (Drivers) What are the drivers of endogenous dynamics in Algorithmic Recourse?\n\nSecondary Concerns\n\nRQ 5 (Mitigation Strategies) What are potential mitigation strategies with respect to endogenous macrodynamics in AR?"
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#empirical-setup",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#empirical-setup",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Empirical Setup",
    "text": "Empirical Setup\n\nEvaluation MetricsModelsDataGenerators\n\n\n\n\nDomain Shifts\n\nMaximum Mean Discrepancy (MMD): a measure of the distance between the kernel mean embeddings of two samples; in our context, large values indicate that a domain shift indeed seems to have occurred.\n\n\nModel Shifts\n\nPerturbations: following Upadhyay, Joshi, and Lakkaraju (2021) we define \\(\\Delta=||\\theta_{t+1}-\\theta_{t}||^2\\), that is the euclidean distance between the vectors of parameters before and after retraining the model \\(M\\).\nPredicted Probability MMD (PP MMD): instead of applying MMD to features directly, we apply it to the predicted probabilities assigned to a set of samples by the model \\(M\\).\nDisagreement Coefficient: this metric was introduced in Hanneke (2007) and estimates \\(p(M(x) \\neq M^\\prime(x))\\), that is the probability that two classifiers disagree on the predicted outcome for a randomly chosen sample.\nDecisiveness: we define the metric simply as \\({\\frac{1}{N}}\\sum_{i=0}^N(\\sigma(M(x)) - 0.5)^2\\) where \\(M(x)\\) are predicted logits from a binary classifier and \\(\\sigma\\) denotes the sigmoid function; it quantifies the likelihood that a model assigns a high probability to its classification of any given sample.\nPerformance: we compute the classifier‚Äôs F-score on a test sample that we leave untouched throughout the experiment.\n\n\n\n\nClassifiers\n\nSimple linear classifier‚ÄîLogistic Regression.\nMultilayer perceptron‚ÄîMLP.\nDeep Ensemble composed of five MLPs following Lakshminarayanan, Pritzel, and Blundell (2017).\n\nGenerative Models\nDifferent specifications of a plain-vanilla Variational Autoencoder (VAE)\n\n\n\n\nTable¬†1: Model parameters.\n\n\n\n\nNeural network architectures and training parameters.\n\n\nModel\nData\nHidden Dim.\nLatent Dim.\nHidden Layers\nBatch\nDropout\nEpochs\n\n\n\n\nMLP\nSynthetic\n32\n-\n1\n-\n-\n100\n\n\nMLP\nReal-World\n64\n-\n2\n500\n0.1\n100\n\n\nVAE\nSynthetic\n32\n2\n1\n-\n-\n100\n\n\nVAE\nReal-World\n32\n8\n1\n-\n-\n250\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSynthetic Data\nFour synthetic binary classification datasets consisting of 1000 samples each: Overlapping, Linearly Separable, Circles and Moons (Figure¬†4).\n\n\n\n\n\n\nFigure¬†4: Synthetic classification datasets used in our experiments. Samples from the negative class (\\(y=0\\)) are marked in orange while samples of the positive class (\\(y=1\\)) are marked in blue.\n\n\n\n\nReal-World Data\nThree real-world datasets from the Finance and Economics domain: all tabular and can be used for binary classification.\n\nThe Give Me Some Credit dataset: predict whether a borrower is likely to experience financial difficulties in the next two years (Kaggle 2011).\nThe UCI defaultCredit dataset (Yeh and Lien 2009): a benchmark dataset that can be used to train binary classifiers to predict the whether credit card clients default on their payment.\nThe California Housing dataset Pace and Barry (1997): continuous outcome variable binarized as \\(\\tilde{y}=\\mathbb{I}_{y&gt;\\text{median}(Y)}\\) indicating if the median house price of a given district is above the median of all districts.\n\n\n\n\n\n\nPrincipal Concerns\n\nWachter (Wachter, Mittelstadt, and Russell 2017)\nREVISE (Joshi et al. 2019)\nCLUE (Antor√°n et al. 2020)\nDiCE (Mothilal, Sharma, and Tan 2020)\nGreedy (Schut et al. 2021)\n\n\nSecondary Concerns\n\nMore Conservative Decision Thresholds\nClassifier Preserving ROAR (ClaPROAR):\n\n\\[\n\\begin{aligned}\n\\text{extcost}(f(\\mathbf{s}^\\prime)) = l(M(f(\\mathbf{s}^\\prime)),y^\\prime)\n\\end{aligned}\n\\qquad(5)\\]\n\nGravitational Counterfactual Explanations:\n\n\\[\n\\begin{aligned}\n\\text{extcost}(f(\\mathbf{s}^\\prime)) = \\text{dist}(f(\\mathbf{s}^\\prime),\\bar{x}^*)\n\\end{aligned}\n\\qquad(6)\\]\n\n\n\nMitigation strategies."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#principal-findings",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#principal-findings",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Principal Findings",
    "text": "Principal Findings\n\n\n\n\n\nResults for synthetic data.\n\n\n\n\n\n\nResults for real-world data."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#secondary-findings",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#secondary-findings",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Secondary Findings",
    "text": "Secondary Findings\n\n\n\n\n\nResults for synthetic data.\n\n\n\n\n\n\nResults for real-world data."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#summary-of-findings",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#summary-of-findings",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Summary of Findings",
    "text": "Summary of Findings\nPrincipal Concerns\n\nFirstly, endogenous dynamics do emerge in our experiments (Proposition¬†1) and we find them substantial enough to be considered costly (Proposition¬†2)\nSecondly, the choice of the counterfactual generator matters, with Latent Space search generally having a dampening effect (Proposition¬†3).\nThe observed dynamics, therefore, seem to be driven by a discrepancy between counterfactual outcomes that minimize costs to individuals and outcomes that comply with the data-generating process (Proposition¬†4).\n\nSecondary Concerns\n\nOur findings indicate that all three proposed mitigation strategies are at least at par with LS generators (Proposition¬†5)."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#key-takeaways",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#key-takeaways",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Key Takeaways üîë",
    "text": "Key Takeaways üîë\n\n\nOur findings indicate that state-of-the-art approaches to Algorithmic Recourse induce substantial domain and model shifts.\n\n\n\n\nWe would argue that the expected external costs of individual recourse should be shared by all stakeholders.\n\n\n\n\nA straightforward way to achieve this is to penalize external costs in the counterfactual search objective function (Equation¬†4).\n\n\n\n\nVarious simple strategies based on this notion can be effectively used to mitigate shifts."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#limitations",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#limitations",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Limitations",
    "text": "Limitations\n\nPrivate vs.¬†External Costs\n\nWe fall short of providing any definitive answers as to how to trade off private vs.¬†external costs.\nProposed strategies are a good starting point, but they are ad-hoc.\n\n. . .\nExperimental Setup\n\nExperimental design is a vast over-simplification of potential real-world scenarios.\n\n. . .\nCausal Modelling\n\nHave focused on popular counterfactual generators that do not incorporate any causal knowledge.\nPerturbations therefore may involve changes to variables that affect the outcome predicted by the black-box model, but not the true, causal outcome.\nFuture work would likely benefit from including recent approaches to AR that incorporate causal knowledge such Karimi, Sch√∂lkopf, and Valera (2021).\n\n. . .\nClassifiers\n\nWe have limited our analysis to differentiable linear and non-linear classifiers; empirical evidence suggests that other models such as boosted decision trees outperform DL on tabular data (Borisov et al. (2022), Grinsztajn, Oyallon, and Varoquaux (2022))."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#more-resources",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#more-resources",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "More Resources üìö",
    "text": "More Resources üìö\n\n\n\nRead on ‚Ä¶\n\n\nGranular results for all of our experiments can be found in this online companion: https://www.patalt.org/endogenous-macrodynamics-in-algorithmic-recourse/.\nBlog post introducing Counterfactual Explanations: [TDS, homepage].\n\n\n‚Ä¶ or get busy üñ•Ô∏è\n\n\nCounterfactualExplanations.jl (Altmeyer 2022) provides an extensible, fast and language-agnostic implementation in Julia.\nWe have built a framework that extends the functionality from static benchmarks to simulation experiments: AlgorithmicRecourseDynamics.jl.\nThe Github repository containing all the code used to produce the results in this paper can be found here."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#image-sources",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#image-sources",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "Image Sources",
    "text": "Image Sources\n\nCopyright for stock images belongs to TU Delft.\nAll other images, graphics or animations were created by us."
  },
  {
    "objectID": "content/talks/posts/2023-ieee-satml/long_presentation.html#references",
    "href": "content/talks/posts/2023-ieee-satml/long_presentation.html#references",
    "title": "Endogenous Macrodynamics in Algorithmic Recourse",
    "section": "References",
    "text": "References\n\n\n\n\nAltmeyer, Patrick. 2022. ‚ÄúCounterfactualExplanations.jl - a Julia Package for Counterfactual Explanations and Algorithmic Recourse.‚Äù https://github.com/pat-alt/CounterfactualExplanations.jl.\n\n\nAntor√°n, Javier, Umang Bhatt, Tameem Adel, Adrian Weller, and Jos√© Miguel Hern√°ndez-Lobato. 2020. ‚ÄúGetting a Clue: A Method for Explaining Uncertainty Estimates.‚Äù https://arxiv.org/abs/2006.06848.\n\n\nBorisov, Vadim, Tobias Leemann, Kathrin Se√üler, Johannes Haug, Martin Pawelczyk, and Gjergji Kasneci. 2022. ‚ÄúDeep Neural Networks and Tabular Data: A Survey.‚Äù IEEE Transactions on Neural Networks and Learning Systems.\n\n\nGrinsztajn, L√©o, Edouard Oyallon, and Ga√´l Varoquaux. 2022. ‚ÄúWhy Do Tree-Based Models Still Outperform Deep Learning on Tabular Data?‚Äù https://arxiv.org/abs/2207.08815.\n\n\nHanneke, Steve. 2007. ‚ÄúA Bound on the Label Complexity of Agnostic Active Learning.‚Äù In Proceedings of the 24th International Conference on Machine Learning, 353‚Äì60. https://doi.org/10.1145/1273496.1273541.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit.\n\n\nKarimi, Amir-Hossein, Bernhard Sch√∂lkopf, and Isabel Valera. 2021. ‚ÄúAlgorithmic Recourse: From Counterfactual Explanations to Interventions.‚Äù In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 353‚Äì62. FAccT ‚Äô21. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3442188.3445899.\n\n\nLakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2017. ‚ÄúSimple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles.‚Äù In Proceedings of the 31st International Conference on Neural Information Processing Systems, 6405‚Äì16. NIPS‚Äô17. Red Hook, NY, USA: Curran Associates Inc.\n\n\nMothilal, Ramaravind K, Amit Sharma, and Chenhao Tan. 2020. ‚ÄúExplaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.‚Äù In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 607‚Äì17. https://doi.org/10.1145/3351095.3372850.\n\n\nPace, R Kelley, and Ronald Barry. 1997. ‚ÄúSparse Spatial Autoregressions.‚Äù Statistics & Probability Letters 33 (3): 291‚Äì97. https://doi.org/10.1016/s0167-7152(96)00140-x.\n\n\nPedregosa, Fabian, Ga√´l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2011. ‚ÄúScikit-Learn: Machine Learning in Python.‚Äù The Journal of Machine Learning Research 12: 2825‚Äì30.\n\n\nPindyck, Robert S, and Daniel L Rubinfeld. 2014. Microeconomics. Pearson Education.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nUpadhyay, Sohini, Shalmali Joshi, and Himabindu Lakkaraju. 2021. ‚ÄúTowards Robust and Reliable Algorithmic Recourse.‚Äù Advances in Neural Information Processing Systems 34: 16926‚Äì37.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289.\n\n\nYeh, I-Cheng, and Che-hui Lien. 2009. ‚ÄúThe Comparisons of Data Mining Techniques for the Predictive Accuracy of Probability of Default of Credit Card Clients.‚Äù Expert Systems with Applications 36 (2): 2473‚Äì80. https://doi.org/10.1016/j.eswa.2007.12.020."
  },
  {
    "objectID": "content/talks/posts/2024-icml/index.html",
    "href": "content/talks/posts/2024-icml/index.html",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "",
    "text": "In Julia 2024, I will present our position paper, Stop Making Unscientific AGI Performance Claims at ICML 2024."
  },
  {
    "objectID": "content/talks/posts/2024-icml/index.html#slides",
    "href": "content/talks/posts/2024-icml/index.html#slides",
    "title": "Stop Making Unscientific AGI Performance Claims",
    "section": "Slides",
    "text": "Slides\nYou can find the slides below or click here to open them in full screen.\nFor more information about the paper see also here or the preprint of the paper itself."
  },
  {
    "objectID": "content/talks/posts/2024-tuev/index.html",
    "href": "content/talks/posts/2024-tuev/index.html",
    "title": "Vertraubare KI durch Counterfactual Explanations",
    "section": "",
    "text": "Sie k√∂nnen die Pr√§sentation untenan finden oder hier klicken, um sie in einem neuen Fenster zu √∂ffnen."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#agenda",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#agenda",
    "title": "Julia on HPC",
    "section": "Agenda",
    "text": "Agenda\n\n\nIntroduction to Parallel Computing (15 min).\n\nWhat is parallel computing?\nParallel computing in Julia.\nDifferent forms of parallelization offered by CounterfactualExplanations.jl.\n\nFirst interactive session: local parallelization (15 min).\nJulia on DelftBlue (25 min).\n\nWhat is DelftBlue?\nHow to use Julia on DelftBlue?\nChallenges and solutions.\n\nSecond interactive session: remote parallelization (25 min)."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#what-is-parallel-computing",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#what-is-parallel-computing",
    "title": "Julia on HPC",
    "section": "What is Parallel Computing?",
    "text": "What is Parallel Computing?\n\nParallel computing is a type of computation in which many calculations or processes are carried out simultaneously. ‚Äî Wikipedia\n\n\n\n\nImage by Kay Jan Wong."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#parallel-computing-in-julia",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#parallel-computing-in-julia",
    "title": "Julia on HPC",
    "section": "Parallel Computing in Julia",
    "text": "Parallel Computing in Julia\nJulia has strong native and external support for parallel computing.\n\n\nMulti-Threading\nCommand line:\njulia --threads 4\nJulia:\nThreads.@threads for i = 1:10\n    a[i] = Threads.threadid()\nend\n\nMulti-Processing\n\nDistributed standard library (not covered here).\nMPI.jl wrapper for MPI (our focus)."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#parallelization-in-counterfactualexplanations.jl",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#parallelization-in-counterfactualexplanations.jl",
    "title": "Julia on HPC",
    "section": "Parallelization in CounterfactualExplanations.jl",
    "text": "Parallelization in CounterfactualExplanations.jl\n\n\n\n\nMotivation: often required to generate many explanations.\nGoal: native support for both forms of parallelization.\nDesiteratum: minimize the burden on users.\n\n\n\n\n\n\nUsage example."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#tasks-15-min",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#tasks-15-min",
    "title": "Julia on HPC",
    "section": "Tasks (15 min)",
    "text": "Tasks (15 min)\n\nIf not already done, either fork or clone the repo.\nOpen the notebook docs/src/tutorials/parallelization.qmd.\nUsing the @time macro, check if multi-threading speeds up computations."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#what-is-delftblue",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#what-is-delftblue",
    "title": "Julia on HPC",
    "section": "What is DelftBlue?",
    "text": "What is DelftBlue?\n\nDelftBlue is [one of two] supercomputer[s] at TU Delft [that] will offer 20,000 CPU cores in over 400 compute nodes. ‚Äî DelftBlue\n\n\nRich documentation including a small section on Julia.\nShould be accessible to all of you.\nYou will be among the first to use Julia on DelftBlue.\nAlternative: DAIC."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#how-to-use-julia-on-delftblue",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#how-to-use-julia-on-delftblue",
    "title": "Julia on HPC",
    "section": "How to Use Julia on DelftBlue?",
    "text": "How to Use Julia on DelftBlue?\n\n\n\n\nUse Julia from the software stack (see docs).\nRecommended: install your own Julia version.\nGet help on Mattermost.\n\n\n\n\n\n\nSelf-install\n\n\nSee julia-hpc-for-dummies for additional details.\n\nSym-link the Julia installation to your home directory.\n\nmkdir -p /scratch/${USER}/.julia\nln -s /scratch/${USER}/.julia $HOME/.julia\n\nSym-link juliaup to your home directory.\n\nmkdir -p /scratch/${USER}/.juliaup\nln -s /scratch/${USER}/.juliaup $HOME/.juliaup\n\nInstall juliaup as follows: curl -fsSL https://install.julialang.org | sh. Customize location to /scratch/${USER}/.juliaup."
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#challenges-and-solutions",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#challenges-and-solutions",
    "title": "Julia on HPC",
    "section": "Challenges and Solutions",
    "text": "Challenges and Solutions\n\n\nJulia version shipped with software stack is outdated. Solution: install your own Julia version.\nLogin nodes are not meant for computations. Compiling Julia takes a long time. Solution: do as much as possible on your local machine. For anything else, rely mostly on the compute nodes.\nSelf-installed Julia uses ‚Äúall the resources!‚Äù üßê Solution: use this header for your scripts.\n\n\n\n\n\n\nWhoopsie!"
  },
  {
    "objectID": "content/talks/posts/2023-julia-hpc-delft/presentation.html#tasks-25-min",
    "href": "content/talks/posts/2023-julia-hpc-delft/presentation.html#tasks-25-min",
    "title": "Julia on HPC",
    "section": "Tasks (25 min)",
    "text": "Tasks (25 min)\n\nInstall your own Julia version on DelftBlue.\nFork and/or clone the julia-hpc-for-dummies repo.\nSend a job to DelftBlue."
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#background",
    "href": "content/talks/posts/2025-dscn/presentation.html#background",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Background",
    "text": "Background\n\n\n\n\n How can we make opaque AI more trustworthy?\n Explainable AI, Adversarial ML, Probabilistic ML\n Banking, Finance, Economics\n Maintainer of Taija (trustworthy AI in Julia)\n\n\n\n\n\n\n\n\n\n\nScan for slides."
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#agenda",
    "href": "content/talks/posts/2025-dscn/presentation.html#agenda",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Agenda",
    "text": "Agenda\n\n\nWhat are counterfactual explanations (CE) and algorithmic recourse (AR) and why are they useful?\nWhat dynamics are generated when off-the-shelf solutions to CE and AR are implemented in practice?\nCan we generate plausible counterfactuals relying only on the opaque model itself?\nHow can we leverage counterfactuals during training to build more trustworthy models?"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#counterfactual-explanations",
    "href": "content/talks/posts/2025-dscn/presentation.html#counterfactual-explanations",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\nModel Training\nObjective:\n\\[\n\\begin{aligned}\n\\min_{\\theta} \\{  {\\text{yloss}(M_{\\theta}(x),\\mathbf{y})} \\}\n\\end{aligned}\n\\]\nSolution:\n\\[\n\\begin{aligned}\n\\nabla_{\\theta} \\{  {\\text{yloss}(M_{\\theta}(x),\\mathbf{y})} \\}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#algorithmic-recourse",
    "href": "content/talks/posts/2025-dscn/presentation.html#algorithmic-recourse",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Algorithmic Recourse",
    "text": "Algorithmic Recourse\n\n\nProvided CE is valid, plausible and actionable, it can be used to provide recourse to individuals negatively affected by models.\n\n‚ÄúIf your income had been X, then ‚Ä¶‚Äù\n\n\n\n\n\n\n\n\nFigure¬†2: Counterfactuals for random samples from the Give Me Some Credit dataset (Kaggle 2011). Features ‚Äòage‚Äô and ‚Äòincome‚Äô are shown."
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#hidden-cost-of-implausibility",
    "href": "content/talks/posts/2025-dscn/presentation.html#hidden-cost-of-implausibility",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Hidden Cost of Implausibility",
    "text": "Hidden Cost of Implausibility\n\n\nAR can introduce costly dynamics1\n\n\n\nEndogenous Macrodynamics in Algorithmic Recourse.\n\n\n\n\n\n\n\n\n\nFigure¬†3: Illustration of external cost of individual recourse.\n\n\n\n\n Insight: individual recourse neglects bigger picture.\n Altmeyer, Angela, et al. (2023) @ SaTML 2023."
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#mitigation-strategies",
    "href": "content/talks/posts/2025-dscn/presentation.html#mitigation-strategies",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Mitigation Strategies",
    "text": "Mitigation Strategies\n\nIncorporate hidden cost in reframed objective (Equation¬†1).\nReducing hidden cost is equivalent to ensuring plausibility.\n\n\\[\n\\begin{aligned}\n\\mathbf{s}^\\prime &= \\arg \\min_{\\mathbf{s}^\\prime \\in \\mathcal{S}} \\{ {\\text{yloss}(M(f(\\mathbf{s}^\\prime)),y^*)} \\\\ &+ \\lambda_1 {\\text{cost}(f(\\mathbf{s}^\\prime))} + \\lambda_2 {\\text{extcost}(f(\\mathbf{s}^\\prime))} \\}  \n\\end{aligned}\n\\tag{1}\\]"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#pick-your-poison",
    "href": "content/talks/posts/2025-dscn/presentation.html#pick-your-poison",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Pick your Poison",
    "text": "Pick your Poison\nAll of these counterfactuals are valid explanations for the model‚Äôs prediction.\n\nWhich one would you pick?\n\n\n\n\n\n\n\nFigure¬†4: Turning a 9 into a 7: Counterfactual explanations for an image classifier produced using Wachter (Wachter, Mittelstadt, and Russell 2017), Schut (Schut et al. 2021) and REVISE (Joshi et al. 2019)."
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#faithful-first-plausible-second",
    "href": "content/talks/posts/2025-dscn/presentation.html#faithful-first-plausible-second",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Faithful First, Plausible Second",
    "text": "Faithful First, Plausible Second\nCounterfactuals as plausible as the model permits1.\n\n\n\n\n\n\n\n\nFigure¬†5: KDE for training data.\n\n\n\n\n\n\n\n\n\n\nFigure¬†6: KDE for model posterior.\n\n\n\n\n Altmeyer, Farmanbar, et al. (2023) @ AAAI 2024. [blog]"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#faithful-counterfactuals",
    "href": "content/talks/posts/2025-dscn/presentation.html#faithful-counterfactuals",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Faithful Counterfactuals",
    "text": "Faithful Counterfactuals\n\n\n\n\n\n\n\n\nFigure¬†7: Turning a 9 into a 7. ECCCo applied to MLP (a), Ensemble (b), JEM (c), JEM Ensemble (d).\n\n\n\n\n Insight: faithfulness facilitates\n\nmodel quality checks (Figure¬†7).\nstate-of-the-art plausibility (Figure¬†8).\n\n\n\n\n\n\n\nFigure¬†8: Results for different generators (from 3 to 5)."
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#counterfactual-training-method",
    "href": "content/talks/posts/2025-dscn/presentation.html#counterfactual-training-method",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Counterfactual Training: Method",
    "text": "Counterfactual Training: Method\n\n\n\n\n\n\nIdea\n\n\nLet the model compare its own explanations to plausible ones1.\n\n\n\n\n\n\nContrast faithful counterfactuals with data.\nUse nascent CE as adversarial examples.\n\n\n\n\n\nExplanation or attack?\n\n\n\n under review"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#counterfactual-training-results",
    "href": "content/talks/posts/2025-dscn/presentation.html#counterfactual-training-results",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Counterfactual Training: Results",
    "text": "Counterfactual Training: Results\n\n\n\n\n\n\nFigure¬†9: (a) conventional training, all mutable; (b) CT, all mutable; (c) conventional, age immutable; (d) CT, age immutable.\n\n\n\n\nModels trained with CT learn more plausible and (provably) actionable explanations.\nPredictive performance does not suffer, robust performance improves."
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#spurious-sparks-of-agi",
    "href": "content/talks/posts/2025-dscn/presentation.html#spurious-sparks-of-agi",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Spurious Sparks of AGI",
    "text": "Spurious Sparks of AGI\n\n\nWe challenge the idea that the finding of meaningful patterns in latent spaces of large models is indicative of AGI1.\n\n\n\n\n\n\n\nFigure¬†10: Inflation of prices or birds? It doesn‚Äôt matter!\n\n\n\n\n In Altmeyer et al. (2024) @ ICML 2024"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#taija",
    "href": "content/talks/posts/2025-dscn/presentation.html#taija",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Taija",
    "text": "Taija\n\n\n\nModel Explainability (CounterfactualExplanations.jl)\nPredictive Uncertainty Quantification (ConformalPrediction.jl)\nEffortless Bayesian Deep Learning (LaplaceRedux.jl)\n‚Ä¶ and more!\n\n\n\nWork presented @ JuliaCon 2022, 2023, 2024.\nGoogle Summer of Code and Julia Season of Contributions 2024.\nTotal of three software projects @ TU Delft.\n\n\n\nTrustworthy AI in Julia: github.com/JuliaTrustworthyAI"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#references",
    "href": "content/talks/posts/2025-dscn/presentation.html#references",
    "title": "Explaining Models or Modelling Explanations",
    "section": "References",
    "text": "References\n\n\n\n\nAltmeyer, Patrick, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, and Cynthia CS Liem. 2023. ‚ÄúEndogenous Macrodynamics in Algorithmic Recourse.‚Äù In 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), 418‚Äì31. IEEE.\n\n\nAltmeyer, Patrick, Andrew M. Demetriou, Antony Bartlett, and Cynthia C. S. Liem. 2024. ‚ÄúPosition Paper: Against Spurious Sparks-Dovelating Inflated AI Claims.‚Äù https://arxiv.org/abs/2402.03962.\n\n\nAltmeyer, Patrick, Arie van Deursen, and Cynthia C. S. Liem. 2023. ‚ÄúExplaining Black-Box Models through Counterfactuals.‚Äù In Proceedings of the JuliaCon Conferences, 1:130.\n\n\nAltmeyer, Patrick, Mojtaba Farmanbar, Arie van Deursen, and Cynthia C. S. Liem. 2023. ‚ÄúFaithful Model Explanations Through Energy-Constrained Conformal Counterfactuals.‚Äù https://arxiv.org/abs/2312.10648.\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nKaggle. 2011. ‚ÄúGive Me Some Credit, Improve on the State of the Art in Credit Scoring by Predicting the Probability That Somebody Will Experience Financial Distress in the Next Two Years.‚Äù https://www.kaggle.com/c/GiveMeSomeCredit; Kaggle. https://www.kaggle.com/c/GiveMeSomeCredit.\n\n\nSchut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu, Yarin Gal, et al. 2021. ‚ÄúGenerating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties.‚Äù In International Conference on Artificial Intelligence and Statistics, 1756‚Äì64. PMLR.\n\n\nWachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017. ‚ÄúCounterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.‚Äù Harv. JL & Tech. 31: 841. https://doi.org/10.2139/ssrn.3063289."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/presentation.html#wat-is-kunstmatige-intelligentie",
    "href": "content/talks/posts/2023-goethe/presentation.html#wat-is-kunstmatige-intelligentie",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "Wat is Kunstmatige Intelligentie?",
    "text": "Wat is Kunstmatige Intelligentie?\n\n\n\nKI is niet alleen ‚Äòmachinaal leren‚Äô (ML), hoewel mensen vandaag meestal ML bedoelen als ze KI zeggen.\nML: je geeft de computer aleen een objectief en data en hij leert (bijna) vanzelf.\n\n\n\n\n\nEen algoritme leert van data.\n\n\n\n\n\nIn de tijden van ChatGPT heeft iederen een idee van KI maar het is niet heel klar wat het eigenlijk betekent.\nVolgens mij bedoelen mensen meestal ‚Äúmachinaal leren‚Äù als ze ‚ÄòKI‚Äô zeggen.\n‚ÄúMachinaal leren‚Äù, of koort ‚ÄúML‚Äù, is niet hetzelfde als ‚ÄúKI‚Äù maar het is wel een belangrijk onderdeel van KI.\n‚ÄúML‚Äù is een manier om een computer te trainen om een taak te doen zonder dat je de computer precies vertelt hoe hij het moet doen.\nJe geeft de computer alleen een objectief en een hoop voorbeelden. Dan lat je de computer zelf een manier vinden om het objectief te bereiken en ten slotte hoop je dat de computer goed geleerd heeft.\nBijvoorbeeld, je zie hier aan de rechte kant een algoritme dat leert tussen twee klassen te onderscheiden. Hoe meer data het heeft gezien, hoe beter het zijn werk doet."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/presentation.html#diep-leren---de-huidige-standaard",
    "href": "content/talks/posts/2023-goethe/presentation.html#diep-leren---de-huidige-standaard",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "‚ÄúDiep Leren‚Äù - de huidige standaard",
    "text": "‚ÄúDiep Leren‚Äù - de huidige standaard\n\n\nDe kerntechniek van de sterkste KI systemen van vandaag is ‚Äúdiep leren‚Äù.\n\n‚ÄúSchaal is alles wat je nodig hebt‚Äù‚Äîiemand van OpenAI\n\n\n\n\n\nEen (niet zo) diep kunstmatiges neuraal netwerk.\n\n\n\n\n\nDe kerntechniek van de sterkste KI systemen van vandaag is ‚Äúdiep leren‚Äù, of ‚Äúdeep learning‚Äù in het Engels.\nIn het kort, bij diep leren gebruiken we grote modellen met veel instellingen. Deze waarden worden geleerd en verbeterd via optimalisatie.\nOpenAI‚Äôs ChatGPT heeft zoveel succes gehad omdat het een heel groot model is. Eigenlijk is het inoffici√´le motto van OpenAI: ‚ÄúScale is all you need‚Äù, dus ‚ÄúSchaal is alles wat je nodig hebt‚Äù.\nAan de rechte kant zien jullie een voorbeeld van een diep neuraal netwerk. Die groene punten zijn de instellingen van het model. Kan iemand tellen hoeveel instellingen dit model heeft?\nDus er zijn 32 plus 6 plus 32 plus 12 groene punten. Dat is 82 instellingen.\nMaar dit is erg niet diep. Ter vergelijking: ChatGPT heeft ongeveer 15 miljard instellingen.\nSommige mensen geloven dat deze sort modellen de toekomst van KI zijn en ons zullen helpen om de meest complexe problemen op te lossen."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/presentation.html#klinkt-goed-maar",
    "href": "content/talks/posts/2023-goethe/presentation.html#klinkt-goed-maar",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "Klinkt goed, maar ‚Ä¶",
    "text": "Klinkt goed, maar ‚Ä¶\n\n\nDeze modellen hebben ook nadele. Ze zijn:\n\nkwetsbaar\nniet transparant\n‚Ä¶\n\n\n\n\n\n\n\n\nAfbeelding¬†1: Stopbord of bloempod? Bron: Wu et al.¬†(2020)\n\n\n\n\n\n\nDit klinkt allemaal goed, maar deze modellen hebben ook nadele.\nBijvoorbeeld, ze zijn kwetsbaar. Ze kunnen makkelijk misleid worden.\nIn de afbeelding aan de rechte kant zien jullie aan de linke kant een stopbord: eerst erkent het model het stopbord als een stopbord. Maar als de foto een beetje veranderen, dan ziet het model een bloempot. Dit zie je aan de rechte kant.\nEen van de grootste problemen met diep leren is dat de modellen zo groot zijn dat niemand ze echt begrijpt.\nJe kan niet het model zomaar openen en zien hoe het werkt. Als een model niet transparant is, noemen we het een ‚Äòblack box‚Äô.\nDit is heel problematisch voor de betrouwbaarheid van KI systemen, vooral als ze gebruikt worden in kritische toepassingen zoals medische diagnoses of autonome voertuigen.\nMaar ook en mer aldagelijkse toepassingen: heeft iemand hier eermaal een lening aangevraagd? Of een sollicitatie gedaan? Of een verzekering afgesloten? Dan is de kans groot dat een KI systeem een rol heeft gespeld in de beslissing."
  },
  {
    "objectID": "content/talks/posts/2023-goethe/presentation.html#verklaarbaarheid",
    "href": "content/talks/posts/2023-goethe/presentation.html#verklaarbaarheid",
    "title": "Betrouwbare Kunstmatige Intelligentie",
    "section": "Verklaarbaarheid",
    "text": "Verklaarbaarheid\n\n\nBetrouwbaarheid door Verklaarbaarheid:\n\nWat moeten we veranderen aan de modelinputs om de outputs te veranderen?\n\n\n\n\n\n\n\n\nAfbeelding¬†2: Kan je het katje helpen om een lieve hondje te worden?\n\n\n\n\n\n\nEen van de belangrijkste manieren om de betrouwbaarheid van KI systemen te verbeteren is door ze verklaarbaar te maken.\nDit is de focus van mijn onderzoek.\nIk richt mij in het bijzonder op een methode die ‚Äúcounterfactual explanations‚Äù heet.\nIntu√Øtief vragen we wat we moeten veranderen aan de modelinputs om de outputs te veranderen.\nBijvorbeeld zien jullie hier aan de rechte kant en model dat tussen katjes and hondjes kan onderscheiden.\nOm te begrijpen waarom het model een katje ziet, kunnen we de characteristieken van het katje veranderen en kijken hoe het model reageert.\nHier zie je hoe het katje van links oven naar rechts beneden wandelt.\nDit betekent in dit geval dat het katje zijn staartje moet inkorten en iets groter moet worden.\nEn dit is dan de verklaring."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#agenda",
    "href": "content/talks/posts/2023-progress/presentation.html#agenda",
    "title": "2nd Year Progress Meeting",
    "section": "Agenda",
    "text": "Agenda\n\nStocktaking\nReflection on the past year\nNext steps"
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#papers",
    "href": "content/talks/posts/2023-progress/presentation.html#papers",
    "title": "2nd Year Progress Meeting",
    "section": "Papers",
    "text": "Papers\nSolid progress on chapter 1 to 3 of the thesis:\n\n1 paper published and presented (SaTML: [Ch2]), 1 published in proceedings (JuliaCon: [Ch1.1]).\n1 paper submitted (ECCCo: [Ch3]).\n1 paper in preparation (LaplaceRedux.jl: [Ch1.2]), 1 about to start (ConformalPrediction.jl [Ch1.3]).\n1 paper co-authored (Conformal Intent Recognition)."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#open-source-and-science",
    "href": "content/talks/posts/2023-progress/presentation.html#open-source-and-science",
    "title": "2nd Year Progress Meeting",
    "section": "Open Source and Science",
    "text": "Open Source and Science\n\n2 new Julia packages published: ConformalPrediction.jl and JointEnergyModels.jl.\nMajor updates to CounterfactualExplanations.jl and LaplaceRedux.jl.\nFirst steps towards a unified ecosystem for Trustworthy AI in Julia: Taija.jl.\nPublished 7 blog posts.\nSome work on Quarto extensions."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#talks",
    "href": "content/talks/posts/2023-progress/presentation.html#talks",
    "title": "2nd Year Progress Meeting",
    "section": "Talks",
    "text": "Talks\nA total of 8 talks:\n\nCompanies (3): DSCC (ING), Bank of England, Verbond van Verzekeraars.\nSoftware community (2): Julia Eindhoven, JuliaCon.\nAcademia (3): SaTML, ICT.Open (demo), Mondai."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#graduate-school",
    "href": "content/talks/posts/2023-progress/presentation.html#graduate-school",
    "title": "2nd Year Progress Meeting",
    "section": "Graduate School",
    "text": "Graduate School\n\nSummer School in Barcelona (5 ECTS: discipline).\nDeep Learning in Julia study group.\nSoftware project (2nd year BSc): CounterfactualExplanations.jl (2 ECTS: research).\nSoftware project (2nd year BSc): LaplaceRedux.jl (2 ECTS: research).\nSaTML and JuliaCon (4 ECTS: research).\n\nTotal (missing): research (-2.5), discipline (5), transferable (8)"
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#other-accomplishments",
    "href": "content/talks/posts/2023-progress/presentation.html#other-accomplishments",
    "title": "2nd Year Progress Meeting",
    "section": "Other Accomplishments",
    "text": "Other Accomplishments\n\n1st Price at ING Experiment Week.\n2nd Price at JuliaCon 2023 Pluto Notebook Competition.\nFirst person at TU Delft to do serious work in Julia on a HPC cluster (as far as I know)."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#what-went-well",
    "href": "content/talks/posts/2023-progress/presentation.html#what-went-well",
    "title": "2nd Year Progress Meeting",
    "section": "What went well?",
    "text": "What went well?\n\n\nVery happy with the progress on the open-source projects.\nGenerally also happy with the progress on papers.\n\nResearch ideas are becoming more refined and interesting.\n\nI am enjoying the work and the people I am working with."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#what-could-have-gone-better",
    "href": "content/talks/posts/2023-progress/presentation.html#what-could-have-gone-better",
    "title": "2nd Year Progress Meeting",
    "section": "What could have gone better?",
    "text": "What could have gone better?\n\n\nI am struggling with the balance between research and open-source.\nI have come to realise that writing truly solid technical papers takes more time than I thought.\n\nCamera-ready version of SaTML paper took about 1 month.\nECCCo took about 2-3 additional months of work after initial submission.\n\nAt times, seriously overwhelmed, to the extent that I was genuinely concerned about my mental health for the first time in my life.\n\nNobody‚Äôs fault if not my own, but not going back to that place again."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#what-did-i-learn",
    "href": "content/talks/posts/2023-progress/presentation.html#what-did-i-learn",
    "title": "2nd Year Progress Meeting",
    "section": "What did I learn?",
    "text": "What did I learn?\n\n\nYou can‚Äôt have it all: open-source, research, outreach, teaching, physical and mental health, social life, ‚Ä¶\nI need to be more selective about what I work on.\nI need to be more realistic about what I can achieve."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#ongoing-papers",
    "href": "content/talks/posts/2023-progress/presentation.html#ongoing-papers",
    "title": "2nd Year Progress Meeting",
    "section": "Ongoing Papers",
    "text": "Ongoing Papers\n\n\nECCCo [Ch3]: only minor revisions left.\n\nEven if AAAI fails, I am finally fully confident about the results and proud of this paper.\n\nConformal Prediction [Ch1.3]: start writing.\nLaplaceRedux [Ch1.2]: turn into full paper."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#planned-papers",
    "href": "content/talks/posts/2023-progress/presentation.html#planned-papers",
    "title": "2nd Year Progress Meeting",
    "section": "Planned Papers",
    "text": "Planned Papers\n\n3rd research paper [Ch4]: What makes models explainable?\n\nInvolve students (ECCCo for trees and model-agnostic).\nCandidate venues: NeuRIPS Datasets and Benchmarks (2024/2025), journal.\n‚ñ∂Ô∏è Difficulty: relatively safe bet, but computationally expensive.\n\n4th research paper [Ch5]:\n\nThe Cost of Unfaithful Model Explanations: agent-based simulation of the impact of unfaithful model explanations on human decision-making.\nCausal ECCCo: combining ECCCo with Causal Abstraction.\n\n\n‚ñ∂Ô∏è Difficulty: both high risk, high reward."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#open-source",
    "href": "content/talks/posts/2023-progress/presentation.html#open-source",
    "title": "2nd Year Progress Meeting",
    "section": "Open Source",
    "text": "Open Source\n\nMaybe: Lightening talk on JointEnergyModels.jl at JuliaCon 2024 [Ch1.4].\nThen: ‚ÄúTaija.jl 4 years later‚Äù at JuliaCon 2025."
  },
  {
    "objectID": "content/talks/posts/2023-progress/presentation.html#time-management",
    "href": "content/talks/posts/2023-progress/presentation.html#time-management",
    "title": "2nd Year Progress Meeting",
    "section": "Time Management",
    "text": "Time Management\n\nI think it is feasible to have the following papers in (near-) final form by the end of year 3: ECCCo [Ch3], LaplaceRedux [Ch1.2], Conformal Prediction [Ch1.3], 3rd research paper [Ch4].\nAt that point, we are looking at a comprehensive thesis: 3 software papers forming the extended introduction and 3 research papers forming the core.\n4th year can then be used to:\n\nCollate chapters (thesis).\nWrite paper on JointEnergyModels.jl [potentially Ch1.4].\nTackle 4th research paper w/o pressure to publish in time [potentially Ch5].\nEnsure Taija.jl is in a good state.\nEnsure Graduate School credits are in order.\nCareer Planning.\nGoogle Summer of Code? Teaching? Research Visit? Internship? Other?"
  },
  {
    "objectID": "content/talks/index.html",
    "href": "content/talks/index.html",
    "title": "Talks",
    "section": "",
    "text": "Below you can find slides and videos of some of my talks. For a slide deck providing a high-level overview of my research see also here.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Year - Oldest\n        \n         \n          Year - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nYear\n\n\nVenue\n\n\nDescription\n\n\n\n\n\n\nDSCNext Conference Europe 2025\n\n\n2025\n\n\nAmsterdam, NL\n\n\nSlides for my oral presentation at DSCNext 2025.\n\n\n\n\nVertraubare KI durch Counterfactual Explanations\n\n\n2024\n\n\nT√úV AI.Lab (online)\n\n\nEin √úberblick √ºber unsere Forschungsergebnisse zum Thema Vertraubare K√ºnstliche Intelligenz.\n\n\n\n\nProgress meeting PhD\n\n\n2024\n\n\n¬†\n\n\nSlides for my PhD progress meeting in October 2024.\n\n\n\n\nStop Making Unscientific AGI Performance Claims\n\n\n2024\n\n\nVienna, Austria\n\n\nOur position paper Stop Making Unscientific AGI Performance Claims has been accepted at ICML 2024.\n\n\n\n\nJuliaCon 2024\n\n\n2024\n\n\nEindhoven, The Netherlands\n\n\nVarious main and lightning talks on Taija, HPC, mechanistic interpretability and Quarto.\n\n\n\n\nTrustworthy AI in Julia\n\n\n2024\n\n\nThe Alan Turing Institute, London, UK\n\n\nSlides for my presentation at the Alan Turing Institute on Trustworthy AI in Julia.\n\n\n\n\nFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals\n\n\n2024\n\n\nImperial College, London, UK\n\n\nIn May, 2024, I presented our AAAI 2024 paper at an XAI seminar at Imperial College London.\n\n\n\n\nAgainst Spurious Sparks ‚àí Dovelating Inflated AI Claims üïäÔ∏è\n\n\n2024\n\n\nECONDAT 2024, London, UK\n\n\nOur position paper Against Spurious Sparks ‚àí Dovelating Inflated AI Claims has been accepted at ICML 2024. In May 2024, I will talk about our work at the ECONDAT Conference 2024.\n\n\n\n\nFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals\n\n\n2024\n\n\nAAAI 2024, Vancouver, Canada\n\n\nSlides and poster for our AAAI 2024 paper, Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals.\n\n\n\n\nFaithful Model Explanations\n\n\n2023\n\n\nDe Nederlandsche Bank\n\n\nSlides for my presentation at the Dutch Central Bank, De Nederlandsche Bank.\n\n\n\n\nBetrouwbare Kunstmatige Intelligentie\n\n\n2023\n\n\nGoethe Instituut, Amsterdam\n\n\nMijn eerste presentatie in het Nederlands.\n\n\n\n\nJulia on HPC\n\n\n2023\n\n\nTU Delft\n\n\nSlides for a tutorial on using Julia on the DelftBlue supercomputer.\n\n\n\n\nProgress meeting PhD\n\n\n2023\n\n\n¬†\n\n\nSlides for my presentation at JuliaCon 2023.\n\n\n\n\nFaithful Model Explanations\n\n\n2023\n\n\nVerbond van Verzekeraars\n\n\nSlides for my presentation at the Delft FinTech Lab Launch.\n\n\n\n\nPredictive Uncertainty Quantification in Machine Learning\n\n\n2023\n\n\nJuliaCon 2023, MIT, Cambridge, Massachusetts\n\n\nSlides for my presentation at JuliaCon 2023.\n\n\n\n\nEchos from the Black Box\n\n\n2023\n\n\nMondai House of AI, Delft\n\n\nSlides for my presentation at the Delft FinTech Lab Launch.\n\n\n\n\nTaija - Trustworthy AI in Julia\n\n\n2023\n\n\nNWO ICT.Open 2023\n\n\nSlides for my demo at the NWO ICT.Open in April, 2023.\n\n\n\n\nEndogenous Macrodynamics in Algorithmic Recourse\n\n\n2023\n\n\nFirst IEEE Conference on Secure and Trustworthy Machine Learning\n\n\nSlides for my presentation at the first IEEE SaTML conference in February, 2023.\n\n\n\n\nA year of using Quarto with Julia\n\n\n2022\n\n\nJulia Eindhoven Meetup\n\n\nSlides for my presentation at the Julia Eindhoven Meetup in November, 2022.\n\n\n\n\nExplaining Black-Box Models through Counterfactuals\n\n\n2022\n\n\nBank of England\n\n\nSlides for my presentation at the Bank of England in November 2022.\n\n\n\n\nJuliaCon 2022\n\n\n2022\n\n\nJuliaCon 2022 (online)\n\n\nI gave three different talks at JuliaCon 2022.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/about/index.html",
    "href": "content/about/index.html",
    "title": "Patrick Altmeyer",
    "section": "",
    "text": "Biography\nResearching Trustworthy Artificial Intelligence (AI) for Finance and Economics. I am an economist by background with an interest in cross-disciplinary research on the intersection of Trustworthy AI and Financial Economics. For my PhD in Trustworthy AI, I currently focus on Counterfactual Explanations and Probabilisitic Machine Learning under supervision of Cynthia Liem and Arie van Deursen at Delft University of Technology. I am also a member of the AI for Fintech Research Lab.\nPreviously, I worked as an economist for Bank of England where I was involved in research, monetary policy briefings and market intelligence. I hold two masters degrees from Barcelona School of Economics, one in Data Science and one in Finance. I also hold an undergraduate degree in Economics from the University of Edinburgh.\nüìÑ Resume: [detailed, compact]\n\n\nContact\nYou can find me on Bluesky, LinkedIn, GitHub or reach out to me through email: patalt[at]patalt.org."
  },
  {
    "objectID": "content/software.html",
    "href": "content/software.html",
    "title": "Software",
    "section": "",
    "text": "I code mostly in Julia and lead development of the Taija package ecosystem for Trustworthy AI in Julia."
  },
  {
    "objectID": "content/software.html#activity",
    "href": "content/software.html#activity",
    "title": "Software",
    "section": "Activity",
    "text": "Activity"
  },
  {
    "objectID": "www/resume_long.html#contact",
    "href": "www/resume_long.html#contact",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Contact Info",
    "text": "Contact Info\n\n p.altmeyer@tudelft.nl\n www.patalt.org\n github.com/pat-alt\n +49 176 48726927\nFor more information, please contact me via email."
  },
  {
    "objectID": "www/resume_long.html#skills",
    "href": "www/resume_long.html#skills",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Skills",
    "text": "Skills\n\nExperienced in Machine Learning, Finance, Economics and Monetary Policy.\nHighly skilled in Julia, R, Python and Quarto.\nResearch expertise in the field of Explainable Artificial Intelligence."
  },
  {
    "objectID": "www/resume_long.html#disclaimer",
    "href": "www/resume_long.html#disclaimer",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Disclaimer",
    "text": "Disclaimer\n\nLast updated on 2024-09-26."
  },
  {
    "objectID": "www/resume_long.html#title",
    "href": "www/resume_long.html#title",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Patrick Altmeyer",
    "text": "Patrick Altmeyer\n\nResearching Trustworthy Artificial Intelligence (AI) for Finance and Economics\nI am an economist by background with an interest in cross-disciplinary research on the intersection of Trustworthy AI and Financial Economics. For my PhD in Trustworthy AI, I currently focus on Counterfactual Explanations and Probabilisitic Machine Learning under supervision of Cynthia Liem and Arie van Deursen at Delft University of Technology."
  },
  {
    "objectID": "www/resume_long.html#education",
    "href": "www/resume_long.html#education",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Education",
    "text": "Education\n\nPhD in Computer Science\nDelft University of Technology\nDelft, Netherlands\n2025 - 2021\nThesis topic: Counterfactual Reasoning and Probabilistic Methods for Trustworthy AI with Applications in Finance\n\n\nMaster in Data Science\nBarcelona School of Economics\nBarcelona, Spain\n2021\nThesis: Deep Vector Autoregression for Macroeconomic Data\n\n\nMaster in Economics and Finance\nBarcelona School of Economics\nBarcelona, Spain\n2018\nThesis: Option Pricing in the Heston Stochastic Volatility Model\n\n\nMaster of Arts with Honours in Economics\nUniversity of Edinburgh\nEdinburgh, United Kingdom\n2017\nThesis: Can misguided monetary policy explain the European housing bubble?"
  },
  {
    "objectID": "www/resume_long.html#professional-experience",
    "href": "www/resume_long.html#professional-experience",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nEconomist\nBank of England\nLondon, United Kingdom\n2021 - 2018\n\n\nCo-author of two staff working papers.\nEconometric data analysis.\nCo-initiated and led app development.\nBriefing work for policy committees.\n\n\n\n\nPostgraduate Intern\nBank of England\nLondon, United Kingdom\n2017\n\n\nEconometric analysis of transaction data set in R.\nInternal presentation of project results."
  },
  {
    "objectID": "www/resume_long.html#teaching-and-supervision",
    "href": "www/resume_long.html#teaching-and-supervision",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Teaching and Supervision",
    "text": "Teaching and Supervision\n\nGoogle Summer of Code\nProject Mentor of the Google Summer of Code program\nVirtual\n2024\n\n\nJulia Season of Contributions\nProject Mentor of Julia Season of Contributions program\nVirtual\n2024\n\n\nMaster‚Äôs Thesis Supervision\nResearch co-supervisor of various master‚Äôs students\nDelft, Netherlands\n2024 - 2023\n\n\nSoftware Project Supervision\nProject supervisor for three groups of students\nDelft, Netherlands\n2024 - 2023\n\n\nProposal of two software projects related to Trustworthy AI in Julia.\nSupervision of two groups of five undergraduate students working on the project.\n\n\n\n\nBachelor‚Äôs Thesis Supervision\nResearch supervisor for group of students\nDelft, Netherlands\n2022\n\n\nProposal of final-year research project on Endogenous Dynamics in Algorithmic Recourse.\nSupervision of group of three undergraduate students working on the project.\n\n\n\n\nFoundations of Data Science Summer School\nTeaching Assistant at Barcelona School of Economics\nBarcelona, Spain\n2021\n\n\nIntroduction course to R and Git\nLead Trainer at Analytics Enablement Hub, Bank of England.\nLondon, United Kingdom\n2020 - 2019\n\n\nHonours Modules in Econometrics\nTeaching assistant at School of Economics, University of Edinburgh\nEdinburgh, United Kingdom\n2017 - 2016"
  },
  {
    "objectID": "www/resume_long.html#selected-publications",
    "href": "www/resume_long.html#selected-publications",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Selected Publications",
    "text": "Selected Publications\n\nPosition: Stop Making Unscientific AGI Performance Claims\nProceedings of the 41st International Conference on Machine Learning: [PDF, code]\nVienna, Austria\n2024\nAltmeyer P., Demetriou A.M., Bartlett A., Liem C.C.S.\n\n\nFaithful Model Explanations through Energy-Constrained Conformal Counterfactuals\nThe 38th Annual AAAI Conference on Artificial Intelligence: [PDF, code]\nVancouver, Canada\n2024\nAltmeyer P., Farmanbar M., van Deursen A., Liem C.C.S.\n\n\nExplaining Black-Box Model through Counterfactuals\nThe Proceedings of the JuliaCon Conferences: [PDF]\nDelft, Netherlands\n2023\nAltmeyer P., van Deursen A., Liem C.C.S.\n\n\nEndogenous Macrodynamics in Algorithmic Recourse\nFirst IEEE Conference on Secure and Trustworthy Machine Learning: [PDF, code]\nRaleigh, North Carolina, United States\n2023\nAltmeyer P., Angela G., Buszydlik A., Dobiczek K., van Deursen A., Liem C.C.S.\n\n\nYield Curve Sensitivity to Investor Positioning Around Economic Shocks\nBank of England Staff Working Paper: [PDF]\nLondon, United Kingdom\n2023\nAltmeyer P., Boneva L., Kinston R., Saha S., Stoja E.\n\n\nDeep Vector Autoregression for Macroeconomic Data\nMasters Thesis (selected for publication): [PDF], [GitHub]\nBarcelona, Spain\n2021\nAgust√≠ M., Altmeyer P., Vidal-Quadras Costa I.\n\n\nOption Pricing in the Heston Stochastic Volatility Model: an Empirical Evaluation\nMasters Thesis (selected for publication): [PDF]\nBarcelona, Spain\n2018\nAltmeyer P., Grapendal J., Pravosud M., Quintana G."
  },
  {
    "objectID": "www/resume_long.html#selected-conferences-workshops-and-posters",
    "href": "www/resume_long.html#selected-conferences-workshops-and-posters",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Selected Conferences, Workshops and Posters",
    "text": "Selected Conferences, Workshops and Posters\n\nJuliaCon 2024\nMultiple talks about Taija, Quarto and more.\nEindhoven, Netherlands\n2024\n\n\nTrustworthy AI in Julia\nInvited talk at the Alan Turing Institute on Trustworthy AI in Julia.\nLondon, United Kingdom\n2024\n\n\nXAI seminar @ Imperial College London\nPresented our AAAI 2024 paper at an XAI seminar at Imperial College London.\nLondon, United Kingdom\n2024\n\n\nECONDAT 2024\nPresented Against Spurious Sparks ‚Äì Dovelating Inflated AI Claims at ECONDAT 2024 conference.\nLondon, United Kingdom\n2024\n\n\nNavigating the Interplay of Explainability and Privacy in AI\nContributed talk at workshop: Faithful Model Explanations through Energy-Constrained Conformal Counterfactuals\nDelft, Netherlands\n2024\n\n\nWorkshop at De Nederlandsche Bank\nInvited talk: Faithful Model Explanations-Central Bank Supervision in the Age of AI\nAmsterdam, Netherlands\n2023\n\n\nDatamiddag 2023: van PET tot Haring\nInvited talk: Faithful Model Explanations\nThe Hague, Netherlands\n2023\n\n\nJuliaCon 2023\nMain talk: Predictive Uncertainty Quantification in Machine Learning\nMIT in Boston, USA\n2023\n\n\nDelft FinTech Lab Launch\nInvited talk: Echos from the Black Box\nDelft, Netherlands\n2023\n\n\nFirst IEEE Conference on Secure and Trustworthy Machine Learning\nOral: Endogenous Macrodynamics in Algorithmic Recourse\nRaleigh, North Carolina\n2023\n\n\nNew Methods Seminar at the Bank of England\nInvited talk: Explaining Black-Box Models through Counterfactuals\nLondon, United Kingdom\n2022\n\n\nING Data Science Community Conference 2022\nContributed talk: Explaining Black-Box Models through Counterfactuals\nAmsterdam, Netherlands\n2022\n\n\nJuliaCon 2022\nPresented Julia packages I developed\nVirtual\n2022\n\n\nExplaining Black-Box Models through Counterfactuals (main talk)\nEffortless Bayesian Deep Learning through Laplace Redux (lightening talk)\nJulia and Quarto: A Match Made in Heaven? (experience talk)\n\n\n\n\nProbAI 2022 Summer School\nPoster presentation ‚ÄúExplainable AI: Probabilistic Methods for Counterfactual Explanations‚Äù: [poster]\nHelsinki, Finland\n2022\n\n\nTU Delft EEMCS PhD event\nPoster presentation ‚ÄúCounterfactual Explanations and Algorithmic Recourse‚Äù: [poster]\nDelft, Netherlands\n2022\n\n\nDe Nederlandse Bank Conference ‚ÄúCentral Bankers Go Data Driven: Applications of AI and ML for Policy and Prudential Supervision‚Äù\nPoster presentation of Altmeyer, Agusti, and Vidal-Quadras Costa (2021).\nAmsterdam, Netherlands\n2022\n\n\nIFC and Bank of Italy workshop on ‚ÄúData science in central banking‚Äù\nPresentation of Altmeyer, Agusti, and Vidal-Quadras Costa (2021): [event link], [YouTube]\nVirtual\n2022\n\n\nNeurIPS 2021 MLECON Workshop\nPoster presentation of Altmeyer, Agusti, and Vidal-Quadras Costa (2021): [event link]\nVirtual\n2021\n\n\nIFABS 2021 Oxford\nPresented our upcoming BoE Staff Working Paper on yield curve pricing [event link]\nVirtual\n2021\n\n\nMoney markets and Central Bank Balance Sheets\nPresented research on demand for central bank reserves at ECB: [event link]\nFrankfurt, Germany\n2019"
  },
  {
    "objectID": "www/resume_long.html#selected-open-source-software",
    "href": "www/resume_long.html#selected-open-source-software",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Selected Open-Source Software",
    "text": "Selected Open-Source Software\n\nConformalPrediction.jl\nJulia package for Conformal Prediction: [docs], [GitHub]\nN/A\n2022-2024\n\n\nCounterfactualExplanations.jl\nJulia package for Counterfactual Explanations: [docs], [GitHub]\nN/A\n2021-2024\n\n\nLaplaceRedux.jl\nJulia package for effortless Bayesian Deep Learning: [docs], [GitHub]\nN/A\n2021-2024\n\n\ndeepvars\nR package implementing Deep Vector Autoregression (Altmeyer, Agusti, and Vidal-Quadras Costa 2021): [GitHub]\nN/A\n2021-2022"
  },
  {
    "objectID": "www/resume_long.html#outreach-and-volunteering",
    "href": "www/resume_long.html#outreach-and-volunteering",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Outreach and Volunteering",
    "text": "Outreach and Volunteering\n\nPersonal blog\nCommunication AI in an accessible, visual manner: [url]\nN/A\n2022 - 2021\n\n\nClass representative\nMasters in Data Science\nBarcelona, Spain\n2020\n\n\nTEDx talk\nHeld a TEDx talk about European Integration: [YouTube]\nEdinburgh, United Kingdom\n2016"
  },
  {
    "objectID": "www/resume_long.html#scholarships-and-awards",
    "href": "www/resume_long.html#scholarships-and-awards",
    "title": "Patrick Altmeyer‚Äôs resume",
    "section": "Scholarships and awards",
    "text": "Scholarships and awards\n\nPluto Notebook Competition for JuliaCon2023\n2nd Price Winner\nMIT in Boston, USA\n2023\n\n\nNovartis Datathon\n3rd Price Winner of Datathon\nBarcelona, Spain\n2020\n\n\nFee Waiver and Funding for Masters\nFull funding for Masters in Data Science through BSE and Bank of England\nBarcelona, Spain\n2020\n\n\nFee waiver for Masters\nTotal tuition fee waiver for Master in Finance through BSE\nBarcelona, Spain\n2017\n\n\nSchool of Economics Prize\nEdinburgh University School of Economics Joint Prize for the best performance in Economics\nEdinburgh, United Kingdom\n2017\n\n\nSchool of Economics Prize\nSchool of Economics Prize for academic excellence in Economics\nEdinburgh, United Kingdom\n2015"
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html",
    "title": "How I‚Äôm building this website in R",
    "section": "",
    "text": "Note\n\n\n\nUpdate on Feb 20, 2022\nThe post below was written when I still used blogdown in combination with Hugo to build this blog. I have recently migrated the blog (along pretty much everything else I do) to quarto.\n\nQuarto¬Æ is an open-source scientific and technical publishing system built on Pandoc.\n\nBased on my first few experiences I would go further and say that quarto is the only open-source scientific and technical publishing system you‚Äôll ever need. The project is supported by RStudio and (unsurprisingly) Yihui Xie is one of the contributors. Go check it out!"
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#getting-started",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#getting-started",
    "title": "How I‚Äôm building this website in R",
    "section": "Getting started",
    "text": "Getting started\nIt turns out building a static website in R is remarkably easy, as long as you know your way around R Markdown. Knowledge of HTML and CSS helps, but is not strictly necessary and can be acquired along the way. My package of choice for this website is blogdown by Yihui Xie who has had a major impact on the R community through his many package contributions (knitr, bookdown, pagedown, ‚Ä¶) and certainly made my life a lot easier on many occasions.\nTo get started just follow the instructions on blogdown‚Äôs GitHub repository or keep reading here for a high-level overview. Setting up a basic website in R requires exactly two steps:\n\nSet up a local directory for the website. Let‚Äôs suppose you create it here ~/Documents/myAwesomeWebsite.\nIn R, navigate to the directory and simply run blogdown::newsite().\n\nThis will set up a basic template which you can develop. Changing the theme and playing with the basic structure of the website is relatively straight-forward. Personally I have so far managed to work things out based on a working knowledge of HTML and CSS that I‚Äôve developed in the past through my work with R Shiny."
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#deploying-your-website",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#deploying-your-website",
    "title": "How I‚Äôm building this website in R",
    "section": "Deploying your website",
    "text": "Deploying your website\nThere are various ways to deploy your website, i.e.¬†make it accessible to the public. This website is deployed through GitHub pages. Detailed instructions on how to do this can be found here. Since I already had an existing local clone of my pat-alt.github.io repo, I just dropped it in the source directory of the website:\nsource/\n‚îÇ\n‚îú‚îÄ‚îÄ config.yaml\n‚îú‚îÄ‚îÄ content/\n‚îú‚îÄ‚îÄ themes/\n‚îî‚îÄ‚îÄ ...\n\npatalt.github.io/\n‚îÇ\n‚îú‚îÄ‚îÄ .git/\n‚îú‚îÄ‚îÄ .nojekyll\n‚îú‚îÄ‚îÄ index.html\n‚îú‚îÄ‚îÄ about/\n‚îî‚îÄ‚îÄ ...\nAfter adding publishDir: pat-alt.github.io to my config.yaml and then running blogdown::hugo_build() the website was built inside the clone. All that was left to do was to commit changes from the local clone to the pat-alt.github.io remote repo. A few moments later the website was already up and running."
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#why-all-the-trouble",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#why-all-the-trouble",
    "title": "How I‚Äôm building this website in R",
    "section": "Why all the trouble?",
    "text": "Why all the trouble?\nThere are certainly easier ways to build a website. But if like me you do pretty much all your work in R Markdown and want to share some of it, then you will love blogdown. The beauty of it is that once the basic infrastructure is set up, adding content is as simple as running the following wrapper function\n\n\nCode\nblogdown::new_post(\"Your new post\", ext = \".Rmd\")\n\n\nwhere the first argument is just the title of your post and the ext argument can be used to specify that you want to create an R Markdown document that can include code chucks. The wrapper function will automatically set up a directory for your post under /post/. R Studio will redirect you to the relevant .Rmd file that you can then fill with content. By default that folder will look roughly like this:\n‚îú‚îÄ‚îÄ index.Rmd\n‚îú‚îÄ‚îÄ index.html\n‚îî‚îÄ‚îÄ index_files\n    ‚îî‚îÄ‚îÄ header-attrs\n        ‚îî‚îÄ‚îÄ header-attrs.js"
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#a-simple-coding-example",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#a-simple-coding-example",
    "title": "How I‚Äôm building this website in R",
    "section": "A simple coding example",
    "text": "A simple coding example\nAs you can probably tell from the code chunks above this post was created just in the way I described. So I thought I might as well go ahead with a simple coding example to add some flavour. Suppose you have built some function that you think is worth sharing with the world or simply learned something new and interesting. As a case in point, I recently had a look at the Rcpp package and wrote a small program in C++ to be used in R. Since R Markdown supports Rcpp code chunks (along with Python, bash, SQL, ‚Ä¶) it is straight-forward to show-case that code on this website.\nThe program can be used to simulate data from a categorical distribution. This distribution describes the possible results of a random variable that can take on one of \\(K\\) possible categories with different probabilities. In base R we could use rmultinom(n=1000,1,p=c(0.5,0.1,0.4)) to simulate draws from one such distribution with three different categories. Alternatively, we could write the program in C++ as follows:\n\n\nCode\n#include &lt;Rcpp.h&gt;\nusing namespace Rcpp;\n\n// [[Rcpp::export]]\nNumericMatrix simCategorical(int n, NumericVector p) {\n  int k = p.size();\n  NumericMatrix mat(k, n);\n  // Normalise prob if necessary:\n  if (sum(p)!=1) {\n    p = p/sum(p);\n  }\n  NumericVector emp_cdf = cumsum(p);\n  NumericVector u = Rcpp::runif(n, 0, 1);\n  // Matrix for 1-hot-encoding:\n  for (int j = 0; j &lt; n; j++) {\n    // Perform binary search:\n    int l = 0;\n    int r = k;\n    double target = u[j];\n    while (l &lt; r) {\n      int m = floor((l+r)/2);\n      if (emp_cdf[m] &gt; target) {\n        r = m;\n      } else {\n        l = m+1;\n      }\n    }\n    mat(r,j) = 1;\n  }\n  return mat;\n}\n\n\nIn terms of performance it turns out that the simple C++ program actually does somewhat better than the base R alternative:\n\n\nCode\nlibrary(microbenchmark)\nlibrary(ggplot2)\nn &lt;- 1000\np &lt;- c(0.5,0.1,0.4)\nmb &lt;- microbenchmark(\n    \"rmultinom\" = {rmultinom(n, 1, p)},\n    \"Rcpp\" = {simCategorical(n, p)}\n)\nautoplot(mb)"
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#embedding-existing-work",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#embedding-existing-work",
    "title": "How I‚Äôm building this website in R",
    "section": "Embedding existing work",
    "text": "Embedding existing work\nIf you have some existing work that you would like to share you can just use it to overwrite the index.Rmd file. blogdown supports any kind of R Markdown documents so you can use all of your favourite markdown packages (bookdown, pagedown, ‚Ä¶). Just make sure to specify HTML output in the YAML header."
  },
  {
    "objectID": "blog/posts/how-i-m-building-this-website-in-r/index.html#resources",
    "href": "blog/posts/how-i-m-building-this-website-in-r/index.html#resources",
    "title": "How I‚Äôm building this website in R",
    "section": "Resources",
    "text": "Resources\nFor more information about blogdown see here. To inspect the code that builds this website check out my GitHub repository."
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html",
    "title": "Individual recourse for Black Box Models",
    "section": "",
    "text": "In her popular book Weapons of Math Destruction Cathy O‚ÄôNeil presents the example of public school teacher Sarah Wysocki, who lost her job after a teacher evaluation algorithm had rendered her redundant (O‚ÄôNeil 2016). Sarah was highly popular among her peers, supervisors and students.\nThis post looks at a novel algorithmic solution to the problem that individuals like Sarah, who are faced with an undesirable outcome, should be provided with means to revise that outcome. The literature commonly refers to this as individual recourse. One of the first approaches towards individual recourse was proposed by Ustun, Spangher, and Liu (2019). In a recent follow-up paper, Joshi et al. (2019) propose a methodology coined REVISE, which extends the earlier approach in at least three key ways:\nFor a detailed discussion of these points you may check out this slide deck or consult the paper directly (freely available on DeepAI). Here, we will abstract from some of these complications and instead look at an application of a slightly simplified version of REVISE. This should help us to first build a good intuition. Readers interested in the technicalities and code may find all of this in the annex below."
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html#from-to",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html#from-to",
    "title": "Individual recourse for Black Box Models",
    "section": "From üê± to üê∂",
    "text": "From üê± to üê∂\nWe will explain REVISE through a short tale of cats and dogs. The protagonist of this tale is Kitty üê±, a young cat that identifies as a dog. Unfortunately, Kitty is not very tall and her tail, though short for a cat, is longer than that of the average dog (Figure¬†1).\n\n\n\n\n\n\nFigure¬†1: Empirical distributions of simulated data set describing cats and dogs. Vertical stalks represent Kitty‚Äôs attribute values.\n\n\n\nMuch to her dismay, Kitty has been recognized as a cat by a linear classifier \\(g_n(X)\\) that we trained through stochastic gradient descent using the data on animals‚Äô height and tail length. Once again interested readers may find technical details and code in the annex below. Figure¬†2 shows the resulting linear separation in the attribute space with the decision boundary in solid black and Kitty‚Äôs location indicated by a red circle. Can we provide individual recourse to Kitty?\n\n\n\n\n\n\nFigure¬†2: Linear separation of cats and dogs in the 2-dimensional attribute space with the decision boundary of the fitted classifier in solid black. Kitty‚Äôs location is indicated by a red circle.\n\n\n\nLet‚Äôs see if and how we can apply REVISE to Kitty‚Äôs problem. The following summary should give you some flavour of how the algorithm works:\n\nInitialize \\(\\mathbf{x}_i'^{(0)}\\), that is the attributes that will be revised recursively. Kitty‚Äôs original attributes seem like a reasonable place to start.\nThrough gradient descent recursively revise \\(\\mathbf{x}_i'^{(t)}\\) until \\(g_n(\\mathbf{x}_i'^{(T)})=\\)üê∂. At this point \\(T\\) the descent terminates since for these revised attributes the classifier labels Kitty as a dog.\nReturn \\(\\delta_i=\\mathbf{x}_i'^{(T)}-\\mathbf{x}_i\\), that is the individual recourse for Kitty.\n\nFigure¬†3 illustrates what happens when this approach is applied to Kitty‚Äôs problem. The different panels show the results for different values of a regularization parameter \\(\\lambda\\) that governs the trade-off between achieving the desired label switch and keeping the distance between the original (\\(\\mathbf{x}_i\\)) and revised (\\(\\mathbf{x}_i'\\)) attributes small. In all but one case, REVISE converges: a decrease in tail length along with an increase in height eventually allows Kitty to cross the decision boundary. In other words, we have successfully turned Kitty into a dog - at least in the eyes of the linear classifier!\nWe also observe that as we increase \\(\\lambda\\) for a fixed learning rate, REVISE takes longer to converge. This should come as no surprise, since higher values of \\(\\lambda\\) lead to greater regularization with respect to the penalty we place on the distance that Kitty has to travel. When we penalize too much (\\(\\lambda=10\\)), Kitty never reaches the decision boundary, because she is reluctant to change her characteristics beyond a certain point. While not visible to the naked eye, in this particular example \\(\\lambda=0.001\\) corresponds to the best choice among the candidate values.\n\n\n\n\n\n\nFigure¬†3: The simplified REVISE algorithm in action: how Kitty crosses the decision boundary by changing her attributes. Regularization with respect to the distance penalty increases from top left to bottom right."
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html#discussion",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html#discussion",
    "title": "Individual recourse for Black Box Models",
    "section": "Discussion",
    "text": "Discussion\nWhile hopefully Kitty‚Äôs journey has provided you with some useful intuition, the story is of course very silly. Even if your cat ever seems to signal that she wants to be a dog, helping her cross that decision boundary will be tricky. Some attributes are simply immutable or very difficult to change, which Joshi et al. (2019) do not fail to account for in their framework. Their proposed methodology offers a simple and ingenious approach towards providing individual recourse. Instead of concerning ourselves with Black Box interpretability, why not simply provide remedy in case things go wrong?\nTo some extent that idea has its merit. As this post has hopefully shown, REVISE is straight-forward to understand and readily applicable. It could be a very useful tool to provide individual recourse in many real-world applications. As the implementation of our simplified version of REVISE demonstrates, researchers should also find it relatively easy to develop the methodology further and tailor it to specific use cases. The simpler version here, for example, may be useful in settings where the dimensionality is relatively small and one can reasonably model the distribution of attributes without the need for generative models.\nStill, you may be wondering: if the original classifier is based on poorly defined rules and proxies, then what good does REVISE really do? Going back to the example of high-school teacher Sarah Wysocki, one of the key attributes determining teachers‚Äô evaluations was their students‚Äô performance. Realizing this, some teachers took the shortest route to success by artificially inflating their students‚Äô test scores. That same course of action may well have been suggested by REVISE. As Joshi et al. (2019) demonstrate, this very property of REVISE may actually proof useful in detecting weaknesses of decision making systems before setting them loose (key contribution 3).\nNonetheless, the example above also demonstrates that approaches like REVISE, useful as they may be, tend to provide solutions for very particular problems. In reality data-driven decision making systems are often subject to many different problems and hence research on trustworthy AI will need to tackle the issue from various angles. A few places to start include the question of dealing with data that is inherently biased, improving ad-hoc and post-hoc model interpretability and continuing efforts around causality-inspired AI."
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html#references",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html#references",
    "title": "Individual recourse for Black Box Models",
    "section": "References",
    "text": "References\n\n\nJoshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. ‚ÄúTowards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems.‚Äù https://arxiv.org/abs/1907.09615.\n\n\nO‚ÄôNeil, Cathy. 2016. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown.\n\n\nUstun, Berk, Alexander Spangher, and Yang Liu. 2019. ‚ÄúActionable Recourse in Linear Classification.‚Äù In Proceedings of the Conference on Fairness, Accountability, and Transparency, 10‚Äì19. https://doi.org/10.1145/3287560.3287566."
  },
  {
    "objectID": "blog/posts/individual-recourse-for-black-box-models/index.html#annex",
    "href": "blog/posts/individual-recourse-for-black-box-models/index.html#annex",
    "title": "Individual recourse for Black Box Models",
    "section": "Annex",
    "text": "Annex\nIn my blog posts I aim to implement interesting ideas from scratch even if that sometimes means that things need to undergo some sort of simplification. The benefit of this approach is that the experience is educationally rewarding - both for myself and hopefully also for readers. The first two sections of this annex show how REVISE and linear classification can be implemented in R. The final section just shows how the synthetic data was generated. To also inspect the code that generates the visualizations and everything else, you can find the source code of this file on GitHub.\n\nLinear classifier\nLinear classification is implemented through stochastic gradient descent (SGD) with Hinge loss\n\\[\n\\begin{aligned}\n&& \\ell(-\\mathbf{w}^T\\mathbf{x}_i y_i)&=(1-\\mathbf{w}^T\\mathbf{x}_i y_i)_+ \\\\\n\\end{aligned}\n\\]\nwhere \\(\\mathbf{w}\\) is a coefficient vector, \\(\\mathbf{x}_i\\) is the attribute vector of individual \\(i\\) and \\(y_i\\) is the individual‚Äôs outcome. Since we apply SGD in order to minimize the loss function \\(\\ell\\) by varying \\(\\mathbf{w}\\), we need an expression for its gradient with respect to \\(\\mathbf{w}\\), which is given by:\n\\[\n\\begin{equation}\n\\begin{aligned}\n&& \\nabla_{\\mathbf{W}} \\left( \\ell(-\\mathbf{w}^T\\mathbf{x}_i y_i) \\right) &= \\begin{cases} -\\mathbf{x}_i y_i & \\text{if} \\ \\ \\ \\mathbf{w}^T\\mathbf{x}_i y_i \\le 1\\\\ 0 & \\text{otherwise} \\end{cases} \\\\\n\\end{aligned}\n\\end{equation}\n\\tag{1}\\]\nThe code below uses this analytical solution to perform SGD over \\(T\\) iterations or as long as updates yield feasible parameter values. As the final vector of coefficients the function returns \\(\\mathbf{\\bar{w}}= \\frac{1}{T} \\sum_{t=1}^{T} \\mathbf{w}_t\\). Denoting the optimal coefficient vector as \\(\\mathbf{w}^*\\), it can be shown that under certain conditions \\(\\ell(\\mathbf{\\bar{w}})\\rightarrow\\ell(\\mathbf{w}^*)\\) as \\(T\\rightarrow\\infty\\).\n\n\nCode\n#' Stochastic gradient descent\n#'\n#' @param X Feature matrix.\n#' @param y Vector containing training labels.\n#' @param eta Learning rate.\n#' @param n_iter Maximum number of iterations.\n#' @param w_init Initial parameter values.\n#' @param save_steps Boolean checking if coefficients should be saved at each step.\n#'\n#' @return\n#' @export\n#'\n#' @author Patrick Altmeyer\nlinear_classifier &lt;- function(X,y,eta=0.001,n_iter=1000,w_init=NULL,save_steps=FALSE) {\n  # Initialization: ----\n  n &lt;- nrow(X) # number of observations\n  d &lt;- ncol(X) # number of dimensions\n  if (is.null(w_init)) {\n    w &lt;- matrix(rep(0,d)) # initialize coefficients as zero...\n  } else {\n    w &lt;- matrix(w_init) # ...unless initial values have been provided.\n  }\n  w_avg &lt;- 1/n_iter * w # initialize average coefficients\n  iter &lt;- 1 # iteration count\n  if (save_steps) {\n    steps &lt;- data.table(iter=0, w=c(w), d=1:d) # if desired, save coefficient at each step\n  } else {\n    steps &lt;- NA\n  }\n  feasible_w &lt;- TRUE # to check if coefficients are finite, non-nan, ...\n  # Surrogate loss:\n  l &lt;- function(X,y,w) {\n    x &lt;- (-1) * crossprod(X,w) * y\n    pmax(0,1 + x) # Hinge loss\n  }\n  grad &lt;- function(X,y,w) {\n    X %*% ifelse(crossprod(X,w) * y&lt;=1,-y,0) # Gradient of Hinge loss\n  }\n  # Stochastic gradient descent: ----\n  while (feasible_w & iter&lt;n_iter) {\n    t &lt;- sample(1:n,1) # random draw\n    X_t &lt;- matrix(X[t,])\n    y_t &lt;- matrix(y[t])\n    v_t &lt;- grad(X_t,y_t,w) # compute estimate of gradient\n    # Update:\n    w &lt;- w - eta * v_t # update coefficient vector\n    feasible_w &lt;- all(sapply(w, function(i) !is.na(i) & is.finite(i))) # check if feasible\n    if (feasible_w) {\n      w_avg &lt;- w_avg + 1/n_iter * w # update average\n    }\n    if (save_steps) {\n      steps &lt;- rbind(steps, data.table(iter=iter, w=c(w), d=1:d))\n    }\n    iter &lt;- iter + 1 # increase counter\n  }\n  # Output: ----\n  output &lt;- list(\n    X = X,\n    y = matrix(y),\n    coefficients = w_avg,\n    eta = eta,\n    n_iter = n_iter,\n    steps = steps\n  )\n  class(output) &lt;- \"classifier\" # assign S3 class\n  return(output)\n}\n\n# Methods: ----\nprint.classifier &lt;- function(classifier) {\n  print(\"Coefficients:\")\n  print(classifier$coefficients)\n}\nprint &lt;- function(classifier) {\n  UseMethod(\"print\")\n}\n\npredict.classifier &lt;- function(classifier, newdata=NULL, discrete=TRUE) {\n  if (!is.null(newdata)) {\n    fitted &lt;- newdata %*% classifier$coefficients # out-of-sampple prediction\n  } else {\n    fitted &lt;- classifier$X %*% classifier$coefficients # in-sample fit\n  }\n  if (discrete) {\n    fitted &lt;- sign(fitted) # map to {-1,1}\n  }\n  return(fitted)\n}\npredict &lt;- function(classifier, newdata=NULL, discrete=TRUE) {\n  UseMethod(\"predict\")\n}\n\n\n\n\nREVISE (simplified)\nAs flagged above, we are looking at a slightly simplified version of the algorithm presented in Joshi et al. (2019). In particular, the approach here does not incorporate the threshold on the likelihood nor does it account for immutable attributes.\nLet \\(y\\in\\{-1,1\\}\\) be a binary outcome variable, \\(X\\in\\mathbb{R}^d\\) a feature matrix containing individuals‚Äô attributes and \\(g_n(X)\\) a corresponding data-dependent classifier. Suppose \\(y_i=-1\\) (the negative outcome) for some individual characterized by attributes \\(\\mathbf{x}_i\\). Then we want to find \\(\\mathbf{x}_i'\\) closest to \\(\\mathbf{x}_i\\) such that the classifier assigns the positive outcome \\(g(\\mathbf{x}_i^{'})=1\\). In order to do so, we use gradient descent with Hinge loss \\(\\ell\\) to minimize the following function\n\\[\n\\begin{aligned}\n&& \\min_{\\mathbf{x}_i^{'}}& \\ \\ell(g_n(\\mathbf{x}_i^{'}),1) + \\lambda d(\\mathbf{x}_i^{'},\\mathbf{x}_i) \\\\\n\\end{aligned}\n\\]\nwhere \\(d=||\\mathbf{x}_i^{'}-\\mathbf{x}_i||\\) denotes the Euclidean distance. Note that this time we take the coefficient vector defining \\(g_n\\) as given and instead vary the attributes. In particular, we will perform gradient descent steps as follows\n\\[\n\\begin{aligned}\n&& {\\mathbf{x}_i^{'}}^t&\\leftarrow {\\mathbf{x}_i^{'}}^{t-1} + \\eta \\nabla_{{\\mathbf{x}_i^{'}}} \\left( \\ell(g_n(\\mathbf{x}_i^{'}),1) + \\lambda d(\\mathbf{x}_i^{'},\\mathbf{x}_i)  \\right)  \\\\\n\\end{aligned}\n\\]\nwhere \\(\\eta\\) is the learning rate. The descent step is almost equivalent to the one described in Joshi et al. (2019), but here we greatly simplify things by optimizing directly in the attribute space instead of a latent space. The gradient of the loss function looks very similar to Equation¬†1. With respect to the Euclidean distance partial derivatives are of the following form:\n\\[\n\\begin{aligned}\n&&  \\frac{\\partial ||\\mathbf{x}_i^{'}-\\mathbf{x}_i||}{\\partial {x_i'}^{(d)}}  &= \\frac{{x_i'}^{(d)}-{x_i}^{(d)}}{||\\mathbf{x}_i^{'}-\\mathbf{x}_i||} \\\\\n\\end{aligned}\n\\]\nThe code that implements this optimization follows below.\n\n\nCode\n#' REVISE algoritm - a simplified version\n#'\n#' @param classifier The fitted classifier.\n#' @param x_star Attributes of individual seeking individual recourse.\n#' @param eta Learning rate.\n#' @param lambda Regularization parameter.\n#' @param n_iter Maximum number of operations.\n#' @param save_steps Boolean indicating if intermediate steps should be saved.\n#'\n#' @return\n#' @export\n#'\n#' @author Patrick Altmeyer\nrevise.classifier &lt;- function(classifier,x_star,eta=1,lambda=0.01,n_iter=1000,save_steps=FALSE) {\n  # Initialization: ----\n  d &lt;- length(x_star) # number of dimensions\n  if (!is.null(names(x_star))) {\n    d_names &lt;- names(x_star) # names of attributes, if provided\n  } else {\n    d_names &lt;- sprintf(\"X%i\", 1:d)\n  }\n  w &lt;- classifier$coefficients # coefficient vector\n  x &lt;- x_star # initialization of revised attributes\n  distance &lt;- 0 # initial distance from starting point\n  converged &lt;- predict(classifier, newdata = x)[1,1]==1 # positive outcome?\n  iter &lt;- 1 # counter\n  if (save_steps) {\n    steps &lt;- data.table(iter=1, x=x, d=d_names) # save intermediate steps, if desired\n  } else {\n    steps &lt;- NA\n  }\n  # Gradients:\n  grad &lt;- function(x,y,w) {\n    w %*% ifelse(crossprod(x,w) * y&lt;=1,-y,0) # gradient of Hinge loss with respect to X\n  }\n  grad_dist &lt;- function(x,x_star) {\n    d &lt;- length(x_star)\n    distance &lt;- dist(matrix(cbind(x_star,x),nrow=d,byrow = T))\n    matrix((x-x_star) / distance) # gradient of Euclidean distance with respect to X\n  }\n  # Gradient descent: ----\n  while(!converged & iter&lt;n_iter) {\n    if (distance!=0) {\n      x &lt;- c(x - eta * (grad(x=matrix(x),y=1,w) + lambda * grad_dist(x,x_star))) # gradient descent step\n    } else {\n      x &lt;- c(x - eta * grad(x=matrix(x),y=1,w)) # gradient with respect to distance not defined at zero\n    }\n    converged &lt;- predict(classifier, newdata = x)[1,1]==1 # positive outcome?\n    iter &lt;- iter + 1 # update counter\n    if (save_steps) {\n      steps &lt;- rbind(steps, data.table(iter=iter, x=x, d=d_names))\n    }\n    distance &lt;- dist(matrix(cbind(x_star,x),nrow=d,byrow = T)) # update distance\n  }\n  # Output: ----\n  if (converged) {\n    revise &lt;- x - x_star\n  } else {\n    revise &lt;- NA\n  }\n  output &lt;- list(\n    x_star = x_star,\n    revise = revise,\n    classifier = classifier,\n    steps = steps,\n    lambda = lambda,\n    distance = distance,\n    mean_distance = mean(abs(revise))\n  )\n  return(output)\n}\n\nrevise &lt;- function(classifier,x_star,eta=1,lambda=0.01,n_iter=1000,save_steps=FALSE) {\n  UseMethod(\"revise\")\n}\n\n\n\n\nSimulated data\nThe synthetic data describing cats and dogs was generated as follows:\n\n\nCode\nsim_data &lt;- function(n=100,averages,noise=0.1) {\n  d &lt;- ncol(averages)\n  y &lt;- 2*(rbinom(n,1,0.5)-0.5) # generate binary outcome: 1=dog, -1=cat\n  X &lt;- as.matrix(averages[(y+1)/2+1,]) # generate attributes conditional on y\n  dogs &lt;- y==1 # boolean index for dogs\n  cats &lt;- y==-1 # boolean index for cats\n  X[cats,] &lt;- X[cats,] + \n    matrix(rnorm(sum(cats)*d),nrow=sum(cats)) %*% diag(noise*averages[2,]) # add noise for y=1 (cats)\n  X[dogs,] &lt;- X[dogs,] + \n    matrix(rnorm(sum(dogs)*d),nrow=sum(dogs)) %*% diag(noise*averages[2,]) # add noise for y=1 (dogs)\n  return(list(X=X,y=y))\n}"
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html",
    "title": "Stuck in the Past",
    "section": "",
    "text": "Photo by Sergiu VƒÉlena»ô on Unsplash\nI‚Äôm officially a third-year PhD student folks! One of my favorite aspects of being a PhD is freedom: the freedom to explore, the freedom to learn, the freedom to create, and, last but not least, the freedom to choose the tools I want to use along the way. On this blog, I have repeatedly advocated for Quarto, my preferred tool for scientific publishing: it is open-source, straightforward to use, backed by an incredibly strong and responsive development team, works well with Julia‚Äîsee my previous posts here and here‚Äîand is highly customizable‚Äîsee my post on extensions.\nOne of my least favorite aspects of being a PhD is the old-fashioned way of publishing scientific papers. Having to deal with clunky LaTeX templates when all I want to do is write up my research is the bane of my existence. It makes me dread the writing process because I know that every time I‚Äôm forced to peek inside the LaTeX compiler log, my eyes will bleed. It shouldn‚Äôt be this way! I want to be able to look forward to writing. It should be the part where you finally get to reap the rewards for the hard work you put into your project. A creative process that allows you to communicate your findings in an engaging manner. Ideas should just be allowed to flow out freely, uninterrupted by frustration about formatting issues.\nThis frustration is amplified by the fact that I‚Äôm so painfully aware of the fact that there are better ways to do this. We have the technology to make the process of scientific publishing so much more enjoyable, efficient, engaging, accessible and reproducible. We also generally seem to agree that science can be much more effectively communicated through modern-day forms of media that involve animated or even interactive content. But for some reason, the academic community still insists on good old-fashioned PDFs as its gold standard for scientific publishing and communication, often enough locked behind paywalls. No wonder that the general public feels disconnected from academia."
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html#legacy-systems",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html#legacy-systems",
    "title": "Stuck in the Past",
    "section": "üìú Legacy Systems",
    "text": "üìú Legacy Systems\nScientists pride themselves in the fact that they are continuously pushing the boundaries of human knowledge, overturning old theories and replacing them with new ones. No idea is ever too good to be challenged. The better the idea, the more challenge it is likely going to attract. The scientific method, in its ideal form, is a transparent process of continuous refinement and creative destruction. And yet we treat our main scientific output, the research paper, as a static artifact: write it up, have it peer-reviewed, publish it, pad yourself on the back‚Äîyour work is now set in stone, the stamp of approval has been obtained, move on to the next one!\n\n‚ÄúTreating research outputs as static artifacts is fundamentally at odds with the dynamic nature of science.‚Äù\n\nI have a real issue with this approach and think that treating research outputs as static artifacts is fundamentally at odds with the dynamic nature of science. It incentivizes us to focus on quantity over quality. A static artifact creates the illusion of a finished product, which is not what science is about. It is about the process of discovery, not the end result. Even though we treat papers as if they were end results, they are really just interim results: the current version of knowledge.\nWait ‚Ä¶ did I say version? Don‚Äôt we have a well-established system for managing versions of digital knowledge artifacts? Yes, we do! It‚Äôs called version control and it is the backbone of modern software development. It allows us to keep track of changes to a digital artifact over time, to collaborate with others on the same artifact, and to easily revert to previous versions if necessary. It is a powerful tool that has revolutionized the way we develop software.\n\n‚ÄúReward researchers for the quality of their total contributions to the scientific community, not for the number of first-author papers they publish.‚Äù\n\nIf academia took the paradigm of continuous and transparent improvement seriously, it would treat research outputs like open-source software. It would use version control to keep track of changes to research outputs over time and create an environment that fosters open collaboration. It would not reward researchers for the number of first-author papers they publish but for the quality of their total contributions to the scientific community. Peer review would be a continuous process, not a one-off event. Peer review could come in many forms: from a simple comment on a GitHub issue to a full-blown pull request.\nMy dear colleagues and supervisors at TU Delft have recently published a position paper that argues for exactly this approach (Liem and Demetriou 2023). It is a well-written and thought-provoking piece that I hope will inspire many to rethink the way we do science. Among the things Liem and Demetriou (2023) point out is that there are clear parallels between the state of free and open-source software (FOSS) today and the goals of the open science movement. The current state of FOSS is characterized by the following:\n\n‚ÄúWhere in terms of ownership, public open-source repositories may have an active team of maintainers and owners of an artifact, other people not in these groups are explicitly welcome to raise issues or feature requests if they see points for improvement, and implement and suggest contributions themselves, that the maintainers and owners may choose to incorporate.‚Äù\n‚Äî Liem and Demetriou (2023)\n\nWhich is exactly what we should be doing in science:\n\n‚ÄúSimilarly, in scientific insight, a core team may work on a particular project, but other researchers and interested parties may suggest changes or improvements that could be incorporated with visible provenance.‚Äù\n‚Äî Liem and Demetriou (2023)\n\nTo get to that point, it seems obvious that we need to stop treating static papers as our gold standard. We need to start treating our research outputs as what they really are: interim results of a continuous process of discovery. We need to start treating them like software."
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html#signs-of-a-brighter-future",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html#signs-of-a-brighter-future",
    "title": "Stuck in the Past",
    "section": "üîÜ Signs of a Brighter Future",
    "text": "üîÜ Signs of a Brighter Future\nThis has been a bit of a rant so far and I‚Äôm not quite done yet. Some of you may be wondering what all the fuss is about. You may think that ‚Äòpublishing through LaTeX and PDF is just what we do; it‚Äôs a proven and reliable system; been there, done that; so why should we fix something that isn‚Äôt broken?‚Äô You might personally prefer engaging with research that is printed out on paper and the LaTeX compiler log doesn‚Äôt even scare you anymore. Perhaps all of this debate so far has simply been below your h-index. In that case, please don‚Äôt feel like you have to stick around! But if you‚Äôre still here reading this, then let me now show you some signs of a brave new world of scientific publishing that is already emerging.\n\nQuarto Journal Extensions\nQuarto journal extensions are the first sign of a brighter future. They allow you to write your paper in Quarto and then render it to a PDF that complies with some journal‚Äôs LaTeX template. This is a huge step forward because it allows you to focus on the content of your paper and not on the formatting. It also allows you to use the same document to render a PDF for submission to the journal and an HTML version for your website. This is a great way to make your work more accessible to the general public.\nThe current list of available journal extensions is admittedly still short. But the list is growing, partially due to the immense efforts of the Quarto team, and partially due to the fact that it is relatively straightforward to create your own journal extension (another hat tip to the dev team). While not everyone has the time and resources to create their own journal extension for every venue they submit to, I encourage you to give it a try. The dev team is very responsive and will help you along the way. Future generations of researchers will thank you for it!\n\n\nPeer Review meets Version Control\nAnother sign of a brighter future is the emergence of publication processes that combine peer review with version control. The Journal of Open Source Software (JOSS) is a great example of this. JOSS is a free and open-access journal that publishes research software packages. It uses GitHub as its platform for peer review and version control. While I have personally never submitted to JOSS, I have submitted my work to JuliaCon Proceedings, which follows a very similar process. This year, we published our first paper on CounterfactualExplanations.jl (Altmeyer, Deursen, and Liem 2023). The review process was refreshingly transparent and collaborative. I was able to engage with reviewers and editors directly on GitHub and paper revisions were automatically rerendered through a bot. Since most of us, especially in the computational sciences, are already using GitHub or GitLab for version control, this approach seems like a no-brainer to me and I am somewhat puzzled that it hasn‚Äôt been adopted more widely yet."
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html#embracing-change",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html#embracing-change",
    "title": "Stuck in the Past",
    "section": "ü§ó Embracing Change",
    "text": "ü§ó Embracing Change\nWhile the publication process for JuliaCon Proceedings is already ahead of the game, I think it can be improved even further. In particular, I think that it could benefit from embracing Quarto. The community as a whole has certainly heard of Quarto by now: in 2022, the CEO of posit himself, J.J. Allaire, gave a talk at JuliaCon about Quarto; later that same year, yours truly gave a talk about using Quarto with Julia at Julia Eindhoven; other Julia developers like Ronny Bergmann have come up with clever ways to combine Quarto with existing documentation tools like Documenter.jl through GitHub actions. To my mind, JuliaCon Proceedings is the perfect place to turn to next for Quarto adoption.\n\nQuarto for JuliaCon Proceedings: A Proposal\nI have been working on just that: a Quarto journal extension for JuliaCon Proceedings that I would like to introduce in this blog post. The extension is called quarto-juliacon-proceedings. It is based on the existing JuliaCon Proceedings LaTeX template and will allow authors to write their JuliaCon Proceedings paper (and more!) in Quarto.\nIt is close to being finished but still needs some work. The repo contains a Quarto version of our JuliaCon Proceedings paper Explaining Black-Box Models through Counterfactuals (Altmeyer, Deursen, and Liem 2023). The rendered PDF serves as a comparison to the published version of the paper. The remaining differences in formatting need to be sorted out. If you notice any differences that we have not already listed, please open an issue. There is also an open issue on JuliaConSubmission.jl which you may use to share your thoughts on this proposal with the JuliaCon Proceedings team (or simply support this proposal by giving it a thumbs up).\n\n\n\n\n\n\nWarning\n\n\n\nAt the time of writing, this is a proof-of-concept for how we could use Quarto for JuliaCon proceedings. For current submissions, please follow the official instructions here.\n\n\nProvided we can eventually get this extension to be officially supported by the JuliaCon Proceedings team, I think it would be a great step forward for the Julia community. It would reduce the process of complying with the JuliaCon Proceedings LaTeX template to a single line of code:\nquarto use template pat-alt/quarto-juliacon-proceedings\nSimply run this command and start writing your paper in Quarto. The extension will take care of the rest.\nBeyond making life easier for authors, I think that this extension would also be a great opportunity for the JuliaCon Proceedings team to rethink the way we publish JuliaCon Proceedings papers. I‚Äôll finish this post by brainstorming some ideas for how we could improve the current process even further by embracing Quarto.\n\nContinuous Peer Review\nThe current process is still very much based on the old-fashioned, print-based approach to scientific publishing. Once the paper is published, that‚Äôs that. This approach is at odds with the way developers treat the software they write about in their papers. Software is continuously updated and improved and aspects discussed in a paper may become outdated over time. I could imagine a world where the JuliaCon Proceedings paper is automatically updated and tagged whenever a new version of the package is released, just like the documentation. Standard code review processes that involve the community as a whole would then act as a form of continuous peer review.\n\n\nDynamic and Interactive Content\nOf course, Quarto adds a whole new dimension to the way we can communicate our work. Since the same Quarto document that is used to render the static PDF can also be used to generate HTML, we can now include animated and interactive content in our papers. Many developers already use thoughtful and illustrative animations in their package documentation. It seems like a lost opportunity to not feature these in the most condensed and public-facing output (the proceedings paper). Further down the road, I could even imagine a world where Quarto integrates seamlessly with Pluto.jl‚Äîboth Quarto documents and Pluto notebooks are essentially just code blended with Markdown‚Äîto allow for fully interactive versions of our papers.\n\n\nSynergies between Docs and Papers\nFinally, using Quarto for package documentation and JuliaCon Proceedings papers would allow us to create synergies between the two. Developers typically spend a lot of time carefully crafting their package documentation. Independent of whether or not they use Quarto to this end, the Markdown-based documentation files are already a great starting point for a JuliaCon Proceedings paper. Quarto makes it easier than LaTeX to recycle that content and turn it into a paper, since any Markdown file can be seamlessly converted to a Quarto document."
  },
  {
    "objectID": "blog/posts/quarto-juliacon-proceedings/index.html#wrap-up",
    "href": "blog/posts/quarto-juliacon-proceedings/index.html#wrap-up",
    "title": "Stuck in the Past",
    "section": "üåØ Wrap Up",
    "text": "üåØ Wrap Up\nI hope that this post has given you some food for thought. I am aware that some of the ideas I have presented here are quite radical and that it will take time for the academic community to embrace them. I am also aware that there are many other aspects of the scientific publishing process that need to be rethought. But the tools I highlight in this post are freely accessible to us. We just need to start using them."
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html",
    "href": "blog/posts/quarto-extensions/index.html",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "",
    "text": "A TU Delft Theme for Quarto.\nI‚Äôve said it before and I‚Äôll say it again: Quarto is amazing! Since the beginning of my PhD I haven‚Äôt used any other tool for prototyping, writing and publishing any of my work.1 That work has included: this website, presentations, academic articles, notebooks and more. By highlighting useful features of Quarto in articles like this one, I hope to encourage more people to try it out.\nWhile I‚Äôm convinced that Quarto can be useful in almost any context including industry, I realize that certain obstacles may have so far prevented some of you from using it. One such obstacle concerns custom formats: the standard Quarto formats for HTML, PDF, Revealjs, etc. are slick but minimalistic. For many formats, there are various themes to choose from, but they too lack personal touch (or corporate identity in the industry setting).\nAt first sight, traditional publishing tools like MS Office seem to have an edge here: customization is made easy through GUIs and standardization through templates is possible to a certain degree. I understand the appeal but still would encourage you to look beyond MS Word, Powerpoint and Beamer presentations. To this end, I‚Äôve put together this short tutorial that explains how I have built and contributed a TU Delft theme for Revealjs. If nothing else, this theme can be used by my colleagues at Delft University of Technology to create beautiful, Delft-styled presentations with ease."
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html#background",
    "href": "blog/posts/quarto-extensions/index.html#background",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "üìñ Background",
    "text": "üìñ Background\nAdvanced and reproducible customization in Quarto is done through Quarto Extensions:\n\n‚ÄúQuarto Extensions are a powerful way to modify or extend the behavior of Quarto, and can be created and distributed by anyone.‚Äù\n‚Äî Quarto team\n\nUsers can already utilize several open-sourced extensions that add filters, journal article formats and other custom formats. As we will see, it is very straightforward to contribute extensions, so the list of available extensions is growing quickly."
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html#contributing-quarto-extensions",
    "href": "blog/posts/quarto-extensions/index.html#contributing-quarto-extensions",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "ü´¥ Contributing Quarto Extensions",
    "text": "ü´¥ Contributing Quarto Extensions\nNormally, I would start by explaining how to use Quarto Extensions, but in this particular case the user and developer experience is so close that I‚Äôll jump straight into development.\n\nSetup\nTo get started with building the TU Delft Custom Format I followed the official Quarto docs. I first used the appropriate Quarto command, which initiates an interactive process in the command line:\n$ quarto create extension format:revealjs\n ? Extension Name ‚Ä∫ lexdoc\nOnce done, the basic folder structure for my extension was set up and ready to be pushed to a remote Github repository for distribution: https://github.com/pat-alt/quarto-tudelft. Even though I had not yet added any custom formatting rules, anyone would now be able to use this empty extension for their work.\n\n\nAdding Rules\nTo actually add some custom formatting rules to the extension I started working on the files contained in _extensions/tudelft/. Using my institution‚Äôs PowerPoint template as a reference, I previewed the template.qmd file and simply made appropriate adjustments to the _extensions/tudelft/custom.scss and _extensions/tudelft/_extension.yml files until I was satisfied. To help me in that process, I took inspiration from various existing Revealjs extensions all listed in the awesome-quarto repository.\nI am no expert in CSS (far from it!), so this was very much trial-and-error based, but I got there eventually. One feature I am particularly happy about is the custom transition slides: by default all slides at level 1, so slides that initiate a new section,\n# Transition Slide\nwill be formatted in a standardized way. The relevant CSS rule can be found here\n\n\nAdding Assets\nThe Reavealjs template also includes a few images, which I have lifted from my institution‚Äôs PowerPoint template. To make sure that these images are also available locally when users install the template, any resources need to be stored inside the theme directory _extensions/tudelft/. I have had some issues pointing to the right location of these images in the _extensions/tudelft/custom.scss and _extensions/tudelft/_extension.yml file. At the time of writing this, the image URLs are pointing to their remote location on Github (see here). This works, but probably isn‚Äôt ideal, so any suggestions are welcome."
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html#example-presentation---using-quarto-extensions",
    "href": "blog/posts/quarto-extensions/index.html#example-presentation---using-quarto-extensions",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "üìã Example Presentation - Using Quarto Extensions",
    "text": "üìã Example Presentation - Using Quarto Extensions\nIn February, 2023, I will present a research paper on Algorithmic Recourse at the first IEEE Conference on Secure and Trustworthy Machine Learning: SaTML 2023. This was a good incentive for me to build a TU Delft Theme once for this occasion and then be able to reuse it again in the future.\n\nWith the template built and distributed, how do you actually use it?\n\nThis part is truly a walk in the park. As outlined in the README users can either work directly with the template,\nquarto use template pat-alt/quarto-tudelft\nor add the template to an existing Quarto project:\nquarto add pat-alt/quarto-tudelft\nThe first option will get you started with a working document straight away. For my paper presentation, I worked with the second option. At the time of writing, I am building and hosting all of my presentations in my website repository (the repo that also builds this very article you‚Äôre reading): https://github.com/pat-alt/pat-alt.github.io.\nWith the extension added to the project, I can now use it anywhere within that project by simply specifying,\nformat: tudelft-revealjs\nin the YAML header of my Quarto document where tudelft-revealjs is just the name of the custom format.\nIt gets better ‚Ä¶ The extension can be extended further by providing yet another custom style sheet, as I have done for my paper presentation:\nformat: \n  tudelft-revealjs:\n    theme: custom.scss\nCheck out the final presentation here or see the embedded version below:"
  },
  {
    "objectID": "blog/posts/quarto-extensions/index.html#footnotes",
    "href": "blog/posts/quarto-extensions/index.html#footnotes",
    "title": "Quarto on Steroids: Advanced Customization through Quarto Extensions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNot entirely true: I‚Äôve also used Pluto.jl üéà and had to resort to .Rmd in one particular case.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html",
    "href": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "",
    "text": "Julia and Quarto: a perfect match.\nDoes your work involve research, coding, writing and publishing? If so, then chances are that you often find yourself bouncing back and forth between different open-source text editors, IDEs, programming languages and platforms depending on your current needs. Using a diverse set of tools is reasonable, because there typically is no single perfect approach that solves all our problems. For example, interactive notebooks like Jupyter are useful for working with code and communicating it to others, but they are probably not anyone‚Äôs first choice for producing a scientific article. Similarly, Beamer presentations can be useful for presenting science in a standardized fashion, but they are the very opposite of interactive and look incredibly boring.\nAs much as the great variety of free tools deserves being celebrated, all this bouncing back and forth can be really tiring. What if there was a single tool, an engine that can turn your work into all kinds of different outputs? I mean literally any output you can think of: Markdown, HTML, PDF, LateX, ePub, entire websites, presentations (yes, also Beamer if you have to), MS Word, OpenOffice, ‚Ä¶ the list goes on. All of that starting from the same place: a plain Markdown document blended with essentially any programming language of your choice and a YAML header defining your output. This tool now exists and it goes by the name Quarto.\nIn this short blog post I hope to convince you that Quarto is the only publishing engine you will ever need. What I am definitely not going to tell you is which IDE, text editor or programming language you should be using to actually produce your work. Quarto does not care about that. Quarto is here to make your life a bit easier (and by ‚Äòa bit‚Äô I mean a whole lot). Quarto is nothing less but a revolution for scientific publishing.\nTo put this all in some context (well, my context), I will now tell you a bit about what has led me to making such bold claims about yet another open-source tool.\nYes! But it‚Äôs worth noting that a lot of the benefits that Quarto brings have been available to R users for many years, thanks to the amazing work of many great open-source contributors like @xieyihui. Julia was the main reason for me to branch out of this comfortable R bubble as I describe below. That said, if you are a Julia user who really couldn‚Äôt care less about my previous experiences with R Markdown, this is a good time to skip straight ahead to Section¬†2. By the way, if you haven‚Äôt clicked on that link, here‚Äôs a small showcase demonstrating how it was generated. It shows easy it is to have everything well organised and connected with Quarto."
  },
  {
    "objectID": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#sec-bubble",
    "href": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#sec-bubble",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "A comfortable bubble üéà",
    "text": "A comfortable bubble üéà\nFor many years I have used R Markdown for essentially anything work-related. As an undergraduate economics student facing the unfortunate reality that people still teach Stata, I was drawn to R. This was partially because R has a great open-source community and also partially because Stata. Once I realised that I would be able to use R Markdown to write up all of my future homework assignments and even my thesis, I never looked back. MS Word was now officially dead to me. Overleaf was nothing more than a last resort if everyone else in my team insisted on using it for a group project. Being able to write my undergraduate dissertation in R Markdown was a first truly triumphant moment. Soon after that I would also try myself at Shiny, produce outputs in HTML and build entire websites through blogdown. And all of that from within R Studio involving R and Markdown and really not much else. During my first professional job at the Bank of England I was reluctant to use anything other than R Markdown to produce all of my output. Luckily for me, the Bank was very much heading in that same direction at the time and my reluctance was not perceived as stubbornness, but actually welcome (at least I hoped so).\n\nCracks in the bubble üß®\nSoon though, part of me felt a little boxed in. For any work that required me to look outside of the R bubble, I knew I might also have to give up a very, very comfortable work environment and my productivity would surely take a hit. During my master‚Äôs in Data Science, for example, the mantra was very much ‚ÄúPython + Jupyter or die‚Äù. Through reticulate and R Studio‚Äôs growing support for Python I managed to get by without having to leave my bubble too often. But reticulate always felt a little clunky (sorry!) and some professors were reluctant to accept anything other than Jupyter notebooks. Even if others had not perceived it that way in the past, I certainly started to feel that I might just be a little too attached the beautiful bubble that R Studio had created around me.\n\n\nEnter: Julia üí£\nThen there was Julia: elegant, fast, pure, scientific and - oh my REPL! - those beautiful colors and unicode symbols. The stuff of dreams, really! Geeky dreams, but dreams nonetheless. I had once before given Julia a shot when working with high-frequency trade data for a course in market microstructure. This was the first time R really revealed its limitations to me and my bubble nearly burst, but thanks to data.table and Rcpp I managed to escape with only minor bruises. Still, Julia kept popping up, teasing me whenever I would work on some Frakenstein-style C++ code snippets that would hopefully resolve my R bottlenecks. I actually enjoyed mixing some C++ into my R code like I did here, but the process was just a little painful and slow. But wouldn‚Äôt learning all of Julia take even more time and patience? And what about my dependence on R Markdown?\n\n\nJulia bursts my bubble üí•\nAs I started my PhD in September 2021, I eventually gave in. New beginnings - time to suck it up! If it meant that I‚Äôd have to use Jupyter notebooks with Julia, so be it! And so I was off to a somewhat bumpy start that would have me bouncing back and forth between trying to make Julia work in R Studio (meh), setting up Jupyter Lab (meeeh), just using the Julia REPL because ‚Äúthe REPL is all you need‚Äù (nope) and even struggling with Vim and Emacs. Then there was also Pluto.jl, of course, which admittedly looks amazing! But it also looks very much tailored to Julia and (I believe) the number of different output formats you can produce is still very limited. Eventually, I settled for VSCode in combination with Jupyter notebooks. As much as I dreaded the latter, Jupyter is popular, arguably versatile and supports both R and Julia. This setup worked well enough for me, but it still definitely fell short of the breeze that R Studio had always provided. One thing that really bugged me, for example, was the fact that the IJulia kernel was not accessible from the Julia REPL. Each notebook would have its own environment, which could only be accessed through the notebook. In R Studio the interaction between R Markdown and the console is seamless, as both have access to the same environment variables.\n\n\nEnter: Quarto ‚ù§Ô∏è‚Äçü©π\nAround the same time that I started using Julia, I read about Quarto for the first time. It looked ‚Ä¶ great! Like a timely little miracle really! But also ‚Ä¶ unfinished? Definitely experimental at the time. I loved the idea though and in a footnote somewhere on their website it said that the project was supported by R Studio which I took as a very good sign. So I decided to at least give it a quick try and built a small (tiny) website summarising some of the literature I had read for my PhD:\n\n\nJust had my first go #quarto and I absolutely love the concept! Open-source and language agnostic - truly amazing work from &#64rstudio https://t.co/veCg7ywQ8v\n\n‚Äî Patrick Altmeyer (&#64paltmey) October 29, 2021\n\n\nThis was a first very pleasant encounter with Quarto, arguable even smoother than building websites in blogdown. As for working with Julia though, I had made up my mind that VSCode was the way to go and at the time there was no Quarto extension (there is now). There was also little in terms of communication about the project by R Studio, probably because things were really still in the early development stages. I was hopeful that eventually Quarto would enable me to emulate the R Studio experience in VS Code, but for now things were not quite there yet.\n\n\nQuarto keeps growing ü§û\nSince I was now working with VSCode + Jupyter and since Quarto supports Jupyter as well as all of my old R Markdown work, my next little Quarto project involved turning my old blogdown-powered blog into a Quarto-powered blog. This was not strictly necessary, as I could always export my new Jupyter notebooks to HTML and let blogdown do the rest. But it did streamline things a little bit and the default Quarto blog theme - you are staring at it - is actually üî•. I also did not have to feel guilty towards @xieyihui about leaving blogdown, because unsurprisingly he is on the Quarto team. As I was working on this little project I started noticing that the Quarto website was updated regularly and responses to issues I opened like this one were answered very swiftly. Clearly, things were moving and they were moving fast. More recently, the news about Quarto has been spreading and it‚Äôs left some folks as confused and amazed as I was, when I first heard about it:\n\n\n#RStats can someone explain to me what's the difference between {Quarto} and {RMarkdown}? I saw a tweet about Quarto and now I'm all confused ‚Ä¶ What gap is it supposed to fill?\n\n‚Äî Erwin Lares (&#64lasrubieras) March 30, 2022\n\n\nThis is why finally I‚Äôve decided I should write a brief post about how and why I use Quarto. Since I have been working mostly with Julia for the past couple of months, I‚Äôve chosen to focus on the interaction between Quarto and Julia. Coincidentally, yesterday was also the first time I saw a guide dedicated to Julia on the Quarto website, so evidently I am not the only one interested in that marriage. This also means that there really is not too much left for me to talk about now, since Quarto‚Äôs documentation is state-of-the-art. But a few bits and pieces I mention below might hopefully still be useful or at least some food for thought."
  },
  {
    "objectID": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#sec-match",
    "href": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#sec-match",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "Quarto and Julia: a perfect match üíôüíúüíö",
    "text": "Quarto and Julia: a perfect match üíôüíúüíö\nWhile what follows may be relevant to other programming languages, my main goal for this last section is to flag Quarto to the Julia community. In any case, #rstats folks have been using R and Python in R Markdown documents for a while now and won‚Äôt need much of an introduction to Quarto. As for Python aficionados, I can only recommend to give Quarto a shot (you will still be able to use Jupyter notebooks).\n\nWorking with VSCode, Quarto and Julia\nThe very article you are reading right now was composed in a Quarto document. These documents feel and look very much like standard Julia Markdown documents, but you can do a lot more with them. You can find the source code for this and other documents presented in this blog here.\nTo get you started, here is my current setup combining VSCode, Quarto and Julia:\n\nVSCode extensions: in addition to the Julia extension you will need the Quarto extension. In addition, the YAML extension and some extension to preview Markdown docs would be helpful. I am not sure if Markdown Julia and Jupyter are strictly necessary, but it won‚Äôt hurt.\nI do most of my work in Quarto documents .qmd.\nIf you choose to also do that, make sure that the .qmd document has access to a Pkg.jl environment that has IJulia added.\n\nJulia code cells can be added anywhere along with your plain text Markdown. They look like this:\n```{julia}\nusing Pkg\nPkg.add(\"CounterfactualExplanations\")\n```\nContrary to Jupyter notebooks, executing this code cells will start a Julia REPL in VSCode. I find this very helpful, because it lets me fiddle with anything I have created inside the Quarto notebook without having to click into cells all the time. Quarto comes with great support for specifying code executing options. For example, for the code below I have specified #| echo: true in order for the code to be rendered. The code itself is the code I actually used to build the animation above (heavily borrowed from this Javis.jl tutorial).\n#| echo: true\nusing Javis, Animations, Colors\n\nsize = 600\nradius_factor = 0.33\n\nfunction ground(args...)\n    background(\"transparent\")\n    sethue(\"white\")\nend\n\nfunction rotate_anim(idx::Number, total::Number) \n    distance_circle = 0.875\n    steps = collect(range(distance_circle,1-distance_circle,length=total))\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [0, steps[idx]*2œÄ],\n        [sineio()],\n    )\nend\n\ntranslate_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(size*radius_factor, 0)],\n    [sineio()],\n)\n\ntranslate_back_anim = Animation(\n    [0, 1], # must go from 0 to 1\n    [O, Point(-(size*radius_factor), 0)],\n    [sineio()],\n)\n\njulia_colours = Dict(\n    :blue =&gt; \"#4063D8\",\n    :green =&gt; \"#389826\",\n    :purple =&gt; \"#9558b2\",\n    :red =&gt; \"#CB3C33\"\n)\ncolour_order = [:red, :purple, :green, :blue]\nn_colours = length(julia_colours)\nfunction color_anim(start_colour::String, quarto_col::String=\"#4b95d0\")\n    Animation(\n        [0, 1], # must go from 0 to 1\n        [Lab(color(start_colour)), Lab(color(quarto_col))],\n        [sineio()],\n    )\nend\n\nvideo = Video(size, size)\n\nframe_starts = 1:10:40\nn_total = 250\nn_frames = 150\nBackground(1:n_total, ground)\n\n# Blob:\nfunction element(; radius = 1)\n    circle(O, radius, :fill) # The 4 is to make the circle not so small\nend\n\n# Cross:\nfunction cross(color=\"black\";orientation=:horizontal)\n    sethue(color)\n    setline(10)\n    if orientation==:horizontal\n        out = line(Point(-size,0),Point(size,0), :stroke)\n    else\n        out = line(Point(0,-size),Point(0,size), :stroke)\n    end\n    return out\nend\n\nfor (i, frame_start) in enumerate(1:10:40)\n\n    # Julia circles:\n    blob = Object(frame_start:n_total, (args...;radius=1) -&gt; element(;radius=radius))\n    act!(blob, Action(1:Int(round(n_frames*0.25)), change(:radius, 1 =&gt; 75))) # scale up\n    act!(blob, Action(n_frames:(n_frames+50), change(:radius, 75 =&gt; 250))) # scale up further\n    act!(blob, Action(1:30, translate_anim, translate()))\n    act!(blob, Action(31:120, rotate_anim(i, n_colours), rotate_around(Point(-(size*radius_factor), 0))))\n    act!(blob, Action(121:150, translate_back_anim, translate()))\n    act!(blob, Action(1:150, color_anim(julia_colours[colour_order[i]]), sethue()))\n\n    # Quarto cross:\n    cross_h = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:horizontal))\n    cross_v = Object((n_frames+50):n_total, (args...) -&gt; cross(;orientation=:vertical))\nend\n\nrender(\n    video;\n    pathname = joinpath(www_path, \"intro.gif\"),\n)\n\n\nWorking with Documenter.jl and Quarto\nAn interesting application of Quarto in the Julia ecosystem is package documentation. This is of course best done using Documenter.jl and fortunately the two play nicely with each other, since both share a common ground (Markdown). Their interaction is perhaps best demonstrated through this Julia library I recently developed: CounterfactualExplanatinos.jl. On there you will find lot of Julia scripts *.jl under src/ and test/, as well as many Markdown .md and Quarto documents .qmd under docs. I wrote the package documentation in the Quarto documents, rendered documents individually through quarto render [doc].qmd and then fed the resulting Markdown documents to Documenter.jl as always.\nBelow is my standard YAML header for those Quarto documents:\nformat: \n  commonmark:\n    variant: -raw_html\n    wrap: none\n    self-contained: true\ncrossref:\n  fig-prefix: Figure\n  tbl-prefix: Table\nbibliography: https://raw.githubusercontent.com/pat-alt/bib/main/bib.bib\noutput: asis\nengine: julia\nexecute: \n  echo: true\n  eval: false\nYou can see that it points to Bibtex file I host on another Github repository. This makes it very easy to generate citations and references for the rendered Markdown documents, that also show up in the docs (e.g.¬†here). Unfortunately, cross-referencing only partially works, because it relies on auto-generated HTML and Documenter.jl expects this to be passed in blocks. Choosing variant: -raw_html is only a workaround as I have discussed here. Ideally, Documenter.jl would just accept HTML documents rendered from Quarto, but currently only Markdown documents are accepted by make_docs. Still, if anything this workaround is a nice gimmick that extends the default Documenter.jl functionality, without any hassle involved. Hopefully, this can be improved in the future.\n\n\nUsing Quarto for JuliaCon Proceedings\nAnother very good use-case for Quarto involves actual scientific publications in journals such as JuliaCon Proceedings. The existing submission process is tailored towards reproducibility and actually involves reviews directly on GitHub, which is fantastic. But currently only submissions in TeX format are accepted, which is not so great. Using Quarto would not only streamline this process further, but also open the JuliaCon Proceedings Journal up to publishing content in different output formats. Quarto docs could be used to still render the traditional PDF. But those same documents could also be used to create interactive versions in HTML. Arguably, the entire journal could probably be built through Quarto."
  },
  {
    "objectID": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#wrapping-up",
    "href": "blog/posts/julia-and-quarto-a-match-made-in-heaven/index.html#wrapping-up",
    "title": "Julia and Quarto: a match made in heaven? üå§",
    "section": "Wrapping up üéó",
    "text": "Wrapping up üéó\nIn this post I wanted to demonstrate that Quarto might just be the next revolution in scientific publishing. In particular, I hope I have managed to demonstrate its appeal to the Julia community, which I am proud to be part of now that I have managed to branch out of my old R bubble. Please let me hear your thoughts and comments below!"
  },
  {
    "objectID": "blog/posts/sidequest/index.html",
    "href": "blog/posts/sidequest/index.html",
    "title": "Sidequest",
    "section": "",
    "text": "Photo of my first fight by Micklin Korsuize.\nAfter moving to the Netherlands for my PhD in 2021, I rediscovered my passion for Muay Thai and Kickboxing about 2 years ago. I used to train Muay Thai back home in Germany for some time during n high school, but had to balance it with club football and never competed. Early this year, I decided that at 31yo, it‚Äôs now or never to step into the ring and so I started preparing for a local tournament. After a failed attempt to compete in May due to injury, I finally won my first amateur fight in early November this year against a strong opponent who I much respect. It was a thrilling, terrifying and humbling experience! On December 1st, I‚Äôm competing again and I‚Äôm hoping for another clean fight and, of course, another win."
  },
  {
    "objectID": "blog/posts/sidequest/index.html#diversification-builds-resilience",
    "href": "blog/posts/sidequest/index.html#diversification-builds-resilience",
    "title": "Sidequest",
    "section": "Diversification Builds Resilience",
    "text": "Diversification Builds Resilience\nIn some ways, the failed attempt in May has been a blessing in disguise. It forced me to take a step back and reflect on what I got out of an intense training camp that led seemingly nowhere. As cliche as it sounds, I truly realized that the journey really was the destination. Despite not getting to compete, I was in a really good place mentally. The sense that I had worked really hard on something that had no direct link to my professional career out me at great ease. For the first time during my PhD, I felt like I would be just fine, even if whatever academic milestone I was planning to reach next would not materialize immediately. I knew that I would just take it on the chin and feel reassured that academic success is not the only leg I‚Äôm standing on.\nAs with so many things in life (financial investments, gambling, societies and cultures, gene pools, ‚Ä¶), I believe that diversification builds resilience when it comes to managing personal goals and priorities. My supervisor, Cynthia, never fails to amaze and inspire me in this respect: she is a highly respected, award-winning academic, an active performing musician and an advocate of public outreach. She has recently been recognised for that by Harper‚Äôs Bazaar, who presented her with mutliple awards this year includgin Woman of the Year. I think that Cynthia manages to do so many things things successfully1, not only through hard work2 but by getting her priorities straight. I think that we have a tendency to focus too much of our energy on a single priority A, thereby losing track of priorities B, C, etc. only to end up frustrated about the latter even if and when we accomplish the former."
  },
  {
    "objectID": "blog/posts/sidequest/index.html#fundraiser-initiative",
    "href": "blog/posts/sidequest/index.html#fundraiser-initiative",
    "title": "Sidequest",
    "section": "Fundraiser Initiative",
    "text": "Fundraiser Initiative\nFollowing May, I decided to keep up my training to potentially compete later in the year. Having learned already that this whole journey was not just about me stepping into that ring, I was looking for ways to create meaningful impact beyond that, ideally also for others. The event I will be competing in is not a charity event but thankfully these days you can turn everything you want into a charity: just come up with a charitable cause and start a fundraiser. So that‚Äôs what I did and here I am still trying to raise a few more funds for my charitable cause of choice, namely‚Äîyou guessed it‚Äîmental health. If you‚Äôre still reading this and you can relate to any of the above, please consider supporting the fundraiser below. Everything you donate will go to Mental Health Europe. I will cover all of the GoFundMe fees and match total donations up to 500EUR (which by now means I am 500EUR poorer). If you cannot donate, please consider sharing the fundraiser with anyone you know who might be interested in supporting it."
  },
  {
    "objectID": "blog/posts/sidequest/index.html#thank-you",
    "href": "blog/posts/sidequest/index.html#thank-you",
    "title": "Sidequest",
    "section": "Thank you!",
    "text": "Thank you!\nFinally, a massive thanks to all of the friendly people who have already supported this journey and the fundraiser in one way or another. Dankesch√∂n!"
  },
  {
    "objectID": "blog/posts/sidequest/index.html#footnotes",
    "href": "blog/posts/sidequest/index.html#footnotes",
    "title": "Sidequest",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nShe truly does all of these things, successfully!‚Ü©Ô∏é\nShe does work incredibly hard!‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html",
    "href": "blog/posts/spurious-sparks/index.html",
    "title": "Spurious Sparks of AGI",
    "section": "",
    "text": "Photo by Jake Oates on Unsplash\nWe humans are prone to seek patterns everywhere. Meaningful patterns have often proven to help us make sense of our past, navigate our presence and predict the future. Our society is so invested in finding patterns that today it seems we are more willing than ever to outsource this task to an Artificial Intelligence (AI): an omniscient oracle that leads us down the right path.\nUnfortunately, history has shown time and again that patterns are double-edged swords: if we attribute the wrong meaning to them, they may lead us nowhere at all, or worse, they may lead us down dark roads. I think that the current debate around large language models (LLMs) is a prime example of this."
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#models-are-tools-treat-them-as-such",
    "href": "blog/posts/spurious-sparks/index.html#models-are-tools-treat-them-as-such",
    "title": "Spurious Sparks of AGI",
    "section": "Models are Tools, Treat Them as Such",
    "text": "Models are Tools, Treat Them as Such\nIn statistics, misleading patterns are referred to as spurious relationships: purely associational relationships between two or more variables that are not causally related to each other at all. The world is full of these and as good as we as species may be at recognizing patterns, we typically have a much harder time discerning spurious relationships from causal ones. Despite new and increased momentum in scientific fields concerned with causal inference and discovery, I am also willing to go out on a limb and claim that we are not about to finally reach the top of Judea Pearl‚Äôs Causal Ladder through the means of Causal AI (although I do think it is a step in the right direction).\nI agree with the premise that in a world full of spurious relationships, causal reasoning is our only remedy. But I am very skeptical of claims that AI will magically provide that remedy. This leads me to the title and topic of this post: spurious sparks of AGI‚Äîpatterns exhibited by AI that may hint at Artificial General Intelligence (AGI) but are really just reflections of the associational patterns found in the data used to train them. The article is written in response to a recent paper that finds a ‚Äòworld model‚Äô from Llama-2‚Äîa popular open-source large language model (LLM)‚Äîusing mechanistic interpretability (Gurnee and Tegmark 2023). In light of these findings, one of the authors, Max Tegmark, was quick to claim on social media that ‚ÄúNo, LLM‚Äôs aren‚Äôt mere stochastic parrots [‚Ä¶]‚Äù.\nSince this is an opinionated post, I feel that I should start by laying out my position on the paper and related claims.\n\n\n\n\n\n\nPosition\n\n\n\n\nI take no issue with the methodological ideas that form the foundation of the article in question. On the contrary, I think that mechanistic interpretability is an interesting and important toolkit that can help us better understand the intrinsics and behavior of opaque artificial intelligence.\nLinear probes are straightforward, the visualizations in Gurnee and Tegmark (2023) are intriguing, the code is open-sourced and the findings are interesting.\nI am surprised that people are surprised by the findings: if we agree that LLMs exhibit strong capabilities that can only be connected to the patterns observed in the data they were trained on, then where exactly should we expect this information to be stored if not in the parameters of the model?1\nI therefore do take issue with the way that these findings are being overblown by people with clout. Perhaps the parrot metaphor should not be taken too literally either, but if anything the paper‚Äôs findings seem to support the notion that LLMs are remarkably capable of memorizing and regurgitating explicit and implicit knowledge contained in text.\nI want to point out that linear probes were proposed in the context of monitoring models and diagnosing potential problems Alain and Bengio (2016). Favorable outcomes from probes merely indicate that the model in question ‚Äúhas learned information relevant for the property [of interest]‚Äù (Belinkov 2021). This is useful but not the same as demonstrating that the model has attained a true ‚Äúunderstanding‚Äù of the world.\n\n\n\nIn summary, I wish people used mechanistic interpretability to better understand the behavior and shortcomings of AI models, rather than chasing pipe dreams of AGI. Models are tools that need to be monitored and diagnosed, not anthropomorphized. This post should not be understood as a bash on the paper that originally inspired it, but rather as a call for more responsible and realistic interpretations of the findings in particular on social media."
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#patterns-in-latent-spaces-and-how-to-find-them",
    "href": "blog/posts/spurious-sparks/index.html#patterns-in-latent-spaces-and-how-to-find-them",
    "title": "Spurious Sparks of AGI",
    "section": "Patterns in Latent Spaces and How to Find Them",
    "text": "Patterns in Latent Spaces and How to Find Them\nTo support my claim that observing patterns in latent spaces should not generally surprise us, we will now go through a couple of simple examples. To illustrate further that this phenomenon is neither surprising nor unique to the field of Computer Science, I will draw on my background in Economics and Finance in this section. We will start with very simple examples to demonstrate that even small and simple models can learn meaningful representations of the data. The final example in Section¬†2.4 is a bit more involved and closer in spirit to the experiments conducted by Gurnee and Tegmark (2023). As we go along, we will try to discuss both the benefits and potential pitfalls of finding patterns in latent spaces.\n\nAre Neural Networks Born with World Models?\nBefore diving into the world of Economics, let‚Äôs start with a somewhat contrived and yet very illustrative example underpinning my point that patterns in latent spaces should not surprise us.\nGurnee and Tegmark (2023) extract and visualize the alleged geographical world model by training linear regression probes on internal activations in LLMs (including Llama-2) for the names of places, to predict geographical coordinates associated with these places. Now, the Llama-2 model has ingested huge amounts of publicly available data from the internet, including Wikipedia dumps from the June-August 2022 period (Touvron et al. 2023). It is therefore highly likely that the training data contains geographical coordinates, either directly or indirectly. At the very least, we should expect that the model has seen features during training that are highly correlated with geographical coordinates. The model itself is essentially a very large latent space to which all features are randomly projected in the very first instance before being passed through a series of layers which are gradually trained for its downstream task (next token prediction).\nIn our first example, we simulate this scenario, stopping short of training the model. In particular, we take the world_place.csv that was used in Gurnee and Tegmark (2023), which maps locations/areas to their latitude and longitude. For each place, it also indicates the corresponding country. From this, we take the subset that contains countries that are currently part of the top 10 FIFA world ranking, and assign the current rank to each country (i.e., Argentina gets 1, France gets 2, ‚Ä¶). To ensure that the training data only involves a noisy version of the coordinates, we transform the longitude and latitude data as follows: \\(\\rho \\cdot \\text{coord} + (1-\\rho) \\cdot \\epsilon\\) where \\(\\rho=0.5\\) and \\(\\epsilon \\sim \\mathcal{N}(0, 5)\\).\n\n\n\n\n\n\nCode\n\n\n\nIn the process of writing the paper, most of the code has been moved into scripts in a designated repository to ensure reproducibility. The code for this example can be found here.\n\n\nNext, we encode all features except the FIFA world rank indicator as continuous variables: \\(X^{(n \\times m)}\\) where \\(n\\) is the number of samples and \\(m\\) is the number of resulting features. Additionally, we add a large number of random features to \\(X\\) to simulate the fact that not all features ingested by Llama-2 are necessarily correlated with geographical coordinates. Let \\(d\\) denote the final number of features, i.e.~\\(d=m+k\\) where \\(k\\) is the number of random features.\nWe then initialize a small neural network, considered a projector, mapping from \\(X\\) to a single hidden layer with \\(h&lt;d\\) hidden units and sigmoid activation, and from there, to a lower-dimensional output space. Without performing any training on the projector, we simply compute a forward pass of \\(X\\) and retrieve activations \\(\\mathbf{Z}^{(n\\times h)}\\). Next, we perform the linear probe on a subset of \\(\\mathbf{Z}\\) through Ridge regression: \\(\\mathbf{W} = (\\mathbf{Z}_{\\text{train}}'\\mathbf{Z}_{\\text{train}} + \\lambda \\mathbf{I}) (\\mathbf{Z}_{\\text{train}}'\\textbf{coord})^{-1}\\), where \\(\\textbf{coord}\\) is the \\((n \\times 2)\\) matrix containing the longitude and latitude for each sample. A hold-out set is reserved for testing, on which we compute predicted coordinates for each sample as \\(\\widehat{\\textbf{coord}}=\\mathbf{Z}_{\\text{test}}\\mathbf{W}\\) and plot these on a world map (Figure¬†1).\n\nIf we can expect even random projections to contain useful representations, then should we really be surprised that a large language model, trained on a diverse set of data, contains representations that are useful for a wide range of tasks? ü§î\n\nWhile the fit certainly is not perfect, the results do indicate that the random projection contains representations that are useful for the task at hand. Thus, this simple example illustrates that meaningful target representations should be recoverable from a sufficiently large latent space, given the random projection of a small number of highly correlated features. Similarly, Alain and Bengio (2016) observe that even before training a convolutional neural network on MNIST data, the layer-wise activations can already be used to perform binary classification. In fact, it is well-known that random projections can be used for prediction tasks (Dasgupta 2013).\n\n\n\n\n\n\nFigure¬†1: Predicted coordinate values (out-of-sample) from a linear probe on final-layer activations of an untrained neural network.\n\n\n\n\n\nPCA as a Yield Curve Interpreter\nIn response to the claims made by Tegmark, numerous commentators on social media have pointed out that even the simplest of models can exhibit structure in their latent spaces. One of the most popular and illustrative examples I remember from my time at the Bank of England is yield curve decomposition through PCA. The yield curve is a popular tool for investors and economists to gauge the health of the economy. It plots the yields of bonds against their maturities. The slope of the yield curve is often used as a predictor of future economic activity: a steep yield curve is associated with a growing economy, while a flat or inverted yield curve is associated with a contracting economy.\nTo understand this better, let us go on a quick detour into economics and look at actual yield curves observed in the US during the Global Financial Crisis (GFC). Figure¬†2 (a) shows the yield curve of US Treasury bonds on 27 February 2007, which according to CNN was a ‚Äúbrutal day on Wall Street‚Äù.2 This followed reports on the previous day of former Federal Reserve Chairman Alan Greenspan‚Äôs warning that the US economy was at risk of a recession. The yield curve was inverted with a sharp negative spread between the 10-year and 3-month yields, indicative of the market‚Äôs expectation of a recession.\nFigure¬†2 (b) shows the corresponding yield curve during the aftermath of the GFC on 20 April 2009. On that day the influential Time Magazine reported that the ‚ÄúBanking Crisis is Over‚Äù. The yield curve was steeply sloped with a positive spread between the 10-year and 3-month yields, indicative of the market‚Äôs expectation of a recovery. The overall level of the yield curve was still very low though, indicative of the fact that US economy had not fully recovered at that point.\n\nCode\ndf = CSV.read(joinpath(BLOG_DIR, \"data/ust_yields.csv\"), DataFrame) |&gt;\n    x -&gt; @pivot_longer(x, -Date) |&gt;\n    x -&gt; @mutate(x, variable=to_year(variable)) |&gt;\n    x -&gt; @mutate(x, year=Dates.year(Date)) |&gt;\n    x -&gt; @mutate(x, quarter=Dates.quarter(Date)) |&gt;\n    x -&gt; @mutate(x, Date=Dates.format(Date, \"yyyy-mm-dd\")) |&gt;\n    x -&gt; @arrange(x, Date) |&gt;\n    x -&gt; @fill_missing(x, \"down\")\nylims = extrema(skipmissing(df.value))\n\n# Peak-crisis:\nonset_date = \"2007-02-27\"\nplt_df = df[df.Date .== onset_date, :]\nplt = plot(\n    plt_df.variable, plt_df.value;\n    label=\"\", color=:blue,\n    xlabel=\"Maturity (years)\", ylabel=\"Yield (%)\",\n    size=(380, 350)\n)\nscatter!(\n    plt_df.variable, plt_df.value;\n    label=\"\", color=:blue, alpha=0.5,\n    ylims=(0,6)\n)\ndisplay(plt)\n\n# Post-crisis:\naftermath_date = \"2009-04-20\"\nplt_df = df[df.Date .== aftermath_date, :]\nplt = plot(\n    plt_df.variable, plt_df.value;\n    label=\"\", color=:blue,\n    xlabel=\"Maturity (years)\", ylabel=\"Yield (%)\",\n    size=(380, 350)\n)\nscatter!(\n    plt_df.variable, plt_df.value;\n    label=\"\", color=:blue, alpha=0.5,\n    ylims=(0,6)\n)\ndisplay(plt)\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Onset of GFC: 27 February 2007.\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Aftermath of GFC: 20 April 2009.\n\n\n\n\n\n\n\nFigure¬†2: Yield curve of US Treasury bonds.\n\n\n\nOf course, US Treasuries are not the only bonds that are traded in the market. To get a more complete picture of the economy, analysts might therefore be interested in looking at the yield curves of other bonds as well. In particular, we might be interested in predicting economic growth based on the yield curves of many different bonds. The problem with that idea is that it is cursed by high dimensionality: we would end up modelling a single variable of interest (economic growth) with a large number of predictors (the yields of many different bonds). To deal with the curse of high dimensionality it can be useful to decompose the yield curves into sets of principal components.\nTo compute the principal components we can decompose the matrix of yields \\(\\mathbf{Y}\\) into a product of its singular vectors and values: \\(\\mathbf{Y}=\\mathbf{U}\\Sigma\\mathbf{V}^{\\prime}\\). I will not go into the details here, because Professor Gilbert Strang has already done a much better job than I ever could in his Linear Algebra lectures. To put this into the broader context of the article, however, let us simply refer to \\(\\mathbf{U}\\), \\(\\Sigma\\) and \\(\\mathbf{V}^{\\prime}\\) as latent embeddings of the yield curve (they are latent because they are not directly observable).\nThe top panel in Figure¬†3 shows the first two principal components of the yield curves of US Treasury bonds over time. Vertical stalks indicate the key dates during the onset and aftermath of the crisis, which we discussed above. For both components, we can observe some marked shifts between the two dates - but can we attribute any meaning to these shifts? It turns out we can: for comparison, the bottom panel in Figure¬†3 shows the average level and spread of the yield curves over time. The first principal component is strongly correlated with the level of the yield curve, while the second principal component is strongly correlated with the spread of the yield curve.\n\n\nCode\n# PCA:\ndf_wide = @select(df, Date, variable, value) |&gt;\n    x -&gt; @pivot_wider(x, names_from = variable, values_from = value) |&gt;\n    x -&gt; dropmissing(x)\nX = @select(df_wide, -Date) |&gt; Matrix\nU, Œ£, V = svd(X)\n\n\n\n\n\n\n\n\nFigure¬†3: Comparison of latent embeddings and observed data of the US Treasury yield curve.\n\n\n\nNot convinced? Let us use \\(\\mathbf{Y}=\\mathbf{U}\\Sigma\\mathbf{V}^{\\prime}\\) in true autoencoder fashion to reconstruct yield curves from principal components. Let \\(z_1\\) denote the first principal component and consider the following: we keep all other \\(M-1\\) principal components fixed at zero where \\(M\\) denotes the total number of maturities; next we traverse the latent space by varying the value of \\(z_1\\) over a fixed grid of length \\(K\\) each time storing the full vector \\(\\mathbf{z}\\); finally, we vertically concatenate the vectors and end up with a matrix \\(\\mathbf{Z}\\) of dimension \\((K \\times M)\\). To reconstruct yields, we simply multiply \\(Z\\) by the singular values and right singular vectors: \\(\\mathbf{Y}=\\mathbf{Z}\\Sigma\\mathbf{V}^{\\prime}\\).\nFigure¬†4 shows the result of this exercise in the left panel. As we can see, our generated yield curves shift vertically as we traverse the latent space. The right panel of Figure¬†4 shows the result of a similar exercise, but this time we keep the first principal component fixed at zero and vary the second principal component. This time the slope of our generated yield curves shifts as we traverse the latent space.\n\n\nCode\nn_vals = 50\npc1_range = range(extrema(U[:,1])..., length=n_vals)\npc2_range = range(extrema(U[:,2])..., length=n_vals)\nZ_1 = [[pc1, 0, zeros(size(U, 2)-2)...] for pc1 in pc1_range] |&gt; x -&gt; reduce(vcat, x')\nY_1 = Z_1 * diagm(Œ£) * V'\nZ_2 = [[0, pc2, zeros(size(U, 2)-2)...] for pc2 in pc2_range] |&gt; x -&gt; reduce(vcat, x')\nY_2 = Z_2 * diagm(Œ£) * V'\nanim = @animate for i in 1:n_vals\n    # Level shifts:\n    y = Y_1[i,:]\n    p1 = plot(\n        unique(df.variable), y;\n        label=\"\", color=:blue,\n        xlabel=\"Maturity (years)\", ylabel=\"Yield (%)\",\n        title=\"PC1: $(round(collect(pc1_range)[i], digits=5))\",\n        ylims=extrema(Y_1)\n    )\n    scatter!(\n        unique(df.variable), y;\n        label=\"\", color=:blue, alpha=0.5,\n    )\n    # Spread shifts:\n    y = Y_2[i,:]\n    p2 = plot(\n        unique(df.variable), y;\n        label=\"\", color=:blue,\n        xlabel=\"Maturity (years)\", ylabel=\"Yield (%)\",\n        title=\"PC2: $(round(collect(pc2_range)[i], digits=5))\",\n        ylims=extrema(Y_2)\n    )\n    scatter!(\n        unique(df.variable), y;\n        label=\"\", color=:blue, alpha=0.5,\n    )\n    plot(p1, p2, layout=(1,2), size=(1000, 400), left_margin=5mm, bottom_margin=5mm)\nend\ngif(anim, joinpath(BLOG_DIR, \"results/figures/pc_anim.gif\"), fps=5)\n\n\n\n\n\n\n\n\nFigure¬†4: Yield curve decomposition through PCA.\n\n\n\n\n\nAutoencoders as Economic Growth Predictors\nSo far we have considered simple matrix decomposition. You might argue that principal components are not really latent embeddings in the traditional sense of deep learning. To address this, let us now consider a simple deep-learning example. Our goal will be to not only predict economic growth from the yield curve but also extract meaningful features at the same time. In particular, we will use a neural network architecture that allows us to recover a compressed latent representation of the yield curve.\n\nData\nTo estimate economic growth we will rely on a quarterly series of the real gross domestic product (GDP) provided by the Federal Reserve Bank of St.¬†Louis. The data arrives in terms of levels of real GDP. In order to estimate growth, we will transform the data into log differences. Since our yield curve data is daily, we will need to aggregate it to the quarterly frequency. To do this, we will simply take the average of the daily yields for each maturity. We will also standardize yields since deep learning models tend to perform better with standardized data. Since COVID-19 was a huge structural break, we will also filter out all observations after 2018. Figure¬†5 shows the pre-processed data.\n\n\nCode\ndf_gdp_full = CSV.read(joinpath(BLOG_DIR, \"data/gdp.csv\"), DataFrame) |&gt;\n    x -&gt; @rename(x, Date=DATE, gdp=GDPC1) |&gt;\n    x -&gt; @mutate(x, gdp_l1=lag(gdp)) |&gt;\n    x -&gt; @mutate(x, growth=(gdp_l1-gdp)/gdp) |&gt;\n    x -&gt; @select(x, Date, growth) |&gt;\n    x -&gt; @mutate(x, year=Dates.year(Date)) |&gt;\n    x -&gt; @mutate(x, quarter=Dates.quarter(Date)) \ndf_gdp = df_gdp_full |&gt;\n    x -&gt; @filter(x, year &lt;= 2018)\n\ndf_yields_qtr = @group_by(df, year, quarter, variable) |&gt;\n    x -&gt; @mutate(x, value=mean(value)) |&gt;\n    x -&gt; @ungroup(x) |&gt;\n    x -&gt; @select(x, -Date) |&gt;\n    unique\n\ndf_all = @inner_join(df_gdp, df_yields_qtr, (year, quarter)) |&gt; \n    x -&gt; @pivot_wider(x, names_from=variable, values_from=value) |&gt;\n    dropmissing\n\ny = df_all.growth |&gt; \n    x -&gt; Float32.(x)\nX = @select(df_all, -(Date:quarter)) |&gt; \n    Matrix |&gt;\n    x -&gt; Float32.(x) |&gt;\n    x -&gt; Flux.normalise(x; dims=1)\n\n# Plot:\np_gdp = plot(\n    df_all.Date, y;\n    label=\"\", color=:blue,\n    size=(800,200),\n    ylabel=\"GDP Growth (log difference)\"\n)\np_yields = plot(\n    df_all.Date, X;\n    label=\"\", color=:blue,\n    ylabel=\"Yield (standardized))\",\n    legend=:bottomright,\n    alpha=0.5,\n    size=(800,400)\n)\nplot(p_gdp, p_yields, layout=(2,1), size=(800, 600), left_margin=5mm)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†5: GDP growth and yield curve data.\n\n\n\n\n\n\nModel\nUsing a simple autoencoder architecture (Figure¬†6), we let our model \\(g_t\\) denote growth and our conditional \\(\\mathbf{r}_t\\) the matrix of aggregated Treasury yield rates at time \\(t\\). Finally, we let \\(\\theta\\) denote our model parameters. Formally, we are interested in maximizing the likelihood \\(p_{\\theta}(g_t|\\mathbf{r}_t)\\).\nThe encoder consists of a single fully connected hidden layer with 32 neurons and a hyperbolic tangent activation function. The bottleneck layer connecting the encoder to the decoder, is a fully connected layer with 6 neurons. The decoder consists of two fully connected layers, each with a hyperbolic tangent activation function: the first layer consists of 32 neurons and the second layer will have the same dimension as the input data. The output layer consists of a single neuron for our output variable, \\(g_t\\). We train the model over 1,000 epochs to minimize mean squared error loss using the Adam optimizer~.\n\n\nCode\ndl = Flux.MLUtils.DataLoader((permutedims(X), permutedims(y)), batchsize=24, shuffle=true) \ninput_dim = size(X,2)\nn_pc = 6\nn_hidden = 32\nepochs = 1000\nactivation = tanh_fast\nencoder = Flux.Chain(\n    Dense(input_dim =&gt; n_hidden, activation),\n    Dense(n_hidden =&gt; n_pc, activation),\n) \ndecoder = Flux.Chain(\n    Dense(n_pc =&gt; n_hidden, activation),\n    Dense(n_hidden =&gt; input_dim, activation),\n) \nmodel = Flux.Chain(\n    encoder.layers...,\n    decoder.layers...,\n    Dense(input_dim, 1),\n) \nplt = plot(model, rand(input_dim))\ndisplay(plt)\n\n\nGKS: could not find font Sans.ttf\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninput\n\n\nDense(12 =&gt; 32, tanh_fast)\n\n\nDense(32 =&gt; 6, tanh_fast)\n\n\nDense(6 =&gt; 32, tanh_fast)\n\n\nDense(32 =&gt; 12, tanh_fast)\n\n\nDense(12 =&gt; 1)\n\n\n\n\nFigure¬†6: Model architecture.\n\n\n\n\nThe in-sample fit of the model is shown in the left chart of Figure¬†7, which shows actual GDP growth and fitted values from the autoencoder model. The model has a large number of free parameters and captures the relationship between economic growth and the yield curve reasonably well, as expected. Since our primary goal is not out-of-sample prediction accuracy but feature extraction for inference, we use all of the available data instead of reserving a hold-out set. As discussed above, we also know that the relationship between economic growth and the yield curve is characterized by two main factors: the level and the spread. Since the model itself is fully characterized by its parameters, we would expect that these two important factors are reflected somewhere in the latent parameter space.\n\n\nLinear Probe\nWhile the loss function applies most direct pressure on layers near the final output layer, any information useful for the downstream task first needs to pass through the bottleneck layer (Alain and Bengio 2016). On a per-neuron basis, the pressure to distill useful representation is therefore likely maximized there. Consequently, the bottleneck layer activations seem like a natural place to start looking for compact, meaningful representations of distilled information. I compute and extract these activations \\(A_t\\) for all time periods \\(t=1,...,T\\). Next, we use a linear probe to regress the observed yield curve factors on the latent embeddings. Let \\(Y_t\\) denote the vector containing the two factors of interest in time \\(t\\): \\(y_{t,l}\\) and \\(y_{t,s}\\) for the level and spread, respectively. Formally, we are interested in the following regression model: \\(p_{w}(Y_t|A_t)\\) where \\(w\\) denotes the regression parameters. I use Ridge regression with \\(\\lambda\\) set to \\(0.1\\). Using the estimated regression parameters \\(\\hat{w}\\), we then predict the yield curve factors from the latent embeddings: \\(\\hat{Y}_t=\\hat{w}^{\\prime}A_t\\).\nThe in-sample predictions of the probe are shown in the right chart of Figure¬†7. Solid lines show the observed yield curve factors over time, while dashed lines show predicted values. We can observe that the latent embeddings predict the two yield curve factors reasonably well, in particular the spread.\n\n\n\n\n\n\nFigure¬†7: The left chart shows the actual GDP growth and fitted values from the autoencoder model. The right chart shows the observed average level and spread of the yield curve (solid) along with the predicted values (in-sample) from the linear probe based on the latent embeddings (dashed).\n\n\n\nDid the neural network now learn an intrinsic understanding of the economic relationship between growth and the yield curve? To me, that would be too big of a statement. Still, the current form of information distillation can be useful, even beyond its intended use for monitoring models.\n\n\nFor example, an interesting idea could be to use the latent embeddings as features in a more traditional and interpretable econometric model. To demonstrate this, let us consider a simple linear regression model for GDP growth. We might be interested in understanding to what degree economic growth in the past is associated with economic growth today. As we might expect, linearly regressing economic growth on lagged growth, as in column (1) of the table below, yields a statistically significant coefficient. However, this coefficient suffers from confounding bias since there are many other confounding variables at play, of which some may be readily observable and measurable, but others may not.\nI already mentioned the relationship between interest rates and economic growth. To account for that, while keeping our regression model as parsimonious as possible, we could include the level and the spread of the US Treasury yield curve as additional regressors. While this slightly changes the estimated magnitude of the coefficient on lagged growth, the coefficients on the observed level and spread are statistically insignificant (column (2) in the table). This indicates that these measures may be too crude to capture valuable information about the relationship between yields and economic growth. Because we have included two additional regressors with little to no predictive power, the model fit as measured by the Bayes Information Criterium (BIC) has actually deteriorated.\nColumn (3) of the table shows the effect of instead including one of the latent embeddings that we recovered above in the regression model. In particular, we pick the one latent embedding that we have found to exhibit the most significant effect on the output variable in a separate regression of growth on all latent embeddings. The estimated coefficient on this latent factor is small in magnitude, but statistically significant. The overall model fit, as measured by the BIC has improved and the magnitude of the coefficient on lagged growth has changed quite a bit. While this is still a very incomplete toy model of economic growth, it appears that the compact latent representation we recovered can be used in order to mitigate confounding bias.\n\n\n\nLLMs for Economic Sentiment Prediction\nTo round up this section, we will jump back on the hype train and consider an example involving an LLM. In particular, we will closely follow the approach in Gurnee and Tegmark (2023) and apply it to a novel financial dataset: the Trillion Dollar Words dataset introduced by Shah, Paturi, and Chava (2023). The dataset contains a curated selection of sentences formulated by central bankers of the US Federal Reserve and communicated to the public in speeches, meeting minutes and press conferences. The authors of the paper use this dataset to train LLMs to classify sentences as either ‚Äòdovish‚Äô, ‚Äòhawkish‚Äô or ‚Äòneutral‚Äô. To this end, they first manually annotate a subsample of the available data and then fine-tune various foundation models. Their model of choice, FOMC-RoBERTa (a fine-tuned version of RoBERTa (Liu et al. 2019)), achieves an \\(F_1\\) score of around \\(&gt;0.7\\) for the classification task. To illustrate the potential usefulness of the learned classifier, they use predicted labels for the entire dataset to compute an ad-hoc, count-based measure of ‚Äòhawkishness‚Äô. They then go on to show that this measure correlates with key economic indicators in the expected direction: when inflationary pressures rise, the measured level of ‚Äòhawkishness‚Äô increases as central bankers need to raise interest rates to bring inflation back to target.\n\nLinear Probes\nInstead of computing a measure based on predicted labels, we can use linear probes to assess if the fine-tuned model has learned associative patterns between central bank communications and key economic indicators. To this end, I have further pre-processed the data provided by Shah, Paturi, and Chava (2023) and used their proposed model to compute layer-wise embeddings for all available sentences. I have made these available and easily accessible through a small Julia package: TrillionDollarWords.jl. For each layer, I have then computed linear probes on two inflation indicators‚Äîthe Consumer Price Index (CPI) and the Producer Price Index (PPI)‚Äîas well as US Treasury yields at different levels of maturity. To mitigate issues related to over-parameterization, I follow the recommendation in Alain and Bengio (2016) to first reduce the dimensionality of the embeddings each time. In particular, linear probes are restricted to the first 128 principal components of the embeddings of each layer.\nFigure¬†8 shows the out-of-sample root mean squared error (RMSE) for the linear probe, plotted against FOMC-RoBERTa‚Äôs \\(n\\)-th layer. The values correspond to averages across cross-validation folds where I have used an expanding window scheme. Consistent with related work Gurnee and Tegmark (2023), we can observe that model performance tends to be higher for layers near the end of the transformer model. Curiously, for yields at longer maturities, we see that performance eventually deteriorates for the very final layers. This is not the case for the training data, so I would attribute this to overfitting. A detailed discussion of all our results including a benchmark of these probes against baseline autoregressive models can be found in the paper.\n\n\n\n\n\n\nFigure¬†8: Out-of-sample root mean squared error (RMSE) for the linear probe plotted against FOMC-RoBERTa‚Äôs \\(n\\)-th layer for different indicators. The values correspond to averages computed across cross-validation folds, where we have used an expanding window approach to split the time series.\n\n\n\n\n\nStochastic Parrots After All?\nThese results from the linear probe shown in Figure¬†8 are certainly not unimpressive: even though FOMC-RoBERTa was not explicitly trained to uncover associations between central bank communications and prices, it appears that the model has distilled representations that can be used to predict inflation and yields. It is worth pointing out here that this model is substantially smaller than the models tested in Gurnee and Tegmark (2023). This begs the following question:\n\nHave we uncovered further evidence that LLMs ‚Äúaren‚Äôt mere stochastic parrots‚Äù? Has FOMC-RoBERTa developed an intrinsic understanding of the economy just by ‚Äòreading‚Äô central bank communications?\n\nPersonally, I am having a very hard time believing this. To argue my case, I will now produce a counter-example demonstrating that, if anything, these findings are very much in line with the parrot metaphor. The counter-example is based on the following premise: if the results from the linear probe truly were indicative of some intrinsic understanding of the economy, then the probe should not be sensitive to random sentences that are most definitely not related to consumer prices.\nTo test this, I select the best-performing probe trained on the final-layer activations to predict changes in the CPI. I then make up sentences that fall into one of these four categories: Inflation/Prices (IP)‚Äîsentences about price inflation, Deflation/Prices (DP)‚Äîsentences about price deflation, Inflation/Birds (IB)‚Äîsentences about inflation in the number of birds and Deflation/Birds (DB)‚Äîsentences about deflation in the number of birds. A sensible sentence for category DP, for example, could be: ‚ÄúIt is essential to bring inflation back to target to avoid drifting into deflation territory.‚Äù. Analogically, we could construct the following sentence for the DB category: ‚ÄúIt is essential to bring the numbers of doves back to target to avoid drifting into dovelation territory.‚Äù.\nIn light of the encouraging results for the probe in Figure¬†8, we should expect the probe to predict higher levels of inflation for activations for sentences in the IP category than for sentences in the DP category. If this was indicative of true intrinsic understanding, we would not expect to see any significant difference in predicted inflation levels for sentences about birds, independent of whether or not their numbers are increasing. More specifically, we would not expect the probe to predict values for sentences about birds that are substantially different from the values it can be expected to predict when using actual white noise as inputs.\nTo get to this last point, I also generate many probe predictions for samples of noise. Let \\(f: \\mathcal{A}^k \\mapsto \\mathcal{Y}\\) denote the linear probe that maps from the \\(k\\)-dimensional space spanned by \\(k\\) first principal components of the final-layer activations to the output variable of interest (CPI growth in this case). Then I sample \\(\\varepsilon_i \\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}^{(k \\times k)})\\) for \\(i \\in [1,1000]\\) and compute the sample average. I repeat this process \\(10000\\) times and compute the median-of-means to get an estimate for \\(\\mathbb{E}[f(\\varepsilon)]=\\mathbb{E}[y|\\varepsilon]\\), that is the predicted value of the probe conditional on white noise.\nNext, I propose the following hypothesis test as a minimum viable testing framework to assess if the probe results (may) provide evidence for an actual understanding of key economic relationships learned purely from text:\n\nProposition 1 (Parrot Test) ¬†\n\nH0 (Null): The probe never predicts values that are statistically significantly different from \\(\\mathbb{E}[f(\\varepsilon)]\\).\nH1 (Stochastic Parrots): The probe predicts values that are statistically significantly different from \\(\\mathbb{E}[f(\\varepsilon)]\\) for sentences related to the outcome of interest and those that are independent (i.e.¬†sentences in all categories).\nH2 (More than Mere Stochastic Parrots): The probe predicts values that are statistically significantly different from \\(\\mathbb{E} [f(\\varepsilon)]\\) for sentences that are related to the outcome variable (IP and DP), but not for sentences that are independent of the outcome (IB and DB).\n\n\nTo be clear, if in such a test we did find substantial evidence in favour of rejecting both HO and H1, this would not automatically imply that H2 is true. But to even continue investigating if based on having learned meaningful representation the underlying LLM is more than just a parrot, it should be able to pass this simple test.\nIn this particular case, Figure¬†9 demonstrates that we find some evidence to reject H0 but not H1 for FOMC-RoBERTa. The median linear probe predictions for sentences about inflation and deflation are indeed substantially higher and lower, respectively than for random noise. Unfortunately, the same is true for sentences about the inflation and deflation in the number of birds, albeit to a somewhat lower degree.\nI should note that the number of sentences in each category is very small here (10), so the results in Figure¬†9 cannot be used to establish statistical significance. That being said, even a handful of convincing counter-examples should be enough for us to seriously question the claim that results from linear probes provide evidence against the parrot metaphor. In fact, even a handful of sentences for which any human annotator would easily arrive at the conclusion of independence, a prediction by the probe in either direction casts doubt.\n\n\n\n\n\n\nFigure¬†9: Probe predictions for sentences about inflation of prices (IP), deflation of prices (DP), inflation of birds (IB) and deflation of birds (DB). The vertical axis shows predicted inflation levels subtracted by the average predicted value of the probe for random noise."
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#conclusion",
    "href": "blog/posts/spurious-sparks/index.html#conclusion",
    "title": "Spurious Sparks of AGI",
    "section": "Conclusion",
    "text": "Conclusion\nLinear probes and related tools from mechanistic interpretability were proposed in the context of monitoring models and diagnosing potential problems Alain and Bengio (2016). Favorable outcomes from probes merely indicate that the model ‚Äúhas learned information relevant for the property [of interest]‚Äù Belinkov (2021). The examples shown here demonstrate that this is achievable even for small models, while these have certainly not developed an intrinsic ‚Äúunderstanding‚Äù of the world. Thus, my co-authors and I argue that more conservative and rigorous tests for emerging capabilities of AI model are needed.\nI want to conclude this blog post just as we conclude in our paper:\n\n‚ÄúWe as academic researchers carry great responsibility for how the narrative will unfold, and what claims are believed. We call upon our colleagues to be explicitly mindful of this. As attractive as it may be to beat the state-of-the-art with a grander claim, let us return to the Mertonian norms, and thus safeguard our academic legitimacy in a world that only will be eager to run with made claims.‚Äù\n‚Äî Altmeyer et al. (2024)"
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#acknowledgements",
    "href": "blog/posts/spurious-sparks/index.html#acknowledgements",
    "title": "Spurious Sparks of AGI",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nA huge thank you to my co-authors Andrew M. Demetriou, Antony Bartlett and Cynthia C. S. Liem who are also my colleagues at TU Delft and (in the case of Cynthia) my supervisor. It‚Äôs been a real pleasure working with you on this project."
  },
  {
    "objectID": "blog/posts/spurious-sparks/index.html#footnotes",
    "href": "blog/posts/spurious-sparks/index.html#footnotes",
    "title": "Spurious Sparks of AGI",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI would be very surprised‚Äîconcerned even‚Äîif our search for patterns in latent spaces of capable LLMs revealed nothing at all.‚Ü©Ô∏é\nThe data is taken from the US Department of the Treasury.‚Ü©Ô∏é"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#counterfactual-explanations-1",
    "href": "content/talks/posts/2025-dscn/presentation.html#counterfactual-explanations-1",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\nCounterfactual Search\nObjective:\n\\[\n\\begin{aligned}\n\\min_{x} \\{  {\\text{yloss}(M_{\\theta}(x),\\mathbf{y})} \\}\n\\end{aligned}\n\\]\nSolution:\n\\[\n\\begin{aligned}\n\\nabla_{x} \\{  {\\text{yloss}(M_{\\theta}(x),\\mathbf{y})} \\}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#counterfactual-explanations-2",
    "href": "content/talks/posts/2025-dscn/presentation.html#counterfactual-explanations-2",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\\[\n\\begin{aligned}\n\\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} \\}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "content/talks/posts/2025-dscn/presentation.html#counterfactual-explanations-3",
    "href": "content/talks/posts/2025-dscn/presentation.html#counterfactual-explanations-3",
    "title": "Explaining Models or Modelling Explanations",
    "section": "Counterfactual Explanations",
    "text": "Counterfactual Explanations\n\\[\n\\begin{aligned}\n\\min_{\\mathbf{Z}^\\prime \\in \\mathcal{Z}^L} \\{  {\\text{yloss}(M_{\\theta}(f(\\mathbf{Z}^\\prime)),\\mathbf{y}^+)} + \\lambda {\\text{cost}(f(\\mathbf{Z}^\\prime)) }  \\}\n\\end{aligned}\n\\]\n\n\nCounterfactual Explanations explain how inputs into a model need to change for it to produce different outputs1.\n\n\n\n\n\n\n\nFigure¬†1: Gradient-based counterfactual search.\n\n\n\n\n Altmeyer, Deursen, and Liem (2023) @ JuliaCon 2022"
  }
]